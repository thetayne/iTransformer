elec.sqfs
INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (389) bind mounts
2
INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (389) bind mounts
Args in experiment:
Namespace(is_training=1, model_id='ECL_96_96_1_emb_64', model='xLSTM', data='custom', root_path='./data/electricity/', data_path='/input-data/electricity.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, enc_in=321, dec_in=7, c_out=321, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=50, batch_size=8, patience=10, learning_rate=0.001, des='test', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, use_norm=True, partial_start_index=0, hidden_size=512, num_layers=2, mark_enc_in=4, embedding_dim=64, weight_decay=1e-05, kernal_size=7, num_heads_xlstm=4, qkv_proj_blocksize=8, proj_factor=1.3, num_blocks=2, slstm_at=1, grad_clip_norm=1.0, d_state=16, d_conv=4, expand=2)
Use GPU: cuda:0
{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-L/usr/local/cuda/lib', '-lcublas'], 'extra_cflags': ['-DSLSTM_HIDDEN_SIZE=64', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__'], 'extra_cuda_cflags': ['-Xptxas="-v"', '-gencode', 'arch=compute_80,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=64', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__']}
Using /home/thetayne/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Creating extension directory /home/thetayne/.cache/torch_extensions/py310_cu121/slstm_HS64BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/thetayne/.cache/torch_extensions/py310_cu121/slstm_HS64BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0/build.ninja...
Building extension module slstm_HS64BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[1/8] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output cuda_error.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS64BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=64 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=4 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/util/cuda_error.cu -o cuda_error.cuda.o 
ptxas info    : 0 bytes gmem
[2/8] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output slstm_pointwise.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS64BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=64 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=4 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/cuda/slstm_pointwise.cu -o slstm_pointwise.cuda.o 
ptxas info    : 0 bytes gmem
ptxas info    : Compiling entry function '_ZN5slstm21SLSTMPointwiseForwardILb0EEEviiiPK13__nv_bfloat16S3_PKfS3_jPS1_jS6_S6_' for 'sm_80'
ptxas info    : Function properties for _ZN5slstm21SLSTMPointwiseForwardILb0EEEviiiPK13__nv_bfloat16S3_PKfS3_jPS1_jS6_S6_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 32 registers, 440 bytes cmem[0]
ptxas info    : Compiling entry function '_ZN5slstm21SLSTMPointwiseForwardILb1EEEviiiPK13__nv_bfloat16S3_PKfS3_jPS1_jS6_S6_' for 'sm_80'
ptxas info    : Function properties for _ZN5slstm21SLSTMPointwiseForwardILb1EEEviiiPK13__nv_bfloat16S3_PKfS3_jPS1_jS6_S6_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 32 registers, 440 bytes cmem[0]
ptxas info    : Compiling entry function '_ZN5slstm22SLSTMPointwiseBackwardEiiiPK13__nv_bfloat16jS2_S2_PKfS2_jS2_jPS0_jS5_S5_S5_' for 'sm_80'
ptxas info    : Function properties for _ZN5slstm22SLSTMPointwiseBackwardEiiiPK13__nv_bfloat16jS2_S2_PKfS2_jS2_jPS0_jS5_S5_S5_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 32 registers, 480 bytes cmem[0]
[3/8] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output slstm_forward.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS64BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=64 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=4 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/cuda/slstm_forward.cu -o slstm_forward.cuda.o 
ptxas info    : 0 bytes gmem
[4/8] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output slstm_backward.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS64BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=64 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=4 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/cuda/slstm_backward.cu -o slstm_backward.cuda.o 
ptxas info    : 0 bytes gmem
ptxas info    : Compiling entry function '_ZN50_GLOBAL__N__d983f13f_17_slstm_backward_cu_3639fa5e29gradientBiasAggregationKernelEjjjjjjPK13__nv_bfloat16S2_Pf' for 'sm_80'
ptxas info    : Function properties for _ZN50_GLOBAL__N__d983f13f_17_slstm_backward_cu_3639fa5e29gradientBiasAggregationKernelEjjjjjjPK13__nv_bfloat16S2_Pf
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 32 registers, 400 bytes cmem[0]
[5/8] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output slstm_backward_cut.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS64BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=64 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=4 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/cuda/slstm_backward_cut.cu -o slstm_backward_cut.cuda.o 
ptxas info    : 0 bytes gmem
ptxas info    : Compiling entry function '_ZN54_GLOBAL__N__2085b59d_21_slstm_backward_cut_cu_1c2c4d0129gradientBiasAggregationKernelEjjjjjjPK13__nv_bfloat16S2_Pf' for 'sm_80'
ptxas info    : Function properties for _ZN54_GLOBAL__N__2085b59d_21_slstm_backward_cut_cu_1c2c4d0129gradientBiasAggregationKernelEjjjjjjPK13__nv_bfloat16S2_Pf
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 32 registers, 400 bytes cmem[0]
[6/8] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output blas.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS64BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=64 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=4 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/util/blas.cu -o blas.cuda.o 
ptxas info    : 0 bytes gmem
ptxas info    : Compiling entry function '_Z10initKernelI13__nv_bfloat16EvPT_iS1_' for 'sm_80'
ptxas info    : Function properties for _Z10initKernelI13__nv_bfloat16EvPT_iS1_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 8 registers, 366 bytes cmem[0]
ptxas info    : Compiling entry function '_Z10initKernelI6__halfEvPT_iS1_' for 'sm_80'
ptxas info    : Function properties for _Z10initKernelI6__halfEvPT_iS1_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 8 registers, 366 bytes cmem[0]
ptxas info    : Compiling entry function '_Z10initKernelIfEvPT_iS0_' for 'sm_80'
ptxas info    : Function properties for _Z10initKernelIfEvPT_iS0_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 8 registers, 368 bytes cmem[0]
ptxas info    : Compiling entry function '_Z10initKernelIdEvPT_iS0_' for 'sm_80'
ptxas info    : Function properties for _Z10initKernelIdEvPT_iS0_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 8 registers, 376 bytes cmem[0]
[7/8] c++ -MMD -MF slstm.o.d -DTORCH_EXTENSION_NAME=slstm_HS64BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -DSLSTM_HIDDEN_SIZE=64 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=4 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/cuda/slstm.cc -o slstm.o 
[8/8] c++ slstm.o slstm_forward.cuda.o slstm_backward.cuda.o slstm_backward_cut.cuda.o slstm_pointwise.cuda.o blas.cuda.o cuda_error.cuda.o -shared -L/usr/local/cuda/lib -lcublas -L/usr/local/lib/python3.10/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o slstm_HS64BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0.so
Loading extension module slstm_HS64BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
>>>>>>>start training : ECL_96_96_1_emb_64_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 18221
val 2537
test 5165
	iters: 100, epoch: 1 | loss: 0.3268033
	speed: 0.0816s/iter; left time: 9285.2892s
	iters: 200, epoch: 1 | loss: 0.3009369
	speed: 0.0240s/iter; left time: 2727.0946s
	iters: 300, epoch: 1 | loss: 0.2000327
	speed: 0.0228s/iter; left time: 2584.7635s
	iters: 400, epoch: 1 | loss: 0.1959623
	speed: 0.0238s/iter; left time: 2694.8434s
	iters: 500, epoch: 1 | loss: 0.1855895
	speed: 0.0233s/iter; left time: 2643.0467s
	iters: 600, epoch: 1 | loss: 0.1902108
	speed: 0.0233s/iter; left time: 2639.7429s
	iters: 700, epoch: 1 | loss: 0.1935005
	speed: 0.0236s/iter; left time: 2668.8409s
	iters: 800, epoch: 1 | loss: 0.1681331
	speed: 0.0235s/iter; left time: 2662.1602s
	iters: 900, epoch: 1 | loss: 0.1495594
	speed: 0.0232s/iter; left time: 2623.0489s
	iters: 1000, epoch: 1 | loss: 0.1686396
	speed: 0.0240s/iter; left time: 2704.7846s
	iters: 1100, epoch: 1 | loss: 0.1326552
	speed: 0.0232s/iter; left time: 2611.2957s
	iters: 1200, epoch: 1 | loss: 0.1567537
	speed: 0.0235s/iter; left time: 2649.3224s
	iters: 1300, epoch: 1 | loss: 0.1621752
	speed: 0.0224s/iter; left time: 2521.8586s
	iters: 1400, epoch: 1 | loss: 0.1406579
	speed: 0.0228s/iter; left time: 2567.3354s
	iters: 1500, epoch: 1 | loss: 0.1797020
	speed: 0.0234s/iter; left time: 2629.0272s
	iters: 1600, epoch: 1 | loss: 0.1330084
	speed: 0.0222s/iter; left time: 2493.5900s
	iters: 1700, epoch: 1 | loss: 0.1397488
	speed: 0.0223s/iter; left time: 2505.1263s
	iters: 1800, epoch: 1 | loss: 0.1347913
	speed: 0.0237s/iter; left time: 2656.6165s
	iters: 1900, epoch: 1 | loss: 0.1500977
	speed: 0.0227s/iter; left time: 2541.9325s
	iters: 2000, epoch: 1 | loss: 0.1316200
	speed: 0.0224s/iter; left time: 2509.8335s
	iters: 2100, epoch: 1 | loss: 0.1446190
	speed: 0.0227s/iter; left time: 2537.5449s
	iters: 2200, epoch: 1 | loss: 0.1258690
	speed: 0.0226s/iter; left time: 2527.3785s
Epoch: 1 cost time: 58.447861194610596
Epoch: 1, Steps: 2277 | Train Loss: 0.1804425 Vali Loss: 0.2213177 Test Loss: 0.2768230
Validation loss decreased (inf --> 0.221318).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.1431616
	speed: 0.4520s/iter; left time: 50388.6743s
	iters: 200, epoch: 2 | loss: 0.1286539
	speed: 0.0174s/iter; left time: 1935.6221s
	iters: 300, epoch: 2 | loss: 0.1403065
	speed: 0.0181s/iter; left time: 2014.0840s
	iters: 400, epoch: 2 | loss: 0.1193572
	speed: 0.0176s/iter; left time: 1957.8965s
	iters: 500, epoch: 2 | loss: 0.1205938
	speed: 0.0186s/iter; left time: 2066.2522s
	iters: 600, epoch: 2 | loss: 0.1467989
	speed: 0.0213s/iter; left time: 2364.6470s
	iters: 700, epoch: 2 | loss: 0.1252798
	speed: 0.0216s/iter; left time: 2395.3889s
	iters: 800, epoch: 2 | loss: 0.1401369
	speed: 0.0213s/iter; left time: 2364.4980s
	iters: 900, epoch: 2 | loss: 0.1481857
	speed: 0.0219s/iter; left time: 2420.4164s
	iters: 1000, epoch: 2 | loss: 0.1163682
	speed: 0.0219s/iter; left time: 2416.7484s
	iters: 1100, epoch: 2 | loss: 0.1315958
	speed: 0.0217s/iter; left time: 2392.0966s
	iters: 1200, epoch: 2 | loss: 0.1379241
	speed: 0.0220s/iter; left time: 2433.6821s
	iters: 1300, epoch: 2 | loss: 0.1354194
	speed: 0.0218s/iter; left time: 2401.1851s
	iters: 1400, epoch: 2 | loss: 0.1190104
	speed: 0.0211s/iter; left time: 2324.0682s
	iters: 1500, epoch: 2 | loss: 0.1251965
	speed: 0.0210s/iter; left time: 2306.7090s
	iters: 1600, epoch: 2 | loss: 0.1230998
	speed: 0.0206s/iter; left time: 2263.4808s
	iters: 1700, epoch: 2 | loss: 0.1210059
	speed: 0.0204s/iter; left time: 2240.5420s
	iters: 1800, epoch: 2 | loss: 0.1381470
	speed: 0.0199s/iter; left time: 2189.9671s
	iters: 1900, epoch: 2 | loss: 0.1212117
	speed: 0.0203s/iter; left time: 2223.3197s
	iters: 2000, epoch: 2 | loss: 0.1397197
	speed: 0.0198s/iter; left time: 2171.2732s
	iters: 2100, epoch: 2 | loss: 0.1212883
	speed: 0.0202s/iter; left time: 2213.0611s
	iters: 2200, epoch: 2 | loss: 0.1400763
	speed: 0.0195s/iter; left time: 2134.1211s
Epoch: 2 cost time: 47.68836760520935
Epoch: 2, Steps: 2277 | Train Loss: 0.1285811 Vali Loss: 0.2469191 Test Loss: 0.2873874
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.1364606
	speed: 0.4486s/iter; left time: 48986.0941s
	iters: 200, epoch: 3 | loss: 0.1227626
	speed: 0.0167s/iter; left time: 1820.2150s
	iters: 300, epoch: 3 | loss: 0.1211939
	speed: 0.0175s/iter; left time: 1909.6657s
	iters: 400, epoch: 3 | loss: 0.1320692
	speed: 0.0189s/iter; left time: 2062.0632s
	iters: 500, epoch: 3 | loss: 0.1196986
	speed: 0.0212s/iter; left time: 2311.8281s
	iters: 600, epoch: 3 | loss: 0.1241783
	speed: 0.0212s/iter; left time: 2301.3900s
	iters: 700, epoch: 3 | loss: 0.1050108
	speed: 0.0208s/iter; left time: 2262.3667s
	iters: 800, epoch: 3 | loss: 0.1162436
	speed: 0.0202s/iter; left time: 2188.4075s
	iters: 900, epoch: 3 | loss: 0.1087065
	speed: 0.0200s/iter; left time: 2166.5592s
	iters: 1000, epoch: 3 | loss: 0.1193106
	speed: 0.0198s/iter; left time: 2140.0425s
	iters: 1100, epoch: 3 | loss: 0.1150178
	speed: 0.0198s/iter; left time: 2145.5086s
	iters: 1200, epoch: 3 | loss: 0.1256715
	speed: 0.0202s/iter; left time: 2187.6884s
	iters: 1300, epoch: 3 | loss: 0.1167621
	speed: 0.0206s/iter; left time: 2221.3726s
	iters: 1400, epoch: 3 | loss: 0.1199224
	speed: 0.0210s/iter; left time: 2264.8203s
	iters: 1500, epoch: 3 | loss: 0.1198248
	speed: 0.0215s/iter; left time: 2321.5843s
	iters: 1600, epoch: 3 | loss: 0.1210535
	speed: 0.0206s/iter; left time: 2213.1809s
	iters: 1700, epoch: 3 | loss: 0.1117554
	speed: 0.0208s/iter; left time: 2241.3409s
	iters: 1800, epoch: 3 | loss: 0.1167156
	speed: 0.0207s/iter; left time: 2222.5337s
	iters: 1900, epoch: 3 | loss: 0.1137474
	speed: 0.0203s/iter; left time: 2183.1961s
	iters: 2000, epoch: 3 | loss: 0.1270558
	speed: 0.0208s/iter; left time: 2234.9545s
	iters: 2100, epoch: 3 | loss: 0.1206986
	speed: 0.0206s/iter; left time: 2205.0793s
	iters: 2200, epoch: 3 | loss: 0.1254310
	speed: 0.0206s/iter; left time: 2202.2302s
Epoch: 3 cost time: 47.439555168151855
Epoch: 3, Steps: 2277 | Train Loss: 0.1195782 Vali Loss: 0.2724270 Test Loss: 0.2922278
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.1100886
	speed: 0.4523s/iter; left time: 48360.9525s
	iters: 200, epoch: 4 | loss: 0.1082263
	speed: 0.0170s/iter; left time: 1815.7368s
	iters: 300, epoch: 4 | loss: 0.1237609
	speed: 0.0181s/iter; left time: 1934.8521s
	iters: 400, epoch: 4 | loss: 0.1131386
	speed: 0.0213s/iter; left time: 2271.9540s
	iters: 500, epoch: 4 | loss: 0.1242907
	speed: 0.0220s/iter; left time: 2344.3889s
	iters: 600, epoch: 4 | loss: 0.1158472
	speed: 0.0218s/iter; left time: 2318.2231s
	iters: 700, epoch: 4 | loss: 0.1075167
	speed: 0.0210s/iter; left time: 2235.3952s
	iters: 800, epoch: 4 | loss: 0.1189499
	speed: 0.0211s/iter; left time: 2244.0686s
	iters: 900, epoch: 4 | loss: 0.1131664
	speed: 0.0215s/iter; left time: 2276.3344s
	iters: 1000, epoch: 4 | loss: 0.1134819
	speed: 0.0214s/iter; left time: 2268.9310s
	iters: 1100, epoch: 4 | loss: 0.1246983
	speed: 0.0225s/iter; left time: 2380.3451s
	iters: 1200, epoch: 4 | loss: 0.1204206
	speed: 0.0211s/iter; left time: 2233.2076s
	iters: 1300, epoch: 4 | loss: 0.1238075
	speed: 0.0213s/iter; left time: 2247.6454s
	iters: 1400, epoch: 4 | loss: 0.1065179
	speed: 0.0207s/iter; left time: 2190.6226s
	iters: 1500, epoch: 4 | loss: 0.1235350
	speed: 0.0211s/iter; left time: 2224.5944s
	iters: 1600, epoch: 4 | loss: 0.1108274
	speed: 0.0214s/iter; left time: 2251.9619s
	iters: 1700, epoch: 4 | loss: 0.1247824
	speed: 0.0216s/iter; left time: 2270.6865s
	iters: 1800, epoch: 4 | loss: 0.1163793
	speed: 0.0218s/iter; left time: 2291.4781s
	iters: 1900, epoch: 4 | loss: 0.1156876
	speed: 0.0217s/iter; left time: 2285.7830s
	iters: 2000, epoch: 4 | loss: 0.1129338
	speed: 0.0214s/iter; left time: 2248.7932s
	iters: 2100, epoch: 4 | loss: 0.1274205
	speed: 0.0215s/iter; left time: 2259.1211s
	iters: 2200, epoch: 4 | loss: 0.1112306
	speed: 0.0219s/iter; left time: 2298.6904s
Epoch: 4 cost time: 49.39626622200012
Epoch: 4, Steps: 2277 | Train Loss: 0.1162682 Vali Loss: 0.2967986 Test Loss: 0.3061604
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.1048476
	speed: 0.4593s/iter; left time: 48066.8292s
	iters: 200, epoch: 5 | loss: 0.1268253
	speed: 0.0173s/iter; left time: 1805.1306s
	iters: 300, epoch: 5 | loss: 0.1083644
	speed: 0.0167s/iter; left time: 1748.7314s
	iters: 400, epoch: 5 | loss: 0.1120258
	speed: 0.0172s/iter; left time: 1794.1653s
	iters: 500, epoch: 5 | loss: 0.1039154
	speed: 0.0208s/iter; left time: 2167.7749s
	iters: 600, epoch: 5 | loss: 0.1188999
	speed: 0.0204s/iter; left time: 2120.9231s
	iters: 700, epoch: 5 | loss: 0.1199956
	speed: 0.0215s/iter; left time: 2240.8452s
	iters: 800, epoch: 5 | loss: 0.1161837
	speed: 0.0212s/iter; left time: 2207.2996s
	iters: 900, epoch: 5 | loss: 0.1085176
	speed: 0.0218s/iter; left time: 2263.0169s
	iters: 1000, epoch: 5 | loss: 0.1181438
	speed: 0.0209s/iter; left time: 2167.1143s
	iters: 1100, epoch: 5 | loss: 0.1031445
	speed: 0.0214s/iter; left time: 2218.1283s
	iters: 1200, epoch: 5 | loss: 0.1176310
	speed: 0.0212s/iter; left time: 2194.3010s
	iters: 1300, epoch: 5 | loss: 0.1083836
	speed: 0.0209s/iter; left time: 2158.9853s
	iters: 1400, epoch: 5 | loss: 0.1070300
	speed: 0.0214s/iter; left time: 2212.5855s
	iters: 1500, epoch: 5 | loss: 0.1172049
	speed: 0.0206s/iter; left time: 2128.9997s
	iters: 1600, epoch: 5 | loss: 0.1160296
	speed: 0.0216s/iter; left time: 2227.9108s
	iters: 1700, epoch: 5 | loss: 0.1072013
	speed: 0.0218s/iter; left time: 2247.7604s
	iters: 1800, epoch: 5 | loss: 0.1021739
	speed: 0.0225s/iter; left time: 2318.6341s
	iters: 1900, epoch: 5 | loss: 0.1171900
	speed: 0.0231s/iter; left time: 2376.2325s
	iters: 2000, epoch: 5 | loss: 0.1165838
	speed: 0.0235s/iter; left time: 2416.0600s
	iters: 2100, epoch: 5 | loss: 0.1213767
	speed: 0.0243s/iter; left time: 2492.9277s
	iters: 2200, epoch: 5 | loss: 0.1039820
	speed: 0.0235s/iter; left time: 2414.4092s
Epoch: 5 cost time: 49.56724524497986
Epoch: 5, Steps: 2277 | Train Loss: 0.1145948 Vali Loss: 0.2987495 Test Loss: 0.3064672
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.1357628
	speed: 0.4605s/iter; left time: 47137.9993s
	iters: 200, epoch: 6 | loss: 0.1198284
	speed: 0.0171s/iter; left time: 1747.9847s
	iters: 300, epoch: 6 | loss: 0.1086584
	speed: 0.0201s/iter; left time: 2053.9875s
	iters: 400, epoch: 6 | loss: 0.1023739
	speed: 0.0228s/iter; left time: 2326.3662s
	iters: 500, epoch: 6 | loss: 0.1100790
	speed: 0.0237s/iter; left time: 2412.4411s
	iters: 600, epoch: 6 | loss: 0.1053889
	speed: 0.0233s/iter; left time: 2378.1974s
	iters: 700, epoch: 6 | loss: 0.1153372
	speed: 0.0201s/iter; left time: 2041.7298s
	iters: 800, epoch: 6 | loss: 0.1170493
	speed: 0.0217s/iter; left time: 2208.0839s
	iters: 900, epoch: 6 | loss: 0.1232274
	speed: 0.0235s/iter; left time: 2386.1432s
	iters: 1000, epoch: 6 | loss: 0.1084858
	speed: 0.0237s/iter; left time: 2399.9080s
	iters: 1100, epoch: 6 | loss: 0.1072115
	speed: 0.0238s/iter; left time: 2408.5402s
	iters: 1200, epoch: 6 | loss: 0.1217932
	speed: 0.0238s/iter; left time: 2414.9821s
	iters: 1300, epoch: 6 | loss: 0.1205443
	speed: 0.0232s/iter; left time: 2351.2528s
	iters: 1400, epoch: 6 | loss: 0.1140766
	speed: 0.0230s/iter; left time: 2319.8660s
	iters: 1500, epoch: 6 | loss: 0.1090079
	speed: 0.0239s/iter; left time: 2409.5405s
	iters: 1600, epoch: 6 | loss: 0.1198958
	speed: 0.0235s/iter; left time: 2374.6654s
	iters: 1700, epoch: 6 | loss: 0.1216296
	speed: 0.0237s/iter; left time: 2384.1252s
	iters: 1800, epoch: 6 | loss: 0.1235954
	speed: 0.0229s/iter; left time: 2309.8571s
	iters: 1900, epoch: 6 | loss: 0.1044905
	speed: 0.0234s/iter; left time: 2354.1056s
	iters: 2000, epoch: 6 | loss: 0.1065304
	speed: 0.0231s/iter; left time: 2320.0706s
	iters: 2100, epoch: 6 | loss: 0.1283028
	speed: 0.0238s/iter; left time: 2386.7114s
	iters: 2200, epoch: 6 | loss: 0.1055984
	speed: 0.0232s/iter; left time: 2322.0453s
Epoch: 6 cost time: 52.92606544494629
Epoch: 6, Steps: 2277 | Train Loss: 0.1137795 Vali Loss: 0.3063410 Test Loss: 0.3114626
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.1168865
	speed: 0.4617s/iter; left time: 46208.3175s
	iters: 200, epoch: 7 | loss: 0.1353101
	speed: 0.0170s/iter; left time: 1697.0272s
	iters: 300, epoch: 7 | loss: 0.1097273
	speed: 0.0171s/iter; left time: 1710.3337s
	iters: 400, epoch: 7 | loss: 0.1098204
	speed: 0.0177s/iter; left time: 1761.8698s
	iters: 500, epoch: 7 | loss: 0.1193094
	speed: 0.0228s/iter; left time: 2271.1627s
	iters: 600, epoch: 7 | loss: 0.1078402
	speed: 0.0232s/iter; left time: 2307.0375s
	iters: 700, epoch: 7 | loss: 0.1125549
	speed: 0.0228s/iter; left time: 2268.0216s
	iters: 800, epoch: 7 | loss: 0.1060637
	speed: 0.0221s/iter; left time: 2199.4286s
	iters: 900, epoch: 7 | loss: 0.1165700
	speed: 0.0235s/iter; left time: 2331.6400s
	iters: 1000, epoch: 7 | loss: 0.1086252
	speed: 0.0228s/iter; left time: 2264.9086s
	iters: 1100, epoch: 7 | loss: 0.0996448
	speed: 0.0225s/iter; left time: 2228.6827s
	iters: 1200, epoch: 7 | loss: 0.1181192
	speed: 0.0228s/iter; left time: 2257.3660s
	iters: 1300, epoch: 7 | loss: 0.1161884
	speed: 0.0233s/iter; left time: 2299.9596s
	iters: 1400, epoch: 7 | loss: 0.1187797
	speed: 0.0228s/iter; left time: 2248.4881s
	iters: 1500, epoch: 7 | loss: 0.1136381
	speed: 0.0231s/iter; left time: 2280.6683s
	iters: 1600, epoch: 7 | loss: 0.1157878
	speed: 0.0233s/iter; left time: 2300.3314s
	iters: 1700, epoch: 7 | loss: 0.1111950
	speed: 0.0232s/iter; left time: 2286.9170s
	iters: 1800, epoch: 7 | loss: 0.1093666
	speed: 0.0230s/iter; left time: 2258.7921s
	iters: 1900, epoch: 7 | loss: 0.1188327
	speed: 0.0227s/iter; left time: 2229.5199s
	iters: 2000, epoch: 7 | loss: 0.1014312
	speed: 0.0230s/iter; left time: 2262.1701s
	iters: 2100, epoch: 7 | loss: 0.1287294
	speed: 0.0226s/iter; left time: 2215.0326s
	iters: 2200, epoch: 7 | loss: 0.1293303
	speed: 0.0231s/iter; left time: 2265.3938s
Epoch: 7 cost time: 51.4691207408905
Epoch: 7, Steps: 2277 | Train Loss: 0.1133592 Vali Loss: 0.3074127 Test Loss: 0.3122062
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.1023099
	speed: 0.4616s/iter; left time: 45146.6222s
	iters: 200, epoch: 8 | loss: 0.1306459
	speed: 0.0173s/iter; left time: 1686.2765s
	iters: 300, epoch: 8 | loss: 0.1224324
	speed: 0.0166s/iter; left time: 1621.2155s
	iters: 400, epoch: 8 | loss: 0.1140593
	speed: 0.0210s/iter; left time: 2052.4772s
	iters: 500, epoch: 8 | loss: 0.1115578
	speed: 0.0229s/iter; left time: 2226.4454s
	iters: 600, epoch: 8 | loss: 0.1246682
	speed: 0.0233s/iter; left time: 2268.1653s
	iters: 700, epoch: 8 | loss: 0.1094835
	speed: 0.0229s/iter; left time: 2224.2329s
	iters: 800, epoch: 8 | loss: 0.1044737
	speed: 0.0228s/iter; left time: 2209.3689s
	iters: 900, epoch: 8 | loss: 0.1041640
	speed: 0.0237s/iter; left time: 2300.4233s
	iters: 1000, epoch: 8 | loss: 0.1132732
	speed: 0.0234s/iter; left time: 2263.3294s
	iters: 1100, epoch: 8 | loss: 0.1107088
	speed: 0.0226s/iter; left time: 2187.6504s
	iters: 1200, epoch: 8 | loss: 0.1176967
	speed: 0.0231s/iter; left time: 2229.3193s
	iters: 1300, epoch: 8 | loss: 0.1170583
	speed: 0.0230s/iter; left time: 2221.9728s
	iters: 1400, epoch: 8 | loss: 0.1138297
	speed: 0.0229s/iter; left time: 2213.3710s
	iters: 1500, epoch: 8 | loss: 0.1084239
	speed: 0.0227s/iter; left time: 2190.9689s
	iters: 1600, epoch: 8 | loss: 0.1108170
	speed: 0.0231s/iter; left time: 2227.5606s
	iters: 1700, epoch: 8 | loss: 0.1070789
	speed: 0.0233s/iter; left time: 2239.5209s
	iters: 1800, epoch: 8 | loss: 0.1060679
	speed: 0.0234s/iter; left time: 2245.9084s
	iters: 1900, epoch: 8 | loss: 0.1058791
	speed: 0.0230s/iter; left time: 2204.0498s
	iters: 2000, epoch: 8 | loss: 0.1225237
	speed: 0.0227s/iter; left time: 2172.4782s
	iters: 2100, epoch: 8 | loss: 0.1286517
	speed: 0.0238s/iter; left time: 2278.0300s
	iters: 2200, epoch: 8 | loss: 0.1131670
	speed: 0.0231s/iter; left time: 2213.0684s
Epoch: 8 cost time: 52.38998460769653
Epoch: 8, Steps: 2277 | Train Loss: 0.1131447 Vali Loss: 0.3080928 Test Loss: 0.3127879
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 0.1116261
	speed: 0.4552s/iter; left time: 43486.4143s
	iters: 200, epoch: 9 | loss: 0.1097888
	speed: 0.0165s/iter; left time: 1577.8310s
	iters: 300, epoch: 9 | loss: 0.1048777
	speed: 0.0169s/iter; left time: 1609.5087s
	iters: 400, epoch: 9 | loss: 0.1243291
	speed: 0.0184s/iter; left time: 1754.3322s
	iters: 500, epoch: 9 | loss: 0.1378630
	speed: 0.0225s/iter; left time: 2141.7140s
	iters: 600, epoch: 9 | loss: 0.1103534
	speed: 0.0225s/iter; left time: 2133.9392s
	iters: 700, epoch: 9 | loss: 0.1079977
	speed: 0.0228s/iter; left time: 2162.9318s
	iters: 800, epoch: 9 | loss: 0.1089963
	speed: 0.0225s/iter; left time: 2130.8656s
	iters: 900, epoch: 9 | loss: 0.1020249
	speed: 0.0218s/iter; left time: 2068.0798s
	iters: 1000, epoch: 9 | loss: 0.1074458
	speed: 0.0225s/iter; left time: 2128.4173s
	iters: 1100, epoch: 9 | loss: 0.1153706
	speed: 0.0231s/iter; left time: 2183.5860s
	iters: 1200, epoch: 9 | loss: 0.1042846
	speed: 0.0225s/iter; left time: 2122.0940s
	iters: 1300, epoch: 9 | loss: 0.1140544
	speed: 0.0228s/iter; left time: 2146.6128s
	iters: 1400, epoch: 9 | loss: 0.1036773
	speed: 0.0232s/iter; left time: 2186.9821s
	iters: 1500, epoch: 9 | loss: 0.1234135
	speed: 0.0228s/iter; left time: 2143.0809s
	iters: 1600, epoch: 9 | loss: 0.1088129
	speed: 0.0218s/iter; left time: 2052.5678s
	iters: 1700, epoch: 9 | loss: 0.1195247
	speed: 0.0228s/iter; left time: 2140.4889s
	iters: 1800, epoch: 9 | loss: 0.1174646
	speed: 0.0196s/iter; left time: 1840.6307s
	iters: 1900, epoch: 9 | loss: 0.1075913
	speed: 0.0193s/iter; left time: 1808.4417s
	iters: 2000, epoch: 9 | loss: 0.1123750
	speed: 0.0191s/iter; left time: 1785.9747s
	iters: 2100, epoch: 9 | loss: 0.1127550
	speed: 0.0194s/iter; left time: 1810.7188s
	iters: 2200, epoch: 9 | loss: 0.1035438
	speed: 0.0227s/iter; left time: 2119.8943s
Epoch: 9 cost time: 49.67017340660095
Epoch: 9, Steps: 2277 | Train Loss: 0.1130383 Vali Loss: 0.3067847 Test Loss: 0.3119444
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 0.1032087
	speed: 0.4600s/iter; left time: 42894.7805s
	iters: 200, epoch: 10 | loss: 0.1260810
	speed: 0.0171s/iter; left time: 1590.2762s
	iters: 300, epoch: 10 | loss: 0.1204831
	speed: 0.0201s/iter; left time: 1868.5253s
	iters: 400, epoch: 10 | loss: 0.1076457
	speed: 0.0230s/iter; left time: 2139.5107s
	iters: 500, epoch: 10 | loss: 0.1259713
	speed: 0.0224s/iter; left time: 2077.1916s
	iters: 600, epoch: 10 | loss: 0.1093265
	speed: 0.0233s/iter; left time: 2161.8237s
	iters: 700, epoch: 10 | loss: 0.1116356
	speed: 0.0231s/iter; left time: 2136.8775s
	iters: 800, epoch: 10 | loss: 0.1051347
	speed: 0.0233s/iter; left time: 2157.8797s
	iters: 900, epoch: 10 | loss: 0.1141211
	speed: 0.0237s/iter; left time: 2190.7592s
	iters: 1000, epoch: 10 | loss: 0.1146958
	speed: 0.0230s/iter; left time: 2125.7608s
	iters: 1100, epoch: 10 | loss: 0.1135822
	speed: 0.0235s/iter; left time: 2166.8806s
	iters: 1200, epoch: 10 | loss: 0.1263876
	speed: 0.0225s/iter; left time: 2074.9522s
	iters: 1300, epoch: 10 | loss: 0.1075884
	speed: 0.0233s/iter; left time: 2142.9240s
	iters: 1400, epoch: 10 | loss: 0.1018147
	speed: 0.0236s/iter; left time: 2165.6486s
	iters: 1500, epoch: 10 | loss: 0.1182357
	speed: 0.0232s/iter; left time: 2126.7202s
	iters: 1600, epoch: 10 | loss: 0.1111061
	speed: 0.0233s/iter; left time: 2133.7511s
	iters: 1700, epoch: 10 | loss: 0.1130309
	speed: 0.0226s/iter; left time: 2073.0733s
	iters: 1800, epoch: 10 | loss: 0.1321112
	speed: 0.0220s/iter; left time: 2010.3175s
	iters: 1900, epoch: 10 | loss: 0.1118016
	speed: 0.0228s/iter; left time: 2085.0612s
	iters: 2000, epoch: 10 | loss: 0.1100637
	speed: 0.0219s/iter; left time: 2002.8724s
	iters: 2100, epoch: 10 | loss: 0.1110482
	speed: 0.0229s/iter; left time: 2087.7786s
	iters: 2200, epoch: 10 | loss: 0.1232332
	speed: 0.0223s/iter; left time: 2031.5816s
Epoch: 10 cost time: 52.23219919204712
Epoch: 10, Steps: 2277 | Train Loss: 0.1129855 Vali Loss: 0.3063687 Test Loss: 0.3120684
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 0.1273931
	speed: 0.4554s/iter; left time: 41432.7233s
	iters: 200, epoch: 11 | loss: 0.1171663
	speed: 0.0167s/iter; left time: 1516.5345s
	iters: 300, epoch: 11 | loss: 0.1040257
	speed: 0.0173s/iter; left time: 1571.9656s
	iters: 400, epoch: 11 | loss: 0.1106908
	speed: 0.0174s/iter; left time: 1574.3896s
	iters: 500, epoch: 11 | loss: 0.1101956
	speed: 0.0179s/iter; left time: 1625.5509s
	iters: 600, epoch: 11 | loss: 0.1109877
	speed: 0.0177s/iter; left time: 1603.6830s
	iters: 700, epoch: 11 | loss: 0.1099172
	speed: 0.0201s/iter; left time: 1818.6386s
	iters: 800, epoch: 11 | loss: 0.1185373
	speed: 0.0220s/iter; left time: 1983.3608s
	iters: 900, epoch: 11 | loss: 0.1023411
	speed: 0.0224s/iter; left time: 2022.5640s
	iters: 1000, epoch: 11 | loss: 0.1014065
	speed: 0.0223s/iter; left time: 2006.8440s
	iters: 1100, epoch: 11 | loss: 0.1121982
	speed: 0.0225s/iter; left time: 2022.8839s
	iters: 1200, epoch: 11 | loss: 0.1116854
	speed: 0.0220s/iter; left time: 1980.4777s
	iters: 1300, epoch: 11 | loss: 0.1267474
	speed: 0.0228s/iter; left time: 2045.0118s
	iters: 1400, epoch: 11 | loss: 0.1072931
	speed: 0.0224s/iter; left time: 2008.1922s
	iters: 1500, epoch: 11 | loss: 0.1029342
	speed: 0.0221s/iter; left time: 1984.0085s
	iters: 1600, epoch: 11 | loss: 0.1050451
	speed: 0.0231s/iter; left time: 2066.8254s
	iters: 1700, epoch: 11 | loss: 0.1111034
	speed: 0.0228s/iter; left time: 2036.4362s
	iters: 1800, epoch: 11 | loss: 0.1157129
	speed: 0.0223s/iter; left time: 1990.2322s
	iters: 1900, epoch: 11 | loss: 0.1161296
	speed: 0.0228s/iter; left time: 2032.1869s
	iters: 2000, epoch: 11 | loss: 0.1005941
	speed: 0.0228s/iter; left time: 2034.6100s
	iters: 2100, epoch: 11 | loss: 0.1107566
	speed: 0.0232s/iter; left time: 2065.7154s
	iters: 2200, epoch: 11 | loss: 0.1084308
	speed: 0.0222s/iter; left time: 1974.4047s
Epoch: 11 cost time: 49.381343603134155
Epoch: 11, Steps: 2277 | Train Loss: 0.1129344 Vali Loss: 0.3065411 Test Loss: 0.3120258
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : ECL_96_96_1_emb_64_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (5165, 1, 96, 321) (5165, 1, 96, 321)
test shape: (5165, 96, 321) (5165, 96, 321)
mse:0.2768232226371765, mae:0.3724706768989563
Args in experiment:
Namespace(is_training=1, model_id='ECL_96_96_2_emb_64', model='xLSTM', data='custom', root_path='./data/electricity/', data_path='/input-data/electricity.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, enc_in=321, dec_in=7, c_out=321, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.3, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=10, batch_size=32, patience=10, learning_rate=0.001, des='test', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, use_norm=True, partial_start_index=0, hidden_size=512, num_layers=2, mark_enc_in=4, embedding_dim=64, weight_decay=1e-06, kernal_size=5, num_heads_xlstm=2, qkv_proj_blocksize=4, proj_factor=1.3, num_blocks=3, slstm_at=1, grad_clip_norm=0.5, d_state=16, d_conv=4, expand=2)
Use GPU: cuda:0
{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-L/usr/local/cuda/lib', '-lcublas'], 'extra_cflags': ['-DSLSTM_HIDDEN_SIZE=64', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=2', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__'], 'extra_cuda_cflags': ['-Xptxas="-v"', '-gencode', 'arch=compute_80,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=64', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=2', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__']}
Using /home/thetayne/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/thetayne/.cache/torch_extensions/py310_cu121/slstm_HS64BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0/build.ninja...
Building extension module slstm_HS64BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[1/7] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output cuda_error.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS64BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=64 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=2 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/util/cuda_error.cu -o cuda_error.cuda.o 
ptxas info    : 0 bytes gmem
[2/7] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output slstm_pointwise.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS64BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=64 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=2 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/cuda/slstm_pointwise.cu -o slstm_pointwise.cuda.o 
ptxas info    : 0 bytes gmem
ptxas info    : Compiling entry function '_ZN5slstm21SLSTMPointwiseForwardILb0EEEviiiPK13__nv_bfloat16S3_PKfS3_jPS1_jS6_S6_' for 'sm_80'
ptxas info    : Function properties for _ZN5slstm21SLSTMPointwiseForwardILb0EEEviiiPK13__nv_bfloat16S3_PKfS3_jPS1_jS6_S6_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 32 registers, 440 bytes cmem[0]
ptxas info    : Compiling entry function '_ZN5slstm21SLSTMPointwiseForwardILb1EEEviiiPK13__nv_bfloat16S3_PKfS3_jPS1_jS6_S6_' for 'sm_80'
ptxas info    : Function properties for _ZN5slstm21SLSTMPointwiseForwardILb1EEEviiiPK13__nv_bfloat16S3_PKfS3_jPS1_jS6_S6_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 32 registers, 440 bytes cmem[0]
ptxas info    : Compiling entry function '_ZN5slstm22SLSTMPointwiseBackwardEiiiPK13__nv_bfloat16jS2_S2_PKfS2_jS2_jPS0_jS5_S5_S5_' for 'sm_80'
ptxas info    : Function properties for _ZN5slstm22SLSTMPointwiseBackwardEiiiPK13__nv_bfloat16jS2_S2_PKfS2_jS2_jPS0_jS5_S5_S5_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 32 registers, 480 bytes cmem[0]
[3/7] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output slstm_forward.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS64BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=64 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=2 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/cuda/slstm_forward.cu -o slstm_forward.cuda.o 
ptxas info    : 0 bytes gmem
[4/7] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output slstm_backward.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS64BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=64 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=2 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/cuda/slstm_backward.cu -o slstm_backward.cuda.o 
ptxas info    : 0 bytes gmem
ptxas info    : Compiling entry function '_ZN50_GLOBAL__N__d983f13f_17_slstm_backward_cu_3639fa5e29gradientBiasAggregationKernelEjjjjjjPK13__nv_bfloat16S2_Pf' for 'sm_80'
ptxas info    : Function properties for _ZN50_GLOBAL__N__d983f13f_17_slstm_backward_cu_3639fa5e29gradientBiasAggregationKernelEjjjjjjPK13__nv_bfloat16S2_Pf
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 32 registers, 400 bytes cmem[0]
[5/7] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output slstm_backward_cut.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS64BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=64 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=2 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/cuda/slstm_backward_cut.cu -o slstm_backward_cut.cuda.o 
ptxas info    : 0 bytes gmem
ptxas info    : Compiling entry function '_ZN54_GLOBAL__N__2085b59d_21_slstm_backward_cut_cu_1c2c4d0129gradientBiasAggregationKernelEjjjjjjPK13__nv_bfloat16S2_Pf' for 'sm_80'
ptxas info    : Function properties for _ZN54_GLOBAL__N__2085b59d_21_slstm_backward_cut_cu_1c2c4d0129gradientBiasAggregationKernelEjjjjjjPK13__nv_bfloat16S2_Pf
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 32 registers, 400 bytes cmem[0]
[6/7] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output blas.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS64BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=64 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=2 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/util/blas.cu -o blas.cuda.o 
ptxas info    : 0 bytes gmem
ptxas info    : Compiling entry function '_Z10initKernelI13__nv_bfloat16EvPT_iS1_' for 'sm_80'
ptxas info    : Function properties for _Z10initKernelI13__nv_bfloat16EvPT_iS1_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 8 registers, 366 bytes cmem[0]
ptxas info    : Compiling entry function '_Z10initKernelI6__halfEvPT_iS1_' for 'sm_80'
ptxas info    : Function properties for _Z10initKernelI6__halfEvPT_iS1_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 8 registers, 366 bytes cmem[0]
ptxas info    : Compiling entry function '_Z10initKernelIfEvPT_iS0_' for 'sm_80'
ptxas info    : Function properties for _Z10initKernelIfEvPT_iS0_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 8 registers, 368 bytes cmem[0]
ptxas info    : Compiling entry function '_Z10initKernelIdEvPT_iS0_' for 'sm_80'
ptxas info    : Function properties for _Z10initKernelIdEvPT_iS0_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 8 registers, 376 bytes cmem[0]
[7/7] c++ slstm.o slstm_forward.cuda.o slstm_backward.cuda.o slstm_backward_cut.cuda.o slstm_pointwise.cuda.o blas.cuda.o cuda_error.cuda.o -shared -L/usr/local/cuda/lib -lcublas -L/usr/local/lib/python3.10/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o slstm_HS64BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0.so
Loading extension module slstm_HS64BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
>>>>>>>start training : ECL_96_96_2_emb_64_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 18221
val 2537
test 5165
	iters: 100, epoch: 1 | loss: 0.3471734
	speed: 0.0608s/iter; left time: 340.2037s
	iters: 200, epoch: 1 | loss: 0.2538527
	speed: 0.0469s/iter; left time: 257.4524s
	iters: 300, epoch: 1 | loss: 0.2323011
	speed: 0.0461s/iter; left time: 248.7589s
	iters: 400, epoch: 1 | loss: 0.2107502
	speed: 0.0451s/iter; left time: 238.6995s
	iters: 500, epoch: 1 | loss: 0.1816528
	speed: 0.0459s/iter; left time: 238.0542s
Epoch: 1 cost time: 27.27917766571045
Epoch: 1, Steps: 569 | Train Loss: 0.2865663 Vali Loss: 0.2272315 Test Loss: 0.3028010
Validation loss decreased (inf --> 0.227231).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.1944293
	speed: 0.6063s/iter; left time: 3044.6770s
	iters: 200, epoch: 2 | loss: 0.1921711
	speed: 0.0370s/iter; left time: 182.0737s
	iters: 300, epoch: 2 | loss: 0.1764444
	speed: 0.0427s/iter; left time: 206.0628s
	iters: 400, epoch: 2 | loss: 0.1786630
	speed: 0.0434s/iter; left time: 205.1377s
	iters: 500, epoch: 2 | loss: 0.1698485
	speed: 0.0428s/iter; left time: 198.0401s
Epoch: 2 cost time: 24.468303203582764
Epoch: 2, Steps: 569 | Train Loss: 0.1816912 Vali Loss: 0.2283014 Test Loss: 0.2998375
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.1637240
	speed: 0.5715s/iter; left time: 2544.8159s
	iters: 200, epoch: 3 | loss: 0.1767327
	speed: 0.0373s/iter; left time: 162.5753s
	iters: 300, epoch: 3 | loss: 0.1746668
	speed: 0.0433s/iter; left time: 184.0797s
	iters: 400, epoch: 3 | loss: 0.1698144
	speed: 0.0436s/iter; left time: 181.2609s
	iters: 500, epoch: 3 | loss: 0.1670812
	speed: 0.0448s/iter; left time: 181.5650s
Epoch: 3 cost time: 25.069361925125122
Epoch: 3, Steps: 569 | Train Loss: 0.1727450 Vali Loss: 0.2259663 Test Loss: 0.3045025
Validation loss decreased (0.227231 --> 0.225966).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.1677539
	speed: 0.5962s/iter; left time: 2315.7983s
	iters: 200, epoch: 4 | loss: 0.1598953
	speed: 0.0392s/iter; left time: 148.2828s
	iters: 300, epoch: 4 | loss: 0.1530834
	speed: 0.0465s/iter; left time: 171.2688s
	iters: 400, epoch: 4 | loss: 0.1714344
	speed: 0.0461s/iter; left time: 165.1805s
	iters: 500, epoch: 4 | loss: 0.1690816
	speed: 0.0462s/iter; left time: 160.9422s
Epoch: 4 cost time: 25.935678243637085
Epoch: 4, Steps: 569 | Train Loss: 0.1702794 Vali Loss: 0.2315278 Test Loss: 0.3048346
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.1685574
	speed: 0.5762s/iter; left time: 1909.9655s
	iters: 200, epoch: 5 | loss: 0.1798033
	speed: 0.0383s/iter; left time: 123.0923s
	iters: 300, epoch: 5 | loss: 0.1694277
	speed: 0.0433s/iter; left time: 134.9739s
	iters: 400, epoch: 5 | loss: 0.1590146
	speed: 0.0439s/iter; left time: 132.3727s
	iters: 500, epoch: 5 | loss: 0.1694717
	speed: 0.0435s/iter; left time: 126.7215s
Epoch: 5 cost time: 24.836604118347168
Epoch: 5, Steps: 569 | Train Loss: 0.1692475 Vali Loss: 0.2307975 Test Loss: 0.3069402
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.1689131
	speed: 0.5993s/iter; left time: 1645.7842s
	iters: 200, epoch: 6 | loss: 0.1703203
	speed: 0.0351s/iter; left time: 92.8884s
	iters: 300, epoch: 6 | loss: 0.1636848
	speed: 0.0409s/iter; left time: 104.2422s
	iters: 400, epoch: 6 | loss: 0.1705642
	speed: 0.0439s/iter; left time: 107.3542s
	iters: 500, epoch: 6 | loss: 0.1634525
	speed: 0.0444s/iter; left time: 104.2356s
Epoch: 6 cost time: 24.57632541656494
Epoch: 6, Steps: 569 | Train Loss: 0.1686820 Vali Loss: 0.2345620 Test Loss: 0.3103078
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.1716090
	speed: 0.5786s/iter; left time: 1259.6813s
	iters: 200, epoch: 7 | loss: 0.1676450
	speed: 0.0362s/iter; left time: 75.1283s
	iters: 300, epoch: 7 | loss: 0.1709752
	speed: 0.0429s/iter; left time: 84.9070s
	iters: 400, epoch: 7 | loss: 0.1642809
	speed: 0.0453s/iter; left time: 85.1070s
	iters: 500, epoch: 7 | loss: 0.1636753
	speed: 0.0448s/iter; left time: 79.5956s
Epoch: 7 cost time: 24.983879804611206
Epoch: 7, Steps: 569 | Train Loss: 0.1683241 Vali Loss: 0.2347305 Test Loss: 0.3110448
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.1679061
	speed: 0.5997s/iter; left time: 964.3389s
	iters: 200, epoch: 8 | loss: 0.1722720
	speed: 0.0374s/iter; left time: 56.4127s
	iters: 300, epoch: 8 | loss: 0.1739723
	speed: 0.0422s/iter; left time: 59.3992s
	iters: 400, epoch: 8 | loss: 0.1697622
	speed: 0.0420s/iter; left time: 54.8988s
	iters: 500, epoch: 8 | loss: 0.1675935
	speed: 0.0418s/iter; left time: 50.4859s
Epoch: 8 cost time: 24.405874252319336
Epoch: 8, Steps: 569 | Train Loss: 0.1681286 Vali Loss: 0.2343321 Test Loss: 0.3111202
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 0.1773288
	speed: 0.6092s/iter; left time: 632.9361s
	iters: 200, epoch: 9 | loss: 0.1649954
	speed: 0.0363s/iter; left time: 34.0512s
	iters: 300, epoch: 9 | loss: 0.1716300
	speed: 0.0447s/iter; left time: 37.5114s
	iters: 400, epoch: 9 | loss: 0.1679176
	speed: 0.0455s/iter; left time: 33.6198s
	iters: 500, epoch: 9 | loss: 0.1634084
	speed: 0.0452s/iter; left time: 28.9049s
Epoch: 9 cost time: 25.185288906097412
Epoch: 9, Steps: 569 | Train Loss: 0.1680283 Vali Loss: 0.2345037 Test Loss: 0.3106700
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 0.1595429
	speed: 0.6000s/iter; left time: 282.0211s
	iters: 200, epoch: 10 | loss: 0.1522927
	speed: 0.0373s/iter; left time: 13.7996s
	iters: 300, epoch: 10 | loss: 0.1719149
	speed: 0.0459s/iter; left time: 12.3965s
	iters: 400, epoch: 10 | loss: 0.1665603
	speed: 0.0467s/iter; left time: 7.9407s
	iters: 500, epoch: 10 | loss: 0.1732633
	speed: 0.0467s/iter; left time: 3.2657s
Epoch: 10 cost time: 25.875730514526367
Epoch: 10, Steps: 569 | Train Loss: 0.1680069 Vali Loss: 0.2352148 Test Loss: 0.3115979
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
>>>>>>>testing : ECL_96_96_2_emb_64_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (5165, 1, 96, 321) (5165, 1, 96, 321)
test shape: (5165, 96, 321) (5165, 96, 321)
mse:0.3045026659965515, mae:0.3980644941329956
Args in experiment:
Namespace(is_training=1, model_id='ECL_96_96_3_emb_64', model='xLSTM', data='custom', root_path='./data/electricity/', data_path='/input-data/electricity.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, enc_in=321, dec_in=7, c_out=321, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.5, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=16, patience=10, learning_rate=0.001, des='test', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, use_norm=True, partial_start_index=0, hidden_size=512, num_layers=2, mark_enc_in=4, embedding_dim=64, weight_decay=1e-05, kernal_size=5, num_heads_xlstm=2, qkv_proj_blocksize=4, proj_factor=1.3, num_blocks=7, slstm_at=1, grad_clip_norm=1.0, d_state=16, d_conv=4, expand=2)
Use GPU: cuda:0
{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-L/usr/local/cuda/lib', '-lcublas'], 'extra_cflags': ['-DSLSTM_HIDDEN_SIZE=64', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=2', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__'], 'extra_cuda_cflags': ['-Xptxas="-v"', '-gencode', 'arch=compute_80,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=64', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=2', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__']}
Using /home/thetayne/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/thetayne/.cache/torch_extensions/py310_cu121/slstm_HS64BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0/build.ninja...
Building extension module slstm_HS64BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module slstm_HS64BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
>>>>>>>start training : ECL_96_96_3_emb_64_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 18221
val 2537
test 5165
	iters: 100, epoch: 1 | loss: 0.3939544
	speed: 0.0748s/iter; left time: 2546.6990s
	iters: 200, epoch: 1 | loss: 0.3571166
	speed: 0.0536s/iter; left time: 1818.6904s
	iters: 300, epoch: 1 | loss: 0.2772319
	speed: 0.0529s/iter; left time: 1788.5120s
	iters: 400, epoch: 1 | loss: 0.2689232
	speed: 0.0531s/iter; left time: 1792.1798s
	iters: 500, epoch: 1 | loss: 0.2457019
	speed: 0.0525s/iter; left time: 1764.6078s
	iters: 600, epoch: 1 | loss: 0.2246882
	speed: 0.0541s/iter; left time: 1813.8399s
	iters: 700, epoch: 1 | loss: 0.2225130
	speed: 0.0583s/iter; left time: 1948.7844s
	iters: 800, epoch: 1 | loss: 0.2363681
	speed: 0.0547s/iter; left time: 1824.8196s
	iters: 900, epoch: 1 | loss: 0.2282757
	speed: 0.0583s/iter; left time: 1936.5434s
	iters: 1000, epoch: 1 | loss: 0.2089180
	speed: 0.0558s/iter; left time: 1850.8537s
	iters: 1100, epoch: 1 | loss: 0.2240262
	speed: 0.0538s/iter; left time: 1776.9706s
Epoch: 1 cost time: 64.14880633354187
Epoch: 1, Steps: 1138 | Train Loss: 0.2963197 Vali Loss: 0.2287946 Test Loss: 0.2908055
Validation loss decreased (inf --> 0.228795).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.2087353
	speed: 0.9043s/iter; left time: 29754.9300s
	iters: 200, epoch: 2 | loss: 0.2231207
	speed: 0.0515s/iter; left time: 1690.5584s
	iters: 300, epoch: 2 | loss: 0.2407344
	speed: 0.0539s/iter; left time: 1762.1941s
	iters: 400, epoch: 2 | loss: 0.2350017
	speed: 0.0545s/iter; left time: 1776.1789s
	iters: 500, epoch: 2 | loss: 0.2265880
	speed: 0.0532s/iter; left time: 1729.7113s
	iters: 600, epoch: 2 | loss: 0.2124452
	speed: 0.0510s/iter; left time: 1651.7936s
	iters: 700, epoch: 2 | loss: 0.2497441
	speed: 0.0534s/iter; left time: 1724.5445s
	iters: 800, epoch: 2 | loss: 0.2381637
	speed: 0.0525s/iter; left time: 1691.8337s
	iters: 900, epoch: 2 | loss: 0.2350792
	speed: 0.0538s/iter; left time: 1727.1192s
	iters: 1000, epoch: 2 | loss: 0.2036006
	speed: 0.0519s/iter; left time: 1660.4686s
	iters: 1100, epoch: 2 | loss: 0.2271504
	speed: 0.0524s/iter; left time: 1672.9574s
Epoch: 2 cost time: 62.01036024093628
Epoch: 2, Steps: 1138 | Train Loss: 0.2256556 Vali Loss: 0.2181195 Test Loss: 0.2872839
Validation loss decreased (0.228795 --> 0.218120).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.2231410
	speed: 0.8926s/iter; left time: 28354.1124s
	iters: 200, epoch: 3 | loss: 0.2449601
	speed: 0.0540s/iter; left time: 1709.8794s
	iters: 300, epoch: 3 | loss: 0.2187069
	speed: 0.0568s/iter; left time: 1791.9998s
	iters: 400, epoch: 3 | loss: 0.2283617
	speed: 0.0553s/iter; left time: 1741.1158s
	iters: 500, epoch: 3 | loss: 0.2269698
	speed: 0.0628s/iter; left time: 1969.9776s
	iters: 600, epoch: 3 | loss: 0.2338636
	speed: 0.0552s/iter; left time: 1725.8969s
	iters: 700, epoch: 3 | loss: 0.2085830
	speed: 0.0545s/iter; left time: 1699.0718s
	iters: 800, epoch: 3 | loss: 0.2433317
	speed: 0.0575s/iter; left time: 1785.8101s
	iters: 900, epoch: 3 | loss: 0.2018079
	speed: 0.0580s/iter; left time: 1796.8821s
	iters: 1000, epoch: 3 | loss: 0.2195085
	speed: 0.0563s/iter; left time: 1737.0537s
	iters: 1100, epoch: 3 | loss: 0.2134037
	speed: 0.0559s/iter; left time: 1720.5920s
Epoch: 3 cost time: 66.32449913024902
Epoch: 3, Steps: 1138 | Train Loss: 0.2196635 Vali Loss: 0.2235700 Test Loss: 0.2882761
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.2166571
	speed: 0.8907s/iter; left time: 27279.1149s
	iters: 200, epoch: 4 | loss: 0.2171407
	speed: 0.0604s/iter; left time: 1844.4190s
	iters: 300, epoch: 4 | loss: 0.2218191
	speed: 0.0562s/iter; left time: 1709.6595s
	iters: 400, epoch: 4 | loss: 0.2326082
	speed: 0.0571s/iter; left time: 1733.0721s
	iters: 500, epoch: 4 | loss: 0.2166558
	speed: 0.0546s/iter; left time: 1651.5057s
	iters: 600, epoch: 4 | loss: 0.2320598
	speed: 0.0574s/iter; left time: 1727.8862s
	iters: 700, epoch: 4 | loss: 0.2140858
	speed: 0.0558s/iter; left time: 1675.1531s
	iters: 800, epoch: 4 | loss: 0.2229783
	speed: 0.0605s/iter; left time: 1811.7804s
	iters: 900, epoch: 4 | loss: 0.2292096
	speed: 0.0564s/iter; left time: 1681.1392s
	iters: 1000, epoch: 4 | loss: 0.2126949
	speed: 0.0555s/iter; left time: 1648.6037s
	iters: 1100, epoch: 4 | loss: 0.2223889
	speed: 0.0553s/iter; left time: 1638.0903s
Epoch: 4 cost time: 66.23658919334412
Epoch: 4, Steps: 1138 | Train Loss: 0.2177403 Vali Loss: 0.2292006 Test Loss: 0.2891604
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.2246018
	speed: 0.9186s/iter; left time: 27087.7492s
	iters: 200, epoch: 5 | loss: 0.2363413
	speed: 0.0512s/iter; left time: 1503.2850s
	iters: 300, epoch: 5 | loss: 0.2251313
	speed: 0.0545s/iter; left time: 1596.1209s
	iters: 400, epoch: 5 | loss: 0.1878148
	speed: 0.0510s/iter; left time: 1488.4398s
	iters: 500, epoch: 5 | loss: 0.2226877
	speed: 0.0523s/iter; left time: 1522.5130s
	iters: 600, epoch: 5 | loss: 0.2080288
	speed: 0.0561s/iter; left time: 1627.2574s
	iters: 700, epoch: 5 | loss: 0.2220933
	speed: 0.0536s/iter; left time: 1548.7348s
	iters: 800, epoch: 5 | loss: 0.2268075
	speed: 0.0549s/iter; left time: 1581.9176s
	iters: 900, epoch: 5 | loss: 0.2239761
	speed: 0.0574s/iter; left time: 1645.6617s
	iters: 1000, epoch: 5 | loss: 0.2107049
	speed: 0.0548s/iter; left time: 1566.9092s
	iters: 1100, epoch: 5 | loss: 0.2071924
	speed: 0.0581s/iter; left time: 1654.2360s
Epoch: 5 cost time: 63.54159712791443
Epoch: 5, Steps: 1138 | Train Loss: 0.2168417 Vali Loss: 0.2300802 Test Loss: 0.2899183
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.2087893
	speed: 0.9448s/iter; left time: 26787.0256s
	iters: 200, epoch: 6 | loss: 0.2058858
	speed: 0.0567s/iter; left time: 1603.0979s
	iters: 300, epoch: 6 | loss: 0.2342801
	speed: 0.0539s/iter; left time: 1516.8516s
	iters: 400, epoch: 6 | loss: 0.2215448
	speed: 0.0535s/iter; left time: 1499.7763s
	iters: 500, epoch: 6 | loss: 0.2124625
	speed: 0.0522s/iter; left time: 1458.7676s
	iters: 600, epoch: 6 | loss: 0.2081172
	speed: 0.0523s/iter; left time: 1456.6244s
	iters: 700, epoch: 6 | loss: 0.1942408
	speed: 0.0528s/iter; left time: 1464.7114s
	iters: 800, epoch: 6 | loss: 0.2049067
	speed: 0.0571s/iter; left time: 1578.4898s
	iters: 900, epoch: 6 | loss: 0.2085491
	speed: 0.0569s/iter; left time: 1567.0426s
	iters: 1000, epoch: 6 | loss: 0.2164207
	speed: 0.0575s/iter; left time: 1577.7829s
	iters: 1100, epoch: 6 | loss: 0.2156209
	speed: 0.0549s/iter; left time: 1502.8581s
Epoch: 6 cost time: 63.68250131607056
Epoch: 6, Steps: 1138 | Train Loss: 0.2162897 Vali Loss: 0.2308244 Test Loss: 0.2892152
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.2203532
	speed: 0.9362s/iter; left time: 25475.6929s
	iters: 200, epoch: 7 | loss: 0.2192742
	speed: 0.0620s/iter; left time: 1680.1724s
	iters: 300, epoch: 7 | loss: 0.2090574
	speed: 0.0586s/iter; left time: 1583.4037s
	iters: 400, epoch: 7 | loss: 0.2084937
	speed: 0.0548s/iter; left time: 1475.7753s
	iters: 500, epoch: 7 | loss: 0.2253835
	speed: 0.0582s/iter; left time: 1559.4090s
	iters: 600, epoch: 7 | loss: 0.2237271
	speed: 0.0553s/iter; left time: 1478.4634s
	iters: 700, epoch: 7 | loss: 0.2239801
	speed: 0.0557s/iter; left time: 1482.4750s
	iters: 800, epoch: 7 | loss: 0.2161190
	speed: 0.0521s/iter; left time: 1381.7658s
	iters: 900, epoch: 7 | loss: 0.2069043
	speed: 0.0554s/iter; left time: 1463.3254s
	iters: 1000, epoch: 7 | loss: 0.2031397
	speed: 0.0573s/iter; left time: 1506.9371s
	iters: 1100, epoch: 7 | loss: 0.2056375
	speed: 0.0519s/iter; left time: 1361.2499s
Epoch: 7 cost time: 65.36823916435242
Epoch: 7, Steps: 1138 | Train Loss: 0.2160714 Vali Loss: 0.2308622 Test Loss: 0.2885805
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.2005155
	speed: 0.9758s/iter; left time: 25443.6863s
	iters: 200, epoch: 8 | loss: 0.2130606
	speed: 0.0587s/iter; left time: 1525.5710s
	iters: 300, epoch: 8 | loss: 0.2240866
	speed: 0.0511s/iter; left time: 1323.4058s
	iters: 400, epoch: 8 | loss: 0.2020784
	speed: 0.0579s/iter; left time: 1492.3048s
	iters: 500, epoch: 8 | loss: 0.2343840
	speed: 0.0629s/iter; left time: 1614.5303s
	iters: 600, epoch: 8 | loss: 0.1968400
	speed: 0.0558s/iter; left time: 1426.3565s
	iters: 700, epoch: 8 | loss: 0.2246531
	speed: 0.0548s/iter; left time: 1395.3062s
	iters: 800, epoch: 8 | loss: 0.2204494
	speed: 0.0571s/iter; left time: 1448.8899s
	iters: 900, epoch: 8 | loss: 0.1993284
	speed: 0.0561s/iter; left time: 1418.7000s
	iters: 1000, epoch: 8 | loss: 0.2091089
	speed: 0.0565s/iter; left time: 1421.4080s
	iters: 1100, epoch: 8 | loss: 0.2292141
	speed: 0.0576s/iter; left time: 1445.4079s
Epoch: 8 cost time: 66.60196709632874
Epoch: 8, Steps: 1138 | Train Loss: 0.2158479 Vali Loss: 0.2301973 Test Loss: 0.2882876
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 0.2034386
	speed: 0.8608s/iter; left time: 21466.4977s
	iters: 200, epoch: 9 | loss: 0.2284250
	speed: 0.0520s/iter; left time: 1290.9546s
	iters: 300, epoch: 9 | loss: 0.2151052
	speed: 0.0596s/iter; left time: 1474.3534s
	iters: 400, epoch: 9 | loss: 0.2181177
	speed: 0.0621s/iter; left time: 1530.5906s
	iters: 500, epoch: 9 | loss: 0.2121469
	speed: 0.0628s/iter; left time: 1541.6037s
	iters: 600, epoch: 9 | loss: 0.2210357
	speed: 0.0585s/iter; left time: 1430.7513s
	iters: 700, epoch: 9 | loss: 0.2288076
	speed: 0.0558s/iter; left time: 1357.8930s
	iters: 800, epoch: 9 | loss: 0.2297490
	speed: 0.0472s/iter; left time: 1144.8727s
	iters: 900, epoch: 9 | loss: 0.2083438
	speed: 0.0481s/iter; left time: 1161.0543s
	iters: 1000, epoch: 9 | loss: 0.1971714
	speed: 0.0490s/iter; left time: 1178.1887s
	iters: 1100, epoch: 9 | loss: 0.2151217
	speed: 0.0530s/iter; left time: 1267.8682s
Epoch: 9 cost time: 63.20604348182678
Epoch: 9, Steps: 1138 | Train Loss: 0.2159291 Vali Loss: 0.2312134 Test Loss: 0.2889103
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 0.2178525
	speed: 0.9518s/iter; left time: 22652.8070s
	iters: 200, epoch: 10 | loss: 0.2182285
	speed: 0.0592s/iter; left time: 1402.1626s
	iters: 300, epoch: 10 | loss: 0.2128142
	speed: 0.0556s/iter; left time: 1312.2118s
	iters: 400, epoch: 10 | loss: 0.2216313
	speed: 0.0552s/iter; left time: 1296.2719s
	iters: 500, epoch: 10 | loss: 0.1941659
	speed: 0.0560s/iter; left time: 1309.7674s
	iters: 600, epoch: 10 | loss: 0.2445699
	speed: 0.0578s/iter; left time: 1346.4988s
	iters: 700, epoch: 10 | loss: 0.2128492
	speed: 0.0556s/iter; left time: 1288.8756s
	iters: 800, epoch: 10 | loss: 0.2217546
	speed: 0.0556s/iter; left time: 1284.2510s
	iters: 900, epoch: 10 | loss: 0.2214685
	speed: 0.0530s/iter; left time: 1219.9235s
	iters: 1000, epoch: 10 | loss: 0.1938627
	speed: 0.0528s/iter; left time: 1207.9449s
	iters: 1100, epoch: 10 | loss: 0.2022761
	speed: 0.0535s/iter; left time: 1219.8506s
Epoch: 10 cost time: 64.75486421585083
Epoch: 10, Steps: 1138 | Train Loss: 0.2157990 Vali Loss: 0.2312640 Test Loss: 0.2887586
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 0.2362281
	speed: 0.9524s/iter; left time: 21582.9931s
	iters: 200, epoch: 11 | loss: 0.2113050
	speed: 0.0508s/iter; left time: 1145.8257s
	iters: 300, epoch: 11 | loss: 0.2053964
	speed: 0.0527s/iter; left time: 1183.9173s
	iters: 400, epoch: 11 | loss: 0.2017280
	speed: 0.0555s/iter; left time: 1240.9717s
	iters: 500, epoch: 11 | loss: 0.2064126
	speed: 0.0529s/iter; left time: 1178.4016s
	iters: 600, epoch: 11 | loss: 0.2154717
	speed: 0.0561s/iter; left time: 1244.0396s
	iters: 700, epoch: 11 | loss: 0.2233047
	speed: 0.0564s/iter; left time: 1244.4576s
	iters: 800, epoch: 11 | loss: 0.2005716
	speed: 0.0572s/iter; left time: 1255.4456s
	iters: 900, epoch: 11 | loss: 0.2097414
	speed: 0.0561s/iter; left time: 1225.3895s
	iters: 1000, epoch: 11 | loss: 0.2139651
	speed: 0.0540s/iter; left time: 1175.5451s
	iters: 1100, epoch: 11 | loss: 0.2172111
	speed: 0.0524s/iter; left time: 1135.6858s
Epoch: 11 cost time: 63.26160407066345
Epoch: 11, Steps: 1138 | Train Loss: 0.2157329 Vali Loss: 0.2311127 Test Loss: 0.2886469
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 0.2108298
	speed: 0.8960s/iter; left time: 19284.5756s
	iters: 200, epoch: 12 | loss: 0.2074935
	speed: 0.0557s/iter; left time: 1193.7827s
	iters: 300, epoch: 12 | loss: 0.2166731
	speed: 0.0526s/iter; left time: 1122.2395s
	iters: 400, epoch: 12 | loss: 0.2193015
	speed: 0.0530s/iter; left time: 1123.7827s
	iters: 500, epoch: 12 | loss: 0.2078480
	speed: 0.0534s/iter; left time: 1128.4058s
	iters: 600, epoch: 12 | loss: 0.2137474
	speed: 0.0541s/iter; left time: 1137.9573s
	iters: 700, epoch: 12 | loss: 0.2229947
	speed: 0.0545s/iter; left time: 1139.9859s
	iters: 800, epoch: 12 | loss: 0.2221476
	speed: 0.0565s/iter; left time: 1175.9079s
	iters: 900, epoch: 12 | loss: 0.1892777
	speed: 0.0498s/iter; left time: 1032.9029s
	iters: 1000, epoch: 12 | loss: 0.1990149
	speed: 0.0549s/iter; left time: 1132.8359s
	iters: 1100, epoch: 12 | loss: 0.2203145
	speed: 0.0632s/iter; left time: 1296.7696s
Epoch: 12 cost time: 63.91390013694763
Epoch: 12, Steps: 1138 | Train Loss: 0.2157747 Vali Loss: 0.2311972 Test Loss: 0.2887524
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : ECL_96_96_3_emb_64_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (5165, 1, 96, 321) (5165, 1, 96, 321)
test shape: (5165, 96, 321) (5165, 96, 321)
mse:0.2872830629348755, mae:0.37368589639663696
Args in experiment:
Namespace(is_training=1, model_id='ECL_96_96_4_emb_64', model='xLSTM', data='custom', root_path='./data/electricity/', data_path='/input-data/electricity.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, enc_in=321, dec_in=7, c_out=321, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=50, batch_size=16, patience=10, learning_rate=0.0001, des='test', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, use_norm=True, partial_start_index=0, hidden_size=512, num_layers=2, mark_enc_in=4, embedding_dim=64, weight_decay=0.0001, kernal_size=5, num_heads_xlstm=2, qkv_proj_blocksize=4, proj_factor=1.3, num_blocks=7, slstm_at=1, grad_clip_norm=1.0, d_state=16, d_conv=4, expand=2)
Use GPU: cuda:0
{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-L/usr/local/cuda/lib', '-lcublas'], 'extra_cflags': ['-DSLSTM_HIDDEN_SIZE=64', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=2', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__'], 'extra_cuda_cflags': ['-Xptxas="-v"', '-gencode', 'arch=compute_80,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=64', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=2', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__']}
Using /home/thetayne/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/thetayne/.cache/torch_extensions/py310_cu121/slstm_HS64BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0/build.ninja...
Building extension module slstm_HS64BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module slstm_HS64BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
>>>>>>>start training : ECL_96_96_4_emb_64_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 18221
val 2537
test 5165
	iters: 100, epoch: 1 | loss: 0.6955009
	speed: 0.0785s/iter; left time: 4456.7646s
	iters: 200, epoch: 1 | loss: 0.5474614
	speed: 0.0559s/iter; left time: 3167.4594s
	iters: 300, epoch: 1 | loss: 0.3831891
	speed: 0.0605s/iter; left time: 3424.7907s
	iters: 400, epoch: 1 | loss: 0.3652082
	speed: 0.0592s/iter; left time: 3342.4155s
	iters: 500, epoch: 1 | loss: 0.3251695
	speed: 0.0567s/iter; left time: 3198.8622s
	iters: 600, epoch: 1 | loss: 0.2857012
	speed: 0.0578s/iter; left time: 3252.9049s
	iters: 700, epoch: 1 | loss: 0.2992590
	speed: 0.0574s/iter; left time: 3224.7131s
	iters: 800, epoch: 1 | loss: 0.3015865
	speed: 0.0561s/iter; left time: 3147.7625s
	iters: 900, epoch: 1 | loss: 0.2791731
	speed: 0.0578s/iter; left time: 3235.0761s
	iters: 1000, epoch: 1 | loss: 0.2513609
	speed: 0.0594s/iter; left time: 3319.6671s
	iters: 1100, epoch: 1 | loss: 0.2596280
	speed: 0.0600s/iter; left time: 3349.4489s
Epoch: 1 cost time: 67.91662049293518
Epoch: 1, Steps: 1138 | Train Loss: 0.4031638 Vali Loss: 0.2774833 Test Loss: 0.3386076
Validation loss decreased (inf --> 0.277483).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.2284760
	speed: 0.9132s/iter; left time: 50830.6395s
	iters: 200, epoch: 2 | loss: 0.2429712
	speed: 0.0580s/iter; left time: 3225.2451s
	iters: 300, epoch: 2 | loss: 0.2559411
	speed: 0.0560s/iter; left time: 3106.7351s
	iters: 400, epoch: 2 | loss: 0.2319102
	speed: 0.0554s/iter; left time: 3068.1255s
	iters: 500, epoch: 2 | loss: 0.2196227
	speed: 0.0570s/iter; left time: 3151.6790s
	iters: 600, epoch: 2 | loss: 0.2049970
	speed: 0.0562s/iter; left time: 3098.6998s
	iters: 700, epoch: 2 | loss: 0.2264509
	speed: 0.0577s/iter; left time: 3177.6467s
	iters: 800, epoch: 2 | loss: 0.2127930
	speed: 0.0573s/iter; left time: 3149.1419s
	iters: 900, epoch: 2 | loss: 0.2114200
	speed: 0.0555s/iter; left time: 3043.7924s
	iters: 1000, epoch: 2 | loss: 0.1738483
	speed: 0.0544s/iter; left time: 2981.4305s
	iters: 1100, epoch: 2 | loss: 0.1957742
	speed: 0.0552s/iter; left time: 3018.5148s
Epoch: 2 cost time: 65.35017538070679
Epoch: 2, Steps: 1138 | Train Loss: 0.2204416 Vali Loss: 0.2487982 Test Loss: 0.3236033
Validation loss decreased (0.277483 --> 0.248798).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.1881759
	speed: 1.0054s/iter; left time: 54819.1444s
	iters: 200, epoch: 3 | loss: 0.2076569
	speed: 0.0528s/iter; left time: 2871.9453s
	iters: 300, epoch: 3 | loss: 0.1809261
	speed: 0.0529s/iter; left time: 2872.8975s
	iters: 400, epoch: 3 | loss: 0.1951764
	speed: 0.0586s/iter; left time: 3175.0824s
	iters: 500, epoch: 3 | loss: 0.1916177
	speed: 0.0571s/iter; left time: 3088.0098s
	iters: 600, epoch: 3 | loss: 0.1965315
	speed: 0.0515s/iter; left time: 2779.6683s
	iters: 700, epoch: 3 | loss: 0.1702172
	speed: 0.0574s/iter; left time: 3095.6517s
	iters: 800, epoch: 3 | loss: 0.1935815
	speed: 0.0532s/iter; left time: 2866.0808s
	iters: 900, epoch: 3 | loss: 0.1656071
	speed: 0.0521s/iter; left time: 2797.9357s
	iters: 1000, epoch: 3 | loss: 0.1762015
	speed: 0.0548s/iter; left time: 2937.3285s
	iters: 1100, epoch: 3 | loss: 0.1695706
	speed: 0.0519s/iter; left time: 2777.9041s
Epoch: 3 cost time: 63.31002116203308
Epoch: 3, Steps: 1138 | Train Loss: 0.1813145 Vali Loss: 0.2468120 Test Loss: 0.3229169
Validation loss decreased (0.248798 --> 0.246812).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.1731874
	speed: 0.8867s/iter; left time: 47338.8286s
	iters: 200, epoch: 4 | loss: 0.1681454
	speed: 0.0534s/iter; left time: 2844.9924s
	iters: 300, epoch: 4 | loss: 0.1766430
	speed: 0.0549s/iter; left time: 2920.7657s
	iters: 400, epoch: 4 | loss: 0.1789795
	speed: 0.0569s/iter; left time: 3020.8514s
	iters: 500, epoch: 4 | loss: 0.1681778
	speed: 0.0545s/iter; left time: 2887.5752s
	iters: 600, epoch: 4 | loss: 0.1737609
	speed: 0.0513s/iter; left time: 2711.9482s
	iters: 700, epoch: 4 | loss: 0.1681812
	speed: 0.0514s/iter; left time: 2713.9010s
	iters: 800, epoch: 4 | loss: 0.1675127
	speed: 0.0522s/iter; left time: 2750.5379s
	iters: 900, epoch: 4 | loss: 0.1774190
	speed: 0.0519s/iter; left time: 2731.6205s
	iters: 1000, epoch: 4 | loss: 0.1676685
	speed: 0.0503s/iter; left time: 2638.2144s
	iters: 1100, epoch: 4 | loss: 0.1724220
	speed: 0.0513s/iter; left time: 2686.2171s
Epoch: 4 cost time: 62.661847829818726
Epoch: 4, Steps: 1138 | Train Loss: 0.1697427 Vali Loss: 0.2446863 Test Loss: 0.3211620
Validation loss decreased (0.246812 --> 0.244686).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.1708712
	speed: 0.8731s/iter; left time: 45620.1282s
	iters: 200, epoch: 5 | loss: 0.1749953
	speed: 0.0554s/iter; left time: 2886.8581s
	iters: 300, epoch: 5 | loss: 0.1723239
	speed: 0.0540s/iter; left time: 2808.8402s
	iters: 400, epoch: 5 | loss: 0.1431315
	speed: 0.0514s/iter; left time: 2671.4869s
	iters: 500, epoch: 5 | loss: 0.1696352
	speed: 0.0524s/iter; left time: 2719.0746s
	iters: 600, epoch: 5 | loss: 0.1580640
	speed: 0.0530s/iter; left time: 2744.9157s
	iters: 700, epoch: 5 | loss: 0.1696882
	speed: 0.0551s/iter; left time: 2845.7375s
	iters: 800, epoch: 5 | loss: 0.1696991
	speed: 0.0533s/iter; left time: 2749.5769s
	iters: 900, epoch: 5 | loss: 0.1725263
	speed: 0.0534s/iter; left time: 2746.3041s
	iters: 1000, epoch: 5 | loss: 0.1561134
	speed: 0.0527s/iter; left time: 2704.6406s
	iters: 1100, epoch: 5 | loss: 0.1535071
	speed: 0.0535s/iter; left time: 2741.8428s
Epoch: 5 cost time: 62.79255127906799
Epoch: 5, Steps: 1138 | Train Loss: 0.1645041 Vali Loss: 0.2415037 Test Loss: 0.3191134
Validation loss decreased (0.244686 --> 0.241504).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.1559324
	speed: 0.9309s/iter; left time: 47578.5598s
	iters: 200, epoch: 6 | loss: 0.1598729
	speed: 0.0534s/iter; left time: 2722.7263s
	iters: 300, epoch: 6 | loss: 0.1713688
	speed: 0.0539s/iter; left time: 2744.9612s
	iters: 400, epoch: 6 | loss: 0.1635128
	speed: 0.0548s/iter; left time: 2783.9175s
	iters: 500, epoch: 6 | loss: 0.1591231
	speed: 0.0546s/iter; left time: 2771.0501s
	iters: 600, epoch: 6 | loss: 0.1588585
	speed: 0.0536s/iter; left time: 2714.4694s
	iters: 700, epoch: 6 | loss: 0.1474817
	speed: 0.0523s/iter; left time: 2639.8735s
	iters: 800, epoch: 6 | loss: 0.1511109
	speed: 0.0530s/iter; left time: 2670.8042s
	iters: 900, epoch: 6 | loss: 0.1548709
	speed: 0.0541s/iter; left time: 2720.9495s
	iters: 1000, epoch: 6 | loss: 0.1653581
	speed: 0.0500s/iter; left time: 2512.2182s
	iters: 1100, epoch: 6 | loss: 0.1629020
	speed: 0.0548s/iter; left time: 2746.1112s
Epoch: 6 cost time: 62.41298770904541
Epoch: 6, Steps: 1138 | Train Loss: 0.1619323 Vali Loss: 0.2417617 Test Loss: 0.3191085
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.1616327
	speed: 1.0040s/iter; left time: 50175.3654s
	iters: 200, epoch: 7 | loss: 0.1654982
	speed: 0.0589s/iter; left time: 2935.2499s
	iters: 300, epoch: 7 | loss: 0.1555955
	speed: 0.0562s/iter; left time: 2798.0722s
	iters: 400, epoch: 7 | loss: 0.1564657
	speed: 0.0552s/iter; left time: 2742.6374s
	iters: 500, epoch: 7 | loss: 0.1685894
	speed: 0.0555s/iter; left time: 2752.2337s
	iters: 600, epoch: 7 | loss: 0.1669690
	speed: 0.0553s/iter; left time: 2733.6047s
	iters: 700, epoch: 7 | loss: 0.1672056
	speed: 0.0546s/iter; left time: 2695.9914s
	iters: 800, epoch: 7 | loss: 0.1582065
	speed: 0.0586s/iter; left time: 2888.6168s
	iters: 900, epoch: 7 | loss: 0.1552604
	speed: 0.0582s/iter; left time: 2863.7127s
	iters: 1000, epoch: 7 | loss: 0.1475358
	speed: 0.0559s/iter; left time: 2744.6775s
	iters: 1100, epoch: 7 | loss: 0.1544149
	speed: 0.0587s/iter; left time: 2872.3193s
Epoch: 7 cost time: 66.59077835083008
Epoch: 7, Steps: 1138 | Train Loss: 0.1606088 Vali Loss: 0.2406838 Test Loss: 0.3181173
Validation loss decreased (0.241504 --> 0.240684).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.1500267
	speed: 0.9466s/iter; left time: 46227.7812s
	iters: 200, epoch: 8 | loss: 0.1586637
	speed: 0.0579s/iter; left time: 2822.5064s
	iters: 300, epoch: 8 | loss: 0.1611201
	speed: 0.0609s/iter; left time: 2960.7656s
	iters: 400, epoch: 8 | loss: 0.1503096
	speed: 0.0584s/iter; left time: 2835.8580s
	iters: 500, epoch: 8 | loss: 0.1742533
	speed: 0.0653s/iter; left time: 3162.2410s
	iters: 600, epoch: 8 | loss: 0.1455793
	speed: 0.0537s/iter; left time: 2594.2237s
	iters: 700, epoch: 8 | loss: 0.1688544
	speed: 0.0539s/iter; left time: 2597.5754s
	iters: 800, epoch: 8 | loss: 0.1640462
	speed: 0.0603s/iter; left time: 2904.8593s
	iters: 900, epoch: 8 | loss: 0.1499733
	speed: 0.0588s/iter; left time: 2825.3675s
	iters: 1000, epoch: 8 | loss: 0.1602577
	speed: 0.0551s/iter; left time: 2641.5360s
	iters: 1100, epoch: 8 | loss: 0.1729037
	speed: 0.0526s/iter; left time: 2517.8027s
Epoch: 8 cost time: 67.4238133430481
Epoch: 8, Steps: 1138 | Train Loss: 0.1599467 Vali Loss: 0.2404979 Test Loss: 0.3179449
Validation loss decreased (0.240684 --> 0.240498).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.1546041
	speed: 0.9167s/iter; left time: 43724.2473s
	iters: 200, epoch: 9 | loss: 0.1665733
	speed: 0.0518s/iter; left time: 2466.6720s
	iters: 300, epoch: 9 | loss: 0.1557628
	speed: 0.0525s/iter; left time: 2491.2811s
	iters: 400, epoch: 9 | loss: 0.1622207
	speed: 0.0530s/iter; left time: 2510.5535s
	iters: 500, epoch: 9 | loss: 0.1627483
	speed: 0.0525s/iter; left time: 2485.2755s
	iters: 600, epoch: 9 | loss: 0.1720761
	speed: 0.0555s/iter; left time: 2617.0908s
	iters: 700, epoch: 9 | loss: 0.1675621
	speed: 0.0514s/iter; left time: 2419.4202s
	iters: 800, epoch: 9 | loss: 0.1742635
	speed: 0.0505s/iter; left time: 2374.5888s
	iters: 900, epoch: 9 | loss: 0.1537165
	speed: 0.0513s/iter; left time: 2404.5860s
	iters: 1000, epoch: 9 | loss: 0.1475978
	speed: 0.0513s/iter; left time: 2400.8918s
	iters: 1100, epoch: 9 | loss: 0.1566286
	speed: 0.0543s/iter; left time: 2537.3696s
Epoch: 9 cost time: 61.62253761291504
Epoch: 9, Steps: 1138 | Train Loss: 0.1596320 Vali Loss: 0.2406939 Test Loss: 0.3183102
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.1611853
	speed: 0.9159s/iter; left time: 42641.2535s
	iters: 200, epoch: 10 | loss: 0.1580317
	speed: 0.0531s/iter; left time: 2465.9815s
	iters: 300, epoch: 10 | loss: 0.1622942
	speed: 0.0541s/iter; left time: 2509.4014s
	iters: 400, epoch: 10 | loss: 0.1600633
	speed: 0.0511s/iter; left time: 2365.8688s
	iters: 500, epoch: 10 | loss: 0.1456501
	speed: 0.0517s/iter; left time: 2388.2344s
	iters: 600, epoch: 10 | loss: 0.1760058
	speed: 0.0529s/iter; left time: 2436.7302s
	iters: 700, epoch: 10 | loss: 0.1638831
	speed: 0.0563s/iter; left time: 2587.9315s
	iters: 800, epoch: 10 | loss: 0.1638040
	speed: 0.0600s/iter; left time: 2752.0473s
	iters: 900, epoch: 10 | loss: 0.1604820
	speed: 0.0561s/iter; left time: 2565.8157s
	iters: 1000, epoch: 10 | loss: 0.1465973
	speed: 0.0593s/iter; left time: 2709.8084s
	iters: 1100, epoch: 10 | loss: 0.1493032
	speed: 0.0626s/iter; left time: 2853.1707s
Epoch: 10 cost time: 64.83240222930908
Epoch: 10, Steps: 1138 | Train Loss: 0.1594523 Vali Loss: 0.2409664 Test Loss: 0.3183305
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.1690956
	speed: 0.9007s/iter; left time: 40908.9311s
	iters: 200, epoch: 11 | loss: 0.1507356
	speed: 0.0563s/iter; left time: 2550.7141s
	iters: 300, epoch: 11 | loss: 0.1507792
	speed: 0.0552s/iter; left time: 2496.2906s
	iters: 400, epoch: 11 | loss: 0.1486606
	speed: 0.0556s/iter; left time: 2506.4794s
	iters: 500, epoch: 11 | loss: 0.1536716
	speed: 0.0522s/iter; left time: 2348.3392s
	iters: 600, epoch: 11 | loss: 0.1622394
	speed: 0.0556s/iter; left time: 2495.8551s
	iters: 700, epoch: 11 | loss: 0.1660922
	speed: 0.0577s/iter; left time: 2585.1024s
	iters: 800, epoch: 11 | loss: 0.1527753
	speed: 0.0597s/iter; left time: 2671.1001s
	iters: 900, epoch: 11 | loss: 0.1553864
	speed: 0.0568s/iter; left time: 2532.8280s
	iters: 1000, epoch: 11 | loss: 0.1575255
	speed: 0.0554s/iter; left time: 2468.6363s
	iters: 1100, epoch: 11 | loss: 0.1572316
	speed: 0.0553s/iter; left time: 2455.5061s
Epoch: 11 cost time: 64.7003870010376
Epoch: 11, Steps: 1138 | Train Loss: 0.1593682 Vali Loss: 0.2409838 Test Loss: 0.3183354
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.1558963
	speed: 0.9205s/iter; left time: 40762.1466s
	iters: 200, epoch: 12 | loss: 0.1600789
	speed: 0.0578s/iter; left time: 2554.0161s
	iters: 300, epoch: 12 | loss: 0.1549187
	speed: 0.0515s/iter; left time: 2268.1273s
	iters: 400, epoch: 12 | loss: 0.1595739
	speed: 0.0544s/iter; left time: 2394.6014s
	iters: 500, epoch: 12 | loss: 0.1517119
	speed: 0.0527s/iter; left time: 2313.9457s
	iters: 600, epoch: 12 | loss: 0.1561832
	speed: 0.0542s/iter; left time: 2371.3524s
	iters: 700, epoch: 12 | loss: 0.1626272
	speed: 0.0548s/iter; left time: 2391.7559s
	iters: 800, epoch: 12 | loss: 0.1642930
	speed: 0.0551s/iter; left time: 2402.0688s
	iters: 900, epoch: 12 | loss: 0.1415765
	speed: 0.0534s/iter; left time: 2320.6572s
	iters: 1000, epoch: 12 | loss: 0.1447305
	speed: 0.0546s/iter; left time: 2366.7272s
	iters: 1100, epoch: 12 | loss: 0.1643852
	speed: 0.0556s/iter; left time: 2404.4232s
Epoch: 12 cost time: 63.13111710548401
Epoch: 12, Steps: 1138 | Train Loss: 0.1593375 Vali Loss: 0.2410305 Test Loss: 0.3182715
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.1425730
	speed: 0.8802s/iter; left time: 37975.9861s
	iters: 200, epoch: 13 | loss: 0.1610317
	speed: 0.0581s/iter; left time: 2499.5347s
	iters: 300, epoch: 13 | loss: 0.1482325
	speed: 0.0529s/iter; left time: 2272.8540s
	iters: 400, epoch: 13 | loss: 0.1556569
	speed: 0.0541s/iter; left time: 2318.8956s
	iters: 500, epoch: 13 | loss: 0.1437216
	speed: 0.0526s/iter; left time: 2248.2062s
	iters: 600, epoch: 13 | loss: 0.1532894
	speed: 0.0555s/iter; left time: 2366.2615s
	iters: 700, epoch: 13 | loss: 0.1638483
	speed: 0.0522s/iter; left time: 2221.2947s
	iters: 800, epoch: 13 | loss: 0.1633513
	speed: 0.0555s/iter; left time: 2354.0406s
	iters: 900, epoch: 13 | loss: 0.1524795
	speed: 0.0532s/iter; left time: 2251.3198s
	iters: 1000, epoch: 13 | loss: 0.1613623
	speed: 0.0536s/iter; left time: 2263.2398s
	iters: 1100, epoch: 13 | loss: 0.1880217
	speed: 0.0542s/iter; left time: 2285.7710s
Epoch: 13 cost time: 63.99850416183472
Epoch: 13, Steps: 1138 | Train Loss: 0.1593465 Vali Loss: 0.2408812 Test Loss: 0.3182106
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.1526844
	speed: 0.9395s/iter; left time: 39466.7535s
	iters: 200, epoch: 14 | loss: 0.1640234
	speed: 0.0575s/iter; left time: 2411.7317s
	iters: 300, epoch: 14 | loss: 0.1489116
	speed: 0.0567s/iter; left time: 2368.5415s
	iters: 400, epoch: 14 | loss: 0.1722516
	speed: 0.0571s/iter; left time: 2380.1049s
	iters: 500, epoch: 14 | loss: 0.1673820
	speed: 0.0591s/iter; left time: 2457.6298s
	iters: 600, epoch: 14 | loss: 0.1576551
	speed: 0.0584s/iter; left time: 2422.0005s
	iters: 700, epoch: 14 | loss: 0.1702794
	speed: 0.0594s/iter; left time: 2460.0587s
	iters: 800, epoch: 14 | loss: 0.1620691
	speed: 0.0587s/iter; left time: 2425.3104s
	iters: 900, epoch: 14 | loss: 0.1499426
	speed: 0.0630s/iter; left time: 2595.6437s
	iters: 1000, epoch: 14 | loss: 0.1455707
	speed: 0.0630s/iter; left time: 2588.0162s
	iters: 1100, epoch: 14 | loss: 0.1676571
	speed: 0.0586s/iter; left time: 2404.5684s
Epoch: 14 cost time: 68.52737736701965
Epoch: 14, Steps: 1138 | Train Loss: 0.1593149 Vali Loss: 0.2409791 Test Loss: 0.3182073
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.1719201
	speed: 0.9099s/iter; left time: 37188.2568s
	iters: 200, epoch: 15 | loss: 0.1453438
	speed: 0.0580s/iter; left time: 2362.7243s
	iters: 300, epoch: 15 | loss: 0.1522398
	speed: 0.0577s/iter; left time: 2347.0506s
	iters: 400, epoch: 15 | loss: 0.1651074
	speed: 0.0564s/iter; left time: 2288.4014s
	iters: 500, epoch: 15 | loss: 0.1669130
	speed: 0.0563s/iter; left time: 2278.9535s
	iters: 600, epoch: 15 | loss: 0.1498423
	speed: 0.0560s/iter; left time: 2262.2573s
	iters: 700, epoch: 15 | loss: 0.1539517
	speed: 0.0589s/iter; left time: 2369.9667s
	iters: 800, epoch: 15 | loss: 0.1532350
	speed: 0.0567s/iter; left time: 2278.1215s
	iters: 900, epoch: 15 | loss: 0.1620892
	speed: 0.0577s/iter; left time: 2313.3711s
	iters: 1000, epoch: 15 | loss: 0.1591279
	speed: 0.0576s/iter; left time: 2302.5778s
	iters: 1100, epoch: 15 | loss: 0.1547132
	speed: 0.0578s/iter; left time: 2306.3983s
Epoch: 15 cost time: 66.79404258728027
Epoch: 15, Steps: 1138 | Train Loss: 0.1593245 Vali Loss: 0.2409141 Test Loss: 0.3182158
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.1537607
	speed: 0.9295s/iter; left time: 36930.8106s
	iters: 200, epoch: 16 | loss: 0.1508145
	speed: 0.0570s/iter; left time: 2258.9798s
	iters: 300, epoch: 16 | loss: 0.1583751
	speed: 0.0564s/iter; left time: 2228.5817s
	iters: 400, epoch: 16 | loss: 0.1610845
	speed: 0.0576s/iter; left time: 2271.2373s
	iters: 500, epoch: 16 | loss: 0.1646983
	speed: 0.0568s/iter; left time: 2235.2936s
	iters: 600, epoch: 16 | loss: 0.1470512
	speed: 0.0610s/iter; left time: 2393.4894s
	iters: 700, epoch: 16 | loss: 0.1669901
	speed: 0.0579s/iter; left time: 2264.4011s
	iters: 800, epoch: 16 | loss: 0.1528033
	speed: 0.0568s/iter; left time: 2218.0255s
	iters: 900, epoch: 16 | loss: 0.1586978
	speed: 0.0563s/iter; left time: 2190.5540s
	iters: 1000, epoch: 16 | loss: 0.1512811
	speed: 0.0585s/iter; left time: 2271.0416s
	iters: 1100, epoch: 16 | loss: 0.1739834
	speed: 0.0586s/iter; left time: 2269.1881s
Epoch: 16 cost time: 66.90364956855774
Epoch: 16, Steps: 1138 | Train Loss: 0.1593031 Vali Loss: 0.2408963 Test Loss: 0.3182213
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.1488964
	speed: 0.8997s/iter; left time: 34720.9115s
	iters: 200, epoch: 17 | loss: 0.1614196
	speed: 0.0525s/iter; left time: 2022.0239s
	iters: 300, epoch: 17 | loss: 0.1579353
	speed: 0.0566s/iter; left time: 2173.3608s
	iters: 400, epoch: 17 | loss: 0.1515389
	speed: 0.0570s/iter; left time: 2181.3096s
	iters: 500, epoch: 17 | loss: 0.1622383
	speed: 0.0589s/iter; left time: 2249.4533s
	iters: 600, epoch: 17 | loss: 0.1404942
	speed: 0.0582s/iter; left time: 2217.2362s
	iters: 700, epoch: 17 | loss: 0.1448419
	speed: 0.0590s/iter; left time: 2242.7879s
	iters: 800, epoch: 17 | loss: 0.1593009
	speed: 0.0564s/iter; left time: 2137.2686s
	iters: 900, epoch: 17 | loss: 0.1461990
	speed: 0.0573s/iter; left time: 2164.4650s
	iters: 1000, epoch: 17 | loss: 0.1700722
	speed: 0.0584s/iter; left time: 2200.3080s
	iters: 1100, epoch: 17 | loss: 0.1564208
	speed: 0.0557s/iter; left time: 2092.8189s
Epoch: 17 cost time: 66.11054491996765
Epoch: 17, Steps: 1138 | Train Loss: 0.1593144 Vali Loss: 0.2408894 Test Loss: 0.3182205
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.1636361
	speed: 0.9519s/iter; left time: 35652.5256s
	iters: 200, epoch: 18 | loss: 0.1598853
	speed: 0.0548s/iter; left time: 2046.0822s
	iters: 300, epoch: 18 | loss: 0.1580962
	speed: 0.0551s/iter; left time: 2052.7626s
	iters: 400, epoch: 18 | loss: 0.1512068
	speed: 0.0559s/iter; left time: 2075.1397s
	iters: 500, epoch: 18 | loss: 0.1669986
	speed: 0.0569s/iter; left time: 2109.6938s
	iters: 600, epoch: 18 | loss: 0.1585617
	speed: 0.0579s/iter; left time: 2139.6803s
	iters: 700, epoch: 18 | loss: 0.1725832
	speed: 0.0569s/iter; left time: 2096.4506s
	iters: 800, epoch: 18 | loss: 0.1563889
	speed: 0.0543s/iter; left time: 1997.0504s
	iters: 900, epoch: 18 | loss: 0.1614700
	speed: 0.0532s/iter; left time: 1951.2244s
	iters: 1000, epoch: 18 | loss: 0.1613757
	speed: 0.0515s/iter; left time: 1884.1096s
	iters: 1100, epoch: 18 | loss: 0.1535949
	speed: 0.0541s/iter; left time: 1971.5332s
Epoch: 18 cost time: 64.47142767906189
Epoch: 18, Steps: 1138 | Train Loss: 0.1593095 Vali Loss: 0.2408971 Test Loss: 0.3182209
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : ECL_96_96_4_emb_64_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (5165, 1, 96, 321) (5165, 1, 96, 321)
test shape: (5165, 96, 321) (5165, 96, 321)
mse:0.3179449737071991, mae:0.39208945631980896
Args in experiment:
Namespace(is_training=1, model_id='ECL_96_96_5_emb_64', model='xLSTM', data='custom', root_path='./data/electricity/', data_path='/input-data/electricity.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, enc_in=321, dec_in=7, c_out=321, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.5, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=10, batch_size=8, patience=10, learning_rate=0.0005, des='test', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, use_norm=True, partial_start_index=0, hidden_size=512, num_layers=2, mark_enc_in=4, embedding_dim=64, weight_decay=0.0001, kernal_size=3, num_heads_xlstm=8, qkv_proj_blocksize=4, proj_factor=1.3, num_blocks=3, slstm_at=1, grad_clip_norm=0.5, d_state=16, d_conv=4, expand=2)
Use GPU: cuda:0
{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-L/usr/local/cuda/lib', '-lcublas'], 'extra_cflags': ['-DSLSTM_HIDDEN_SIZE=64', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=8', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__'], 'extra_cuda_cflags': ['-Xptxas="-v"', '-gencode', 'arch=compute_80,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=64', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=8', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__']}
Using /home/thetayne/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Creating extension directory /home/thetayne/.cache/torch_extensions/py310_cu121/slstm_HS64BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/thetayne/.cache/torch_extensions/py310_cu121/slstm_HS64BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0/build.ninja...
Building extension module slstm_HS64BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[1/8] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output cuda_error.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS64BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=64 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=8 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/util/cuda_error.cu -o cuda_error.cuda.o 
ptxas info    : 0 bytes gmem
[2/8] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output slstm_forward.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS64BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=64 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=8 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/cuda/slstm_forward.cu -o slstm_forward.cuda.o 
ptxas info    : 0 bytes gmem
[3/8] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output slstm_backward_cut.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS64BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=64 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=8 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/cuda/slstm_backward_cut.cu -o slstm_backward_cut.cuda.o 
ptxas info    : 0 bytes gmem
ptxas info    : Compiling entry function '_ZN54_GLOBAL__N__2085b59d_21_slstm_backward_cut_cu_1c2c4d0129gradientBiasAggregationKernelEjjjjjjPK13__nv_bfloat16S2_Pf' for 'sm_80'
ptxas info    : Function properties for _ZN54_GLOBAL__N__2085b59d_21_slstm_backward_cut_cu_1c2c4d0129gradientBiasAggregationKernelEjjjjjjPK13__nv_bfloat16S2_Pf
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 32 registers, 400 bytes cmem[0]
[4/8] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output slstm_backward.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS64BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=64 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=8 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/cuda/slstm_backward.cu -o slstm_backward.cuda.o 
ptxas info    : 0 bytes gmem
ptxas info    : Compiling entry function '_ZN50_GLOBAL__N__d983f13f_17_slstm_backward_cu_3639fa5e29gradientBiasAggregationKernelEjjjjjjPK13__nv_bfloat16S2_Pf' for 'sm_80'
ptxas info    : Function properties for _ZN50_GLOBAL__N__d983f13f_17_slstm_backward_cu_3639fa5e29gradientBiasAggregationKernelEjjjjjjPK13__nv_bfloat16S2_Pf
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 32 registers, 400 bytes cmem[0]
[5/8] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output slstm_pointwise.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS64BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=64 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=8 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/cuda/slstm_pointwise.cu -o slstm_pointwise.cuda.o 
ptxas info    : 0 bytes gmem
ptxas info    : Compiling entry function '_ZN5slstm21SLSTMPointwiseForwardILb0EEEviiiPK13__nv_bfloat16S3_PKfS3_jPS1_jS6_S6_' for 'sm_80'
ptxas info    : Function properties for _ZN5slstm21SLSTMPointwiseForwardILb0EEEviiiPK13__nv_bfloat16S3_PKfS3_jPS1_jS6_S6_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 32 registers, 440 bytes cmem[0]
ptxas info    : Compiling entry function '_ZN5slstm21SLSTMPointwiseForwardILb1EEEviiiPK13__nv_bfloat16S3_PKfS3_jPS1_jS6_S6_' for 'sm_80'
ptxas info    : Function properties for _ZN5slstm21SLSTMPointwiseForwardILb1EEEviiiPK13__nv_bfloat16S3_PKfS3_jPS1_jS6_S6_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 32 registers, 440 bytes cmem[0]
ptxas info    : Compiling entry function '_ZN5slstm22SLSTMPointwiseBackwardEiiiPK13__nv_bfloat16jS2_S2_PKfS2_jS2_jPS0_jS5_S5_S5_' for 'sm_80'
ptxas info    : Function properties for _ZN5slstm22SLSTMPointwiseBackwardEiiiPK13__nv_bfloat16jS2_S2_PKfS2_jS2_jPS0_jS5_S5_S5_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 32 registers, 480 bytes cmem[0]
[6/8] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output blas.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS64BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=64 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=8 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/util/blas.cu -o blas.cuda.o 
ptxas info    : 0 bytes gmem
ptxas info    : Compiling entry function '_Z10initKernelI13__nv_bfloat16EvPT_iS1_' for 'sm_80'
ptxas info    : Function properties for _Z10initKernelI13__nv_bfloat16EvPT_iS1_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 8 registers, 366 bytes cmem[0]
ptxas info    : Compiling entry function '_Z10initKernelI6__halfEvPT_iS1_' for 'sm_80'
ptxas info    : Function properties for _Z10initKernelI6__halfEvPT_iS1_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 8 registers, 366 bytes cmem[0]
ptxas info    : Compiling entry function '_Z10initKernelIfEvPT_iS0_' for 'sm_80'
ptxas info    : Function properties for _Z10initKernelIfEvPT_iS0_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 8 registers, 368 bytes cmem[0]
ptxas info    : Compiling entry function '_Z10initKernelIdEvPT_iS0_' for 'sm_80'
ptxas info    : Function properties for _Z10initKernelIdEvPT_iS0_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 8 registers, 376 bytes cmem[0]
[7/8] c++ -MMD -MF slstm.o.d -DTORCH_EXTENSION_NAME=slstm_HS64BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -DSLSTM_HIDDEN_SIZE=64 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=8 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/cuda/slstm.cc -o slstm.o 
[8/8] c++ slstm.o slstm_forward.cuda.o slstm_backward.cuda.o slstm_backward_cut.cuda.o slstm_pointwise.cuda.o blas.cuda.o cuda_error.cuda.o -shared -L/usr/local/cuda/lib -lcublas -L/usr/local/lib/python3.10/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o slstm_HS64BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0.so
Loading extension module slstm_HS64BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
>>>>>>>start training : ECL_96_96_5_emb_64_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 18221
val 2537
test 5165
	iters: 100, epoch: 1 | loss: 0.5174571
	speed: 0.0442s/iter; left time: 1002.7589s
	iters: 200, epoch: 1 | loss: 0.3881565
	speed: 0.0210s/iter; left time: 472.9773s
	iters: 300, epoch: 1 | loss: 0.3249251
	speed: 0.0215s/iter; left time: 483.3236s
	iters: 400, epoch: 1 | loss: 0.3002452
	speed: 0.0256s/iter; left time: 572.1323s
	iters: 500, epoch: 1 | loss: 0.2632124
	speed: 0.0254s/iter; left time: 564.9044s
	iters: 600, epoch: 1 | loss: 0.2747913
	speed: 0.0253s/iter; left time: 561.3203s
	iters: 700, epoch: 1 | loss: 0.2438050
	speed: 0.0250s/iter; left time: 552.4323s
	iters: 800, epoch: 1 | loss: 0.3073487
	speed: 0.0253s/iter; left time: 556.8130s
	iters: 900, epoch: 1 | loss: 0.2735429
	speed: 0.0255s/iter; left time: 558.2644s
	iters: 1000, epoch: 1 | loss: 0.2369212
	speed: 0.0254s/iter; left time: 553.9837s
	iters: 1100, epoch: 1 | loss: 0.2573255
	speed: 0.0258s/iter; left time: 560.1702s
	iters: 1200, epoch: 1 | loss: 0.2324089
	speed: 0.0255s/iter; left time: 549.1004s
	iters: 1300, epoch: 1 | loss: 0.2893423
	speed: 0.0258s/iter; left time: 553.6655s
	iters: 1400, epoch: 1 | loss: 0.2148104
	speed: 0.0258s/iter; left time: 552.2202s
	iters: 1500, epoch: 1 | loss: 0.2379111
	speed: 0.0259s/iter; left time: 551.6768s
	iters: 1600, epoch: 1 | loss: 0.2638905
	speed: 0.0269s/iter; left time: 569.2909s
	iters: 1700, epoch: 1 | loss: 0.2635835
	speed: 0.0261s/iter; left time: 548.9779s
	iters: 1800, epoch: 1 | loss: 0.2465207
	speed: 0.0264s/iter; left time: 554.4616s
	iters: 1900, epoch: 1 | loss: 0.2417222
	speed: 0.0271s/iter; left time: 566.5861s
	iters: 2000, epoch: 1 | loss: 0.2320626
	speed: 0.0256s/iter; left time: 532.7609s
	iters: 2100, epoch: 1 | loss: 0.2151274
	speed: 0.0261s/iter; left time: 539.3914s
	iters: 2200, epoch: 1 | loss: 0.2115179
	speed: 0.0267s/iter; left time: 549.6460s
Epoch: 1 cost time: 59.836867809295654
Epoch: 1, Steps: 2277 | Train Loss: 0.2912297 Vali Loss: 0.2288266 Test Loss: 0.3006459
Validation loss decreased (inf --> 0.228827).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2190364
	speed: 0.5794s/iter; left time: 11816.6017s
	iters: 200, epoch: 2 | loss: 0.2296816
	speed: 0.0267s/iter; left time: 541.2453s
	iters: 300, epoch: 2 | loss: 0.2310417
	speed: 0.0275s/iter; left time: 555.1671s
	iters: 400, epoch: 2 | loss: 0.2161058
	speed: 0.0278s/iter; left time: 558.3085s
	iters: 500, epoch: 2 | loss: 0.2115492
	speed: 0.0272s/iter; left time: 543.2314s
	iters: 600, epoch: 2 | loss: 0.2215244
	speed: 0.0272s/iter; left time: 541.4094s
	iters: 700, epoch: 2 | loss: 0.2160770
	speed: 0.0272s/iter; left time: 538.9492s
	iters: 800, epoch: 2 | loss: 0.2134194
	speed: 0.0268s/iter; left time: 527.8785s
	iters: 900, epoch: 2 | loss: 0.2422852
	speed: 0.0263s/iter; left time: 516.2504s
	iters: 1000, epoch: 2 | loss: 0.2092359
	speed: 0.0278s/iter; left time: 541.0947s
	iters: 1100, epoch: 2 | loss: 0.1933887
	speed: 0.0267s/iter; left time: 518.2418s
	iters: 1200, epoch: 2 | loss: 0.2046491
	speed: 0.0269s/iter; left time: 518.7272s
	iters: 1300, epoch: 2 | loss: 0.2425916
	speed: 0.0265s/iter; left time: 508.3356s
	iters: 1400, epoch: 2 | loss: 0.2199513
	speed: 0.0265s/iter; left time: 505.3623s
	iters: 1500, epoch: 2 | loss: 0.2309127
	speed: 0.0264s/iter; left time: 501.5653s
	iters: 1600, epoch: 2 | loss: 0.2045995
	speed: 0.0261s/iter; left time: 492.3332s
	iters: 1700, epoch: 2 | loss: 0.2257815
	speed: 0.0274s/iter; left time: 515.5719s
	iters: 1800, epoch: 2 | loss: 0.2107167
	speed: 0.0263s/iter; left time: 491.9897s
	iters: 1900, epoch: 2 | loss: 0.2171059
	speed: 0.0255s/iter; left time: 473.9508s
	iters: 2000, epoch: 2 | loss: 0.1913533
	speed: 0.0247s/iter; left time: 457.0293s
	iters: 2100, epoch: 2 | loss: 0.2225234
	speed: 0.0252s/iter; left time: 462.6574s
	iters: 2200, epoch: 2 | loss: 0.2522541
	speed: 0.0252s/iter; left time: 460.5661s
Epoch: 2 cost time: 61.90316867828369
Epoch: 2, Steps: 2277 | Train Loss: 0.2278115 Vali Loss: 0.2175079 Test Loss: 0.2905144
Validation loss decreased (0.228827 --> 0.217508).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.2225103
	speed: 0.5777s/iter; left time: 10466.7177s
	iters: 200, epoch: 3 | loss: 0.2279362
	speed: 0.0211s/iter; left time: 379.8204s
	iters: 300, epoch: 3 | loss: 0.2186297
	speed: 0.0220s/iter; left time: 393.9732s
	iters: 400, epoch: 3 | loss: 0.2238850
	speed: 0.0240s/iter; left time: 427.9338s
	iters: 500, epoch: 3 | loss: 0.1999840
	speed: 0.0273s/iter; left time: 483.5163s
	iters: 600, epoch: 3 | loss: 0.2339237
	speed: 0.0277s/iter; left time: 488.8445s
	iters: 700, epoch: 3 | loss: 0.2044574
	speed: 0.0273s/iter; left time: 477.4758s
	iters: 800, epoch: 3 | loss: 0.2023199
	speed: 0.0282s/iter; left time: 491.7250s
	iters: 900, epoch: 3 | loss: 0.2055660
	speed: 0.0268s/iter; left time: 464.6090s
	iters: 1000, epoch: 3 | loss: 0.2152963
	speed: 0.0271s/iter; left time: 466.4193s
	iters: 1100, epoch: 3 | loss: 0.2312378
	speed: 0.0269s/iter; left time: 460.9054s
	iters: 1200, epoch: 3 | loss: 0.2328112
	speed: 0.0264s/iter; left time: 449.2663s
	iters: 1300, epoch: 3 | loss: 0.2426594
	speed: 0.0258s/iter; left time: 436.8993s
	iters: 1400, epoch: 3 | loss: 0.1975779
	speed: 0.0268s/iter; left time: 449.9117s
	iters: 1500, epoch: 3 | loss: 0.2488619
	speed: 0.0264s/iter; left time: 442.0388s
	iters: 1600, epoch: 3 | loss: 0.2128179
	speed: 0.0262s/iter; left time: 436.0357s
	iters: 1700, epoch: 3 | loss: 0.2461233
	speed: 0.0262s/iter; left time: 432.4099s
	iters: 1800, epoch: 3 | loss: 0.1939573
	speed: 0.0253s/iter; left time: 415.0009s
	iters: 1900, epoch: 3 | loss: 0.2537329
	speed: 0.0253s/iter; left time: 412.4768s
	iters: 2000, epoch: 3 | loss: 0.2260998
	speed: 0.0256s/iter; left time: 414.6402s
	iters: 2100, epoch: 3 | loss: 0.2147334
	speed: 0.0259s/iter; left time: 417.3970s
	iters: 2200, epoch: 3 | loss: 0.2037820
	speed: 0.0255s/iter; left time: 408.9825s
Epoch: 3 cost time: 60.17560648918152
Epoch: 3, Steps: 2277 | Train Loss: 0.2223264 Vali Loss: 0.2211227 Test Loss: 0.2903256
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.2280983
	speed: 0.5570s/iter; left time: 8822.0985s
	iters: 200, epoch: 4 | loss: 0.1937146
	speed: 0.0235s/iter; left time: 369.5497s
	iters: 300, epoch: 4 | loss: 0.2319221
	speed: 0.0260s/iter; left time: 405.9319s
	iters: 400, epoch: 4 | loss: 0.2422042
	speed: 0.0256s/iter; left time: 398.2044s
	iters: 500, epoch: 4 | loss: 0.2179370
	speed: 0.0249s/iter; left time: 383.8286s
	iters: 600, epoch: 4 | loss: 0.2073458
	speed: 0.0242s/iter; left time: 371.2152s
	iters: 700, epoch: 4 | loss: 0.2136241
	speed: 0.0238s/iter; left time: 363.0355s
	iters: 800, epoch: 4 | loss: 0.2171132
	speed: 0.0207s/iter; left time: 313.3172s
	iters: 900, epoch: 4 | loss: 0.2127075
	speed: 0.0211s/iter; left time: 317.9709s
	iters: 1000, epoch: 4 | loss: 0.2015535
	speed: 0.0243s/iter; left time: 363.7431s
	iters: 1100, epoch: 4 | loss: 0.2257549
	speed: 0.0240s/iter; left time: 355.4383s
	iters: 1200, epoch: 4 | loss: 0.2223432
	speed: 0.0247s/iter; left time: 364.5840s
	iters: 1300, epoch: 4 | loss: 0.2002664
	speed: 0.0240s/iter; left time: 351.1324s
	iters: 1400, epoch: 4 | loss: 0.2155540
	speed: 0.0248s/iter; left time: 360.4403s
	iters: 1500, epoch: 4 | loss: 0.2395801
	speed: 0.0255s/iter; left time: 368.4076s
	iters: 1600, epoch: 4 | loss: 0.2223392
	speed: 0.0251s/iter; left time: 360.6124s
	iters: 1700, epoch: 4 | loss: 0.2081750
	speed: 0.0248s/iter; left time: 352.8627s
	iters: 1800, epoch: 4 | loss: 0.2345950
	speed: 0.0241s/iter; left time: 340.7167s
	iters: 1900, epoch: 4 | loss: 0.2114247
	speed: 0.0237s/iter; left time: 332.0473s
	iters: 2000, epoch: 4 | loss: 0.2344226
	speed: 0.0230s/iter; left time: 321.0255s
	iters: 2100, epoch: 4 | loss: 0.1983882
	speed: 0.0239s/iter; left time: 330.3166s
	iters: 2200, epoch: 4 | loss: 0.2198567
	speed: 0.0237s/iter; left time: 325.6942s
Epoch: 4 cost time: 56.0856819152832
Epoch: 4, Steps: 2277 | Train Loss: 0.2203971 Vali Loss: 0.2233857 Test Loss: 0.2922395
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.2264616
	speed: 0.5672s/iter; left time: 7693.0248s
	iters: 200, epoch: 5 | loss: 0.2102823
	speed: 0.0216s/iter; left time: 290.6648s
	iters: 300, epoch: 5 | loss: 0.2359295
	speed: 0.0214s/iter; left time: 286.0773s
	iters: 400, epoch: 5 | loss: 0.2280184
	speed: 0.0215s/iter; left time: 285.5749s
	iters: 500, epoch: 5 | loss: 0.2263168
	speed: 0.0213s/iter; left time: 280.6500s
	iters: 600, epoch: 5 | loss: 0.2039065
	speed: 0.0228s/iter; left time: 297.6816s
	iters: 700, epoch: 5 | loss: 0.2303425
	speed: 0.0249s/iter; left time: 322.7465s
	iters: 800, epoch: 5 | loss: 0.2224405
	speed: 0.0259s/iter; left time: 333.4369s
	iters: 900, epoch: 5 | loss: 0.2170079
	speed: 0.0263s/iter; left time: 335.9624s
	iters: 1000, epoch: 5 | loss: 0.1877306
	speed: 0.0278s/iter; left time: 352.4807s
	iters: 1100, epoch: 5 | loss: 0.2159769
	speed: 0.0249s/iter; left time: 313.3736s
	iters: 1200, epoch: 5 | loss: 0.2120850
	speed: 0.0255s/iter; left time: 318.1431s
	iters: 1300, epoch: 5 | loss: 0.1873439
	speed: 0.0251s/iter; left time: 310.0875s
	iters: 1400, epoch: 5 | loss: 0.2371814
	speed: 0.0248s/iter; left time: 304.4246s
	iters: 1500, epoch: 5 | loss: 0.2126125
	speed: 0.0250s/iter; left time: 304.6309s
	iters: 1600, epoch: 5 | loss: 0.2047905
	speed: 0.0258s/iter; left time: 311.1120s
	iters: 1700, epoch: 5 | loss: 0.2004697
	speed: 0.0265s/iter; left time: 317.5144s
	iters: 1800, epoch: 5 | loss: 0.2024202
	speed: 0.0259s/iter; left time: 306.7889s
	iters: 1900, epoch: 5 | loss: 0.2274339
	speed: 0.0261s/iter; left time: 307.3744s
	iters: 2000, epoch: 5 | loss: 0.2295264
	speed: 0.0256s/iter; left time: 298.3090s
	iters: 2100, epoch: 5 | loss: 0.2210167
	speed: 0.0256s/iter; left time: 296.2215s
	iters: 2200, epoch: 5 | loss: 0.2141244
	speed: 0.0264s/iter; left time: 302.0677s
Epoch: 5 cost time: 57.94897699356079
Epoch: 5, Steps: 2277 | Train Loss: 0.2193431 Vali Loss: 0.2242497 Test Loss: 0.2904755
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.2092611
	speed: 0.5888s/iter; left time: 6644.8501s
	iters: 200, epoch: 6 | loss: 0.2197660
	speed: 0.0208s/iter; left time: 232.5936s
	iters: 300, epoch: 6 | loss: 0.2407709
	speed: 0.0208s/iter; left time: 230.2820s
	iters: 400, epoch: 6 | loss: 0.2346530
	speed: 0.0207s/iter; left time: 227.5770s
	iters: 500, epoch: 6 | loss: 0.2260738
	speed: 0.0210s/iter; left time: 228.9089s
	iters: 600, epoch: 6 | loss: 0.2120404
	speed: 0.0217s/iter; left time: 233.7763s
	iters: 700, epoch: 6 | loss: 0.2110048
	speed: 0.0216s/iter; left time: 231.2199s
	iters: 800, epoch: 6 | loss: 0.1846684
	speed: 0.0233s/iter; left time: 246.1807s
	iters: 900, epoch: 6 | loss: 0.2229230
	speed: 0.0227s/iter; left time: 238.1393s
	iters: 1000, epoch: 6 | loss: 0.2262166
	speed: 0.0230s/iter; left time: 238.6915s
	iters: 1100, epoch: 6 | loss: 0.2512434
	speed: 0.0237s/iter; left time: 243.7795s
	iters: 1200, epoch: 6 | loss: 0.2130427
	speed: 0.0237s/iter; left time: 241.1854s
	iters: 1300, epoch: 6 | loss: 0.2167321
	speed: 0.0230s/iter; left time: 231.5729s
	iters: 1400, epoch: 6 | loss: 0.2164249
	speed: 0.0233s/iter; left time: 232.3891s
	iters: 1500, epoch: 6 | loss: 0.2570563
	speed: 0.0232s/iter; left time: 229.1651s
	iters: 1600, epoch: 6 | loss: 0.1974646
	speed: 0.0233s/iter; left time: 227.6800s
	iters: 1700, epoch: 6 | loss: 0.2384102
	speed: 0.0234s/iter; left time: 226.3462s
	iters: 1800, epoch: 6 | loss: 0.1896453
	speed: 0.0225s/iter; left time: 215.7077s
	iters: 1900, epoch: 6 | loss: 0.2227394
	speed: 0.0221s/iter; left time: 209.4824s
	iters: 2000, epoch: 6 | loss: 0.2003483
	speed: 0.0212s/iter; left time: 198.6430s
	iters: 2100, epoch: 6 | loss: 0.1913262
	speed: 0.0208s/iter; left time: 193.2367s
	iters: 2200, epoch: 6 | loss: 0.2035422
	speed: 0.0210s/iter; left time: 192.8337s
Epoch: 6 cost time: 52.207313776016235
Epoch: 6, Steps: 2277 | Train Loss: 0.2189264 Vali Loss: 0.2260031 Test Loss: 0.2905675
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.2213985
	speed: 0.5424s/iter; left time: 4886.0413s
	iters: 200, epoch: 7 | loss: 0.2026436
	speed: 0.0231s/iter; left time: 206.0491s
	iters: 300, epoch: 7 | loss: 0.2118813
	speed: 0.0235s/iter; left time: 206.9018s
	iters: 400, epoch: 7 | loss: 0.2342794
	speed: 0.0229s/iter; left time: 199.3482s
	iters: 500, epoch: 7 | loss: 0.2107423
	speed: 0.0233s/iter; left time: 200.9740s
	iters: 600, epoch: 7 | loss: 0.2084149
	speed: 0.0226s/iter; left time: 191.9409s
	iters: 700, epoch: 7 | loss: 0.2390189
	speed: 0.0225s/iter; left time: 189.3031s
	iters: 800, epoch: 7 | loss: 0.2112960
	speed: 0.0242s/iter; left time: 201.2722s
	iters: 900, epoch: 7 | loss: 0.2205188
	speed: 0.0229s/iter; left time: 188.1380s
	iters: 1000, epoch: 7 | loss: 0.2099226
	speed: 0.0210s/iter; left time: 170.1938s
	iters: 1100, epoch: 7 | loss: 0.2187945
	speed: 0.0206s/iter; left time: 165.2672s
	iters: 1200, epoch: 7 | loss: 0.2208185
	speed: 0.0206s/iter; left time: 162.7984s
	iters: 1300, epoch: 7 | loss: 0.2227687
	speed: 0.0207s/iter; left time: 161.9043s
	iters: 1400, epoch: 7 | loss: 0.2065705
	speed: 0.0207s/iter; left time: 159.3905s
	iters: 1500, epoch: 7 | loss: 0.2384677
	speed: 0.0209s/iter; left time: 158.6931s
	iters: 1600, epoch: 7 | loss: 0.2142208
	speed: 0.0206s/iter; left time: 154.6308s
	iters: 1700, epoch: 7 | loss: 0.2274766
	speed: 0.0206s/iter; left time: 152.8057s
	iters: 1800, epoch: 7 | loss: 0.1923313
	speed: 0.0214s/iter; left time: 156.4823s
	iters: 1900, epoch: 7 | loss: 0.2246314
	speed: 0.0229s/iter; left time: 165.3124s
	iters: 2000, epoch: 7 | loss: 0.2030201
	speed: 0.0242s/iter; left time: 171.9830s
	iters: 2100, epoch: 7 | loss: 0.2306803
	speed: 0.0227s/iter; left time: 159.2459s
	iters: 2200, epoch: 7 | loss: 0.2249593
	speed: 0.0226s/iter; left time: 156.3427s
Epoch: 7 cost time: 51.66765522956848
Epoch: 7, Steps: 2277 | Train Loss: 0.2187508 Vali Loss: 0.2287735 Test Loss: 0.2922087
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.2285419
	speed: 0.5605s/iter; left time: 3773.2041s
	iters: 200, epoch: 8 | loss: 0.2240330
	speed: 0.0224s/iter; left time: 148.6401s
	iters: 300, epoch: 8 | loss: 0.2397025
	speed: 0.0232s/iter; left time: 151.2898s
	iters: 400, epoch: 8 | loss: 0.2034991
	speed: 0.0235s/iter; left time: 150.9969s
	iters: 500, epoch: 8 | loss: 0.2198135
	speed: 0.0229s/iter; left time: 144.8546s
	iters: 600, epoch: 8 | loss: 0.2319970
	speed: 0.0230s/iter; left time: 143.2749s
	iters: 700, epoch: 8 | loss: 0.2489622
	speed: 0.0227s/iter; left time: 139.4433s
	iters: 800, epoch: 8 | loss: 0.2445358
	speed: 0.0217s/iter; left time: 130.6647s
	iters: 900, epoch: 8 | loss: 0.2199313
	speed: 0.0214s/iter; left time: 126.9249s
	iters: 1000, epoch: 8 | loss: 0.2095301
	speed: 0.0227s/iter; left time: 132.3820s
	iters: 1100, epoch: 8 | loss: 0.2540942
	speed: 0.0228s/iter; left time: 130.5167s
	iters: 1200, epoch: 8 | loss: 0.2237353
	speed: 0.0222s/iter; left time: 124.8285s
	iters: 1300, epoch: 8 | loss: 0.2111942
	speed: 0.0228s/iter; left time: 126.1918s
	iters: 1400, epoch: 8 | loss: 0.2307671
	speed: 0.0227s/iter; left time: 123.5296s
	iters: 1500, epoch: 8 | loss: 0.1983957
	speed: 0.0232s/iter; left time: 123.7680s
	iters: 1600, epoch: 8 | loss: 0.2324654
	speed: 0.0230s/iter; left time: 120.2377s
	iters: 1700, epoch: 8 | loss: 0.2358384
	speed: 0.0227s/iter; left time: 116.7102s
	iters: 1800, epoch: 8 | loss: 0.2294848
	speed: 0.0226s/iter; left time: 113.6169s
	iters: 1900, epoch: 8 | loss: 0.2094020
	speed: 0.0235s/iter; left time: 115.6657s
	iters: 2000, epoch: 8 | loss: 0.2250820
	speed: 0.0236s/iter; left time: 113.9263s
	iters: 2100, epoch: 8 | loss: 0.1933329
	speed: 0.0212s/iter; left time: 100.2363s
	iters: 2200, epoch: 8 | loss: 0.2028269
	speed: 0.0207s/iter; left time: 95.8356s
Epoch: 8 cost time: 52.719778060913086
Epoch: 8, Steps: 2277 | Train Loss: 0.2186878 Vali Loss: 0.2280828 Test Loss: 0.2915952
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.2198767
	speed: 0.5680s/iter; left time: 2530.5636s
	iters: 200, epoch: 9 | loss: 0.1912071
	speed: 0.0215s/iter; left time: 93.4283s
	iters: 300, epoch: 9 | loss: 0.2150472
	speed: 0.0220s/iter; left time: 93.7342s
	iters: 400, epoch: 9 | loss: 0.2231596
	speed: 0.0228s/iter; left time: 94.9093s
	iters: 500, epoch: 9 | loss: 0.2090322
	speed: 0.0226s/iter; left time: 91.7363s
	iters: 600, epoch: 9 | loss: 0.2192574
	speed: 0.0220s/iter; left time: 86.8624s
	iters: 700, epoch: 9 | loss: 0.2231902
	speed: 0.0215s/iter; left time: 82.7104s
	iters: 800, epoch: 9 | loss: 0.2183304
	speed: 0.0214s/iter; left time: 80.3199s
	iters: 900, epoch: 9 | loss: 0.2354397
	speed: 0.0214s/iter; left time: 78.1430s
	iters: 1000, epoch: 9 | loss: 0.2164145
	speed: 0.0213s/iter; left time: 75.8388s
	iters: 1100, epoch: 9 | loss: 0.2250341
	speed: 0.0214s/iter; left time: 73.9977s
	iters: 1200, epoch: 9 | loss: 0.2116606
	speed: 0.0214s/iter; left time: 71.8316s
	iters: 1300, epoch: 9 | loss: 0.2328876
	speed: 0.0218s/iter; left time: 71.0298s
	iters: 1400, epoch: 9 | loss: 0.2235521
	speed: 0.0219s/iter; left time: 69.1186s
	iters: 1500, epoch: 9 | loss: 0.2058670
	speed: 0.0228s/iter; left time: 69.7004s
	iters: 1600, epoch: 9 | loss: 0.1859086
	speed: 0.0231s/iter; left time: 68.2183s
	iters: 1700, epoch: 9 | loss: 0.2092755
	speed: 0.0223s/iter; left time: 63.8059s
	iters: 1800, epoch: 9 | loss: 0.1978974
	speed: 0.0209s/iter; left time: 57.7057s
	iters: 1900, epoch: 9 | loss: 0.2005129
	speed: 0.0212s/iter; left time: 56.2926s
	iters: 2000, epoch: 9 | loss: 0.2309996
	speed: 0.0210s/iter; left time: 53.7251s
	iters: 2100, epoch: 9 | loss: 0.2179123
	speed: 0.0211s/iter; left time: 51.7239s
	iters: 2200, epoch: 9 | loss: 0.2383062
	speed: 0.0211s/iter; left time: 49.6455s
Epoch: 9 cost time: 50.955899477005005
Epoch: 9, Steps: 2277 | Train Loss: 0.2185256 Vali Loss: 0.2280084 Test Loss: 0.2912163
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.1914956
	speed: 0.5703s/iter; left time: 1242.0649s
	iters: 200, epoch: 10 | loss: 0.2074754
	speed: 0.0208s/iter; left time: 43.2138s
	iters: 300, epoch: 10 | loss: 0.2153512
	speed: 0.0208s/iter; left time: 41.2198s
	iters: 400, epoch: 10 | loss: 0.2410613
	speed: 0.0224s/iter; left time: 42.1300s
	iters: 500, epoch: 10 | loss: 0.2035155
	speed: 0.0228s/iter; left time: 40.4816s
	iters: 600, epoch: 10 | loss: 0.2078515
	speed: 0.0232s/iter; left time: 38.9088s
	iters: 700, epoch: 10 | loss: 0.1995671
	speed: 0.0233s/iter; left time: 36.8053s
	iters: 800, epoch: 10 | loss: 0.2021326
	speed: 0.0233s/iter; left time: 34.5041s
	iters: 900, epoch: 10 | loss: 0.2077242
	speed: 0.0225s/iter; left time: 31.0028s
	iters: 1000, epoch: 10 | loss: 0.2034641
	speed: 0.0231s/iter; left time: 29.5832s
	iters: 1100, epoch: 10 | loss: 0.2048164
	speed: 0.0228s/iter; left time: 26.8496s
	iters: 1200, epoch: 10 | loss: 0.2100172
	speed: 0.0228s/iter; left time: 24.5455s
	iters: 1300, epoch: 10 | loss: 0.2363666
	speed: 0.0213s/iter; left time: 20.8498s
	iters: 1400, epoch: 10 | loss: 0.2392626
	speed: 0.0210s/iter; left time: 18.4784s
	iters: 1500, epoch: 10 | loss: 0.2449814
	speed: 0.0213s/iter; left time: 16.5981s
	iters: 1600, epoch: 10 | loss: 0.1996779
	speed: 0.0222s/iter; left time: 15.0184s
	iters: 1700, epoch: 10 | loss: 0.2109564
	speed: 0.0221s/iter; left time: 12.7710s
	iters: 1800, epoch: 10 | loss: 0.2151298
	speed: 0.0212s/iter; left time: 10.1123s
	iters: 1900, epoch: 10 | loss: 0.2166466
	speed: 0.0220s/iter; left time: 8.2992s
	iters: 2000, epoch: 10 | loss: 0.2223366
	speed: 0.0208s/iter; left time: 5.7931s
	iters: 2100, epoch: 10 | loss: 0.2181022
	speed: 0.0218s/iter; left time: 3.8824s
	iters: 2200, epoch: 10 | loss: 0.1955357
	speed: 0.0228s/iter; left time: 1.7790s
Epoch: 10 cost time: 52.05996823310852
Epoch: 10, Steps: 2277 | Train Loss: 0.2185197 Vali Loss: 0.2285164 Test Loss: 0.2916270
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
>>>>>>>testing : ECL_96_96_5_emb_64_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (5165, 1, 96, 321) (5165, 1, 96, 321)
test shape: (5165, 96, 321) (5165, 96, 321)
mse:0.2905149757862091, mae:0.3784838020801544
Args in experiment:
Namespace(is_training=1, model_id='ECL_96_96_6_emb_64', model='xLSTM', data='custom', root_path='./data/electricity/', data_path='/input-data/electricity.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, enc_in=321, dec_in=7, c_out=321, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.5, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=10, batch_size=16, patience=10, learning_rate=0.0005, des='test', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, use_norm=True, partial_start_index=0, hidden_size=512, num_layers=2, mark_enc_in=4, embedding_dim=64, weight_decay=0.0001, kernal_size=5, num_heads_xlstm=2, qkv_proj_blocksize=8, proj_factor=1.3, num_blocks=3, slstm_at=1, grad_clip_norm=5.0, d_state=16, d_conv=4, expand=2)
Use GPU: cuda:0
{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-L/usr/local/cuda/lib', '-lcublas'], 'extra_cflags': ['-DSLSTM_HIDDEN_SIZE=64', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=2', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__'], 'extra_cuda_cflags': ['-Xptxas="-v"', '-gencode', 'arch=compute_80,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=64', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=2', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__']}
Using /home/thetayne/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/thetayne/.cache/torch_extensions/py310_cu121/slstm_HS64BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0/build.ninja...
Building extension module slstm_HS64BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module slstm_HS64BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
>>>>>>>start training : ECL_96_96_6_emb_64_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 18221
val 2537
test 5165
	iters: 100, epoch: 1 | loss: 0.6068577
	speed: 0.0499s/iter; left time: 562.7726s
	iters: 200, epoch: 1 | loss: 0.3769367
	speed: 0.0284s/iter; left time: 317.5906s
	iters: 300, epoch: 1 | loss: 0.3396093
	speed: 0.0291s/iter; left time: 322.8438s
	iters: 400, epoch: 1 | loss: 0.3054594
	speed: 0.0293s/iter; left time: 322.2307s
	iters: 500, epoch: 1 | loss: 0.2877677
	speed: 0.0292s/iter; left time: 317.7148s
	iters: 600, epoch: 1 | loss: 0.2461213
	speed: 0.0289s/iter; left time: 311.5291s
	iters: 700, epoch: 1 | loss: 0.2747143
	speed: 0.0284s/iter; left time: 303.2642s
	iters: 800, epoch: 1 | loss: 0.2602284
	speed: 0.0288s/iter; left time: 304.4528s
	iters: 900, epoch: 1 | loss: 0.2496261
	speed: 0.0287s/iter; left time: 300.3983s
	iters: 1000, epoch: 1 | loss: 0.2307190
	speed: 0.0287s/iter; left time: 298.0159s
	iters: 1100, epoch: 1 | loss: 0.2502502
	speed: 0.0294s/iter; left time: 302.0040s
Epoch: 1 cost time: 34.88644051551819
Epoch: 1, Steps: 1138 | Train Loss: 0.3445666 Vali Loss: 0.2366177 Test Loss: 0.3092080
Validation loss decreased (inf --> 0.236618).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2260136
	speed: 0.5508s/iter; left time: 5586.8923s
	iters: 200, epoch: 2 | loss: 0.2449218
	speed: 0.0261s/iter; left time: 262.3678s
	iters: 300, epoch: 2 | loss: 0.2439050
	speed: 0.0257s/iter; left time: 255.0894s
	iters: 400, epoch: 2 | loss: 0.2290706
	speed: 0.0275s/iter; left time: 270.7752s
	iters: 500, epoch: 2 | loss: 0.2111336
	speed: 0.0289s/iter; left time: 281.0869s
	iters: 600, epoch: 2 | loss: 0.2397747
	speed: 0.0289s/iter; left time: 278.4244s
	iters: 700, epoch: 2 | loss: 0.2275252
	speed: 0.0290s/iter; left time: 277.1377s
	iters: 800, epoch: 2 | loss: 0.2756272
	speed: 0.0294s/iter; left time: 277.2542s
	iters: 900, epoch: 2 | loss: 0.2333113
	speed: 0.0289s/iter; left time: 269.9691s
	iters: 1000, epoch: 2 | loss: 0.2553988
	speed: 0.0291s/iter; left time: 268.8275s
	iters: 1100, epoch: 2 | loss: 0.2120834
	speed: 0.0292s/iter; left time: 267.3932s
Epoch: 2 cost time: 33.5453941822052
Epoch: 2, Steps: 1138 | Train Loss: 0.2312487 Vali Loss: 0.2327615 Test Loss: 0.3039410
Validation loss decreased (0.236618 --> 0.232762).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.2086748
	speed: 0.5536s/iter; left time: 4984.9927s
	iters: 200, epoch: 3 | loss: 0.2334720
	speed: 0.0263s/iter; left time: 234.5917s
	iters: 300, epoch: 3 | loss: 0.2129534
	speed: 0.0271s/iter; left time: 238.3880s
	iters: 400, epoch: 3 | loss: 0.2208745
	speed: 0.0267s/iter; left time: 232.4633s
	iters: 500, epoch: 3 | loss: 0.2121255
	speed: 0.0267s/iter; left time: 229.9788s
	iters: 600, epoch: 3 | loss: 0.2383188
	speed: 0.0255s/iter; left time: 216.9122s
	iters: 700, epoch: 3 | loss: 0.2243635
	speed: 0.0255s/iter; left time: 214.6480s
	iters: 800, epoch: 3 | loss: 0.2162477
	speed: 0.0285s/iter; left time: 236.8711s
	iters: 900, epoch: 3 | loss: 0.2018599
	speed: 0.0293s/iter; left time: 240.0246s
	iters: 1000, epoch: 3 | loss: 0.2044133
	speed: 0.0295s/iter; left time: 239.3632s
	iters: 1100, epoch: 3 | loss: 0.2270705
	speed: 0.0288s/iter; left time: 230.2915s
Epoch: 3 cost time: 32.64654803276062
Epoch: 3, Steps: 1138 | Train Loss: 0.2238663 Vali Loss: 0.2327649 Test Loss: 0.3112183
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.2122850
	speed: 0.5559s/iter; left time: 4373.1235s
	iters: 200, epoch: 4 | loss: 0.2007555
	speed: 0.0251s/iter; left time: 195.0693s
	iters: 300, epoch: 4 | loss: 0.2139598
	speed: 0.0259s/iter; left time: 198.4433s
	iters: 400, epoch: 4 | loss: 0.2361216
	speed: 0.0287s/iter; left time: 216.8643s
	iters: 500, epoch: 4 | loss: 0.2349854
	speed: 0.0290s/iter; left time: 216.3372s
	iters: 600, epoch: 4 | loss: 0.2142881
	speed: 0.0294s/iter; left time: 216.2847s
	iters: 700, epoch: 4 | loss: 0.2089394
	speed: 0.0289s/iter; left time: 210.3517s
	iters: 800, epoch: 4 | loss: 0.2366367
	speed: 0.0284s/iter; left time: 203.7001s
	iters: 900, epoch: 4 | loss: 0.2275139
	speed: 0.0283s/iter; left time: 200.0868s
	iters: 1000, epoch: 4 | loss: 0.2233222
	speed: 0.0285s/iter; left time: 198.3100s
	iters: 1100, epoch: 4 | loss: 0.2241454
	speed: 0.0283s/iter; left time: 194.0218s
Epoch: 4 cost time: 33.2232141494751
Epoch: 4, Steps: 1138 | Train Loss: 0.2220085 Vali Loss: 0.2321462 Test Loss: 0.3125921
Validation loss decreased (0.232762 --> 0.232146).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.2538919
	speed: 0.5594s/iter; left time: 3764.4130s
	iters: 200, epoch: 5 | loss: 0.2368666
	speed: 0.0275s/iter; left time: 182.0301s
	iters: 300, epoch: 5 | loss: 0.2211434
	speed: 0.0294s/iter; left time: 192.0083s
	iters: 400, epoch: 5 | loss: 0.2290898
	speed: 0.0294s/iter; left time: 188.8641s
	iters: 500, epoch: 5 | loss: 0.2317065
	speed: 0.0295s/iter; left time: 186.6112s
	iters: 600, epoch: 5 | loss: 0.2060555
	speed: 0.0295s/iter; left time: 183.6562s
	iters: 700, epoch: 5 | loss: 0.2234135
	speed: 0.0291s/iter; left time: 178.2102s
	iters: 800, epoch: 5 | loss: 0.2237190
	speed: 0.0291s/iter; left time: 175.5385s
	iters: 900, epoch: 5 | loss: 0.2293451
	speed: 0.0289s/iter; left time: 171.2121s
	iters: 1000, epoch: 5 | loss: 0.2024430
	speed: 0.0294s/iter; left time: 171.2610s
	iters: 1100, epoch: 5 | loss: 0.2250888
	speed: 0.0295s/iter; left time: 168.9060s
Epoch: 5 cost time: 34.59827375411987
Epoch: 5, Steps: 1138 | Train Loss: 0.2210343 Vali Loss: 0.2288634 Test Loss: 0.3103463
Validation loss decreased (0.232146 --> 0.228863).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.2353247
	speed: 0.5301s/iter; left time: 2964.0122s
	iters: 200, epoch: 6 | loss: 0.2200939
	speed: 0.0246s/iter; left time: 135.2383s
	iters: 300, epoch: 6 | loss: 0.2105176
	speed: 0.0265s/iter; left time: 142.9076s
	iters: 400, epoch: 6 | loss: 0.2086552
	speed: 0.0263s/iter; left time: 138.9185s
	iters: 500, epoch: 6 | loss: 0.2368277
	speed: 0.0263s/iter; left time: 136.2856s
	iters: 600, epoch: 6 | loss: 0.2248615
	speed: 0.0292s/iter; left time: 148.8184s
	iters: 700, epoch: 6 | loss: 0.2075289
	speed: 0.0290s/iter; left time: 144.5707s
	iters: 800, epoch: 6 | loss: 0.2097674
	speed: 0.0290s/iter; left time: 141.6777s
	iters: 900, epoch: 6 | loss: 0.2096256
	speed: 0.0296s/iter; left time: 141.9142s
	iters: 1000, epoch: 6 | loss: 0.2166275
	speed: 0.0288s/iter; left time: 134.9619s
	iters: 1100, epoch: 6 | loss: 0.2107511
	speed: 0.0289s/iter; left time: 132.8071s
Epoch: 6 cost time: 32.93252944946289
Epoch: 6, Steps: 1138 | Train Loss: 0.2205906 Vali Loss: 0.2289614 Test Loss: 0.3115076
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.2197324
	speed: 0.5302s/iter; left time: 2360.9068s
	iters: 200, epoch: 7 | loss: 0.2295552
	speed: 0.0256s/iter; left time: 111.5293s
	iters: 300, epoch: 7 | loss: 0.2047751
	speed: 0.0293s/iter; left time: 124.4560s
	iters: 400, epoch: 7 | loss: 0.2167152
	speed: 0.0289s/iter; left time: 120.0299s
	iters: 500, epoch: 7 | loss: 0.2076636
	speed: 0.0295s/iter; left time: 119.7661s
	iters: 600, epoch: 7 | loss: 0.2056152
	speed: 0.0297s/iter; left time: 117.2298s
	iters: 700, epoch: 7 | loss: 0.2354682
	speed: 0.0284s/iter; left time: 109.4555s
	iters: 800, epoch: 7 | loss: 0.2158081
	speed: 0.0291s/iter; left time: 109.3839s
	iters: 900, epoch: 7 | loss: 0.2102509
	speed: 0.0293s/iter; left time: 107.1245s
	iters: 1000, epoch: 7 | loss: 0.2127207
	speed: 0.0288s/iter; left time: 102.4030s
	iters: 1100, epoch: 7 | loss: 0.2185819
	speed: 0.0288s/iter; left time: 99.5461s
Epoch: 7 cost time: 33.66709780693054
Epoch: 7, Steps: 1138 | Train Loss: 0.2204108 Vali Loss: 0.2291920 Test Loss: 0.3120009
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.2218567
	speed: 0.5541s/iter; left time: 1836.7330s
	iters: 200, epoch: 8 | loss: 0.2124099
	speed: 0.0280s/iter; left time: 90.1381s
	iters: 300, epoch: 8 | loss: 0.2124839
	speed: 0.0289s/iter; left time: 89.8926s
	iters: 400, epoch: 8 | loss: 0.1993122
	speed: 0.0292s/iter; left time: 88.1364s
	iters: 500, epoch: 8 | loss: 0.1968059
	speed: 0.0290s/iter; left time: 84.4635s
	iters: 600, epoch: 8 | loss: 0.2061417
	speed: 0.0293s/iter; left time: 82.3555s
	iters: 700, epoch: 8 | loss: 0.2180788
	speed: 0.0293s/iter; left time: 79.5218s
	iters: 800, epoch: 8 | loss: 0.2125849
	speed: 0.0286s/iter; left time: 74.8903s
	iters: 900, epoch: 8 | loss: 0.2164092
	speed: 0.0290s/iter; left time: 72.8720s
	iters: 1000, epoch: 8 | loss: 0.2185657
	speed: 0.0286s/iter; left time: 68.9893s
	iters: 1100, epoch: 8 | loss: 0.2436682
	speed: 0.0291s/iter; left time: 67.3123s
Epoch: 8 cost time: 34.03067374229431
Epoch: 8, Steps: 1138 | Train Loss: 0.2201992 Vali Loss: 0.2298640 Test Loss: 0.3125010
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.2194459
	speed: 0.5389s/iter; left time: 1173.1127s
	iters: 200, epoch: 9 | loss: 0.1910410
	speed: 0.0266s/iter; left time: 55.3099s
	iters: 300, epoch: 9 | loss: 0.2279949
	speed: 0.0270s/iter; left time: 53.3302s
	iters: 400, epoch: 9 | loss: 0.2080184
	speed: 0.0286s/iter; left time: 53.6154s
	iters: 500, epoch: 9 | loss: 0.2224845
	speed: 0.0294s/iter; left time: 52.1918s
	iters: 600, epoch: 9 | loss: 0.2250618
	speed: 0.0293s/iter; left time: 49.1227s
	iters: 700, epoch: 9 | loss: 0.2154363
	speed: 0.0296s/iter; left time: 46.6058s
	iters: 800, epoch: 9 | loss: 0.2312311
	speed: 0.0294s/iter; left time: 43.4420s
	iters: 900, epoch: 9 | loss: 0.2278034
	speed: 0.0294s/iter; left time: 40.4368s
	iters: 1000, epoch: 9 | loss: 0.2082565
	speed: 0.0292s/iter; left time: 37.3170s
	iters: 1100, epoch: 9 | loss: 0.2068849
	speed: 0.0290s/iter; left time: 34.0912s
Epoch: 9 cost time: 34.00724411010742
Epoch: 9, Steps: 1138 | Train Loss: 0.2201874 Vali Loss: 0.2295128 Test Loss: 0.3134591
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.2206184
	speed: 0.5583s/iter; left time: 580.1107s
	iters: 200, epoch: 10 | loss: 0.2420044
	speed: 0.0262s/iter; left time: 24.5954s
	iters: 300, epoch: 10 | loss: 0.2190540
	speed: 0.0282s/iter; left time: 23.6188s
	iters: 400, epoch: 10 | loss: 0.2019426
	speed: 0.0291s/iter; left time: 21.4926s
	iters: 500, epoch: 10 | loss: 0.2277454
	speed: 0.0288s/iter; left time: 18.4294s
	iters: 600, epoch: 10 | loss: 0.2344481
	speed: 0.0286s/iter; left time: 15.4240s
	iters: 700, epoch: 10 | loss: 0.2191776
	speed: 0.0285s/iter; left time: 12.5086s
	iters: 800, epoch: 10 | loss: 0.2099037
	speed: 0.0285s/iter; left time: 9.6490s
	iters: 900, epoch: 10 | loss: 0.2042503
	speed: 0.0284s/iter; left time: 6.7847s
	iters: 1000, epoch: 10 | loss: 0.2218424
	speed: 0.0286s/iter; left time: 3.9700s
	iters: 1100, epoch: 10 | loss: 0.2281198
	speed: 0.0290s/iter; left time: 1.1292s
Epoch: 10 cost time: 33.469074964523315
Epoch: 10, Steps: 1138 | Train Loss: 0.2201301 Vali Loss: 0.2292405 Test Loss: 0.3125062
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-07
>>>>>>>testing : ECL_96_96_6_emb_64_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (5165, 1, 96, 321) (5165, 1, 96, 321)
test shape: (5165, 96, 321) (5165, 96, 321)
mse:0.31034791469573975, mae:0.4007302522659302
Args in experiment:
Namespace(is_training=1, model_id='ECL_96_96_7_emb_64', model='xLSTM', data='custom', root_path='./data/electricity/', data_path='/input-data/electricity.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, enc_in=321, dec_in=7, c_out=321, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=50, batch_size=16, patience=10, learning_rate=0.0005, des='test', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, use_norm=True, partial_start_index=0, hidden_size=512, num_layers=2, mark_enc_in=4, embedding_dim=64, weight_decay=1e-06, kernal_size=7, num_heads_xlstm=4, qkv_proj_blocksize=2, proj_factor=1.3, num_blocks=7, slstm_at=1, grad_clip_norm=5.0, d_state=16, d_conv=4, expand=2)
Use GPU: cuda:0
{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-L/usr/local/cuda/lib', '-lcublas'], 'extra_cflags': ['-DSLSTM_HIDDEN_SIZE=64', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__'], 'extra_cuda_cflags': ['-Xptxas="-v"', '-gencode', 'arch=compute_80,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=64', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__']}
Using /home/thetayne/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/thetayne/.cache/torch_extensions/py310_cu121/slstm_HS64BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0/build.ninja...
Building extension module slstm_HS64BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module slstm_HS64BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
>>>>>>>start training : ECL_96_96_7_emb_64_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 18221
val 2537
test 5165
	iters: 100, epoch: 1 | loss: 0.3517103
	speed: 0.0697s/iter; left time: 3961.0582s
	iters: 200, epoch: 1 | loss: 0.3327131
	speed: 0.0512s/iter; left time: 2902.0375s
	iters: 300, epoch: 1 | loss: 0.2484562
	speed: 0.0502s/iter; left time: 2843.5903s
	iters: 400, epoch: 1 | loss: 0.2355507
	speed: 0.0474s/iter; left time: 2676.5554s
	iters: 500, epoch: 1 | loss: 0.1972330
	speed: 0.0545s/iter; left time: 3074.4830s
	iters: 600, epoch: 1 | loss: 0.1949771
	speed: 0.0489s/iter; left time: 2755.3927s
	iters: 700, epoch: 1 | loss: 0.1664617
	speed: 0.0558s/iter; left time: 3136.6067s
	iters: 800, epoch: 1 | loss: 0.1863299
	speed: 0.0467s/iter; left time: 2622.1167s
	iters: 900, epoch: 1 | loss: 0.1710486
	speed: 0.0506s/iter; left time: 2830.8866s
	iters: 1000, epoch: 1 | loss: 0.1522021
	speed: 0.0548s/iter; left time: 3065.8201s
	iters: 1100, epoch: 1 | loss: 0.1620243
	speed: 0.0561s/iter; left time: 3131.3009s
Epoch: 1 cost time: 60.34994697570801
Epoch: 1, Steps: 1138 | Train Loss: 0.2380443 Vali Loss: 0.2257968 Test Loss: 0.2990395
Validation loss decreased (inf --> 0.225797).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.1601419
	speed: 0.8884s/iter; left time: 49453.7568s
	iters: 200, epoch: 2 | loss: 0.1337289
	speed: 0.0524s/iter; left time: 2909.6307s
	iters: 300, epoch: 2 | loss: 0.1312932
	speed: 0.0493s/iter; left time: 2735.6347s
	iters: 400, epoch: 2 | loss: 0.1378003
	speed: 0.0507s/iter; left time: 2806.6955s
	iters: 500, epoch: 2 | loss: 0.1333184
	speed: 0.0492s/iter; left time: 2721.2001s
	iters: 600, epoch: 2 | loss: 0.1371023
	speed: 0.0557s/iter; left time: 3072.2797s
	iters: 700, epoch: 2 | loss: 0.1355948
	speed: 0.0529s/iter; left time: 2911.4838s
	iters: 800, epoch: 2 | loss: 0.1366595
	speed: 0.0519s/iter; left time: 2851.0739s
	iters: 900, epoch: 2 | loss: 0.1345537
	speed: 0.0477s/iter; left time: 2615.6467s
	iters: 1000, epoch: 2 | loss: 0.1349695
	speed: 0.0506s/iter; left time: 2770.4006s
	iters: 1100, epoch: 2 | loss: 0.1302703
	speed: 0.0545s/iter; left time: 2980.6757s
Epoch: 2 cost time: 60.252251625061035
Epoch: 2, Steps: 1138 | Train Loss: 0.1377581 Vali Loss: 0.2213426 Test Loss: 0.2941488
Validation loss decreased (0.225797 --> 0.221343).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.1281685
	speed: 0.8390s/iter; left time: 45747.6205s
	iters: 200, epoch: 3 | loss: 0.1257893
	speed: 0.0459s/iter; left time: 2499.0483s
	iters: 300, epoch: 3 | loss: 0.1385258
	speed: 0.0473s/iter; left time: 2568.2716s
	iters: 400, epoch: 3 | loss: 0.1232345
	speed: 0.0470s/iter; left time: 2546.9490s
	iters: 500, epoch: 3 | loss: 0.1305282
	speed: 0.0484s/iter; left time: 2618.5444s
	iters: 600, epoch: 3 | loss: 0.1257759
	speed: 0.0484s/iter; left time: 2613.0948s
	iters: 700, epoch: 3 | loss: 0.1287563
	speed: 0.0506s/iter; left time: 2729.1525s
	iters: 800, epoch: 3 | loss: 0.1201257
	speed: 0.0491s/iter; left time: 2641.4089s
	iters: 900, epoch: 3 | loss: 0.1176710
	speed: 0.0466s/iter; left time: 2504.0022s
	iters: 1000, epoch: 3 | loss: 0.1120957
	speed: 0.0503s/iter; left time: 2695.1393s
	iters: 1100, epoch: 3 | loss: 0.1303691
	speed: 0.0496s/iter; left time: 2654.9234s
Epoch: 3 cost time: 56.18547987937927
Epoch: 3, Steps: 1138 | Train Loss: 0.1247978 Vali Loss: 0.2306211 Test Loss: 0.3131453
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.1291201
	speed: 0.8406s/iter; left time: 44874.8553s
	iters: 200, epoch: 4 | loss: 0.1253080
	speed: 0.0495s/iter; left time: 2635.2336s
	iters: 300, epoch: 4 | loss: 0.1232260
	speed: 0.0485s/iter; left time: 2581.6578s
	iters: 400, epoch: 4 | loss: 0.1314058
	speed: 0.0488s/iter; left time: 2589.6931s
	iters: 500, epoch: 4 | loss: 0.1244673
	speed: 0.0476s/iter; left time: 2523.7881s
	iters: 600, epoch: 4 | loss: 0.1077543
	speed: 0.0476s/iter; left time: 2517.2669s
	iters: 700, epoch: 4 | loss: 0.1145982
	speed: 0.0456s/iter; left time: 2405.5009s
	iters: 800, epoch: 4 | loss: 0.1252884
	speed: 0.0479s/iter; left time: 2525.0422s
	iters: 900, epoch: 4 | loss: 0.1251142
	speed: 0.0466s/iter; left time: 2452.4368s
	iters: 1000, epoch: 4 | loss: 0.1159034
	speed: 0.0470s/iter; left time: 2466.4580s
	iters: 1100, epoch: 4 | loss: 0.1251084
	speed: 0.0469s/iter; left time: 2457.7582s
Epoch: 4 cost time: 55.97454071044922
Epoch: 4, Steps: 1138 | Train Loss: 0.1208352 Vali Loss: 0.2287215 Test Loss: 0.3042517
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.1208444
	speed: 0.8030s/iter; left time: 41953.4418s
	iters: 200, epoch: 5 | loss: 0.1127122
	speed: 0.0456s/iter; left time: 2377.9971s
	iters: 300, epoch: 5 | loss: 0.1115315
	speed: 0.0491s/iter; left time: 2557.7183s
	iters: 400, epoch: 5 | loss: 0.1281802
	speed: 0.0477s/iter; left time: 2479.9643s
	iters: 500, epoch: 5 | loss: 0.1161086
	speed: 0.0480s/iter; left time: 2490.2036s
	iters: 600, epoch: 5 | loss: 0.1247179
	speed: 0.0465s/iter; left time: 2404.7620s
	iters: 700, epoch: 5 | loss: 0.1217062
	speed: 0.0465s/iter; left time: 2399.2008s
	iters: 800, epoch: 5 | loss: 0.1261012
	speed: 0.0470s/iter; left time: 2420.5594s
	iters: 900, epoch: 5 | loss: 0.1197780
	speed: 0.0475s/iter; left time: 2442.4454s
	iters: 1000, epoch: 5 | loss: 0.1165714
	speed: 0.0476s/iter; left time: 2445.0379s
	iters: 1100, epoch: 5 | loss: 0.1162463
	speed: 0.0476s/iter; left time: 2441.3451s
Epoch: 5 cost time: 55.3342399597168
Epoch: 5, Steps: 1138 | Train Loss: 0.1190072 Vali Loss: 0.2311235 Test Loss: 0.3084489
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.1179620
	speed: 0.8088s/iter; left time: 41340.3627s
	iters: 200, epoch: 6 | loss: 0.1240108
	speed: 0.0484s/iter; left time: 2468.1388s
	iters: 300, epoch: 6 | loss: 0.1211545
	speed: 0.0475s/iter; left time: 2417.0990s
	iters: 400, epoch: 6 | loss: 0.1167110
	speed: 0.0502s/iter; left time: 2548.6400s
	iters: 500, epoch: 6 | loss: 0.1209304
	speed: 0.0493s/iter; left time: 2502.1086s
	iters: 600, epoch: 6 | loss: 0.1205516
	speed: 0.0483s/iter; left time: 2444.5485s
	iters: 700, epoch: 6 | loss: 0.1153762
	speed: 0.0492s/iter; left time: 2487.4495s
	iters: 800, epoch: 6 | loss: 0.1158040
	speed: 0.0478s/iter; left time: 2409.4335s
	iters: 900, epoch: 6 | loss: 0.1174674
	speed: 0.0467s/iter; left time: 2350.2154s
	iters: 1000, epoch: 6 | loss: 0.1202736
	speed: 0.0479s/iter; left time: 2403.2019s
	iters: 1100, epoch: 6 | loss: 0.1101607
	speed: 0.0477s/iter; left time: 2389.0534s
Epoch: 6 cost time: 56.53138041496277
Epoch: 6, Steps: 1138 | Train Loss: 0.1180690 Vali Loss: 0.2328062 Test Loss: 0.3106005
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.1123591
	speed: 0.8340s/iter; left time: 41678.4893s
	iters: 200, epoch: 7 | loss: 0.1132947
	speed: 0.0489s/iter; left time: 2437.6813s
	iters: 300, epoch: 7 | loss: 0.1231988
	speed: 0.0466s/iter; left time: 2320.2321s
	iters: 400, epoch: 7 | loss: 0.1073758
	speed: 0.0468s/iter; left time: 2324.7322s
	iters: 500, epoch: 7 | loss: 0.1155196
	speed: 0.0469s/iter; left time: 2326.4564s
	iters: 600, epoch: 7 | loss: 0.1229882
	speed: 0.0466s/iter; left time: 2303.6301s
	iters: 700, epoch: 7 | loss: 0.1170106
	speed: 0.0475s/iter; left time: 2347.5600s
	iters: 800, epoch: 7 | loss: 0.1144455
	speed: 0.0493s/iter; left time: 2429.7134s
	iters: 900, epoch: 7 | loss: 0.1165057
	speed: 0.0469s/iter; left time: 2308.6606s
	iters: 1000, epoch: 7 | loss: 0.1116335
	speed: 0.0490s/iter; left time: 2406.2685s
	iters: 1100, epoch: 7 | loss: 0.1250936
	speed: 0.0479s/iter; left time: 2344.1905s
Epoch: 7 cost time: 56.11875605583191
Epoch: 7, Steps: 1138 | Train Loss: 0.1175663 Vali Loss: 0.2326781 Test Loss: 0.3102675
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.1200568
	speed: 0.8499s/iter; left time: 41502.5113s
	iters: 200, epoch: 8 | loss: 0.1252172
	speed: 0.0487s/iter; left time: 2372.0759s
	iters: 300, epoch: 8 | loss: 0.1292225
	speed: 0.0474s/iter; left time: 2305.5205s
	iters: 400, epoch: 8 | loss: 0.1150066
	speed: 0.0484s/iter; left time: 2349.3789s
	iters: 500, epoch: 8 | loss: 0.1169952
	speed: 0.0458s/iter; left time: 2218.7112s
	iters: 600, epoch: 8 | loss: 0.1162384
	speed: 0.0461s/iter; left time: 2226.2941s
	iters: 700, epoch: 8 | loss: 0.1143414
	speed: 0.0483s/iter; left time: 2331.1697s
	iters: 800, epoch: 8 | loss: 0.1181933
	speed: 0.0489s/iter; left time: 2354.6386s
	iters: 900, epoch: 8 | loss: 0.1236277
	speed: 0.0475s/iter; left time: 2282.7223s
	iters: 1000, epoch: 8 | loss: 0.1188150
	speed: 0.0474s/iter; left time: 2271.7709s
	iters: 1100, epoch: 8 | loss: 0.1105594
	speed: 0.0480s/iter; left time: 2296.7722s
Epoch: 8 cost time: 56.27327060699463
Epoch: 8, Steps: 1138 | Train Loss: 0.1173248 Vali Loss: 0.2328384 Test Loss: 0.3098135
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.1132620
	speed: 0.8089s/iter; left time: 38582.7484s
	iters: 200, epoch: 9 | loss: 0.1153556
	speed: 0.0467s/iter; left time: 2222.8928s
	iters: 300, epoch: 9 | loss: 0.1135777
	speed: 0.0491s/iter; left time: 2331.4037s
	iters: 400, epoch: 9 | loss: 0.1213850
	speed: 0.0477s/iter; left time: 2260.4823s
	iters: 500, epoch: 9 | loss: 0.1189162
	speed: 0.0477s/iter; left time: 2257.1944s
	iters: 600, epoch: 9 | loss: 0.1204060
	speed: 0.0464s/iter; left time: 2191.0194s
	iters: 700, epoch: 9 | loss: 0.1273280
	speed: 0.0475s/iter; left time: 2237.0325s
	iters: 800, epoch: 9 | loss: 0.1069899
	speed: 0.0466s/iter; left time: 2191.7380s
	iters: 900, epoch: 9 | loss: 0.1093948
	speed: 0.0478s/iter; left time: 2242.6104s
	iters: 1000, epoch: 9 | loss: 0.1167177
	speed: 0.0477s/iter; left time: 2231.9824s
	iters: 1100, epoch: 9 | loss: 0.1101968
	speed: 0.0496s/iter; left time: 2318.1947s
Epoch: 9 cost time: 55.80889630317688
Epoch: 9, Steps: 1138 | Train Loss: 0.1172215 Vali Loss: 0.2336129 Test Loss: 0.3106906
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.1142524
	speed: 0.8019s/iter; left time: 37335.7408s
	iters: 200, epoch: 10 | loss: 0.1183218
	speed: 0.0468s/iter; left time: 2172.9705s
	iters: 300, epoch: 10 | loss: 0.1174842
	speed: 0.0557s/iter; left time: 2580.8247s
	iters: 400, epoch: 10 | loss: 0.1129022
	speed: 0.0559s/iter; left time: 2584.0684s
	iters: 500, epoch: 10 | loss: 0.1177280
	speed: 0.0522s/iter; left time: 2410.6280s
	iters: 600, epoch: 10 | loss: 0.1198537
	speed: 0.0516s/iter; left time: 2377.9157s
	iters: 700, epoch: 10 | loss: 0.1130877
	speed: 0.0482s/iter; left time: 2213.6497s
	iters: 800, epoch: 10 | loss: 0.1097205
	speed: 0.0489s/iter; left time: 2244.4563s
	iters: 900, epoch: 10 | loss: 0.1182562
	speed: 0.0539s/iter; left time: 2466.3096s
	iters: 1000, epoch: 10 | loss: 0.1288103
	speed: 0.0512s/iter; left time: 2338.2759s
	iters: 1100, epoch: 10 | loss: 0.1164410
	speed: 0.0547s/iter; left time: 2491.5833s
Epoch: 10 cost time: 60.34197211265564
Epoch: 10, Steps: 1138 | Train Loss: 0.1171666 Vali Loss: 0.2332260 Test Loss: 0.3105210
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.1172161
	speed: 0.8492s/iter; left time: 38569.6575s
	iters: 200, epoch: 11 | loss: 0.1113111
	speed: 0.0500s/iter; left time: 2267.3296s
	iters: 300, epoch: 11 | loss: 0.1109235
	speed: 0.0592s/iter; left time: 2678.0278s
	iters: 400, epoch: 11 | loss: 0.1266373
	speed: 0.0528s/iter; left time: 2382.8515s
	iters: 500, epoch: 11 | loss: 0.1223139
	speed: 0.0481s/iter; left time: 2166.8669s
	iters: 600, epoch: 11 | loss: 0.1112867
	speed: 0.0564s/iter; left time: 2535.2429s
	iters: 700, epoch: 11 | loss: 0.1118596
	speed: 0.0552s/iter; left time: 2472.3598s
	iters: 800, epoch: 11 | loss: 0.1173932
	speed: 0.0482s/iter; left time: 2157.5798s
	iters: 900, epoch: 11 | loss: 0.1174910
	speed: 0.0557s/iter; left time: 2487.4391s
	iters: 1000, epoch: 11 | loss: 0.1144626
	speed: 0.0612s/iter; left time: 2725.2693s
	iters: 1100, epoch: 11 | loss: 0.1151317
	speed: 0.0522s/iter; left time: 2319.1351s
Epoch: 11 cost time: 62.01287364959717
Epoch: 11, Steps: 1138 | Train Loss: 0.1171270 Vali Loss: 0.2333917 Test Loss: 0.3104812
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.1153323
	speed: 0.8691s/iter; left time: 38488.0363s
	iters: 200, epoch: 12 | loss: 0.1199621
	speed: 0.0488s/iter; left time: 2155.3239s
	iters: 300, epoch: 12 | loss: 0.1159391
	speed: 0.0497s/iter; left time: 2192.6832s
	iters: 400, epoch: 12 | loss: 0.1141714
	speed: 0.0511s/iter; left time: 2248.9451s
	iters: 500, epoch: 12 | loss: 0.1137399
	speed: 0.0461s/iter; left time: 2021.8330s
	iters: 600, epoch: 12 | loss: 0.1180837
	speed: 0.0502s/iter; left time: 2196.4863s
	iters: 700, epoch: 12 | loss: 0.1176460
	speed: 0.0509s/iter; left time: 2221.3990s
	iters: 800, epoch: 12 | loss: 0.1146639
	speed: 0.0463s/iter; left time: 2017.4979s
	iters: 900, epoch: 12 | loss: 0.1078115
	speed: 0.0491s/iter; left time: 2135.5219s
	iters: 1000, epoch: 12 | loss: 0.1165339
	speed: 0.0480s/iter; left time: 2083.5288s
	iters: 1100, epoch: 12 | loss: 0.1125846
	speed: 0.0470s/iter; left time: 2032.8668s
Epoch: 12 cost time: 57.0608115196228
Epoch: 12, Steps: 1138 | Train Loss: 0.1170773 Vali Loss: 0.2331407 Test Loss: 0.3106704
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : ECL_96_96_7_emb_64_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (5165, 1, 96, 321) (5165, 1, 96, 321)
test shape: (5165, 96, 321) (5165, 96, 321)
mse:0.2941487729549408, mae:0.3804894983768463
Args in experiment:
Namespace(is_training=1, model_id='ECL_96_96_8_emb_64', model='xLSTM', data='custom', root_path='./data/electricity/', data_path='/input-data/electricity.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, enc_in=321, dec_in=7, c_out=321, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=50, batch_size=16, patience=10, learning_rate=0.0005, des='test', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, use_norm=True, partial_start_index=0, hidden_size=512, num_layers=2, mark_enc_in=4, embedding_dim=64, weight_decay=1e-05, kernal_size=5, num_heads_xlstm=2, qkv_proj_blocksize=8, proj_factor=1.3, num_blocks=2, slstm_at=1, grad_clip_norm=5.0, d_state=16, d_conv=4, expand=2)
Use GPU: cuda:0
{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-L/usr/local/cuda/lib', '-lcublas'], 'extra_cflags': ['-DSLSTM_HIDDEN_SIZE=64', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=2', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__'], 'extra_cuda_cflags': ['-Xptxas="-v"', '-gencode', 'arch=compute_80,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=64', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=2', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__']}
Using /home/thetayne/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/thetayne/.cache/torch_extensions/py310_cu121/slstm_HS64BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0/build.ninja...
Building extension module slstm_HS64BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module slstm_HS64BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
>>>>>>>start training : ECL_96_96_8_emb_64_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 18221
val 2537
test 5165
	iters: 100, epoch: 1 | loss: 0.3593280
	speed: 0.0481s/iter; left time: 2729.6248s
	iters: 200, epoch: 1 | loss: 0.2943116
	speed: 0.0257s/iter; left time: 1457.4019s
	iters: 300, epoch: 1 | loss: 0.2461467
	speed: 0.0261s/iter; left time: 1474.8515s
	iters: 400, epoch: 1 | loss: 0.2468237
	speed: 0.0259s/iter; left time: 1462.9205s
	iters: 500, epoch: 1 | loss: 0.2464206
	speed: 0.0259s/iter; left time: 1461.2535s
	iters: 600, epoch: 1 | loss: 0.2083314
	speed: 0.0255s/iter; left time: 1435.0569s
	iters: 700, epoch: 1 | loss: 0.1856074
	speed: 0.0258s/iter; left time: 1447.9661s
	iters: 800, epoch: 1 | loss: 0.1592658
	speed: 0.0256s/iter; left time: 1438.8803s
	iters: 900, epoch: 1 | loss: 0.1620301
	speed: 0.0258s/iter; left time: 1442.1989s
	iters: 1000, epoch: 1 | loss: 0.1726350
	speed: 0.0258s/iter; left time: 1441.2089s
	iters: 1100, epoch: 1 | loss: 0.1598209
	speed: 0.0257s/iter; left time: 1434.2270s
Epoch: 1 cost time: 31.46945095062256
Epoch: 1, Steps: 1138 | Train Loss: 0.2497382 Vali Loss: 0.2240440 Test Loss: 0.3044836
Validation loss decreased (inf --> 0.224044).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.1628312
	speed: 0.4133s/iter; left time: 23003.5357s
	iters: 200, epoch: 2 | loss: 0.1522076
	speed: 0.0213s/iter; left time: 1184.4425s
	iters: 300, epoch: 2 | loss: 0.1537433
	speed: 0.0211s/iter; left time: 1169.4105s
	iters: 400, epoch: 2 | loss: 0.1536604
	speed: 0.0210s/iter; left time: 1159.8984s
	iters: 500, epoch: 2 | loss: 0.1367991
	speed: 0.0215s/iter; left time: 1185.9564s
	iters: 600, epoch: 2 | loss: 0.1567365
	speed: 0.0216s/iter; left time: 1193.3559s
	iters: 700, epoch: 2 | loss: 0.1514335
	speed: 0.0225s/iter; left time: 1238.6423s
	iters: 800, epoch: 2 | loss: 0.1398496
	speed: 0.0226s/iter; left time: 1242.6518s
	iters: 900, epoch: 2 | loss: 0.1221710
	speed: 0.0226s/iter; left time: 1239.7559s
	iters: 1000, epoch: 2 | loss: 0.1562058
	speed: 0.0230s/iter; left time: 1259.1312s
	iters: 1100, epoch: 2 | loss: 0.1439498
	speed: 0.0238s/iter; left time: 1302.0531s
Epoch: 2 cost time: 26.65084981918335
Epoch: 2, Steps: 1138 | Train Loss: 0.1449472 Vali Loss: 0.2133274 Test Loss: 0.2880931
Validation loss decreased (0.224044 --> 0.213327).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.1289139
	speed: 0.5064s/iter; left time: 27610.0092s
	iters: 200, epoch: 3 | loss: 0.1280988
	speed: 0.0227s/iter; left time: 1233.2313s
	iters: 300, epoch: 3 | loss: 0.1395803
	speed: 0.0225s/iter; left time: 1222.5170s
	iters: 400, epoch: 3 | loss: 0.1294042
	speed: 0.0234s/iter; left time: 1269.5264s
	iters: 500, epoch: 3 | loss: 0.1388542
	speed: 0.0234s/iter; left time: 1267.2124s
	iters: 600, epoch: 3 | loss: 0.1313662
	speed: 0.0237s/iter; left time: 1282.2244s
	iters: 700, epoch: 3 | loss: 0.1167884
	speed: 0.0228s/iter; left time: 1227.5642s
	iters: 800, epoch: 3 | loss: 0.1239618
	speed: 0.0227s/iter; left time: 1221.2377s
	iters: 900, epoch: 3 | loss: 0.1292519
	speed: 0.0230s/iter; left time: 1236.7484s
	iters: 1000, epoch: 3 | loss: 0.1248734
	speed: 0.0241s/iter; left time: 1290.9696s
	iters: 1100, epoch: 3 | loss: 0.1239022
	speed: 0.0244s/iter; left time: 1303.3918s
Epoch: 3 cost time: 28.26322603225708
Epoch: 3, Steps: 1138 | Train Loss: 0.1314725 Vali Loss: 0.2134907 Test Loss: 0.2832962
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.1346184
	speed: 0.4231s/iter; left time: 22587.4875s
	iters: 200, epoch: 4 | loss: 0.1249860
	speed: 0.0208s/iter; left time: 1106.5022s
	iters: 300, epoch: 4 | loss: 0.1415534
	speed: 0.0210s/iter; left time: 1119.0898s
	iters: 400, epoch: 4 | loss: 0.1346114
	speed: 0.0214s/iter; left time: 1134.6099s
	iters: 500, epoch: 4 | loss: 0.1335427
	speed: 0.0207s/iter; left time: 1095.3485s
	iters: 600, epoch: 4 | loss: 0.1130788
	speed: 0.0211s/iter; left time: 1118.3640s
	iters: 700, epoch: 4 | loss: 0.1358430
	speed: 0.0211s/iter; left time: 1114.1219s
	iters: 800, epoch: 4 | loss: 0.1259767
	speed: 0.0211s/iter; left time: 1112.0712s
	iters: 900, epoch: 4 | loss: 0.1165122
	speed: 0.0213s/iter; left time: 1118.5016s
	iters: 1000, epoch: 4 | loss: 0.1220408
	speed: 0.0212s/iter; left time: 1114.5343s
	iters: 1100, epoch: 4 | loss: 0.1224155
	speed: 0.0206s/iter; left time: 1081.0327s
Epoch: 4 cost time: 25.603914260864258
Epoch: 4, Steps: 1138 | Train Loss: 0.1274588 Vali Loss: 0.2198367 Test Loss: 0.2889826
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.1329038
	speed: 0.4173s/iter; left time: 21802.6233s
	iters: 200, epoch: 5 | loss: 0.1189343
	speed: 0.0212s/iter; left time: 1104.5331s
	iters: 300, epoch: 5 | loss: 0.1336570
	speed: 0.0209s/iter; left time: 1088.4873s
	iters: 400, epoch: 5 | loss: 0.1173447
	speed: 0.0210s/iter; left time: 1092.1852s
	iters: 500, epoch: 5 | loss: 0.1202439
	speed: 0.0208s/iter; left time: 1078.5726s
	iters: 600, epoch: 5 | loss: 0.1297512
	speed: 0.0211s/iter; left time: 1092.4198s
	iters: 700, epoch: 5 | loss: 0.1341837
	speed: 0.0212s/iter; left time: 1096.8155s
	iters: 800, epoch: 5 | loss: 0.1440812
	speed: 0.0212s/iter; left time: 1090.2615s
	iters: 900, epoch: 5 | loss: 0.1237540
	speed: 0.0207s/iter; left time: 1067.3288s
	iters: 1000, epoch: 5 | loss: 0.1242077
	speed: 0.0212s/iter; left time: 1088.4561s
	iters: 1100, epoch: 5 | loss: 0.1130156
	speed: 0.0212s/iter; left time: 1086.2814s
Epoch: 5 cost time: 25.431812524795532
Epoch: 5, Steps: 1138 | Train Loss: 0.1256802 Vali Loss: 0.2178295 Test Loss: 0.2881368
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.1268395
	speed: 0.4193s/iter; left time: 21428.6658s
	iters: 200, epoch: 6 | loss: 0.1192605
	speed: 0.0212s/iter; left time: 1081.5550s
	iters: 300, epoch: 6 | loss: 0.1266969
	speed: 0.0212s/iter; left time: 1079.1331s
	iters: 400, epoch: 6 | loss: 0.1245368
	speed: 0.0209s/iter; left time: 1062.3279s
	iters: 500, epoch: 6 | loss: 0.1217901
	speed: 0.0212s/iter; left time: 1076.7450s
	iters: 600, epoch: 6 | loss: 0.1221991
	speed: 0.0211s/iter; left time: 1068.2731s
	iters: 700, epoch: 6 | loss: 0.1230465
	speed: 0.0212s/iter; left time: 1071.0492s
	iters: 800, epoch: 6 | loss: 0.1238137
	speed: 0.0211s/iter; left time: 1064.1932s
	iters: 900, epoch: 6 | loss: 0.1206346
	speed: 0.0210s/iter; left time: 1058.0311s
	iters: 1000, epoch: 6 | loss: 0.1196607
	speed: 0.0208s/iter; left time: 1046.4057s
	iters: 1100, epoch: 6 | loss: 0.1327154
	speed: 0.0211s/iter; left time: 1057.3561s
Epoch: 6 cost time: 25.85229182243347
Epoch: 6, Steps: 1138 | Train Loss: 0.1247640 Vali Loss: 0.2205364 Test Loss: 0.2891991
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.1246304
	speed: 0.4148s/iter; left time: 20728.3671s
	iters: 200, epoch: 7 | loss: 0.1252021
	speed: 0.0212s/iter; left time: 1058.0561s
	iters: 300, epoch: 7 | loss: 0.1201542
	speed: 0.0209s/iter; left time: 1038.4565s
	iters: 400, epoch: 7 | loss: 0.1242374
	speed: 0.0210s/iter; left time: 1042.2154s
	iters: 500, epoch: 7 | loss: 0.1308147
	speed: 0.0211s/iter; left time: 1044.7086s
	iters: 600, epoch: 7 | loss: 0.1213642
	speed: 0.0210s/iter; left time: 1038.9649s
	iters: 700, epoch: 7 | loss: 0.1214444
	speed: 0.0210s/iter; left time: 1036.8935s
	iters: 800, epoch: 7 | loss: 0.1332321
	speed: 0.0212s/iter; left time: 1043.5321s
	iters: 900, epoch: 7 | loss: 0.1260833
	speed: 0.0210s/iter; left time: 1034.6310s
	iters: 1000, epoch: 7 | loss: 0.1253841
	speed: 0.0210s/iter; left time: 1031.9082s
	iters: 1100, epoch: 7 | loss: 0.1307524
	speed: 0.0211s/iter; left time: 1032.8898s
Epoch: 7 cost time: 25.454840183258057
Epoch: 7, Steps: 1138 | Train Loss: 0.1242703 Vali Loss: 0.2199412 Test Loss: 0.2893365
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.1213673
	speed: 0.4140s/iter; left time: 20217.2598s
	iters: 200, epoch: 8 | loss: 0.1376446
	speed: 0.0217s/iter; left time: 1058.1563s
	iters: 300, epoch: 8 | loss: 0.1244941
	speed: 0.0215s/iter; left time: 1046.2532s
	iters: 400, epoch: 8 | loss: 0.1181663
	speed: 0.0210s/iter; left time: 1019.8927s
	iters: 500, epoch: 8 | loss: 0.1351260
	speed: 0.0211s/iter; left time: 1023.7848s
	iters: 600, epoch: 8 | loss: 0.1318932
	speed: 0.0209s/iter; left time: 1011.9522s
	iters: 700, epoch: 8 | loss: 0.1252739
	speed: 0.0207s/iter; left time: 998.9437s
	iters: 800, epoch: 8 | loss: 0.1282153
	speed: 0.0208s/iter; left time: 1000.4183s
	iters: 900, epoch: 8 | loss: 0.1162581
	speed: 0.0211s/iter; left time: 1012.4946s
	iters: 1000, epoch: 8 | loss: 0.1226151
	speed: 0.0210s/iter; left time: 1006.2226s
	iters: 1100, epoch: 8 | loss: 0.1133989
	speed: 0.0208s/iter; left time: 995.1167s
Epoch: 8 cost time: 25.575153589248657
Epoch: 8, Steps: 1138 | Train Loss: 0.1240363 Vali Loss: 0.2212741 Test Loss: 0.2897300
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.1250350
	speed: 0.4171s/iter; left time: 19896.2573s
	iters: 200, epoch: 9 | loss: 0.1276130
	speed: 0.0212s/iter; left time: 1008.4473s
	iters: 300, epoch: 9 | loss: 0.1228398
	speed: 0.0210s/iter; left time: 995.6269s
	iters: 400, epoch: 9 | loss: 0.1227896
	speed: 0.0212s/iter; left time: 1006.7086s
	iters: 500, epoch: 9 | loss: 0.1338506
	speed: 0.0221s/iter; left time: 1045.4777s
	iters: 600, epoch: 9 | loss: 0.1251814
	speed: 0.0213s/iter; left time: 1006.8795s
	iters: 700, epoch: 9 | loss: 0.1278939
	speed: 0.0215s/iter; left time: 1014.2174s
	iters: 800, epoch: 9 | loss: 0.1245771
	speed: 0.0215s/iter; left time: 1010.1953s
	iters: 900, epoch: 9 | loss: 0.1265279
	speed: 0.0217s/iter; left time: 1017.0054s
	iters: 1000, epoch: 9 | loss: 0.1237698
	speed: 0.0211s/iter; left time: 987.1336s
	iters: 1100, epoch: 9 | loss: 0.1233638
	speed: 0.0213s/iter; left time: 992.6259s
Epoch: 9 cost time: 25.972588300704956
Epoch: 9, Steps: 1138 | Train Loss: 0.1239014 Vali Loss: 0.2208181 Test Loss: 0.2898093
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.1273220
	speed: 0.4196s/iter; left time: 19533.8987s
	iters: 200, epoch: 10 | loss: 0.1296409
	speed: 0.0213s/iter; left time: 991.6619s
	iters: 300, epoch: 10 | loss: 0.1260500
	speed: 0.0212s/iter; left time: 980.8837s
	iters: 400, epoch: 10 | loss: 0.1301562
	speed: 0.0213s/iter; left time: 985.2408s
	iters: 500, epoch: 10 | loss: 0.1345722
	speed: 0.0213s/iter; left time: 981.6897s
	iters: 600, epoch: 10 | loss: 0.1135749
	speed: 0.0210s/iter; left time: 966.5505s
	iters: 700, epoch: 10 | loss: 0.1289835
	speed: 0.0210s/iter; left time: 967.1921s
	iters: 800, epoch: 10 | loss: 0.1231013
	speed: 0.0212s/iter; left time: 970.6354s
	iters: 900, epoch: 10 | loss: 0.1381624
	speed: 0.0213s/iter; left time: 975.2149s
	iters: 1000, epoch: 10 | loss: 0.1219278
	speed: 0.0212s/iter; left time: 969.4447s
	iters: 1100, epoch: 10 | loss: 0.1263242
	speed: 0.0213s/iter; left time: 970.4690s
Epoch: 10 cost time: 25.789353847503662
Epoch: 10, Steps: 1138 | Train Loss: 0.1238442 Vali Loss: 0.2215439 Test Loss: 0.2902805
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.1258399
	speed: 0.4191s/iter; left time: 19034.6895s
	iters: 200, epoch: 11 | loss: 0.1129693
	speed: 0.0216s/iter; left time: 979.8994s
	iters: 300, epoch: 11 | loss: 0.1258142
	speed: 0.0216s/iter; left time: 978.2432s
	iters: 400, epoch: 11 | loss: 0.1224282
	speed: 0.0215s/iter; left time: 967.8488s
	iters: 500, epoch: 11 | loss: 0.1320286
	speed: 0.0217s/iter; left time: 977.8691s
	iters: 600, epoch: 11 | loss: 0.1188478
	speed: 0.0219s/iter; left time: 985.7439s
	iters: 700, epoch: 11 | loss: 0.1345744
	speed: 0.0216s/iter; left time: 969.1106s
	iters: 800, epoch: 11 | loss: 0.1159793
	speed: 0.0214s/iter; left time: 958.8482s
	iters: 900, epoch: 11 | loss: 0.1247523
	speed: 0.0212s/iter; left time: 946.1141s
	iters: 1000, epoch: 11 | loss: 0.1184684
	speed: 0.0213s/iter; left time: 949.2603s
	iters: 1100, epoch: 11 | loss: 0.1245374
	speed: 0.0215s/iter; left time: 954.4351s
Epoch: 11 cost time: 26.1003737449646
Epoch: 11, Steps: 1138 | Train Loss: 0.1238353 Vali Loss: 0.2216454 Test Loss: 0.2902908
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.1256329
	speed: 0.4174s/iter; left time: 18485.0155s
	iters: 200, epoch: 12 | loss: 0.1190474
	speed: 0.0210s/iter; left time: 929.0693s
	iters: 300, epoch: 12 | loss: 0.1245440
	speed: 0.0212s/iter; left time: 933.0885s
	iters: 400, epoch: 12 | loss: 0.1254310
	speed: 0.0212s/iter; left time: 931.4994s
	iters: 500, epoch: 12 | loss: 0.1222255
	speed: 0.0209s/iter; left time: 918.9926s
	iters: 600, epoch: 12 | loss: 0.1219420
	speed: 0.0211s/iter; left time: 925.3841s
	iters: 700, epoch: 12 | loss: 0.1379577
	speed: 0.0216s/iter; left time: 944.5421s
	iters: 800, epoch: 12 | loss: 0.1120579
	speed: 0.0208s/iter; left time: 904.4728s
	iters: 900, epoch: 12 | loss: 0.1248660
	speed: 0.0211s/iter; left time: 917.1324s
	iters: 1000, epoch: 12 | loss: 0.1187673
	speed: 0.0215s/iter; left time: 932.3978s
	iters: 1100, epoch: 12 | loss: 0.1211603
	speed: 0.0224s/iter; left time: 970.4445s
Epoch: 12 cost time: 25.755180835723877
Epoch: 12, Steps: 1138 | Train Loss: 0.1238175 Vali Loss: 0.2217062 Test Loss: 0.2904159
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : ECL_96_96_8_emb_64_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (5165, 1, 96, 321) (5165, 1, 96, 321)
test shape: (5165, 96, 321) (5165, 96, 321)
mse:0.28809261322021484, mae:0.3798942267894745
Args in experiment:
Namespace(is_training=1, model_id='ECL_96_96_9_emb_64', model='xLSTM', data='custom', root_path='./data/electricity/', data_path='/input-data/electricity.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, enc_in=321, dec_in=7, c_out=321, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=50, batch_size=16, patience=10, learning_rate=0.0005, des='test', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, use_norm=True, partial_start_index=0, hidden_size=512, num_layers=2, mark_enc_in=4, embedding_dim=64, weight_decay=1e-05, kernal_size=3, num_heads_xlstm=4, qkv_proj_blocksize=8, proj_factor=1.3, num_blocks=3, slstm_at=1, grad_clip_norm=0.5, d_state=16, d_conv=4, expand=2)
Use GPU: cuda:0
{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-L/usr/local/cuda/lib', '-lcublas'], 'extra_cflags': ['-DSLSTM_HIDDEN_SIZE=64', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__'], 'extra_cuda_cflags': ['-Xptxas="-v"', '-gencode', 'arch=compute_80,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=64', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__']}
Using /home/thetayne/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/thetayne/.cache/torch_extensions/py310_cu121/slstm_HS64BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0/build.ninja...
Building extension module slstm_HS64BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module slstm_HS64BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
>>>>>>>start training : ECL_96_96_9_emb_64_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 18221
val 2537
test 5165
	iters: 100, epoch: 1 | loss: 0.3345266
	speed: 0.0454s/iter; left time: 2578.3519s
	iters: 200, epoch: 1 | loss: 0.3102588
	speed: 0.0251s/iter; left time: 1422.8290s
	iters: 300, epoch: 1 | loss: 0.2525069
	speed: 0.0261s/iter; left time: 1474.8903s
	iters: 400, epoch: 1 | loss: 0.2439515
	speed: 0.0265s/iter; left time: 1496.9328s
	iters: 500, epoch: 1 | loss: 0.2228943
	speed: 0.0258s/iter; left time: 1456.5564s
	iters: 600, epoch: 1 | loss: 0.1864067
	speed: 0.0252s/iter; left time: 1420.1864s
	iters: 700, epoch: 1 | loss: 0.2050419
	speed: 0.0254s/iter; left time: 1425.3463s
	iters: 800, epoch: 1 | loss: 0.1610620
	speed: 0.0266s/iter; left time: 1490.0254s
	iters: 900, epoch: 1 | loss: 0.1750047
	speed: 0.0290s/iter; left time: 1621.3251s
	iters: 1000, epoch: 1 | loss: 0.1523261
	speed: 0.0296s/iter; left time: 1652.2818s
	iters: 1100, epoch: 1 | loss: 0.1685749
	speed: 0.0299s/iter; left time: 1670.8162s
Epoch: 1 cost time: 32.467498540878296
Epoch: 1, Steps: 1138 | Train Loss: 0.2435224 Vali Loss: 0.2377998 Test Loss: 0.2976094
Validation loss decreased (inf --> 0.237800).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.1574347
	speed: 0.5576s/iter; left time: 31035.4895s
	iters: 200, epoch: 2 | loss: 0.1358330
	speed: 0.0287s/iter; left time: 1592.9591s
	iters: 300, epoch: 2 | loss: 0.1479066
	speed: 0.0297s/iter; left time: 1649.1407s
	iters: 400, epoch: 2 | loss: 0.1237972
	speed: 0.0313s/iter; left time: 1735.4992s
	iters: 500, epoch: 2 | loss: 0.1425412
	speed: 0.0311s/iter; left time: 1720.4751s
	iters: 600, epoch: 2 | loss: 0.1489990
	speed: 0.0310s/iter; left time: 1709.6969s
	iters: 700, epoch: 2 | loss: 0.1454548
	speed: 0.0312s/iter; left time: 1719.7960s
	iters: 800, epoch: 2 | loss: 0.1306954
	speed: 0.0310s/iter; left time: 1705.3856s
	iters: 900, epoch: 2 | loss: 0.1351625
	speed: 0.0306s/iter; left time: 1676.4474s
	iters: 1000, epoch: 2 | loss: 0.1494857
	speed: 0.0295s/iter; left time: 1618.0138s
	iters: 1100, epoch: 2 | loss: 0.1258320
	speed: 0.0303s/iter; left time: 1657.5408s
Epoch: 2 cost time: 36.16775822639465
Epoch: 2, Steps: 1138 | Train Loss: 0.1428862 Vali Loss: 0.2329612 Test Loss: 0.2948994
Validation loss decreased (0.237800 --> 0.232961).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.1391047
	speed: 0.5636s/iter; left time: 30728.2329s
	iters: 200, epoch: 3 | loss: 0.1352948
	speed: 0.0261s/iter; left time: 1419.3219s
	iters: 300, epoch: 3 | loss: 0.1272917
	speed: 0.0275s/iter; left time: 1496.0455s
	iters: 400, epoch: 3 | loss: 0.1297205
	speed: 0.0295s/iter; left time: 1600.6587s
	iters: 500, epoch: 3 | loss: 0.1278518
	speed: 0.0288s/iter; left time: 1557.7170s
	iters: 600, epoch: 3 | loss: 0.1275465
	speed: 0.0287s/iter; left time: 1548.1506s
	iters: 700, epoch: 3 | loss: 0.1244756
	speed: 0.0291s/iter; left time: 1570.0366s
	iters: 800, epoch: 3 | loss: 0.1429242
	speed: 0.0291s/iter; left time: 1563.6415s
	iters: 900, epoch: 3 | loss: 0.1305639
	speed: 0.0287s/iter; left time: 1541.7722s
	iters: 1000, epoch: 3 | loss: 0.1289407
	speed: 0.0296s/iter; left time: 1589.1862s
	iters: 1100, epoch: 3 | loss: 0.1268784
	speed: 0.0287s/iter; left time: 1538.5040s
Epoch: 3 cost time: 33.98078393936157
Epoch: 3, Steps: 1138 | Train Loss: 0.1296601 Vali Loss: 0.2494381 Test Loss: 0.2944520
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.1380904
	speed: 0.5492s/iter; left time: 29321.6606s
	iters: 200, epoch: 4 | loss: 0.1303436
	speed: 0.0259s/iter; left time: 1378.7642s
	iters: 300, epoch: 4 | loss: 0.1279653
	speed: 0.0262s/iter; left time: 1392.6889s
	iters: 400, epoch: 4 | loss: 0.1291877
	speed: 0.0287s/iter; left time: 1521.6797s
	iters: 500, epoch: 4 | loss: 0.1403965
	speed: 0.0292s/iter; left time: 1549.7766s
	iters: 600, epoch: 4 | loss: 0.1356688
	speed: 0.0293s/iter; left time: 1547.9938s
	iters: 700, epoch: 4 | loss: 0.1235039
	speed: 0.0291s/iter; left time: 1537.4123s
	iters: 800, epoch: 4 | loss: 0.1193104
	speed: 0.0291s/iter; left time: 1534.5510s
	iters: 900, epoch: 4 | loss: 0.1200731
	speed: 0.0294s/iter; left time: 1544.3242s
	iters: 1000, epoch: 4 | loss: 0.1269064
	speed: 0.0288s/iter; left time: 1509.9842s
	iters: 1100, epoch: 4 | loss: 0.1151835
	speed: 0.0290s/iter; left time: 1520.4524s
Epoch: 4 cost time: 33.67204737663269
Epoch: 4, Steps: 1138 | Train Loss: 0.1257882 Vali Loss: 0.2603973 Test Loss: 0.2972164
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.1129594
	speed: 0.5585s/iter; left time: 29178.7657s
	iters: 200, epoch: 5 | loss: 0.1296533
	speed: 0.0250s/iter; left time: 1303.3498s
	iters: 300, epoch: 5 | loss: 0.1230582
	speed: 0.0259s/iter; left time: 1346.4619s
	iters: 400, epoch: 5 | loss: 0.1328216
	speed: 0.0263s/iter; left time: 1367.0620s
	iters: 500, epoch: 5 | loss: 0.1130395
	speed: 0.0257s/iter; left time: 1330.3820s
	iters: 600, epoch: 5 | loss: 0.1227236
	speed: 0.0255s/iter; left time: 1321.5611s
	iters: 700, epoch: 5 | loss: 0.1210532
	speed: 0.0269s/iter; left time: 1390.7465s
	iters: 800, epoch: 5 | loss: 0.1171288
	speed: 0.0286s/iter; left time: 1475.6436s
	iters: 900, epoch: 5 | loss: 0.1220460
	speed: 0.0286s/iter; left time: 1469.5697s
	iters: 1000, epoch: 5 | loss: 0.1184151
	speed: 0.0290s/iter; left time: 1487.1058s
	iters: 1100, epoch: 5 | loss: 0.1219400
	speed: 0.0284s/iter; left time: 1457.9572s
Epoch: 5 cost time: 32.168797731399536
Epoch: 5, Steps: 1138 | Train Loss: 0.1239753 Vali Loss: 0.2646050 Test Loss: 0.2982841
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.1172731
	speed: 0.5343s/iter; left time: 27307.3724s
	iters: 200, epoch: 6 | loss: 0.1317307
	speed: 0.0295s/iter; left time: 1506.2938s
	iters: 300, epoch: 6 | loss: 0.1268097
	speed: 0.0295s/iter; left time: 1503.7286s
	iters: 400, epoch: 6 | loss: 0.1337183
	speed: 0.0289s/iter; left time: 1467.5191s
	iters: 500, epoch: 6 | loss: 0.1140921
	speed: 0.0291s/iter; left time: 1473.3028s
	iters: 600, epoch: 6 | loss: 0.1400912
	speed: 0.0297s/iter; left time: 1503.9664s
	iters: 700, epoch: 6 | loss: 0.1147111
	speed: 0.0293s/iter; left time: 1482.1998s
	iters: 800, epoch: 6 | loss: 0.1178064
	speed: 0.0296s/iter; left time: 1490.7788s
	iters: 900, epoch: 6 | loss: 0.1296171
	speed: 0.0295s/iter; left time: 1481.7562s
	iters: 1000, epoch: 6 | loss: 0.1185691
	speed: 0.0291s/iter; left time: 1462.7405s
	iters: 1100, epoch: 6 | loss: 0.1125539
	speed: 0.0295s/iter; left time: 1479.1384s
Epoch: 6 cost time: 34.61393594741821
Epoch: 6, Steps: 1138 | Train Loss: 0.1230569 Vali Loss: 0.2660940 Test Loss: 0.2987100
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.1190553
	speed: 0.5594s/iter; left time: 27952.8345s
	iters: 200, epoch: 7 | loss: 0.1235104
	speed: 0.0268s/iter; left time: 1334.1478s
	iters: 300, epoch: 7 | loss: 0.1267401
	speed: 0.0287s/iter; left time: 1428.8019s
	iters: 400, epoch: 7 | loss: 0.1191198
	speed: 0.0288s/iter; left time: 1432.4433s
	iters: 500, epoch: 7 | loss: 0.1184292
	speed: 0.0291s/iter; left time: 1442.9336s
	iters: 600, epoch: 7 | loss: 0.1337994
	speed: 0.0285s/iter; left time: 1408.7576s
	iters: 700, epoch: 7 | loss: 0.1172868
	speed: 0.0293s/iter; left time: 1444.1968s
	iters: 800, epoch: 7 | loss: 0.1278801
	speed: 0.0289s/iter; left time: 1425.6928s
	iters: 900, epoch: 7 | loss: 0.1253189
	speed: 0.0284s/iter; left time: 1394.5274s
	iters: 1000, epoch: 7 | loss: 0.1152331
	speed: 0.0289s/iter; left time: 1420.2886s
	iters: 1100, epoch: 7 | loss: 0.1188999
	speed: 0.0292s/iter; left time: 1428.6953s
Epoch: 7 cost time: 33.71259880065918
Epoch: 7, Steps: 1138 | Train Loss: 0.1225484 Vali Loss: 0.2681158 Test Loss: 0.2994454
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.1217664
	speed: 0.5558s/iter; left time: 27140.4753s
	iters: 200, epoch: 8 | loss: 0.1149819
	speed: 0.0268s/iter; left time: 1305.4713s
	iters: 300, epoch: 8 | loss: 0.1212150
	speed: 0.0294s/iter; left time: 1431.8357s
	iters: 400, epoch: 8 | loss: 0.1196635
	speed: 0.0291s/iter; left time: 1411.3476s
	iters: 500, epoch: 8 | loss: 0.1154940
	speed: 0.0288s/iter; left time: 1392.9980s
	iters: 600, epoch: 8 | loss: 0.1206714
	speed: 0.0290s/iter; left time: 1402.4787s
	iters: 700, epoch: 8 | loss: 0.1279221
	speed: 0.0294s/iter; left time: 1417.5978s
	iters: 800, epoch: 8 | loss: 0.1219129
	speed: 0.0291s/iter; left time: 1398.7816s
	iters: 900, epoch: 8 | loss: 0.1159321
	speed: 0.0295s/iter; left time: 1416.9053s
	iters: 1000, epoch: 8 | loss: 0.1336118
	speed: 0.0294s/iter; left time: 1411.4089s
	iters: 1100, epoch: 8 | loss: 0.1153923
	speed: 0.0297s/iter; left time: 1419.2528s
Epoch: 8 cost time: 34.188742876052856
Epoch: 8, Steps: 1138 | Train Loss: 0.1223142 Vali Loss: 0.2691720 Test Loss: 0.3004951
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.1242629
	speed: 0.5505s/iter; left time: 26254.8661s
	iters: 200, epoch: 9 | loss: 0.1289091
	speed: 0.0270s/iter; left time: 1285.8353s
	iters: 300, epoch: 9 | loss: 0.1215196
	speed: 0.0295s/iter; left time: 1401.0894s
	iters: 400, epoch: 9 | loss: 0.1232348
	speed: 0.0287s/iter; left time: 1360.9297s
	iters: 500, epoch: 9 | loss: 0.1198726
	speed: 0.0290s/iter; left time: 1373.2985s
	iters: 600, epoch: 9 | loss: 0.1220016
	speed: 0.0290s/iter; left time: 1369.5967s
	iters: 700, epoch: 9 | loss: 0.1227782
	speed: 0.0292s/iter; left time: 1373.3670s
	iters: 800, epoch: 9 | loss: 0.1299274
	speed: 0.0288s/iter; left time: 1351.4981s
	iters: 900, epoch: 9 | loss: 0.1328627
	speed: 0.0288s/iter; left time: 1352.0155s
	iters: 1000, epoch: 9 | loss: 0.1238753
	speed: 0.0293s/iter; left time: 1371.4288s
	iters: 1100, epoch: 9 | loss: 0.1133615
	speed: 0.0299s/iter; left time: 1398.3650s
Epoch: 9 cost time: 34.18519425392151
Epoch: 9, Steps: 1138 | Train Loss: 0.1221948 Vali Loss: 0.2687817 Test Loss: 0.3000701
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.1273776
	speed: 0.5689s/iter; left time: 26488.3323s
	iters: 200, epoch: 10 | loss: 0.1211139
	speed: 0.0274s/iter; left time: 1271.1478s
	iters: 300, epoch: 10 | loss: 0.1242767
	speed: 0.0292s/iter; left time: 1355.6668s
	iters: 400, epoch: 10 | loss: 0.1250823
	speed: 0.0292s/iter; left time: 1352.6224s
	iters: 500, epoch: 10 | loss: 0.1189786
	speed: 0.0291s/iter; left time: 1343.6725s
	iters: 600, epoch: 10 | loss: 0.1253948
	speed: 0.0293s/iter; left time: 1351.5150s
	iters: 700, epoch: 10 | loss: 0.1264035
	speed: 0.0290s/iter; left time: 1334.6551s
	iters: 800, epoch: 10 | loss: 0.1218165
	speed: 0.0292s/iter; left time: 1338.9360s
	iters: 900, epoch: 10 | loss: 0.1080192
	speed: 0.0290s/iter; left time: 1324.7768s
	iters: 1000, epoch: 10 | loss: 0.1190576
	speed: 0.0290s/iter; left time: 1324.8198s
	iters: 1100, epoch: 10 | loss: 0.1152806
	speed: 0.0286s/iter; left time: 1302.4718s
Epoch: 10 cost time: 34.26399755477905
Epoch: 10, Steps: 1138 | Train Loss: 0.1221142 Vali Loss: 0.2696250 Test Loss: 0.3004305
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.1313254
	speed: 0.5694s/iter; left time: 25863.5721s
	iters: 200, epoch: 11 | loss: 0.1230654
	speed: 0.0260s/iter; left time: 1180.1924s
	iters: 300, epoch: 11 | loss: 0.1274718
	speed: 0.0254s/iter; left time: 1146.4798s
	iters: 400, epoch: 11 | loss: 0.1270898
	speed: 0.0248s/iter; left time: 1118.5928s
	iters: 500, epoch: 11 | loss: 0.1331934
	speed: 0.0251s/iter; left time: 1128.7514s
	iters: 600, epoch: 11 | loss: 0.1194866
	speed: 0.0259s/iter; left time: 1164.7379s
	iters: 700, epoch: 11 | loss: 0.1211590
	speed: 0.0268s/iter; left time: 1202.1513s
	iters: 800, epoch: 11 | loss: 0.1277952
	speed: 0.0272s/iter; left time: 1217.2202s
	iters: 900, epoch: 11 | loss: 0.1147928
	speed: 0.0289s/iter; left time: 1289.3883s
	iters: 1000, epoch: 11 | loss: 0.1194659
	speed: 0.0293s/iter; left time: 1304.4046s
	iters: 1100, epoch: 11 | loss: 0.1168710
	speed: 0.0300s/iter; left time: 1332.7568s
Epoch: 11 cost time: 32.24085712432861
Epoch: 11, Steps: 1138 | Train Loss: 0.1221198 Vali Loss: 0.2692678 Test Loss: 0.3004941
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.1185996
	speed: 0.5549s/iter; left time: 24574.7270s
	iters: 200, epoch: 12 | loss: 0.1298343
	speed: 0.0255s/iter; left time: 1128.0559s
	iters: 300, epoch: 12 | loss: 0.1208923
	speed: 0.0254s/iter; left time: 1117.9010s
	iters: 400, epoch: 12 | loss: 0.1265357
	speed: 0.0299s/iter; left time: 1316.0253s
	iters: 500, epoch: 12 | loss: 0.1325203
	speed: 0.0294s/iter; left time: 1291.0541s
	iters: 600, epoch: 12 | loss: 0.1305089
	speed: 0.0288s/iter; left time: 1262.3113s
	iters: 700, epoch: 12 | loss: 0.1272494
	speed: 0.0293s/iter; left time: 1279.0553s
	iters: 800, epoch: 12 | loss: 0.1283246
	speed: 0.0288s/iter; left time: 1254.6840s
	iters: 900, epoch: 12 | loss: 0.1231745
	speed: 0.0288s/iter; left time: 1251.1946s
	iters: 1000, epoch: 12 | loss: 0.1258207
	speed: 0.0283s/iter; left time: 1225.6026s
	iters: 1100, epoch: 12 | loss: 0.1255688
	speed: 0.0287s/iter; left time: 1242.2643s
Epoch: 12 cost time: 33.33507943153381
Epoch: 12, Steps: 1138 | Train Loss: 0.1220782 Vali Loss: 0.2694559 Test Loss: 0.3004973
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : ECL_96_96_9_emb_64_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (5165, 1, 96, 321) (5165, 1, 96, 321)
test shape: (5165, 96, 321) (5165, 96, 321)
mse:0.2948997914791107, mae:0.38166344165802
Args in experiment:
Namespace(is_training=1, model_id='ECL_96_96_10_emb_64', model='xLSTM', data='custom', root_path='./data/electricity/', data_path='/input-data/electricity.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, enc_in=321, dec_in=7, c_out=321, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.3, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=50, batch_size=8, patience=10, learning_rate=0.001, des='test', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, use_norm=True, partial_start_index=0, hidden_size=512, num_layers=2, mark_enc_in=4, embedding_dim=64, weight_decay=0.0001, kernal_size=3, num_heads_xlstm=4, qkv_proj_blocksize=4, proj_factor=1.3, num_blocks=3, slstm_at=1, grad_clip_norm=0.5, d_state=16, d_conv=4, expand=2)
Use GPU: cuda:0
{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-L/usr/local/cuda/lib', '-lcublas'], 'extra_cflags': ['-DSLSTM_HIDDEN_SIZE=64', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__'], 'extra_cuda_cflags': ['-Xptxas="-v"', '-gencode', 'arch=compute_80,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=64', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__']}
Using /home/thetayne/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/thetayne/.cache/torch_extensions/py310_cu121/slstm_HS64BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0/build.ninja...
Building extension module slstm_HS64BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module slstm_HS64BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
>>>>>>>start training : ECL_96_96_10_emb_64_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 18221
val 2537
test 5165
	iters: 100, epoch: 1 | loss: 0.4717282
	speed: 0.0429s/iter; left time: 4881.9562s
	iters: 200, epoch: 1 | loss: 0.3267635
	speed: 0.0212s/iter; left time: 2414.6957s
	iters: 300, epoch: 1 | loss: 0.2557420
	speed: 0.0224s/iter; left time: 2539.3981s
	iters: 400, epoch: 1 | loss: 0.2703675
	speed: 0.0210s/iter; left time: 2385.3094s
	iters: 500, epoch: 1 | loss: 0.2211152
	speed: 0.0211s/iter; left time: 2388.2144s
	iters: 600, epoch: 1 | loss: 0.2039868
	speed: 0.0210s/iter; left time: 2377.3342s
	iters: 700, epoch: 1 | loss: 0.1975453
	speed: 0.0211s/iter; left time: 2388.1949s
	iters: 800, epoch: 1 | loss: 0.2127582
	speed: 0.0209s/iter; left time: 2358.9228s
	iters: 900, epoch: 1 | loss: 0.1787928
	speed: 0.0210s/iter; left time: 2373.6998s
	iters: 1000, epoch: 1 | loss: 0.1993251
	speed: 0.0208s/iter; left time: 2348.2408s
	iters: 1100, epoch: 1 | loss: 0.1798555
	speed: 0.0209s/iter; left time: 2353.4146s
	iters: 1200, epoch: 1 | loss: 0.1835386
	speed: 0.0211s/iter; left time: 2371.3702s
	iters: 1300, epoch: 1 | loss: 0.1810056
	speed: 0.0229s/iter; left time: 2574.3851s
	iters: 1400, epoch: 1 | loss: 0.1658253
	speed: 0.0225s/iter; left time: 2533.8093s
	iters: 1500, epoch: 1 | loss: 0.1562362
	speed: 0.0230s/iter; left time: 2585.9518s
	iters: 1600, epoch: 1 | loss: 0.1988882
	speed: 0.0229s/iter; left time: 2575.6087s
	iters: 1700, epoch: 1 | loss: 0.1657468
	speed: 0.0227s/iter; left time: 2548.3917s
	iters: 1800, epoch: 1 | loss: 0.1696842
	speed: 0.0233s/iter; left time: 2608.5615s
	iters: 1900, epoch: 1 | loss: 0.1929585
	speed: 0.0232s/iter; left time: 2595.4778s
	iters: 2000, epoch: 1 | loss: 0.2092295
	speed: 0.0231s/iter; left time: 2578.6523s
	iters: 2100, epoch: 1 | loss: 0.1461740
	speed: 0.0225s/iter; left time: 2512.0486s
	iters: 2200, epoch: 1 | loss: 0.1544784
	speed: 0.0225s/iter; left time: 2515.0320s
Epoch: 1 cost time: 52.15396070480347
Epoch: 1, Steps: 2277 | Train Loss: 0.2198426 Vali Loss: 0.2170155 Test Loss: 0.2704343
Validation loss decreased (inf --> 0.217016).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.1538790
	speed: 0.5524s/iter; left time: 61579.8854s
	iters: 200, epoch: 2 | loss: 0.1794140
	speed: 0.0211s/iter; left time: 2345.0858s
	iters: 300, epoch: 2 | loss: 0.1843872
	speed: 0.0209s/iter; left time: 2323.1882s
	iters: 400, epoch: 2 | loss: 0.1773931
	speed: 0.0230s/iter; left time: 2558.9729s
	iters: 500, epoch: 2 | loss: 0.1790978
	speed: 0.0230s/iter; left time: 2558.6210s
	iters: 600, epoch: 2 | loss: 0.1803946
	speed: 0.0235s/iter; left time: 2604.7756s
	iters: 700, epoch: 2 | loss: 0.1681741
	speed: 0.0226s/iter; left time: 2506.5919s
	iters: 800, epoch: 2 | loss: 0.1719890
	speed: 0.0227s/iter; left time: 2519.8643s
	iters: 900, epoch: 2 | loss: 0.1748714
	speed: 0.0232s/iter; left time: 2562.3330s
	iters: 1000, epoch: 2 | loss: 0.1819058
	speed: 0.0230s/iter; left time: 2545.5211s
	iters: 1100, epoch: 2 | loss: 0.2173066
	speed: 0.0244s/iter; left time: 2697.9833s
	iters: 1200, epoch: 2 | loss: 0.1801009
	speed: 0.0237s/iter; left time: 2612.2480s
	iters: 1300, epoch: 2 | loss: 0.1754363
	speed: 0.0226s/iter; left time: 2488.5537s
	iters: 1400, epoch: 2 | loss: 0.1715064
	speed: 0.0226s/iter; left time: 2486.9305s
	iters: 1500, epoch: 2 | loss: 0.1706589
	speed: 0.0219s/iter; left time: 2408.1913s
	iters: 1600, epoch: 2 | loss: 0.1571938
	speed: 0.0211s/iter; left time: 2324.9894s
	iters: 1700, epoch: 2 | loss: 0.1635524
	speed: 0.0209s/iter; left time: 2296.0846s
	iters: 1800, epoch: 2 | loss: 0.2065432
	speed: 0.0217s/iter; left time: 2381.7334s
	iters: 1900, epoch: 2 | loss: 0.1648500
	speed: 0.0231s/iter; left time: 2531.5145s
	iters: 2000, epoch: 2 | loss: 0.1514702
	speed: 0.0237s/iter; left time: 2592.5213s
	iters: 2100, epoch: 2 | loss: 0.1645239
	speed: 0.0225s/iter; left time: 2464.0015s
	iters: 2200, epoch: 2 | loss: 0.1828582
	speed: 0.0227s/iter; left time: 2479.8833s
Epoch: 2 cost time: 52.82244515419006
Epoch: 2, Steps: 2277 | Train Loss: 0.1778363 Vali Loss: 0.2126256 Test Loss: 0.2721810
Validation loss decreased (0.217016 --> 0.212626).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.1681557
	speed: 0.5373s/iter; left time: 58671.4471s
	iters: 200, epoch: 3 | loss: 0.1644462
	speed: 0.0208s/iter; left time: 2272.2935s
	iters: 300, epoch: 3 | loss: 0.1644858
	speed: 0.0209s/iter; left time: 2281.6289s
	iters: 400, epoch: 3 | loss: 0.1626306
	speed: 0.0220s/iter; left time: 2393.4545s
	iters: 500, epoch: 3 | loss: 0.1653574
	speed: 0.0208s/iter; left time: 2257.6898s
	iters: 600, epoch: 3 | loss: 0.1610789
	speed: 0.0211s/iter; left time: 2288.6586s
	iters: 700, epoch: 3 | loss: 0.1688956
	speed: 0.0206s/iter; left time: 2234.4533s
	iters: 800, epoch: 3 | loss: 0.1630594
	speed: 0.0214s/iter; left time: 2323.4446s
	iters: 900, epoch: 3 | loss: 0.1572376
	speed: 0.0231s/iter; left time: 2501.5519s
	iters: 1000, epoch: 3 | loss: 0.1718748
	speed: 0.0233s/iter; left time: 2519.5521s
	iters: 1100, epoch: 3 | loss: 0.1611959
	speed: 0.0230s/iter; left time: 2486.0604s
	iters: 1200, epoch: 3 | loss: 0.1503565
	speed: 0.0231s/iter; left time: 2497.4630s
	iters: 1300, epoch: 3 | loss: 0.1999708
	speed: 0.0230s/iter; left time: 2479.8681s
	iters: 1400, epoch: 3 | loss: 0.1637933
	speed: 0.0225s/iter; left time: 2427.8402s
	iters: 1500, epoch: 3 | loss: 0.1692552
	speed: 0.0212s/iter; left time: 2282.3474s
	iters: 1600, epoch: 3 | loss: 0.1632739
	speed: 0.0207s/iter; left time: 2233.5822s
	iters: 1700, epoch: 3 | loss: 0.1576572
	speed: 0.0207s/iter; left time: 2227.5564s
	iters: 1800, epoch: 3 | loss: 0.1660468
	speed: 0.0208s/iter; left time: 2238.4807s
	iters: 1900, epoch: 3 | loss: 0.1702256
	speed: 0.0210s/iter; left time: 2254.4786s
	iters: 2000, epoch: 3 | loss: 0.1823177
	speed: 0.0212s/iter; left time: 2277.0626s
	iters: 2100, epoch: 3 | loss: 0.1750631
	speed: 0.0207s/iter; left time: 2221.1684s
	iters: 2200, epoch: 3 | loss: 0.1510214
	speed: 0.0207s/iter; left time: 2211.6731s
Epoch: 3 cost time: 50.784475326538086
Epoch: 3, Steps: 2277 | Train Loss: 0.1709189 Vali Loss: 0.2278404 Test Loss: 0.2851812
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.1770604
	speed: 0.5706s/iter; left time: 61012.5541s
	iters: 200, epoch: 4 | loss: 0.1813794
	speed: 0.0207s/iter; left time: 2208.5569s
	iters: 300, epoch: 4 | loss: 0.1962413
	speed: 0.0206s/iter; left time: 2201.1723s
	iters: 400, epoch: 4 | loss: 0.1772398
	speed: 0.0207s/iter; left time: 2203.5038s
	iters: 500, epoch: 4 | loss: 0.1742766
	speed: 0.0206s/iter; left time: 2196.9273s
	iters: 600, epoch: 4 | loss: 0.1663497
	speed: 0.0219s/iter; left time: 2326.5973s
	iters: 700, epoch: 4 | loss: 0.1570442
	speed: 0.0232s/iter; left time: 2466.4386s
	iters: 800, epoch: 4 | loss: 0.1703402
	speed: 0.0231s/iter; left time: 2451.8408s
	iters: 900, epoch: 4 | loss: 0.1793571
	speed: 0.0237s/iter; left time: 2517.4110s
	iters: 1000, epoch: 4 | loss: 0.1674220
	speed: 0.0229s/iter; left time: 2431.5305s
	iters: 1100, epoch: 4 | loss: 0.1706492
	speed: 0.0219s/iter; left time: 2316.1891s
	iters: 1200, epoch: 4 | loss: 0.1513285
	speed: 0.0212s/iter; left time: 2246.6852s
	iters: 1300, epoch: 4 | loss: 0.1492466
	speed: 0.0213s/iter; left time: 2254.5407s
	iters: 1400, epoch: 4 | loss: 0.1673167
	speed: 0.0231s/iter; left time: 2443.7891s
	iters: 1500, epoch: 4 | loss: 0.1685917
	speed: 0.0225s/iter; left time: 2374.7824s
	iters: 1600, epoch: 4 | loss: 0.1574470
	speed: 0.0228s/iter; left time: 2407.0141s
	iters: 1700, epoch: 4 | loss: 0.1697852
	speed: 0.0237s/iter; left time: 2500.0789s
	iters: 1800, epoch: 4 | loss: 0.1595055
	speed: 0.0233s/iter; left time: 2449.2909s
	iters: 1900, epoch: 4 | loss: 0.1552906
	speed: 0.0230s/iter; left time: 2418.5183s
	iters: 2000, epoch: 4 | loss: 0.1988671
	speed: 0.0221s/iter; left time: 2323.3733s
	iters: 2100, epoch: 4 | loss: 0.1756441
	speed: 0.0211s/iter; left time: 2214.5396s
	iters: 2200, epoch: 4 | loss: 0.1787585
	speed: 0.0209s/iter; left time: 2193.0191s
Epoch: 4 cost time: 51.91093444824219
Epoch: 4, Steps: 2277 | Train Loss: 0.1681365 Vali Loss: 0.2406342 Test Loss: 0.2928006
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.1678052
	speed: 0.5711s/iter; left time: 59758.8007s
	iters: 200, epoch: 5 | loss: 0.1762030
	speed: 0.0208s/iter; left time: 2169.3947s
	iters: 300, epoch: 5 | loss: 0.1646564
	speed: 0.0209s/iter; left time: 2177.7758s
	iters: 400, epoch: 5 | loss: 0.1676401
	speed: 0.0213s/iter; left time: 2220.4743s
	iters: 500, epoch: 5 | loss: 0.1783654
	speed: 0.0228s/iter; left time: 2379.1541s
	iters: 600, epoch: 5 | loss: 0.1684771
	speed: 0.0232s/iter; left time: 2419.9532s
	iters: 700, epoch: 5 | loss: 0.1634121
	speed: 0.0236s/iter; left time: 2452.9907s
	iters: 800, epoch: 5 | loss: 0.1688660
	speed: 0.0227s/iter; left time: 2355.3826s
	iters: 900, epoch: 5 | loss: 0.1691516
	speed: 0.0237s/iter; left time: 2459.4380s
	iters: 1000, epoch: 5 | loss: 0.1824974
	speed: 0.0226s/iter; left time: 2345.4795s
	iters: 1100, epoch: 5 | loss: 0.1694172
	speed: 0.0227s/iter; left time: 2357.4042s
	iters: 1200, epoch: 5 | loss: 0.1733915
	speed: 0.0209s/iter; left time: 2162.9994s
	iters: 1300, epoch: 5 | loss: 0.1423714
	speed: 0.0210s/iter; left time: 2170.5112s
	iters: 1400, epoch: 5 | loss: 0.1598313
	speed: 0.0234s/iter; left time: 2423.0871s
	iters: 1500, epoch: 5 | loss: 0.1725662
	speed: 0.0230s/iter; left time: 2374.1582s
	iters: 1600, epoch: 5 | loss: 0.1984669
	speed: 0.0238s/iter; left time: 2451.0280s
	iters: 1700, epoch: 5 | loss: 0.1655976
	speed: 0.0225s/iter; left time: 2321.8792s
	iters: 1800, epoch: 5 | loss: 0.1758326
	speed: 0.0226s/iter; left time: 2328.8675s
	iters: 1900, epoch: 5 | loss: 0.1570681
	speed: 0.0238s/iter; left time: 2451.1696s
	iters: 2000, epoch: 5 | loss: 0.1616550
	speed: 0.0229s/iter; left time: 2350.9775s
	iters: 2100, epoch: 5 | loss: 0.1742455
	speed: 0.0237s/iter; left time: 2435.7007s
	iters: 2200, epoch: 5 | loss: 0.1813960
	speed: 0.0232s/iter; left time: 2377.4402s
Epoch: 5 cost time: 53.20106530189514
Epoch: 5, Steps: 2277 | Train Loss: 0.1666265 Vali Loss: 0.2568570 Test Loss: 0.3047536
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.1641331
	speed: 0.5687s/iter; left time: 58210.9223s
	iters: 200, epoch: 6 | loss: 0.1665905
	speed: 0.0211s/iter; left time: 2155.4621s
	iters: 300, epoch: 6 | loss: 0.1431342
	speed: 0.0210s/iter; left time: 2148.3772s
	iters: 400, epoch: 6 | loss: 0.1678393
	speed: 0.0228s/iter; left time: 2329.9709s
	iters: 500, epoch: 6 | loss: 0.1837177
	speed: 0.0234s/iter; left time: 2390.2117s
	iters: 600, epoch: 6 | loss: 0.1679379
	speed: 0.0237s/iter; left time: 2411.1030s
	iters: 700, epoch: 6 | loss: 0.1655783
	speed: 0.0248s/iter; left time: 2519.3873s
	iters: 800, epoch: 6 | loss: 0.1491586
	speed: 0.0234s/iter; left time: 2382.1044s
	iters: 900, epoch: 6 | loss: 0.1567232
	speed: 0.0228s/iter; left time: 2313.0050s
	iters: 1000, epoch: 6 | loss: 0.1531856
	speed: 0.0216s/iter; left time: 2188.5859s
	iters: 1100, epoch: 6 | loss: 0.1747531
	speed: 0.0211s/iter; left time: 2138.2437s
	iters: 1200, epoch: 6 | loss: 0.1991064
	speed: 0.0228s/iter; left time: 2306.9386s
	iters: 1300, epoch: 6 | loss: 0.1694105
	speed: 0.0225s/iter; left time: 2276.4583s
	iters: 1400, epoch: 6 | loss: 0.1571139
	speed: 0.0228s/iter; left time: 2304.3525s
	iters: 1500, epoch: 6 | loss: 0.1627174
	speed: 0.0226s/iter; left time: 2284.1762s
	iters: 1600, epoch: 6 | loss: 0.1643895
	speed: 0.0228s/iter; left time: 2301.9767s
	iters: 1700, epoch: 6 | loss: 0.1695365
	speed: 0.0227s/iter; left time: 2285.2522s
	iters: 1800, epoch: 6 | loss: 0.1483884
	speed: 0.0229s/iter; left time: 2302.6259s
	iters: 1900, epoch: 6 | loss: 0.1648772
	speed: 0.0231s/iter; left time: 2322.6748s
	iters: 2000, epoch: 6 | loss: 0.1723047
	speed: 0.0225s/iter; left time: 2261.8177s
	iters: 2100, epoch: 6 | loss: 0.1605147
	speed: 0.0226s/iter; left time: 2268.1189s
	iters: 2200, epoch: 6 | loss: 0.1504811
	speed: 0.0216s/iter; left time: 2164.7063s
Epoch: 6 cost time: 53.318864822387695
Epoch: 6, Steps: 2277 | Train Loss: 0.1657861 Vali Loss: 0.2616440 Test Loss: 0.3069221
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.1587493
	speed: 0.5785s/iter; left time: 57900.3052s
	iters: 200, epoch: 7 | loss: 0.1594162
	speed: 0.0217s/iter; left time: 2171.5074s
	iters: 300, epoch: 7 | loss: 0.1619699
	speed: 0.0233s/iter; left time: 2329.3858s
	iters: 400, epoch: 7 | loss: 0.1613390
	speed: 0.0232s/iter; left time: 2313.8685s
	iters: 500, epoch: 7 | loss: 0.1529208
	speed: 0.0226s/iter; left time: 2251.5698s
	iters: 600, epoch: 7 | loss: 0.1795596
	speed: 0.0224s/iter; left time: 2232.7565s
	iters: 700, epoch: 7 | loss: 0.1596930
	speed: 0.0214s/iter; left time: 2132.3499s
	iters: 800, epoch: 7 | loss: 0.1678266
	speed: 0.0223s/iter; left time: 2211.7878s
	iters: 900, epoch: 7 | loss: 0.1846708
	speed: 0.0227s/iter; left time: 2252.2804s
	iters: 1000, epoch: 7 | loss: 0.1680282
	speed: 0.0226s/iter; left time: 2237.1136s
	iters: 1100, epoch: 7 | loss: 0.1730977
	speed: 0.0229s/iter; left time: 2269.9430s
	iters: 1200, epoch: 7 | loss: 0.1766254
	speed: 0.0237s/iter; left time: 2347.4984s
	iters: 1300, epoch: 7 | loss: 0.1846829
	speed: 0.0238s/iter; left time: 2352.3424s
	iters: 1400, epoch: 7 | loss: 0.1504772
	speed: 0.0231s/iter; left time: 2285.1565s
	iters: 1500, epoch: 7 | loss: 0.1502893
	speed: 0.0234s/iter; left time: 2310.8700s
	iters: 1600, epoch: 7 | loss: 0.1747851
	speed: 0.0226s/iter; left time: 2232.0956s
	iters: 1700, epoch: 7 | loss: 0.1714273
	speed: 0.0228s/iter; left time: 2250.4655s
	iters: 1800, epoch: 7 | loss: 0.1528737
	speed: 0.0239s/iter; left time: 2348.6677s
	iters: 1900, epoch: 7 | loss: 0.1723141
	speed: 0.0226s/iter; left time: 2221.8533s
	iters: 2000, epoch: 7 | loss: 0.1573238
	speed: 0.0227s/iter; left time: 2224.6247s
	iters: 2100, epoch: 7 | loss: 0.1632329
	speed: 0.0210s/iter; left time: 2059.3960s
	iters: 2200, epoch: 7 | loss: 0.1499595
	speed: 0.0207s/iter; left time: 2027.8473s
Epoch: 7 cost time: 52.80662250518799
Epoch: 7, Steps: 2277 | Train Loss: 0.1653952 Vali Loss: 0.2605176 Test Loss: 0.3071971
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.1615548
	speed: 0.5724s/iter; left time: 55987.7362s
	iters: 200, epoch: 8 | loss: 0.1711608
	speed: 0.0206s/iter; left time: 2008.0530s
	iters: 300, epoch: 8 | loss: 0.1587608
	speed: 0.0210s/iter; left time: 2052.3893s
	iters: 400, epoch: 8 | loss: 0.1827643
	speed: 0.0206s/iter; left time: 2010.3011s
	iters: 500, epoch: 8 | loss: 0.1510083
	speed: 0.0205s/iter; left time: 1993.9068s
	iters: 600, epoch: 8 | loss: 0.1482762
	speed: 0.0209s/iter; left time: 2035.5179s
	iters: 700, epoch: 8 | loss: 0.1424659
	speed: 0.0227s/iter; left time: 2207.9735s
	iters: 800, epoch: 8 | loss: 0.1568699
	speed: 0.0235s/iter; left time: 2282.1421s
	iters: 900, epoch: 8 | loss: 0.1537151
	speed: 0.0236s/iter; left time: 2289.0029s
	iters: 1000, epoch: 8 | loss: 0.1683411
	speed: 0.0223s/iter; left time: 2157.5872s
	iters: 1100, epoch: 8 | loss: 0.1657262
	speed: 0.0226s/iter; left time: 2187.7585s
	iters: 1200, epoch: 8 | loss: 0.1502668
	speed: 0.0231s/iter; left time: 2234.0096s
	iters: 1300, epoch: 8 | loss: 0.1617301
	speed: 0.0228s/iter; left time: 2200.5025s
	iters: 1400, epoch: 8 | loss: 0.1706401
	speed: 0.0231s/iter; left time: 2226.6680s
	iters: 1500, epoch: 8 | loss: 0.1714248
	speed: 0.0233s/iter; left time: 2242.9081s
	iters: 1600, epoch: 8 | loss: 0.1587335
	speed: 0.0227s/iter; left time: 2185.9669s
	iters: 1700, epoch: 8 | loss: 0.1658352
	speed: 0.0226s/iter; left time: 2175.8728s
	iters: 1800, epoch: 8 | loss: 0.1752733
	speed: 0.0216s/iter; left time: 2079.2544s
	iters: 1900, epoch: 8 | loss: 0.1644143
	speed: 0.0221s/iter; left time: 2124.0227s
	iters: 2000, epoch: 8 | loss: 0.1659021
	speed: 0.0225s/iter; left time: 2157.1010s
	iters: 2100, epoch: 8 | loss: 0.1671379
	speed: 0.0226s/iter; left time: 2169.3522s
	iters: 2200, epoch: 8 | loss: 0.1839743
	speed: 0.0230s/iter; left time: 2204.6225s
Epoch: 8 cost time: 52.27970600128174
Epoch: 8, Steps: 2277 | Train Loss: 0.1652107 Vali Loss: 0.2666874 Test Loss: 0.3111213
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 0.1756166
	speed: 0.5431s/iter; left time: 51882.4684s
	iters: 200, epoch: 9 | loss: 0.1732429
	speed: 0.0211s/iter; left time: 2013.5687s
	iters: 300, epoch: 9 | loss: 0.1501678
	speed: 0.0229s/iter; left time: 2187.0475s
	iters: 400, epoch: 9 | loss: 0.1462208
	speed: 0.0224s/iter; left time: 2135.0008s
	iters: 500, epoch: 9 | loss: 0.1738369
	speed: 0.0226s/iter; left time: 2149.0997s
	iters: 600, epoch: 9 | loss: 0.1583708
	speed: 0.0215s/iter; left time: 2039.2210s
	iters: 700, epoch: 9 | loss: 0.1680124
	speed: 0.0206s/iter; left time: 1956.4348s
	iters: 800, epoch: 9 | loss: 0.1768897
	speed: 0.0206s/iter; left time: 1955.2203s
	iters: 900, epoch: 9 | loss: 0.1481816
	speed: 0.0213s/iter; left time: 2020.5732s
	iters: 1000, epoch: 9 | loss: 0.1835795
	speed: 0.0215s/iter; left time: 2030.7389s
	iters: 1100, epoch: 9 | loss: 0.1759809
	speed: 0.0206s/iter; left time: 1950.7673s
	iters: 1200, epoch: 9 | loss: 0.1694014
	speed: 0.0208s/iter; left time: 1965.0152s
	iters: 1300, epoch: 9 | loss: 0.1629585
	speed: 0.0208s/iter; left time: 1958.4668s
	iters: 1400, epoch: 9 | loss: 0.1738732
	speed: 0.0208s/iter; left time: 1955.4334s
	iters: 1500, epoch: 9 | loss: 0.1736605
	speed: 0.0223s/iter; left time: 2102.1645s
	iters: 1600, epoch: 9 | loss: 0.1691825
	speed: 0.0226s/iter; left time: 2123.4544s
	iters: 1700, epoch: 9 | loss: 0.1664257
	speed: 0.0234s/iter; left time: 2199.4661s
	iters: 1800, epoch: 9 | loss: 0.1667943
	speed: 0.0228s/iter; left time: 2135.3202s
	iters: 1900, epoch: 9 | loss: 0.1786544
	speed: 0.0231s/iter; left time: 2166.2591s
	iters: 2000, epoch: 9 | loss: 0.1490765
	speed: 0.0226s/iter; left time: 2111.9232s
	iters: 2100, epoch: 9 | loss: 0.1781468
	speed: 0.0223s/iter; left time: 2086.2520s
	iters: 2200, epoch: 9 | loss: 0.1578568
	speed: 0.0223s/iter; left time: 2081.5357s
Epoch: 9 cost time: 51.255996227264404
Epoch: 9, Steps: 2277 | Train Loss: 0.1651165 Vali Loss: 0.2664410 Test Loss: 0.3109791
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 0.1580022
	speed: 0.5765s/iter; left time: 53766.4882s
	iters: 200, epoch: 10 | loss: 0.1624248
	speed: 0.0215s/iter; left time: 2000.9925s
	iters: 300, epoch: 10 | loss: 0.1671868
	speed: 0.0214s/iter; left time: 1988.9932s
	iters: 400, epoch: 10 | loss: 0.1580662
	speed: 0.0225s/iter; left time: 2090.2904s
	iters: 500, epoch: 10 | loss: 0.1547402
	speed: 0.0228s/iter; left time: 2121.6411s
	iters: 600, epoch: 10 | loss: 0.1811823
	speed: 0.0228s/iter; left time: 2110.3368s
	iters: 700, epoch: 10 | loss: 0.1726885
	speed: 0.0231s/iter; left time: 2141.1692s
	iters: 800, epoch: 10 | loss: 0.1563394
	speed: 0.0239s/iter; left time: 2207.6341s
	iters: 900, epoch: 10 | loss: 0.1530605
	speed: 0.0233s/iter; left time: 2152.4765s
	iters: 1000, epoch: 10 | loss: 0.1597813
	speed: 0.0238s/iter; left time: 2194.0999s
	iters: 1100, epoch: 10 | loss: 0.1442563
	speed: 0.0227s/iter; left time: 2091.8379s
	iters: 1200, epoch: 10 | loss: 0.1749095
	speed: 0.0225s/iter; left time: 2071.0102s
	iters: 1300, epoch: 10 | loss: 0.1768805
	speed: 0.0217s/iter; left time: 1999.8500s
	iters: 1400, epoch: 10 | loss: 0.1688553
	speed: 0.0212s/iter; left time: 1950.7853s
	iters: 1500, epoch: 10 | loss: 0.1801969
	speed: 0.0207s/iter; left time: 1897.1268s
	iters: 1600, epoch: 10 | loss: 0.1585624
	speed: 0.0206s/iter; left time: 1889.9975s
	iters: 1700, epoch: 10 | loss: 0.1572049
	speed: 0.0213s/iter; left time: 1954.7484s
	iters: 1800, epoch: 10 | loss: 0.1625987
	speed: 0.0226s/iter; left time: 2071.6297s
	iters: 1900, epoch: 10 | loss: 0.1560175
	speed: 0.0225s/iter; left time: 2058.9408s
	iters: 2000, epoch: 10 | loss: 0.1602720
	speed: 0.0216s/iter; left time: 1970.2841s
	iters: 2100, epoch: 10 | loss: 0.1700718
	speed: 0.0206s/iter; left time: 1884.4479s
	iters: 2200, epoch: 10 | loss: 0.1684105
	speed: 0.0209s/iter; left time: 1906.0895s
Epoch: 10 cost time: 51.76127552986145
Epoch: 10, Steps: 2277 | Train Loss: 0.1650478 Vali Loss: 0.2683207 Test Loss: 0.3122796
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 0.1525161
	speed: 0.5474s/iter; left time: 49802.2393s
	iters: 200, epoch: 11 | loss: 0.1698235
	speed: 0.0216s/iter; left time: 1962.8665s
	iters: 300, epoch: 11 | loss: 0.1608466
	speed: 0.0227s/iter; left time: 2057.8414s
	iters: 400, epoch: 11 | loss: 0.1563819
	speed: 0.0229s/iter; left time: 2075.2501s
	iters: 500, epoch: 11 | loss: 0.1704076
	speed: 0.0229s/iter; left time: 2076.3343s
	iters: 600, epoch: 11 | loss: 0.1626453
	speed: 0.0235s/iter; left time: 2125.2792s
	iters: 700, epoch: 11 | loss: 0.1587585
	speed: 0.0233s/iter; left time: 2109.9630s
	iters: 800, epoch: 11 | loss: 0.1533126
	speed: 0.0227s/iter; left time: 2050.0597s
	iters: 900, epoch: 11 | loss: 0.1677601
	speed: 0.0228s/iter; left time: 2052.0530s
	iters: 1000, epoch: 11 | loss: 0.1633855
	speed: 0.0210s/iter; left time: 1887.4693s
	iters: 1100, epoch: 11 | loss: 0.1912658
	speed: 0.0211s/iter; left time: 1901.3710s
	iters: 1200, epoch: 11 | loss: 0.1697915
	speed: 0.0233s/iter; left time: 2098.5797s
	iters: 1300, epoch: 11 | loss: 0.1796581
	speed: 0.0235s/iter; left time: 2113.9502s
	iters: 1400, epoch: 11 | loss: 0.1586992
	speed: 0.0228s/iter; left time: 2040.6367s
	iters: 1500, epoch: 11 | loss: 0.1596952
	speed: 0.0221s/iter; left time: 1978.2692s
	iters: 1600, epoch: 11 | loss: 0.1706301
	speed: 0.0219s/iter; left time: 1957.3090s
	iters: 1700, epoch: 11 | loss: 0.1676721
	speed: 0.0241s/iter; left time: 2154.1442s
	iters: 1800, epoch: 11 | loss: 0.2063919
	speed: 0.0232s/iter; left time: 2069.0971s
	iters: 1900, epoch: 11 | loss: 0.1634227
	speed: 0.0233s/iter; left time: 2074.9575s
	iters: 2000, epoch: 11 | loss: 0.1739746
	speed: 0.0229s/iter; left time: 2039.6556s
	iters: 2100, epoch: 11 | loss: 0.1599034
	speed: 0.0224s/iter; left time: 1990.3968s
	iters: 2200, epoch: 11 | loss: 0.1789899
	speed: 0.0225s/iter; left time: 1998.3864s
Epoch: 11 cost time: 53.19151163101196
Epoch: 11, Steps: 2277 | Train Loss: 0.1650306 Vali Loss: 0.2674813 Test Loss: 0.3114787
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 0.1586029
	speed: 0.5806s/iter; left time: 51497.4393s
	iters: 200, epoch: 12 | loss: 0.1594138
	speed: 0.0209s/iter; left time: 1851.7088s
	iters: 300, epoch: 12 | loss: 0.1630218
	speed: 0.0208s/iter; left time: 1842.5218s
	iters: 400, epoch: 12 | loss: 0.1717248
	speed: 0.0225s/iter; left time: 1986.6994s
	iters: 500, epoch: 12 | loss: 0.1657672
	speed: 0.0229s/iter; left time: 2023.7450s
	iters: 600, epoch: 12 | loss: 0.1597942
	speed: 0.0228s/iter; left time: 2014.7160s
	iters: 700, epoch: 12 | loss: 0.1782734
	speed: 0.0228s/iter; left time: 2012.6795s
	iters: 800, epoch: 12 | loss: 0.1484559
	speed: 0.0229s/iter; left time: 2013.3734s
	iters: 900, epoch: 12 | loss: 0.1649152
	speed: 0.0226s/iter; left time: 1982.6526s
	iters: 1000, epoch: 12 | loss: 0.1775002
	speed: 0.0231s/iter; left time: 2029.2866s
	iters: 1100, epoch: 12 | loss: 0.1589565
	speed: 0.0221s/iter; left time: 1935.4399s
	iters: 1200, epoch: 12 | loss: 0.1629312
	speed: 0.0207s/iter; left time: 1810.2871s
	iters: 1300, epoch: 12 | loss: 0.1518872
	speed: 0.0207s/iter; left time: 1808.8029s
	iters: 1400, epoch: 12 | loss: 0.1772166
	speed: 0.0208s/iter; left time: 1817.4351s
	iters: 1500, epoch: 12 | loss: 0.1619179
	speed: 0.0206s/iter; left time: 1798.8578s
	iters: 1600, epoch: 12 | loss: 0.1692007
	speed: 0.0206s/iter; left time: 1799.3387s
	iters: 1700, epoch: 12 | loss: 0.1598420
	speed: 0.0207s/iter; left time: 1801.1210s
	iters: 1800, epoch: 12 | loss: 0.1762350
	speed: 0.0209s/iter; left time: 1822.0420s
	iters: 1900, epoch: 12 | loss: 0.1833391
	speed: 0.0238s/iter; left time: 2064.3171s
	iters: 2000, epoch: 12 | loss: 0.1617584
	speed: 0.0231s/iter; left time: 2006.2131s
	iters: 2100, epoch: 12 | loss: 0.1636197
	speed: 0.0232s/iter; left time: 2008.2248s
	iters: 2200, epoch: 12 | loss: 0.1647647
	speed: 0.0228s/iter; left time: 1975.9288s
Epoch: 12 cost time: 51.83232593536377
Epoch: 12, Steps: 2277 | Train Loss: 0.1649800 Vali Loss: 0.2678533 Test Loss: 0.3120610
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : ECL_96_96_10_emb_64_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (5165, 1, 96, 321) (5165, 1, 96, 321)
test shape: (5165, 96, 321) (5165, 96, 321)
mse:0.27217984199523926, mae:0.3660043179988861
Args in experiment:
Namespace(is_training=1, model_id='ECL_96_96_11_emb_128', model='xLSTM', data='custom', root_path='./data/electricity/', data_path='/input-data/electricity.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, enc_in=321, dec_in=7, c_out=321, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=10, batch_size=32, patience=10, learning_rate=0.0001, des='test', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, use_norm=True, partial_start_index=0, hidden_size=512, num_layers=2, mark_enc_in=4, embedding_dim=128, weight_decay=1e-06, kernal_size=3, num_heads_xlstm=2, qkv_proj_blocksize=4, proj_factor=1.3, num_blocks=3, slstm_at=1, grad_clip_norm=1.0, d_state=16, d_conv=4, expand=2)
Use GPU: cuda:0
{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-L/usr/local/cuda/lib', '-lcublas'], 'extra_cflags': ['-DSLSTM_HIDDEN_SIZE=128', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=2', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__'], 'extra_cuda_cflags': ['-Xptxas="-v"', '-gencode', 'arch=compute_80,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=128', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=2', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__']}
Using /home/thetayne/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Creating extension directory /home/thetayne/.cache/torch_extensions/py310_cu121/slstm_HS128BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/thetayne/.cache/torch_extensions/py310_cu121/slstm_HS128BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0/build.ninja...
Building extension module slstm_HS128BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[1/8] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output cuda_error.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS128BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=128 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=2 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/util/cuda_error.cu -o cuda_error.cuda.o 
ptxas info    : 0 bytes gmem
[2/8] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output slstm_forward.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS128BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=128 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=2 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/cuda/slstm_forward.cu -o slstm_forward.cuda.o 
ptxas info    : 0 bytes gmem
[3/8] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output slstm_backward_cut.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS128BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=128 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=2 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/cuda/slstm_backward_cut.cu -o slstm_backward_cut.cuda.o 
ptxas info    : 0 bytes gmem
ptxas info    : Compiling entry function '_ZN54_GLOBAL__N__2085b59d_21_slstm_backward_cut_cu_1c2c4d0129gradientBiasAggregationKernelEjjjjjjPK13__nv_bfloat16S2_Pf' for 'sm_80'
ptxas info    : Function properties for _ZN54_GLOBAL__N__2085b59d_21_slstm_backward_cut_cu_1c2c4d0129gradientBiasAggregationKernelEjjjjjjPK13__nv_bfloat16S2_Pf
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 32 registers, 400 bytes cmem[0]
[4/8] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output slstm_pointwise.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS128BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=128 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=2 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/cuda/slstm_pointwise.cu -o slstm_pointwise.cuda.o 
ptxas info    : 0 bytes gmem
ptxas info    : Compiling entry function '_ZN5slstm21SLSTMPointwiseForwardILb0EEEviiiPK13__nv_bfloat16S3_PKfS3_jPS1_jS6_S6_' for 'sm_80'
ptxas info    : Function properties for _ZN5slstm21SLSTMPointwiseForwardILb0EEEviiiPK13__nv_bfloat16S3_PKfS3_jPS1_jS6_S6_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 32 registers, 440 bytes cmem[0]
ptxas info    : Compiling entry function '_ZN5slstm21SLSTMPointwiseForwardILb1EEEviiiPK13__nv_bfloat16S3_PKfS3_jPS1_jS6_S6_' for 'sm_80'
ptxas info    : Function properties for _ZN5slstm21SLSTMPointwiseForwardILb1EEEviiiPK13__nv_bfloat16S3_PKfS3_jPS1_jS6_S6_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 32 registers, 440 bytes cmem[0]
ptxas info    : Compiling entry function '_ZN5slstm22SLSTMPointwiseBackwardEiiiPK13__nv_bfloat16jS2_S2_PKfS2_jS2_jPS0_jS5_S5_S5_' for 'sm_80'
ptxas info    : Function properties for _ZN5slstm22SLSTMPointwiseBackwardEiiiPK13__nv_bfloat16jS2_S2_PKfS2_jS2_jPS0_jS5_S5_S5_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 32 registers, 480 bytes cmem[0]
[5/8] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output slstm_backward.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS128BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=128 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=2 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/cuda/slstm_backward.cu -o slstm_backward.cuda.o 
ptxas info    : 0 bytes gmem
ptxas info    : Compiling entry function '_ZN50_GLOBAL__N__d983f13f_17_slstm_backward_cu_3639fa5e29gradientBiasAggregationKernelEjjjjjjPK13__nv_bfloat16S2_Pf' for 'sm_80'
ptxas info    : Function properties for _ZN50_GLOBAL__N__d983f13f_17_slstm_backward_cu_3639fa5e29gradientBiasAggregationKernelEjjjjjjPK13__nv_bfloat16S2_Pf
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 32 registers, 400 bytes cmem[0]
[6/8] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output blas.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS128BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=128 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=2 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/util/blas.cu -o blas.cuda.o 
ptxas info    : 0 bytes gmem
ptxas info    : Compiling entry function '_Z10initKernelI13__nv_bfloat16EvPT_iS1_' for 'sm_80'
ptxas info    : Function properties for _Z10initKernelI13__nv_bfloat16EvPT_iS1_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 8 registers, 366 bytes cmem[0]
ptxas info    : Compiling entry function '_Z10initKernelI6__halfEvPT_iS1_' for 'sm_80'
ptxas info    : Function properties for _Z10initKernelI6__halfEvPT_iS1_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 8 registers, 366 bytes cmem[0]
ptxas info    : Compiling entry function '_Z10initKernelIfEvPT_iS0_' for 'sm_80'
ptxas info    : Function properties for _Z10initKernelIfEvPT_iS0_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 8 registers, 368 bytes cmem[0]
ptxas info    : Compiling entry function '_Z10initKernelIdEvPT_iS0_' for 'sm_80'
ptxas info    : Function properties for _Z10initKernelIdEvPT_iS0_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 8 registers, 376 bytes cmem[0]
[7/8] c++ -MMD -MF slstm.o.d -DTORCH_EXTENSION_NAME=slstm_HS128BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -DSLSTM_HIDDEN_SIZE=128 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=2 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/cuda/slstm.cc -o slstm.o 
[8/8] c++ slstm.o slstm_forward.cuda.o slstm_backward.cuda.o slstm_backward_cut.cuda.o slstm_pointwise.cuda.o blas.cuda.o cuda_error.cuda.o -shared -L/usr/local/cuda/lib -lcublas -L/usr/local/lib/python3.10/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o slstm_HS128BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0.so
Loading extension module slstm_HS128BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
>>>>>>>start training : ECL_96_96_11_emb_128_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 18221
val 2537
test 5165
	iters: 100, epoch: 1 | loss: 0.5019084
	speed: 0.0588s/iter; left time: 328.8945s
	iters: 200, epoch: 1 | loss: 0.3178470
	speed: 0.0399s/iter; left time: 219.1370s
	iters: 300, epoch: 1 | loss: 0.3050386
	speed: 0.0401s/iter; left time: 216.1827s
	iters: 400, epoch: 1 | loss: 0.2804952
	speed: 0.0400s/iter; left time: 211.4729s
	iters: 500, epoch: 1 | loss: 0.2405002
	speed: 0.0403s/iter; left time: 209.2668s
Epoch: 1 cost time: 24.392069101333618
Epoch: 1, Steps: 569 | Train Loss: 0.3918521 Vali Loss: 0.2669103 Test Loss: 0.3305422
Validation loss decreased (inf --> 0.266910).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.2340657
	speed: 0.5802s/iter; left time: 2913.7198s
	iters: 200, epoch: 2 | loss: 0.2309596
	speed: 0.0366s/iter; left time: 180.1530s
	iters: 300, epoch: 2 | loss: 0.2004059
	speed: 0.0399s/iter; left time: 192.2127s
	iters: 400, epoch: 2 | loss: 0.2013728
	speed: 0.0397s/iter; left time: 187.3113s
	iters: 500, epoch: 2 | loss: 0.1904353
	speed: 0.0397s/iter; left time: 183.6453s
Epoch: 2 cost time: 23.382415294647217
Epoch: 2, Steps: 569 | Train Loss: 0.2117074 Vali Loss: 0.2490111 Test Loss: 0.3433355
Validation loss decreased (0.266910 --> 0.249011).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.1898259
	speed: 0.5822s/iter; left time: 2592.3520s
	iters: 200, epoch: 3 | loss: 0.1727236
	speed: 0.0368s/iter; left time: 160.1001s
	iters: 300, epoch: 3 | loss: 0.1762302
	speed: 0.0396s/iter; left time: 168.3364s
	iters: 400, epoch: 3 | loss: 0.1692391
	speed: 0.0397s/iter; left time: 164.7839s
	iters: 500, epoch: 3 | loss: 0.1617019
	speed: 0.0395s/iter; left time: 160.2023s
Epoch: 3 cost time: 23.265854835510254
Epoch: 3, Steps: 569 | Train Loss: 0.1746317 Vali Loss: 0.2454899 Test Loss: 0.3521033
Validation loss decreased (0.249011 --> 0.245490).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.1620726
	speed: 0.5874s/iter; left time: 2281.5567s
	iters: 200, epoch: 4 | loss: 0.1509440
	speed: 0.0372s/iter; left time: 140.6845s
	iters: 300, epoch: 4 | loss: 0.1792690
	speed: 0.0395s/iter; left time: 145.3705s
	iters: 400, epoch: 4 | loss: 0.1585571
	speed: 0.0403s/iter; left time: 144.3480s
	iters: 500, epoch: 4 | loss: 0.1537437
	speed: 0.0396s/iter; left time: 137.9840s
Epoch: 4 cost time: 23.442421674728394
Epoch: 4, Steps: 569 | Train Loss: 0.1622527 Vali Loss: 0.2462527 Test Loss: 0.3556498
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.1571259
	speed: 0.5959s/iter; left time: 1975.3188s
	iters: 200, epoch: 5 | loss: 0.1535426
	speed: 0.0366s/iter; left time: 117.5622s
	iters: 300, epoch: 5 | loss: 0.1548242
	speed: 0.0361s/iter; left time: 112.5009s
	iters: 400, epoch: 5 | loss: 0.1534508
	speed: 0.0398s/iter; left time: 120.0099s
	iters: 500, epoch: 5 | loss: 0.1582159
	speed: 0.0400s/iter; left time: 116.6057s
Epoch: 5 cost time: 23.012515783309937
Epoch: 5, Steps: 569 | Train Loss: 0.1566423 Vali Loss: 0.2459626 Test Loss: 0.3549245
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.1499203
	speed: 0.5831s/iter; left time: 1601.2076s
	iters: 200, epoch: 6 | loss: 0.1558573
	speed: 0.0390s/iter; left time: 103.0830s
	iters: 300, epoch: 6 | loss: 0.1580878
	speed: 0.0400s/iter; left time: 101.7252s
	iters: 400, epoch: 6 | loss: 0.1555120
	speed: 0.0397s/iter; left time: 97.1915s
	iters: 500, epoch: 6 | loss: 0.1472864
	speed: 0.0399s/iter; left time: 93.5346s
Epoch: 6 cost time: 23.52551579475403
Epoch: 6, Steps: 569 | Train Loss: 0.1538846 Vali Loss: 0.2452498 Test Loss: 0.3551795
Validation loss decreased (0.245490 --> 0.245250).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.1528022
	speed: 0.5896s/iter; left time: 1283.4700s
	iters: 200, epoch: 7 | loss: 0.1595529
	speed: 0.0372s/iter; left time: 77.1795s
	iters: 300, epoch: 7 | loss: 0.1505841
	speed: 0.0388s/iter; left time: 76.7263s
	iters: 400, epoch: 7 | loss: 0.1590877
	speed: 0.0401s/iter; left time: 75.2981s
	iters: 500, epoch: 7 | loss: 0.1442886
	speed: 0.0407s/iter; left time: 72.3151s
Epoch: 7 cost time: 23.510753870010376
Epoch: 7, Steps: 569 | Train Loss: 0.1524056 Vali Loss: 0.2456198 Test Loss: 0.3561774
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.1430933
	speed: 0.6046s/iter; left time: 972.1648s
	iters: 200, epoch: 8 | loss: 0.1511639
	speed: 0.0375s/iter; left time: 56.6178s
	iters: 300, epoch: 8 | loss: 0.1527288
	speed: 0.0396s/iter; left time: 55.7300s
	iters: 400, epoch: 8 | loss: 0.1451061
	speed: 0.0394s/iter; left time: 51.5243s
	iters: 500, epoch: 8 | loss: 0.1545463
	speed: 0.0394s/iter; left time: 47.6308s
Epoch: 8 cost time: 23.39066791534424
Epoch: 8, Steps: 569 | Train Loss: 0.1516770 Vali Loss: 0.2450809 Test Loss: 0.3560185
Validation loss decreased (0.245250 --> 0.245081).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.1523303
	speed: 0.5789s/iter; left time: 601.4326s
	iters: 200, epoch: 9 | loss: 0.1417012
	speed: 0.0378s/iter; left time: 35.4798s
	iters: 300, epoch: 9 | loss: 0.1452311
	speed: 0.0402s/iter; left time: 33.6869s
	iters: 400, epoch: 9 | loss: 0.1470847
	speed: 0.0393s/iter; left time: 29.0477s
	iters: 500, epoch: 9 | loss: 0.1657763
	speed: 0.0398s/iter; left time: 25.4382s
Epoch: 9 cost time: 23.621253728866577
Epoch: 9, Steps: 569 | Train Loss: 0.1512578 Vali Loss: 0.2449251 Test Loss: 0.3560256
Validation loss decreased (0.245081 --> 0.244925).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.1544552
	speed: 0.5867s/iter; left time: 275.7377s
	iters: 200, epoch: 10 | loss: 0.1554637
	speed: 0.0394s/iter; left time: 14.5629s
	iters: 300, epoch: 10 | loss: 0.1540895
	speed: 0.0404s/iter; left time: 10.8948s
	iters: 400, epoch: 10 | loss: 0.1502842
	speed: 0.0399s/iter; left time: 6.7831s
	iters: 500, epoch: 10 | loss: 0.1494063
	speed: 0.0399s/iter; left time: 2.7931s
Epoch: 10 cost time: 23.678993225097656
Epoch: 10, Steps: 569 | Train Loss: 0.1510502 Vali Loss: 0.2450271 Test Loss: 0.3558324
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
>>>>>>>testing : ECL_96_96_11_emb_128_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (5165, 1, 96, 321) (5165, 1, 96, 321)
test shape: (5165, 96, 321) (5165, 96, 321)
mse:0.35602596402168274, mae:0.416130393743515
Args in experiment:
Namespace(is_training=1, model_id='ECL_96_96_12_emb_128', model='xLSTM', data='custom', root_path='./data/electricity/', data_path='/input-data/electricity.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, enc_in=321, dec_in=7, c_out=321, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=10, batch_size=8, patience=10, learning_rate=0.0005, des='test', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, use_norm=True, partial_start_index=0, hidden_size=512, num_layers=2, mark_enc_in=4, embedding_dim=128, weight_decay=0.0001, kernal_size=3, num_heads_xlstm=4, qkv_proj_blocksize=2, proj_factor=1.3, num_blocks=2, slstm_at=1, grad_clip_norm=0.5, d_state=16, d_conv=4, expand=2)
Use GPU: cuda:0
{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-L/usr/local/cuda/lib', '-lcublas'], 'extra_cflags': ['-DSLSTM_HIDDEN_SIZE=128', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__'], 'extra_cuda_cflags': ['-Xptxas="-v"', '-gencode', 'arch=compute_80,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=128', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__']}
Using /home/thetayne/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/thetayne/.cache/torch_extensions/py310_cu121/slstm_HS128BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0/build.ninja...
Building extension module slstm_HS128BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module slstm_HS128BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
>>>>>>>start training : ECL_96_96_12_emb_128_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 18221
val 2537
test 5165
	iters: 100, epoch: 1 | loss: 0.3724920
	speed: 0.0412s/iter; left time: 935.1090s
	iters: 200, epoch: 1 | loss: 0.2238251
	speed: 0.0185s/iter; left time: 416.6180s
	iters: 300, epoch: 1 | loss: 0.2128336
	speed: 0.0191s/iter; left time: 430.2376s
	iters: 400, epoch: 1 | loss: 0.1755120
	speed: 0.0199s/iter; left time: 445.7880s
	iters: 500, epoch: 1 | loss: 0.1967690
	speed: 0.0189s/iter; left time: 421.4109s
	iters: 600, epoch: 1 | loss: 0.1501189
	speed: 0.0186s/iter; left time: 412.3658s
	iters: 700, epoch: 1 | loss: 0.1648140
	speed: 0.0189s/iter; left time: 417.3515s
	iters: 800, epoch: 1 | loss: 0.1444416
	speed: 0.0187s/iter; left time: 411.7976s
	iters: 900, epoch: 1 | loss: 0.1386261
	speed: 0.0190s/iter; left time: 415.0695s
	iters: 1000, epoch: 1 | loss: 0.1417780
	speed: 0.0187s/iter; left time: 406.9734s
	iters: 1100, epoch: 1 | loss: 0.1405845
	speed: 0.0187s/iter; left time: 405.9135s
	iters: 1200, epoch: 1 | loss: 0.1120364
	speed: 0.0191s/iter; left time: 411.6613s
	iters: 1300, epoch: 1 | loss: 0.1147792
	speed: 0.0192s/iter; left time: 413.2502s
	iters: 1400, epoch: 1 | loss: 0.1158930
	speed: 0.0187s/iter; left time: 399.4186s
	iters: 1500, epoch: 1 | loss: 0.1202095
	speed: 0.0186s/iter; left time: 396.5434s
	iters: 1600, epoch: 1 | loss: 0.1119286
	speed: 0.0188s/iter; left time: 398.0065s
	iters: 1700, epoch: 1 | loss: 0.1152661
	speed: 0.0188s/iter; left time: 396.3523s
	iters: 1800, epoch: 1 | loss: 0.1459601
	speed: 0.0187s/iter; left time: 392.1906s
	iters: 1900, epoch: 1 | loss: 0.1168167
	speed: 0.0190s/iter; left time: 396.6600s
	iters: 2000, epoch: 1 | loss: 0.1231462
	speed: 0.0187s/iter; left time: 389.0899s
	iters: 2100, epoch: 1 | loss: 0.1122561
	speed: 0.0186s/iter; left time: 385.4370s
	iters: 2200, epoch: 1 | loss: 0.1315438
	speed: 0.0187s/iter; left time: 384.0188s
Epoch: 1 cost time: 45.19731688499451
Epoch: 1, Steps: 2277 | Train Loss: 0.1626399 Vali Loss: 0.2028864 Test Loss: 0.2640555
Validation loss decreased (inf --> 0.202886).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.1229224
	speed: 0.4337s/iter; left time: 8845.3475s
	iters: 200, epoch: 2 | loss: 0.1042947
	speed: 0.0169s/iter; left time: 342.7136s
	iters: 300, epoch: 2 | loss: 0.1039398
	speed: 0.0181s/iter; left time: 366.1856s
	iters: 400, epoch: 2 | loss: 0.1068685
	speed: 0.0187s/iter; left time: 375.3430s
	iters: 500, epoch: 2 | loss: 0.1252782
	speed: 0.0187s/iter; left time: 373.8321s
	iters: 600, epoch: 2 | loss: 0.1022970
	speed: 0.0190s/iter; left time: 377.1060s
	iters: 700, epoch: 2 | loss: 0.1169582
	speed: 0.0190s/iter; left time: 375.5472s
	iters: 800, epoch: 2 | loss: 0.1052092
	speed: 0.0198s/iter; left time: 389.8213s
	iters: 900, epoch: 2 | loss: 0.1113218
	speed: 0.0199s/iter; left time: 390.2120s
	iters: 1000, epoch: 2 | loss: 0.1079174
	speed: 0.0190s/iter; left time: 369.8536s
	iters: 1100, epoch: 2 | loss: 0.0954833
	speed: 0.0187s/iter; left time: 362.3948s
	iters: 1200, epoch: 2 | loss: 0.1130946
	speed: 0.0189s/iter; left time: 364.5294s
	iters: 1300, epoch: 2 | loss: 0.1100401
	speed: 0.0185s/iter; left time: 355.3507s
	iters: 1400, epoch: 2 | loss: 0.1116974
	speed: 0.0189s/iter; left time: 360.3038s
	iters: 1500, epoch: 2 | loss: 0.1163405
	speed: 0.0191s/iter; left time: 362.0923s
	iters: 1600, epoch: 2 | loss: 0.0944794
	speed: 0.0190s/iter; left time: 359.4997s
	iters: 1700, epoch: 2 | loss: 0.0964933
	speed: 0.0188s/iter; left time: 353.7180s
	iters: 1800, epoch: 2 | loss: 0.1082328
	speed: 0.0187s/iter; left time: 350.1435s
	iters: 1900, epoch: 2 | loss: 0.1059720
	speed: 0.0187s/iter; left time: 347.2923s
	iters: 2000, epoch: 2 | loss: 0.1064793
	speed: 0.0191s/iter; left time: 353.4934s
	iters: 2100, epoch: 2 | loss: 0.1042337
	speed: 0.0189s/iter; left time: 347.6839s
	iters: 2200, epoch: 2 | loss: 0.1049395
	speed: 0.0187s/iter; left time: 342.7416s
Epoch: 2 cost time: 44.551371574401855
Epoch: 2, Steps: 2277 | Train Loss: 0.1079623 Vali Loss: 0.2005370 Test Loss: 0.2651500
Validation loss decreased (0.202886 --> 0.200537).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.0964617
	speed: 0.4385s/iter; left time: 7943.7492s
	iters: 200, epoch: 3 | loss: 0.0984324
	speed: 0.0164s/iter; left time: 295.2638s
	iters: 300, epoch: 3 | loss: 0.1067006
	speed: 0.0167s/iter; left time: 299.7181s
	iters: 400, epoch: 3 | loss: 0.0905279
	speed: 0.0176s/iter; left time: 313.0238s
	iters: 500, epoch: 3 | loss: 0.0985077
	speed: 0.0188s/iter; left time: 332.9748s
	iters: 600, epoch: 3 | loss: 0.0889608
	speed: 0.0187s/iter; left time: 330.0019s
	iters: 700, epoch: 3 | loss: 0.0974529
	speed: 0.0191s/iter; left time: 335.1200s
	iters: 800, epoch: 3 | loss: 0.0970250
	speed: 0.0188s/iter; left time: 327.4818s
	iters: 900, epoch: 3 | loss: 0.0895484
	speed: 0.0191s/iter; left time: 330.1244s
	iters: 1000, epoch: 3 | loss: 0.1094971
	speed: 0.0190s/iter; left time: 326.4178s
	iters: 1100, epoch: 3 | loss: 0.0926289
	speed: 0.0188s/iter; left time: 321.3787s
	iters: 1200, epoch: 3 | loss: 0.1016087
	speed: 0.0188s/iter; left time: 320.6981s
	iters: 1300, epoch: 3 | loss: 0.0996534
	speed: 0.0187s/iter; left time: 316.0406s
	iters: 1400, epoch: 3 | loss: 0.0966243
	speed: 0.0189s/iter; left time: 318.4457s
	iters: 1500, epoch: 3 | loss: 0.0981873
	speed: 0.0190s/iter; left time: 318.0257s
	iters: 1600, epoch: 3 | loss: 0.0962140
	speed: 0.0202s/iter; left time: 336.0117s
	iters: 1700, epoch: 3 | loss: 0.1038356
	speed: 0.0208s/iter; left time: 342.9051s
	iters: 1800, epoch: 3 | loss: 0.1015298
	speed: 0.0208s/iter; left time: 342.2130s
	iters: 1900, epoch: 3 | loss: 0.0895059
	speed: 0.0208s/iter; left time: 339.2761s
	iters: 2000, epoch: 3 | loss: 0.0869832
	speed: 0.0206s/iter; left time: 333.6256s
	iters: 2100, epoch: 3 | loss: 0.0989143
	speed: 0.0207s/iter; left time: 333.7666s
	iters: 2200, epoch: 3 | loss: 0.0920638
	speed: 0.0206s/iter; left time: 329.9498s
Epoch: 3 cost time: 45.1110417842865
Epoch: 3, Steps: 2277 | Train Loss: 0.0970569 Vali Loss: 0.2061235 Test Loss: 0.2683988
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.0933975
	speed: 0.5726s/iter; left time: 9070.1781s
	iters: 200, epoch: 4 | loss: 0.0969122
	speed: 0.0194s/iter; left time: 305.6775s
	iters: 300, epoch: 4 | loss: 0.0938521
	speed: 0.0203s/iter; left time: 317.2441s
	iters: 400, epoch: 4 | loss: 0.0883765
	speed: 0.0210s/iter; left time: 326.3183s
	iters: 500, epoch: 4 | loss: 0.0867084
	speed: 0.0208s/iter; left time: 320.7497s
	iters: 600, epoch: 4 | loss: 0.0836238
	speed: 0.0209s/iter; left time: 320.8454s
	iters: 700, epoch: 4 | loss: 0.0925778
	speed: 0.0212s/iter; left time: 323.0758s
	iters: 800, epoch: 4 | loss: 0.0966843
	speed: 0.0206s/iter; left time: 312.3963s
	iters: 900, epoch: 4 | loss: 0.0853276
	speed: 0.0208s/iter; left time: 313.4110s
	iters: 1000, epoch: 4 | loss: 0.0854577
	speed: 0.0208s/iter; left time: 311.4487s
	iters: 1100, epoch: 4 | loss: 0.0902089
	speed: 0.0209s/iter; left time: 310.0064s
	iters: 1200, epoch: 4 | loss: 0.0934658
	speed: 0.0208s/iter; left time: 306.6389s
	iters: 1300, epoch: 4 | loss: 0.0861885
	speed: 0.0208s/iter; left time: 304.0376s
	iters: 1400, epoch: 4 | loss: 0.0917016
	speed: 0.0210s/iter; left time: 304.8934s
	iters: 1500, epoch: 4 | loss: 0.0973928
	speed: 0.0210s/iter; left time: 303.0748s
	iters: 1600, epoch: 4 | loss: 0.0832393
	speed: 0.0210s/iter; left time: 300.6989s
	iters: 1700, epoch: 4 | loss: 0.0903490
	speed: 0.0206s/iter; left time: 294.0446s
	iters: 1800, epoch: 4 | loss: 0.0921545
	speed: 0.0207s/iter; left time: 293.3133s
	iters: 1900, epoch: 4 | loss: 0.0889397
	speed: 0.0207s/iter; left time: 290.1028s
	iters: 2000, epoch: 4 | loss: 0.0908292
	speed: 0.0206s/iter; left time: 287.6312s
	iters: 2100, epoch: 4 | loss: 0.1044802
	speed: 0.0207s/iter; left time: 285.9830s
	iters: 2200, epoch: 4 | loss: 0.0925725
	speed: 0.0207s/iter; left time: 284.8848s
Epoch: 4 cost time: 48.8435742855072
Epoch: 4, Steps: 2277 | Train Loss: 0.0927076 Vali Loss: 0.2015585 Test Loss: 0.2686569
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.0934244
	speed: 0.5294s/iter; left time: 7180.6506s
	iters: 200, epoch: 5 | loss: 0.0905940
	speed: 0.0195s/iter; left time: 262.2650s
	iters: 300, epoch: 5 | loss: 0.0848457
	speed: 0.0194s/iter; left time: 258.8014s
	iters: 400, epoch: 5 | loss: 0.0892169
	speed: 0.0197s/iter; left time: 261.3486s
	iters: 500, epoch: 5 | loss: 0.1066318
	speed: 0.0209s/iter; left time: 275.2651s
	iters: 600, epoch: 5 | loss: 0.0938056
	speed: 0.0209s/iter; left time: 272.7058s
	iters: 700, epoch: 5 | loss: 0.0968183
	speed: 0.0209s/iter; left time: 270.3614s
	iters: 800, epoch: 5 | loss: 0.0889571
	speed: 0.0207s/iter; left time: 266.4404s
	iters: 900, epoch: 5 | loss: 0.0965986
	speed: 0.0208s/iter; left time: 265.1535s
	iters: 1000, epoch: 5 | loss: 0.0888960
	speed: 0.0211s/iter; left time: 266.6189s
	iters: 1100, epoch: 5 | loss: 0.0908217
	speed: 0.0203s/iter; left time: 255.3066s
	iters: 1200, epoch: 5 | loss: 0.0895528
	speed: 0.0201s/iter; left time: 250.1715s
	iters: 1300, epoch: 5 | loss: 0.0909870
	speed: 0.0201s/iter; left time: 248.0029s
	iters: 1400, epoch: 5 | loss: 0.1024189
	speed: 0.0206s/iter; left time: 253.0909s
	iters: 1500, epoch: 5 | loss: 0.0881496
	speed: 0.0209s/iter; left time: 253.6645s
	iters: 1600, epoch: 5 | loss: 0.0877337
	speed: 0.0207s/iter; left time: 249.8972s
	iters: 1700, epoch: 5 | loss: 0.0864905
	speed: 0.0209s/iter; left time: 249.5766s
	iters: 1800, epoch: 5 | loss: 0.0955310
	speed: 0.0206s/iter; left time: 244.7047s
	iters: 1900, epoch: 5 | loss: 0.0935802
	speed: 0.0206s/iter; left time: 242.2771s
	iters: 2000, epoch: 5 | loss: 0.0814674
	speed: 0.0211s/iter; left time: 246.4858s
	iters: 2100, epoch: 5 | loss: 0.0924630
	speed: 0.0211s/iter; left time: 243.7257s
	iters: 2200, epoch: 5 | loss: 0.0872569
	speed: 0.0206s/iter; left time: 236.1652s
Epoch: 5 cost time: 48.458797454833984
Epoch: 5, Steps: 2277 | Train Loss: 0.0904645 Vali Loss: 0.2027508 Test Loss: 0.2715519
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.0789233
	speed: 0.5298s/iter; left time: 5979.8517s
	iters: 200, epoch: 6 | loss: 0.0911880
	speed: 0.0190s/iter; left time: 212.1360s
	iters: 300, epoch: 6 | loss: 0.0921893
	speed: 0.0194s/iter; left time: 214.9860s
	iters: 400, epoch: 6 | loss: 0.0922090
	speed: 0.0184s/iter; left time: 202.5147s
	iters: 500, epoch: 6 | loss: 0.0865798
	speed: 0.0204s/iter; left time: 221.5666s
	iters: 600, epoch: 6 | loss: 0.0838621
	speed: 0.0207s/iter; left time: 223.1452s
	iters: 700, epoch: 6 | loss: 0.0905190
	speed: 0.0208s/iter; left time: 222.6317s
	iters: 800, epoch: 6 | loss: 0.0791747
	speed: 0.0209s/iter; left time: 221.0120s
	iters: 900, epoch: 6 | loss: 0.0883444
	speed: 0.0208s/iter; left time: 217.8513s
	iters: 1000, epoch: 6 | loss: 0.0909116
	speed: 0.0205s/iter; left time: 212.9700s
	iters: 1100, epoch: 6 | loss: 0.0978828
	speed: 0.0209s/iter; left time: 215.0679s
	iters: 1200, epoch: 6 | loss: 0.0854941
	speed: 0.0207s/iter; left time: 211.0227s
	iters: 1300, epoch: 6 | loss: 0.0923671
	speed: 0.0206s/iter; left time: 207.5276s
	iters: 1400, epoch: 6 | loss: 0.0882303
	speed: 0.0207s/iter; left time: 206.7410s
	iters: 1500, epoch: 6 | loss: 0.0911347
	speed: 0.0211s/iter; left time: 208.5673s
	iters: 1600, epoch: 6 | loss: 0.0887126
	speed: 0.0206s/iter; left time: 201.1557s
	iters: 1700, epoch: 6 | loss: 0.0835322
	speed: 0.0209s/iter; left time: 201.9586s
	iters: 1800, epoch: 6 | loss: 0.0909044
	speed: 0.0190s/iter; left time: 182.2113s
	iters: 1900, epoch: 6 | loss: 0.0785391
	speed: 0.0195s/iter; left time: 184.6761s
	iters: 2000, epoch: 6 | loss: 0.0903147
	speed: 0.0214s/iter; left time: 200.5749s
	iters: 2100, epoch: 6 | loss: 0.0866365
	speed: 0.0210s/iter; left time: 195.4108s
	iters: 2200, epoch: 6 | loss: 0.0870138
	speed: 0.0207s/iter; left time: 190.1353s
Epoch: 6 cost time: 47.828492879867554
Epoch: 6, Steps: 2277 | Train Loss: 0.0893089 Vali Loss: 0.2032245 Test Loss: 0.2726588
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.0754650
	speed: 0.5440s/iter; left time: 4901.3039s
	iters: 200, epoch: 7 | loss: 0.0820754
	speed: 0.0191s/iter; left time: 170.1458s
	iters: 300, epoch: 7 | loss: 0.0979667
	speed: 0.0197s/iter; left time: 173.4925s
	iters: 400, epoch: 7 | loss: 0.0945220
	speed: 0.0198s/iter; left time: 172.2818s
	iters: 500, epoch: 7 | loss: 0.0981294
	speed: 0.0204s/iter; left time: 175.6214s
	iters: 600, epoch: 7 | loss: 0.0772313
	speed: 0.0207s/iter; left time: 176.4689s
	iters: 700, epoch: 7 | loss: 0.0756239
	speed: 0.0210s/iter; left time: 176.2663s
	iters: 800, epoch: 7 | loss: 0.0841153
	speed: 0.0210s/iter; left time: 174.1038s
	iters: 900, epoch: 7 | loss: 0.0942838
	speed: 0.0195s/iter; left time: 160.1791s
	iters: 1000, epoch: 7 | loss: 0.0983895
	speed: 0.0185s/iter; left time: 149.6186s
	iters: 1100, epoch: 7 | loss: 0.0802391
	speed: 0.0209s/iter; left time: 167.7049s
	iters: 1200, epoch: 7 | loss: 0.0923049
	speed: 0.0211s/iter; left time: 166.8088s
	iters: 1300, epoch: 7 | loss: 0.1007520
	speed: 0.0213s/iter; left time: 166.6969s
	iters: 1400, epoch: 7 | loss: 0.0896804
	speed: 0.0192s/iter; left time: 147.7716s
	iters: 1500, epoch: 7 | loss: 0.0901917
	speed: 0.0195s/iter; left time: 148.0615s
	iters: 1600, epoch: 7 | loss: 0.0929198
	speed: 0.0206s/iter; left time: 154.8071s
	iters: 1700, epoch: 7 | loss: 0.0819400
	speed: 0.0210s/iter; left time: 155.8032s
	iters: 1800, epoch: 7 | loss: 0.0871747
	speed: 0.0207s/iter; left time: 151.3816s
	iters: 1900, epoch: 7 | loss: 0.0891524
	speed: 0.0211s/iter; left time: 152.1653s
	iters: 2000, epoch: 7 | loss: 0.0931965
	speed: 0.0211s/iter; left time: 149.8252s
	iters: 2100, epoch: 7 | loss: 0.0935997
	speed: 0.0206s/iter; left time: 144.6131s
	iters: 2200, epoch: 7 | loss: 0.0871028
	speed: 0.0208s/iter; left time: 143.3701s
Epoch: 7 cost time: 47.938876152038574
Epoch: 7, Steps: 2277 | Train Loss: 0.0887534 Vali Loss: 0.2038433 Test Loss: 0.2739825
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.0918420
	speed: 0.5487s/iter; left time: 3693.7170s
	iters: 200, epoch: 8 | loss: 0.0950559
	speed: 0.0192s/iter; left time: 127.3621s
	iters: 300, epoch: 8 | loss: 0.0893426
	speed: 0.0194s/iter; left time: 126.6186s
	iters: 400, epoch: 8 | loss: 0.0884243
	speed: 0.0196s/iter; left time: 126.1014s
	iters: 500, epoch: 8 | loss: 0.0858332
	speed: 0.0177s/iter; left time: 111.9332s
	iters: 600, epoch: 8 | loss: 0.0860090
	speed: 0.0192s/iter; left time: 119.9482s
	iters: 700, epoch: 8 | loss: 0.0771489
	speed: 0.0209s/iter; left time: 128.3203s
	iters: 800, epoch: 8 | loss: 0.0955895
	speed: 0.0206s/iter; left time: 124.3801s
	iters: 900, epoch: 8 | loss: 0.0792460
	speed: 0.0207s/iter; left time: 122.5471s
	iters: 1000, epoch: 8 | loss: 0.0965786
	speed: 0.0209s/iter; left time: 122.1001s
	iters: 1100, epoch: 8 | loss: 0.0778285
	speed: 0.0207s/iter; left time: 118.7940s
	iters: 1200, epoch: 8 | loss: 0.0751934
	speed: 0.0206s/iter; left time: 116.1427s
	iters: 1300, epoch: 8 | loss: 0.1033901
	speed: 0.0206s/iter; left time: 113.9724s
	iters: 1400, epoch: 8 | loss: 0.0818777
	speed: 0.0207s/iter; left time: 112.5299s
	iters: 1500, epoch: 8 | loss: 0.0864512
	speed: 0.0207s/iter; left time: 110.4829s
	iters: 1600, epoch: 8 | loss: 0.0890495
	speed: 0.0209s/iter; left time: 109.4866s
	iters: 1700, epoch: 8 | loss: 0.0960206
	speed: 0.0210s/iter; left time: 107.8881s
	iters: 1800, epoch: 8 | loss: 0.0926277
	speed: 0.0209s/iter; left time: 105.1830s
	iters: 1900, epoch: 8 | loss: 0.0802949
	speed: 0.0194s/iter; left time: 95.6381s
	iters: 2000, epoch: 8 | loss: 0.1107776
	speed: 0.0186s/iter; left time: 89.7303s
	iters: 2100, epoch: 8 | loss: 0.0862237
	speed: 0.0202s/iter; left time: 95.6663s
	iters: 2200, epoch: 8 | loss: 0.0931585
	speed: 0.0209s/iter; left time: 96.6744s
Epoch: 8 cost time: 47.562270402908325
Epoch: 8, Steps: 2277 | Train Loss: 0.0884323 Vali Loss: 0.2034804 Test Loss: 0.2739680
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.0970081
	speed: 0.5461s/iter; left time: 2432.9666s
	iters: 200, epoch: 9 | loss: 0.0857856
	speed: 0.0197s/iter; left time: 85.8453s
	iters: 300, epoch: 9 | loss: 0.0823217
	speed: 0.0194s/iter; left time: 82.4506s
	iters: 400, epoch: 9 | loss: 0.0988616
	speed: 0.0193s/iter; left time: 80.0914s
	iters: 500, epoch: 9 | loss: 0.0951365
	speed: 0.0197s/iter; left time: 79.9520s
	iters: 600, epoch: 9 | loss: 0.0894394
	speed: 0.0200s/iter; left time: 78.9117s
	iters: 700, epoch: 9 | loss: 0.0898697
	speed: 0.0200s/iter; left time: 76.9215s
	iters: 800, epoch: 9 | loss: 0.1006409
	speed: 0.0188s/iter; left time: 70.7538s
	iters: 900, epoch: 9 | loss: 0.1033746
	speed: 0.0190s/iter; left time: 69.6015s
	iters: 1000, epoch: 9 | loss: 0.0844987
	speed: 0.0192s/iter; left time: 68.0936s
	iters: 1100, epoch: 9 | loss: 0.0997227
	speed: 0.0170s/iter; left time: 58.6989s
	iters: 1200, epoch: 9 | loss: 0.0922753
	speed: 0.0179s/iter; left time: 60.0212s
	iters: 1300, epoch: 9 | loss: 0.0881447
	speed: 0.0211s/iter; left time: 68.6855s
	iters: 1400, epoch: 9 | loss: 0.0928825
	speed: 0.0214s/iter; left time: 67.3962s
	iters: 1500, epoch: 9 | loss: 0.0885217
	speed: 0.0211s/iter; left time: 64.5291s
	iters: 1600, epoch: 9 | loss: 0.0839539
	speed: 0.0186s/iter; left time: 55.0750s
	iters: 1700, epoch: 9 | loss: 0.0874230
	speed: 0.0189s/iter; left time: 53.9463s
	iters: 1800, epoch: 9 | loss: 0.0823313
	speed: 0.0208s/iter; left time: 57.4256s
	iters: 1900, epoch: 9 | loss: 0.0862550
	speed: 0.0207s/iter; left time: 55.0524s
	iters: 2000, epoch: 9 | loss: 0.0897813
	speed: 0.0207s/iter; left time: 52.9133s
	iters: 2100, epoch: 9 | loss: 0.0867924
	speed: 0.0210s/iter; left time: 51.4857s
	iters: 2200, epoch: 9 | loss: 0.0858878
	speed: 0.0207s/iter; left time: 48.8342s
Epoch: 9 cost time: 46.7358672618866
Epoch: 9, Steps: 2277 | Train Loss: 0.0882711 Vali Loss: 0.2032865 Test Loss: 0.2743843
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.0883080
	speed: 0.5486s/iter; left time: 1194.8594s
	iters: 200, epoch: 10 | loss: 0.0796055
	speed: 0.0171s/iter; left time: 35.4553s
	iters: 300, epoch: 10 | loss: 0.0957669
	speed: 0.0172s/iter; left time: 34.0525s
	iters: 400, epoch: 10 | loss: 0.0880443
	speed: 0.0210s/iter; left time: 39.4251s
	iters: 500, epoch: 10 | loss: 0.1004212
	speed: 0.0220s/iter; left time: 39.0642s
	iters: 600, epoch: 10 | loss: 0.0811908
	speed: 0.0214s/iter; left time: 35.8861s
	iters: 700, epoch: 10 | loss: 0.0919021
	speed: 0.0185s/iter; left time: 29.2218s
	iters: 800, epoch: 10 | loss: 0.0789114
	speed: 0.0190s/iter; left time: 28.0913s
	iters: 900, epoch: 10 | loss: 0.0915821
	speed: 0.0204s/iter; left time: 28.1481s
	iters: 1000, epoch: 10 | loss: 0.0942315
	speed: 0.0206s/iter; left time: 26.2722s
	iters: 1100, epoch: 10 | loss: 0.0894925
	speed: 0.0206s/iter; left time: 24.2815s
	iters: 1200, epoch: 10 | loss: 0.0859386
	speed: 0.0206s/iter; left time: 22.1733s
	iters: 1300, epoch: 10 | loss: 0.0833457
	speed: 0.0209s/iter; left time: 20.4776s
	iters: 1400, epoch: 10 | loss: 0.0774980
	speed: 0.0205s/iter; left time: 17.9991s
	iters: 1500, epoch: 10 | loss: 0.0999293
	speed: 0.0205s/iter; left time: 15.9721s
	iters: 1600, epoch: 10 | loss: 0.0864611
	speed: 0.0209s/iter; left time: 14.1397s
	iters: 1700, epoch: 10 | loss: 0.0838210
	speed: 0.0207s/iter; left time: 11.9808s
	iters: 1800, epoch: 10 | loss: 0.0856046
	speed: 0.0212s/iter; left time: 10.1310s
	iters: 1900, epoch: 10 | loss: 0.0826131
	speed: 0.0210s/iter; left time: 7.9424s
	iters: 2000, epoch: 10 | loss: 0.0873060
	speed: 0.0213s/iter; left time: 5.9316s
	iters: 2100, epoch: 10 | loss: 0.0844257
	speed: 0.0202s/iter; left time: 3.5949s
	iters: 2200, epoch: 10 | loss: 0.0847582
	speed: 0.0187s/iter; left time: 1.4605s
Epoch: 10 cost time: 47.58012127876282
Epoch: 10, Steps: 2277 | Train Loss: 0.0881909 Vali Loss: 0.2034330 Test Loss: 0.2742042
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
>>>>>>>testing : ECL_96_96_12_emb_128_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (5165, 1, 96, 321) (5165, 1, 96, 321)
test shape: (5165, 96, 321) (5165, 96, 321)
mse:0.2651495039463043, mae:0.35718321800231934
Args in experiment:
Namespace(is_training=1, model_id='ECL_96_96_13_emb_128', model='xLSTM', data='custom', root_path='./data/electricity/', data_path='/input-data/electricity.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, enc_in=321, dec_in=7, c_out=321, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.5, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=16, patience=10, learning_rate=0.0001, des='test', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, use_norm=True, partial_start_index=0, hidden_size=512, num_layers=2, mark_enc_in=4, embedding_dim=128, weight_decay=1e-06, kernal_size=3, num_heads_xlstm=8, qkv_proj_blocksize=4, proj_factor=1.3, num_blocks=2, slstm_at=1, grad_clip_norm=5.0, d_state=16, d_conv=4, expand=2)
Use GPU: cuda:0
{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-L/usr/local/cuda/lib', '-lcublas'], 'extra_cflags': ['-DSLSTM_HIDDEN_SIZE=128', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=8', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__'], 'extra_cuda_cflags': ['-Xptxas="-v"', '-gencode', 'arch=compute_80,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=128', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=8', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__']}
Using /home/thetayne/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Creating extension directory /home/thetayne/.cache/torch_extensions/py310_cu121/slstm_HS128BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/thetayne/.cache/torch_extensions/py310_cu121/slstm_HS128BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0/build.ninja...
Building extension module slstm_HS128BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[1/8] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output cuda_error.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS128BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=128 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=8 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/util/cuda_error.cu -o cuda_error.cuda.o 
ptxas info    : 0 bytes gmem
[2/8] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output slstm_pointwise.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS128BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=128 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=8 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/cuda/slstm_pointwise.cu -o slstm_pointwise.cuda.o 
ptxas info    : 0 bytes gmem
ptxas info    : Compiling entry function '_ZN5slstm21SLSTMPointwiseForwardILb0EEEviiiPK13__nv_bfloat16S3_PKfS3_jPS1_jS6_S6_' for 'sm_80'
ptxas info    : Function properties for _ZN5slstm21SLSTMPointwiseForwardILb0EEEviiiPK13__nv_bfloat16S3_PKfS3_jPS1_jS6_S6_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 32 registers, 440 bytes cmem[0]
ptxas info    : Compiling entry function '_ZN5slstm21SLSTMPointwiseForwardILb1EEEviiiPK13__nv_bfloat16S3_PKfS3_jPS1_jS6_S6_' for 'sm_80'
ptxas info    : Function properties for _ZN5slstm21SLSTMPointwiseForwardILb1EEEviiiPK13__nv_bfloat16S3_PKfS3_jPS1_jS6_S6_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 32 registers, 440 bytes cmem[0]
ptxas info    : Compiling entry function '_ZN5slstm22SLSTMPointwiseBackwardEiiiPK13__nv_bfloat16jS2_S2_PKfS2_jS2_jPS0_jS5_S5_S5_' for 'sm_80'
ptxas info    : Function properties for _ZN5slstm22SLSTMPointwiseBackwardEiiiPK13__nv_bfloat16jS2_S2_PKfS2_jS2_jPS0_jS5_S5_S5_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 32 registers, 480 bytes cmem[0]
[3/8] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output slstm_backward_cut.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS128BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=128 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=8 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/cuda/slstm_backward_cut.cu -o slstm_backward_cut.cuda.o 
ptxas info    : 0 bytes gmem
ptxas info    : Compiling entry function '_ZN54_GLOBAL__N__2085b59d_21_slstm_backward_cut_cu_1c2c4d0129gradientBiasAggregationKernelEjjjjjjPK13__nv_bfloat16S2_Pf' for 'sm_80'
ptxas info    : Function properties for _ZN54_GLOBAL__N__2085b59d_21_slstm_backward_cut_cu_1c2c4d0129gradientBiasAggregationKernelEjjjjjjPK13__nv_bfloat16S2_Pf
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 32 registers, 400 bytes cmem[0]
[4/8] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output slstm_forward.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS128BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=128 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=8 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/cuda/slstm_forward.cu -o slstm_forward.cuda.o 
ptxas info    : 0 bytes gmem
[5/8] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output slstm_backward.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS128BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=128 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=8 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/cuda/slstm_backward.cu -o slstm_backward.cuda.o 
ptxas info    : 0 bytes gmem
ptxas info    : Compiling entry function '_ZN50_GLOBAL__N__d983f13f_17_slstm_backward_cu_3639fa5e29gradientBiasAggregationKernelEjjjjjjPK13__nv_bfloat16S2_Pf' for 'sm_80'
ptxas info    : Function properties for _ZN50_GLOBAL__N__d983f13f_17_slstm_backward_cu_3639fa5e29gradientBiasAggregationKernelEjjjjjjPK13__nv_bfloat16S2_Pf
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 32 registers, 400 bytes cmem[0]
[6/8] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output blas.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS128BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=128 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=8 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/util/blas.cu -o blas.cuda.o 
ptxas info    : 0 bytes gmem
ptxas info    : Compiling entry function '_Z10initKernelI13__nv_bfloat16EvPT_iS1_' for 'sm_80'
ptxas info    : Function properties for _Z10initKernelI13__nv_bfloat16EvPT_iS1_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 8 registers, 366 bytes cmem[0]
ptxas info    : Compiling entry function '_Z10initKernelI6__halfEvPT_iS1_' for 'sm_80'
ptxas info    : Function properties for _Z10initKernelI6__halfEvPT_iS1_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 8 registers, 366 bytes cmem[0]
ptxas info    : Compiling entry function '_Z10initKernelIfEvPT_iS0_' for 'sm_80'
ptxas info    : Function properties for _Z10initKernelIfEvPT_iS0_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 8 registers, 368 bytes cmem[0]
ptxas info    : Compiling entry function '_Z10initKernelIdEvPT_iS0_' for 'sm_80'
ptxas info    : Function properties for _Z10initKernelIdEvPT_iS0_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 8 registers, 376 bytes cmem[0]
[7/8] c++ -MMD -MF slstm.o.d -DTORCH_EXTENSION_NAME=slstm_HS128BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -DSLSTM_HIDDEN_SIZE=128 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=8 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/cuda/slstm.cc -o slstm.o 
[8/8] c++ slstm.o slstm_forward.cuda.o slstm_backward.cuda.o slstm_backward_cut.cuda.o slstm_pointwise.cuda.o blas.cuda.o cuda_error.cuda.o -shared -L/usr/local/cuda/lib -lcublas -L/usr/local/lib/python3.10/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o slstm_HS128BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0.so
Loading extension module slstm_HS128BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
>>>>>>>start training : ECL_96_96_13_emb_128_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 18221
val 2537
test 5165
	iters: 100, epoch: 1 | loss: 0.7480866
	speed: 0.0451s/iter; left time: 1536.9175s
	iters: 200, epoch: 1 | loss: 0.6268227
	speed: 0.0227s/iter; left time: 770.5636s
	iters: 300, epoch: 1 | loss: 0.5672430
	speed: 0.0225s/iter; left time: 762.5906s
	iters: 400, epoch: 1 | loss: 0.4585678
	speed: 0.0226s/iter; left time: 764.2267s
	iters: 500, epoch: 1 | loss: 0.3512255
	speed: 0.0242s/iter; left time: 815.5024s
	iters: 600, epoch: 1 | loss: 0.3455818
	speed: 0.0249s/iter; left time: 836.7529s
	iters: 700, epoch: 1 | loss: 0.3222189
	speed: 0.0245s/iter; left time: 819.8630s
	iters: 800, epoch: 1 | loss: 0.2927464
	speed: 0.0242s/iter; left time: 808.4858s
	iters: 900, epoch: 1 | loss: 0.3217627
	speed: 0.0246s/iter; left time: 818.8531s
	iters: 1000, epoch: 1 | loss: 0.2923856
	speed: 0.0244s/iter; left time: 810.0493s
	iters: 1100, epoch: 1 | loss: 0.2894876
	speed: 0.0248s/iter; left time: 820.4515s
Epoch: 1 cost time: 29.354191303253174
Epoch: 1, Steps: 1138 | Train Loss: 0.4646946 Vali Loss: 0.2601836 Test Loss: 0.3220900
Validation loss decreased (inf --> 0.260184).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.2585909
	speed: 0.4231s/iter; left time: 13922.4536s
	iters: 200, epoch: 2 | loss: 0.2503076
	speed: 0.0212s/iter; left time: 696.4484s
	iters: 300, epoch: 2 | loss: 0.2155343
	speed: 0.0211s/iter; left time: 691.1712s
	iters: 400, epoch: 2 | loss: 0.2435141
	speed: 0.0215s/iter; left time: 701.0379s
	iters: 500, epoch: 2 | loss: 0.2373534
	speed: 0.0213s/iter; left time: 692.2985s
	iters: 600, epoch: 2 | loss: 0.2393335
	speed: 0.0214s/iter; left time: 692.8853s
	iters: 700, epoch: 2 | loss: 0.2545675
	speed: 0.0211s/iter; left time: 682.7621s
	iters: 800, epoch: 2 | loss: 0.2184235
	speed: 0.0215s/iter; left time: 691.3179s
	iters: 900, epoch: 2 | loss: 0.2283791
	speed: 0.0212s/iter; left time: 681.8005s
	iters: 1000, epoch: 2 | loss: 0.2120769
	speed: 0.0214s/iter; left time: 684.4158s
	iters: 1100, epoch: 2 | loss: 0.2188746
	speed: 0.0211s/iter; left time: 673.8305s
Epoch: 2 cost time: 25.594306468963623
Epoch: 2, Steps: 1138 | Train Loss: 0.2374905 Vali Loss: 0.2362152 Test Loss: 0.3064362
Validation loss decreased (0.260184 --> 0.236215).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.2270589
	speed: 0.4221s/iter; left time: 13409.3715s
	iters: 200, epoch: 3 | loss: 0.2080481
	speed: 0.0211s/iter; left time: 668.7709s
	iters: 300, epoch: 3 | loss: 0.1944379
	speed: 0.0214s/iter; left time: 675.0819s
	iters: 400, epoch: 3 | loss: 0.2096307
	speed: 0.0217s/iter; left time: 682.0520s
	iters: 500, epoch: 3 | loss: 0.2158181
	speed: 0.0212s/iter; left time: 664.1801s
	iters: 600, epoch: 3 | loss: 0.2043893
	speed: 0.0215s/iter; left time: 671.5114s
	iters: 700, epoch: 3 | loss: 0.2309824
	speed: 0.0213s/iter; left time: 663.3018s
	iters: 800, epoch: 3 | loss: 0.2105460
	speed: 0.0211s/iter; left time: 656.7068s
	iters: 900, epoch: 3 | loss: 0.1837894
	speed: 0.0211s/iter; left time: 652.5861s
	iters: 1000, epoch: 3 | loss: 0.1920516
	speed: 0.0217s/iter; left time: 670.6665s
	iters: 1100, epoch: 3 | loss: 0.1862889
	speed: 0.0218s/iter; left time: 669.2380s
Epoch: 3 cost time: 25.82626962661743
Epoch: 3, Steps: 1138 | Train Loss: 0.2064779 Vali Loss: 0.2341164 Test Loss: 0.3045448
Validation loss decreased (0.236215 --> 0.234116).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.2071710
	speed: 0.4219s/iter; left time: 12920.9504s
	iters: 200, epoch: 4 | loss: 0.2052680
	speed: 0.0211s/iter; left time: 644.1694s
	iters: 300, epoch: 4 | loss: 0.2177456
	speed: 0.0216s/iter; left time: 655.8619s
	iters: 400, epoch: 4 | loss: 0.1941407
	speed: 0.0220s/iter; left time: 666.6244s
	iters: 500, epoch: 4 | loss: 0.1919705
	speed: 0.0216s/iter; left time: 651.7638s
	iters: 600, epoch: 4 | loss: 0.2070670
	speed: 0.0221s/iter; left time: 664.9873s
	iters: 700, epoch: 4 | loss: 0.2072784
	speed: 0.0215s/iter; left time: 644.7877s
	iters: 800, epoch: 4 | loss: 0.2018916
	speed: 0.0215s/iter; left time: 644.8047s
	iters: 900, epoch: 4 | loss: 0.1916308
	speed: 0.0223s/iter; left time: 665.6779s
	iters: 1000, epoch: 4 | loss: 0.1915106
	speed: 0.0215s/iter; left time: 639.5449s
	iters: 1100, epoch: 4 | loss: 0.2030950
	speed: 0.0215s/iter; left time: 636.0390s
Epoch: 4 cost time: 26.246903657913208
Epoch: 4, Steps: 1138 | Train Loss: 0.1977498 Vali Loss: 0.2286872 Test Loss: 0.2984644
Validation loss decreased (0.234116 --> 0.228687).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.2004792
	speed: 0.4247s/iter; left time: 12523.1687s
	iters: 200, epoch: 5 | loss: 0.2075075
	speed: 0.0216s/iter; left time: 635.8088s
	iters: 300, epoch: 5 | loss: 0.1987033
	speed: 0.0213s/iter; left time: 623.3981s
	iters: 400, epoch: 5 | loss: 0.2075296
	speed: 0.0225s/iter; left time: 656.3963s
	iters: 500, epoch: 5 | loss: 0.1749222
	speed: 0.0236s/iter; left time: 685.6905s
	iters: 600, epoch: 5 | loss: 0.1875417
	speed: 0.0234s/iter; left time: 679.4626s
	iters: 700, epoch: 5 | loss: 0.2138994
	speed: 0.0240s/iter; left time: 692.5531s
	iters: 800, epoch: 5 | loss: 0.1814250
	speed: 0.0249s/iter; left time: 715.6989s
	iters: 900, epoch: 5 | loss: 0.1768312
	speed: 0.0265s/iter; left time: 760.8298s
	iters: 1000, epoch: 5 | loss: 0.1880793
	speed: 0.0260s/iter; left time: 744.0006s
	iters: 1100, epoch: 5 | loss: 0.1866093
	speed: 0.0260s/iter; left time: 739.6432s
Epoch: 5 cost time: 28.819944143295288
Epoch: 5, Steps: 1138 | Train Loss: 0.1940272 Vali Loss: 0.2264290 Test Loss: 0.2973782
Validation loss decreased (0.228687 --> 0.226429).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.1953324
	speed: 0.5359s/iter; left time: 15193.1954s
	iters: 200, epoch: 6 | loss: 0.1766252
	speed: 0.0253s/iter; left time: 715.8253s
	iters: 300, epoch: 6 | loss: 0.1969026
	speed: 0.0258s/iter; left time: 725.0107s
	iters: 400, epoch: 6 | loss: 0.2035911
	speed: 0.0243s/iter; left time: 682.5106s
	iters: 500, epoch: 6 | loss: 0.2069611
	speed: 0.0263s/iter; left time: 733.9042s
	iters: 600, epoch: 6 | loss: 0.1898593
	speed: 0.0270s/iter; left time: 751.0088s
	iters: 700, epoch: 6 | loss: 0.1906339
	speed: 0.0264s/iter; left time: 732.4320s
	iters: 800, epoch: 6 | loss: 0.1939506
	speed: 0.0261s/iter; left time: 722.3522s
	iters: 900, epoch: 6 | loss: 0.1769825
	speed: 0.0265s/iter; left time: 729.1532s
	iters: 1000, epoch: 6 | loss: 0.1997208
	speed: 0.0263s/iter; left time: 722.9777s
	iters: 1100, epoch: 6 | loss: 0.1821088
	speed: 0.0260s/iter; left time: 710.1058s
Epoch: 6 cost time: 30.75624132156372
Epoch: 6, Steps: 1138 | Train Loss: 0.1922791 Vali Loss: 0.2279809 Test Loss: 0.2974764
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.1774684
	speed: 0.4964s/iter; left time: 13508.9988s
	iters: 200, epoch: 7 | loss: 0.1911191
	speed: 0.0212s/iter; left time: 574.2120s
	iters: 300, epoch: 7 | loss: 0.1787711
	speed: 0.0214s/iter; left time: 579.0633s
	iters: 400, epoch: 7 | loss: 0.1864464
	speed: 0.0211s/iter; left time: 568.0182s
	iters: 500, epoch: 7 | loss: 0.1886524
	speed: 0.0212s/iter; left time: 567.8019s
	iters: 600, epoch: 7 | loss: 0.1880533
	speed: 0.0209s/iter; left time: 558.1475s
	iters: 700, epoch: 7 | loss: 0.1780691
	speed: 0.0210s/iter; left time: 560.0968s
	iters: 800, epoch: 7 | loss: 0.1772965
	speed: 0.0210s/iter; left time: 556.7302s
	iters: 900, epoch: 7 | loss: 0.2040522
	speed: 0.0211s/iter; left time: 556.5932s
	iters: 1000, epoch: 7 | loss: 0.1980517
	speed: 0.0208s/iter; left time: 548.2023s
	iters: 1100, epoch: 7 | loss: 0.1965003
	speed: 0.0211s/iter; left time: 553.7867s
Epoch: 7 cost time: 25.67939043045044
Epoch: 7, Steps: 1138 | Train Loss: 0.1913958 Vali Loss: 0.2275089 Test Loss: 0.2962406
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.1743305
	speed: 0.4195s/iter; left time: 10938.4281s
	iters: 200, epoch: 8 | loss: 0.1912176
	speed: 0.0213s/iter; left time: 554.5243s
	iters: 300, epoch: 8 | loss: 0.1860714
	speed: 0.0218s/iter; left time: 564.0845s
	iters: 400, epoch: 8 | loss: 0.2003982
	speed: 0.0216s/iter; left time: 555.9969s
	iters: 500, epoch: 8 | loss: 0.1760711
	speed: 0.0214s/iter; left time: 548.9170s
	iters: 600, epoch: 8 | loss: 0.1807005
	speed: 0.0214s/iter; left time: 547.9441s
	iters: 700, epoch: 8 | loss: 0.1811187
	speed: 0.0217s/iter; left time: 553.3248s
	iters: 800, epoch: 8 | loss: 0.2035446
	speed: 0.0217s/iter; left time: 551.7878s
	iters: 900, epoch: 8 | loss: 0.1800245
	speed: 0.0214s/iter; left time: 540.7997s
	iters: 1000, epoch: 8 | loss: 0.1947500
	speed: 0.0215s/iter; left time: 540.0874s
	iters: 1100, epoch: 8 | loss: 0.1921541
	speed: 0.0218s/iter; left time: 546.0907s
Epoch: 8 cost time: 26.079488277435303
Epoch: 8, Steps: 1138 | Train Loss: 0.1909636 Vali Loss: 0.2269440 Test Loss: 0.2959437
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.1875421
	speed: 0.4895s/iter; left time: 12207.7891s
	iters: 200, epoch: 9 | loss: 0.2009884
	speed: 0.0216s/iter; left time: 536.2493s
	iters: 300, epoch: 9 | loss: 0.1898975
	speed: 0.0216s/iter; left time: 535.2977s
	iters: 400, epoch: 9 | loss: 0.1985303
	speed: 0.0226s/iter; left time: 556.8444s
	iters: 500, epoch: 9 | loss: 0.1842789
	speed: 0.0237s/iter; left time: 581.3890s
	iters: 600, epoch: 9 | loss: 0.2035979
	speed: 0.0243s/iter; left time: 594.8258s
	iters: 700, epoch: 9 | loss: 0.1948798
	speed: 0.0237s/iter; left time: 576.1289s
	iters: 800, epoch: 9 | loss: 0.1794679
	speed: 0.0240s/iter; left time: 581.1494s
	iters: 900, epoch: 9 | loss: 0.1656130
	speed: 0.0250s/iter; left time: 603.1941s
	iters: 1000, epoch: 9 | loss: 0.1871618
	speed: 0.0261s/iter; left time: 627.6119s
	iters: 1100, epoch: 9 | loss: 0.1823760
	speed: 0.0269s/iter; left time: 644.0734s
Epoch: 9 cost time: 28.729379177093506
Epoch: 9, Steps: 1138 | Train Loss: 0.1907274 Vali Loss: 0.2271679 Test Loss: 0.2964027
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.1834848
	speed: 0.5312s/iter; left time: 12641.3371s
	iters: 200, epoch: 10 | loss: 0.2009833
	speed: 0.0243s/iter; left time: 576.2448s
	iters: 300, epoch: 10 | loss: 0.1879421
	speed: 0.0244s/iter; left time: 575.2489s
	iters: 400, epoch: 10 | loss: 0.1882213
	speed: 0.0245s/iter; left time: 576.5675s
	iters: 500, epoch: 10 | loss: 0.2000283
	speed: 0.0261s/iter; left time: 611.1189s
	iters: 600, epoch: 10 | loss: 0.1985761
	speed: 0.0263s/iter; left time: 612.6194s
	iters: 700, epoch: 10 | loss: 0.2088095
	speed: 0.0266s/iter; left time: 617.1171s
	iters: 800, epoch: 10 | loss: 0.2132454
	speed: 0.0265s/iter; left time: 611.3471s
	iters: 900, epoch: 10 | loss: 0.1968311
	speed: 0.0264s/iter; left time: 607.1275s
	iters: 1000, epoch: 10 | loss: 0.1775122
	speed: 0.0267s/iter; left time: 611.0025s
	iters: 1100, epoch: 10 | loss: 0.1908596
	speed: 0.0264s/iter; left time: 601.8084s
Epoch: 10 cost time: 30.836470365524292
Epoch: 10, Steps: 1138 | Train Loss: 0.1906277 Vali Loss: 0.2270683 Test Loss: 0.2960947
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.2056248
	speed: 0.5337s/iter; left time: 12095.2106s
	iters: 200, epoch: 11 | loss: 0.1907160
	speed: 0.0246s/iter; left time: 555.6358s
	iters: 300, epoch: 11 | loss: 0.1901122
	speed: 0.0234s/iter; left time: 525.9904s
	iters: 400, epoch: 11 | loss: 0.1796570
	speed: 0.0243s/iter; left time: 544.4714s
	iters: 500, epoch: 11 | loss: 0.1999581
	speed: 0.0256s/iter; left time: 570.3135s
	iters: 600, epoch: 11 | loss: 0.1803932
	speed: 0.0264s/iter; left time: 585.1419s
	iters: 700, epoch: 11 | loss: 0.1968594
	speed: 0.0264s/iter; left time: 582.0638s
	iters: 800, epoch: 11 | loss: 0.1812226
	speed: 0.0266s/iter; left time: 583.8321s
	iters: 900, epoch: 11 | loss: 0.1730831
	speed: 0.0265s/iter; left time: 579.6090s
	iters: 1000, epoch: 11 | loss: 0.2221701
	speed: 0.0265s/iter; left time: 577.2940s
	iters: 1100, epoch: 11 | loss: 0.2042874
	speed: 0.0261s/iter; left time: 566.1072s
Epoch: 11 cost time: 30.458516120910645
Epoch: 11, Steps: 1138 | Train Loss: 0.1905883 Vali Loss: 0.2271325 Test Loss: 0.2960790
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.1965677
	speed: 0.5293s/iter; left time: 11392.9444s
	iters: 200, epoch: 12 | loss: 0.2016745
	speed: 0.0244s/iter; left time: 521.8566s
	iters: 300, epoch: 12 | loss: 0.1914342
	speed: 0.0233s/iter; left time: 497.5778s
	iters: 400, epoch: 12 | loss: 0.1820446
	speed: 0.0256s/iter; left time: 543.9446s
	iters: 500, epoch: 12 | loss: 0.1920652
	speed: 0.0257s/iter; left time: 542.2780s
	iters: 600, epoch: 12 | loss: 0.2008943
	speed: 0.0265s/iter; left time: 556.4631s
	iters: 700, epoch: 12 | loss: 0.1900262
	speed: 0.0262s/iter; left time: 548.5825s
	iters: 800, epoch: 12 | loss: 0.2003226
	speed: 0.0256s/iter; left time: 532.9910s
	iters: 900, epoch: 12 | loss: 0.1853345
	speed: 0.0261s/iter; left time: 540.3557s
	iters: 1000, epoch: 12 | loss: 0.1835215
	speed: 0.0260s/iter; left time: 536.9215s
	iters: 1100, epoch: 12 | loss: 0.2014457
	speed: 0.0261s/iter; left time: 536.2802s
Epoch: 12 cost time: 30.684672355651855
Epoch: 12, Steps: 1138 | Train Loss: 0.1904848 Vali Loss: 0.2271466 Test Loss: 0.2961721
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.1986599
	speed: 0.4730s/iter; left time: 9641.8366s
	iters: 200, epoch: 13 | loss: 0.1924928
	speed: 0.0217s/iter; left time: 440.6415s
	iters: 300, epoch: 13 | loss: 0.1859385
	speed: 0.0213s/iter; left time: 429.3825s
	iters: 400, epoch: 13 | loss: 0.1904309
	speed: 0.0213s/iter; left time: 427.0315s
	iters: 500, epoch: 13 | loss: 0.1869607
	speed: 0.0213s/iter; left time: 425.3944s
	iters: 600, epoch: 13 | loss: 0.1939616
	speed: 0.0213s/iter; left time: 423.2645s
	iters: 700, epoch: 13 | loss: 0.2105876
	speed: 0.0213s/iter; left time: 421.0434s
	iters: 800, epoch: 13 | loss: 0.2079737
	speed: 0.0217s/iter; left time: 426.1908s
	iters: 900, epoch: 13 | loss: 0.2014680
	speed: 0.0214s/iter; left time: 419.7284s
	iters: 1000, epoch: 13 | loss: 0.1894658
	speed: 0.0211s/iter; left time: 411.2974s
	iters: 1100, epoch: 13 | loss: 0.2000659
	speed: 0.0213s/iter; left time: 412.4539s
Epoch: 13 cost time: 26.131589651107788
Epoch: 13, Steps: 1138 | Train Loss: 0.1906106 Vali Loss: 0.2270028 Test Loss: 0.2960593
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.1950996
	speed: 0.4213s/iter; left time: 8107.8471s
	iters: 200, epoch: 14 | loss: 0.2031523
	speed: 0.0216s/iter; left time: 414.5026s
	iters: 300, epoch: 14 | loss: 0.1895729
	speed: 0.0217s/iter; left time: 413.2976s
	iters: 400, epoch: 14 | loss: 0.1819219
	speed: 0.0215s/iter; left time: 406.7849s
	iters: 500, epoch: 14 | loss: 0.1948674
	speed: 0.0217s/iter; left time: 409.0798s
	iters: 600, epoch: 14 | loss: 0.1854980
	speed: 0.0214s/iter; left time: 401.4998s
	iters: 700, epoch: 14 | loss: 0.1877799
	speed: 0.0217s/iter; left time: 404.4686s
	iters: 800, epoch: 14 | loss: 0.1890235
	speed: 0.0213s/iter; left time: 395.3194s
	iters: 900, epoch: 14 | loss: 0.1996012
	speed: 0.0214s/iter; left time: 394.3458s
	iters: 1000, epoch: 14 | loss: 0.1692043
	speed: 0.0214s/iter; left time: 391.9307s
	iters: 1100, epoch: 14 | loss: 0.1817557
	speed: 0.0212s/iter; left time: 386.5748s
Epoch: 14 cost time: 26.229687452316284
Epoch: 14, Steps: 1138 | Train Loss: 0.1905084 Vali Loss: 0.2272291 Test Loss: 0.2960910
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.1933650
	speed: 0.4218s/iter; left time: 7637.9240s
	iters: 200, epoch: 15 | loss: 0.1926586
	speed: 0.0213s/iter; left time: 383.9886s
	iters: 300, epoch: 15 | loss: 0.2033716
	speed: 0.0214s/iter; left time: 382.9776s
	iters: 400, epoch: 15 | loss: 0.1836137
	speed: 0.0218s/iter; left time: 387.4480s
	iters: 500, epoch: 15 | loss: 0.1739811
	speed: 0.0219s/iter; left time: 388.6612s
	iters: 600, epoch: 15 | loss: 0.1831156
	speed: 0.0217s/iter; left time: 381.7405s
	iters: 700, epoch: 15 | loss: 0.2053054
	speed: 0.0216s/iter; left time: 377.3930s
	iters: 800, epoch: 15 | loss: 0.1889982
	speed: 0.0217s/iter; left time: 378.5875s
	iters: 900, epoch: 15 | loss: 0.2080718
	speed: 0.0215s/iter; left time: 371.7738s
	iters: 1000, epoch: 15 | loss: 0.1926726
	speed: 0.0218s/iter; left time: 374.3821s
	iters: 1100, epoch: 15 | loss: 0.1789893
	speed: 0.0217s/iter; left time: 372.0722s
Epoch: 15 cost time: 26.166722059249878
Epoch: 15, Steps: 1138 | Train Loss: 0.1905226 Vali Loss: 0.2271312 Test Loss: 0.2960904
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : ECL_96_96_13_emb_128_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (5165, 1, 96, 321) (5165, 1, 96, 321)
test shape: (5165, 96, 321) (5165, 96, 321)
mse:0.2973790466785431, mae:0.3860105872154236
Args in experiment:
Namespace(is_training=1, model_id='ECL_96_96_14_emb_128', model='xLSTM', data='custom', root_path='./data/electricity/', data_path='/input-data/electricity.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, enc_in=321, dec_in=7, c_out=321, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.3, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=50, batch_size=32, patience=10, learning_rate=0.001, des='test', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, use_norm=True, partial_start_index=0, hidden_size=512, num_layers=2, mark_enc_in=4, embedding_dim=128, weight_decay=0.0001, kernal_size=5, num_heads_xlstm=8, qkv_proj_blocksize=2, proj_factor=1.3, num_blocks=3, slstm_at=1, grad_clip_norm=5.0, d_state=16, d_conv=4, expand=2)
Use GPU: cuda:0
{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-L/usr/local/cuda/lib', '-lcublas'], 'extra_cflags': ['-DSLSTM_HIDDEN_SIZE=128', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=8', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__'], 'extra_cuda_cflags': ['-Xptxas="-v"', '-gencode', 'arch=compute_80,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=128', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=8', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__']}
Using /home/thetayne/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/thetayne/.cache/torch_extensions/py310_cu121/slstm_HS128BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0/build.ninja...
Building extension module slstm_HS128BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module slstm_HS128BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
>>>>>>>start training : ECL_96_96_14_emb_128_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 18221
val 2537
test 5165
	iters: 100, epoch: 1 | loss: 0.2746259
	speed: 0.0642s/iter; left time: 1821.3554s
	iters: 200, epoch: 1 | loss: 0.2325539
	speed: 0.0420s/iter; left time: 1185.3544s
	iters: 300, epoch: 1 | loss: 0.1925112
	speed: 0.0416s/iter; left time: 1171.6801s
	iters: 400, epoch: 1 | loss: 0.1702417
	speed: 0.0418s/iter; left time: 1173.0432s
	iters: 500, epoch: 1 | loss: 0.1666523
	speed: 0.0422s/iter; left time: 1180.4119s
Epoch: 1 cost time: 25.817091941833496
Epoch: 1, Steps: 569 | Train Loss: 0.2344790 Vali Loss: 0.2156308 Test Loss: 0.2734662
Validation loss decreased (inf --> 0.215631).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.1438326
	speed: 0.5670s/iter; left time: 15752.3066s
	iters: 200, epoch: 2 | loss: 0.1498315
	speed: 0.0424s/iter; left time: 1172.9087s
	iters: 300, epoch: 2 | loss: 0.1444458
	speed: 0.0425s/iter; left time: 1172.8945s
	iters: 400, epoch: 2 | loss: 0.1433329
	speed: 0.0434s/iter; left time: 1193.9330s
	iters: 500, epoch: 2 | loss: 0.1369978
	speed: 0.0424s/iter; left time: 1160.6336s
Epoch: 2 cost time: 25.299588441848755
Epoch: 2, Steps: 569 | Train Loss: 0.1474393 Vali Loss: 0.2066243 Test Loss: 0.2653157
Validation loss decreased (0.215631 --> 0.206624).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.1335406
	speed: 0.5909s/iter; left time: 16079.3127s
	iters: 200, epoch: 3 | loss: 0.1355927
	speed: 0.0428s/iter; left time: 1161.5881s
	iters: 300, epoch: 3 | loss: 0.1423156
	speed: 0.0424s/iter; left time: 1146.5827s
	iters: 400, epoch: 3 | loss: 0.1279296
	speed: 0.0424s/iter; left time: 1142.2343s
	iters: 500, epoch: 3 | loss: 0.1395344
	speed: 0.0424s/iter; left time: 1136.3632s
Epoch: 3 cost time: 25.09494924545288
Epoch: 3, Steps: 569 | Train Loss: 0.1382953 Vali Loss: 0.2090546 Test Loss: 0.2600360
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.1342982
	speed: 0.5853s/iter; left time: 15594.9902s
	iters: 200, epoch: 4 | loss: 0.1344500
	speed: 0.0423s/iter; left time: 1123.2322s
	iters: 300, epoch: 4 | loss: 0.1289537
	speed: 0.0424s/iter; left time: 1122.2190s
	iters: 400, epoch: 4 | loss: 0.1410674
	speed: 0.0426s/iter; left time: 1121.7779s
	iters: 500, epoch: 4 | loss: 0.1282711
	speed: 0.0419s/iter; left time: 1099.0499s
Epoch: 4 cost time: 25.090418815612793
Epoch: 4, Steps: 569 | Train Loss: 0.1349980 Vali Loss: 0.2051308 Test Loss: 0.2599491
Validation loss decreased (0.206624 --> 0.205131).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.1301561
	speed: 0.5783s/iter; left time: 15079.4014s
	iters: 200, epoch: 5 | loss: 0.1350648
	speed: 0.0394s/iter; left time: 1024.1103s
	iters: 300, epoch: 5 | loss: 0.1314571
	speed: 0.0417s/iter; left time: 1079.9973s
	iters: 400, epoch: 5 | loss: 0.1323600
	speed: 0.0425s/iter; left time: 1095.4999s
	iters: 500, epoch: 5 | loss: 0.1329236
	speed: 0.0420s/iter; left time: 1077.3959s
Epoch: 5 cost time: 24.88018536567688
Epoch: 5, Steps: 569 | Train Loss: 0.1333666 Vali Loss: 0.2056371 Test Loss: 0.2617795
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.1284952
	speed: 0.5872s/iter; left time: 14977.1228s
	iters: 200, epoch: 6 | loss: 0.1305900
	speed: 0.0421s/iter; left time: 1070.1583s
	iters: 300, epoch: 6 | loss: 0.1318118
	speed: 0.0426s/iter; left time: 1077.2401s
	iters: 400, epoch: 6 | loss: 0.1328752
	speed: 0.0424s/iter; left time: 1069.0547s
	iters: 500, epoch: 6 | loss: 0.1376278
	speed: 0.0419s/iter; left time: 1051.0518s
Epoch: 6 cost time: 25.384918212890625
Epoch: 6, Steps: 569 | Train Loss: 0.1325104 Vali Loss: 0.2070754 Test Loss: 0.2614931
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.1333512
	speed: 0.5931s/iter; left time: 14791.0999s
	iters: 200, epoch: 7 | loss: 0.1307842
	speed: 0.0388s/iter; left time: 963.1099s
	iters: 300, epoch: 7 | loss: 0.1302332
	speed: 0.0419s/iter; left time: 1035.4674s
	iters: 400, epoch: 7 | loss: 0.1275331
	speed: 0.0419s/iter; left time: 1032.4839s
	iters: 500, epoch: 7 | loss: 0.1293294
	speed: 0.0423s/iter; left time: 1037.6682s
Epoch: 7 cost time: 24.639399528503418
Epoch: 7, Steps: 569 | Train Loss: 0.1320875 Vali Loss: 0.2060030 Test Loss: 0.2619504
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.1228151
	speed: 0.5608s/iter; left time: 13665.5678s
	iters: 200, epoch: 8 | loss: 0.1211728
	speed: 0.0422s/iter; left time: 1024.2118s
	iters: 300, epoch: 8 | loss: 0.1276187
	speed: 0.0420s/iter; left time: 1016.0591s
	iters: 400, epoch: 8 | loss: 0.1346968
	speed: 0.0430s/iter; left time: 1035.3206s
	iters: 500, epoch: 8 | loss: 0.1294691
	speed: 0.0423s/iter; left time: 1014.8614s
Epoch: 8 cost time: 25.039000749588013
Epoch: 8, Steps: 569 | Train Loss: 0.1318460 Vali Loss: 0.2069474 Test Loss: 0.2614889
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 0.1293448
	speed: 0.5719s/iter; left time: 13609.9977s
	iters: 200, epoch: 9 | loss: 0.1272675
	speed: 0.0422s/iter; left time: 999.7255s
	iters: 300, epoch: 9 | loss: 0.1252910
	speed: 0.0426s/iter; left time: 1004.5730s
	iters: 400, epoch: 9 | loss: 0.1243881
	speed: 0.0421s/iter; left time: 989.0435s
	iters: 500, epoch: 9 | loss: 0.1316431
	speed: 0.0416s/iter; left time: 972.8810s
Epoch: 9 cost time: 25.095872402191162
Epoch: 9, Steps: 569 | Train Loss: 0.1316937 Vali Loss: 0.2075818 Test Loss: 0.2619447
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 0.1306097
	speed: 0.5886s/iter; left time: 13673.5617s
	iters: 200, epoch: 10 | loss: 0.1342519
	speed: 0.0391s/iter; left time: 904.2960s
	iters: 300, epoch: 10 | loss: 0.1317268
	speed: 0.0403s/iter; left time: 928.2994s
	iters: 400, epoch: 10 | loss: 0.1237782
	speed: 0.0426s/iter; left time: 977.6279s
	iters: 500, epoch: 10 | loss: 0.1310132
	speed: 0.0427s/iter; left time: 974.6549s
Epoch: 10 cost time: 24.874884128570557
Epoch: 10, Steps: 569 | Train Loss: 0.1316084 Vali Loss: 0.2072455 Test Loss: 0.2617255
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 0.1283638
	speed: 0.5887s/iter; left time: 13340.3118s
	iters: 200, epoch: 11 | loss: 0.1232110
	speed: 0.0386s/iter; left time: 871.3802s
	iters: 300, epoch: 11 | loss: 0.1292578
	speed: 0.0406s/iter; left time: 911.2868s
	iters: 400, epoch: 11 | loss: 0.1318224
	speed: 0.0419s/iter; left time: 937.9505s
	iters: 500, epoch: 11 | loss: 0.1347223
	speed: 0.0424s/iter; left time: 944.1963s
Epoch: 11 cost time: 24.405648231506348
Epoch: 11, Steps: 569 | Train Loss: 0.1315970 Vali Loss: 0.2071441 Test Loss: 0.2618799
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 0.1297588
	speed: 0.5864s/iter; left time: 12954.6284s
	iters: 200, epoch: 12 | loss: 0.1310876
	speed: 0.0426s/iter; left time: 935.9675s
	iters: 300, epoch: 12 | loss: 0.1378257
	speed: 0.0424s/iter; left time: 927.4412s
	iters: 400, epoch: 12 | loss: 0.1252809
	speed: 0.0418s/iter; left time: 911.2937s
	iters: 500, epoch: 12 | loss: 0.1311332
	speed: 0.0420s/iter; left time: 911.1913s
Epoch: 12 cost time: 25.106319427490234
Epoch: 12, Steps: 569 | Train Loss: 0.1315827 Vali Loss: 0.2072802 Test Loss: 0.2618396
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 0.1380193
	speed: 0.5626s/iter; left time: 12108.2580s
	iters: 200, epoch: 13 | loss: 0.1339929
	speed: 0.0417s/iter; left time: 894.3599s
	iters: 300, epoch: 13 | loss: 0.1343837
	speed: 0.0419s/iter; left time: 892.8577s
	iters: 400, epoch: 13 | loss: 0.1296673
	speed: 0.0418s/iter; left time: 887.4368s
	iters: 500, epoch: 13 | loss: 0.1394017
	speed: 0.0419s/iter; left time: 885.5892s
Epoch: 13 cost time: 24.859781503677368
Epoch: 13, Steps: 569 | Train Loss: 0.1315588 Vali Loss: 0.2071941 Test Loss: 0.2618811
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 0.1264858
	speed: 0.5928s/iter; left time: 12421.9637s
	iters: 200, epoch: 14 | loss: 0.1297602
	speed: 0.0417s/iter; left time: 869.2855s
	iters: 300, epoch: 14 | loss: 0.1265625
	speed: 0.0420s/iter; left time: 872.4225s
	iters: 400, epoch: 14 | loss: 0.1332651
	speed: 0.0421s/iter; left time: 869.0745s
	iters: 500, epoch: 14 | loss: 0.1429765
	speed: 0.0420s/iter; left time: 863.7133s
Epoch: 14 cost time: 25.378649711608887
Epoch: 14, Steps: 569 | Train Loss: 0.1315592 Vali Loss: 0.2071576 Test Loss: 0.2619110
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : ECL_96_96_14_emb_128_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (5165, 1, 96, 321) (5165, 1, 96, 321)
test shape: (5165, 96, 321) (5165, 96, 321)
mse:0.25994861125946045, mae:0.35667628049850464
Args in experiment:
Namespace(is_training=1, model_id='ECL_96_96_15_emb_128', model='xLSTM', data='custom', root_path='./data/electricity/', data_path='/input-data/electricity.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, enc_in=321, dec_in=7, c_out=321, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.5, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=50, batch_size=16, patience=10, learning_rate=0.001, des='test', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, use_norm=True, partial_start_index=0, hidden_size=512, num_layers=2, mark_enc_in=4, embedding_dim=128, weight_decay=1e-06, kernal_size=3, num_heads_xlstm=8, qkv_proj_blocksize=8, proj_factor=1.3, num_blocks=2, slstm_at=1, grad_clip_norm=0.5, d_state=16, d_conv=4, expand=2)
Use GPU: cuda:0
{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-L/usr/local/cuda/lib', '-lcublas'], 'extra_cflags': ['-DSLSTM_HIDDEN_SIZE=128', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=8', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__'], 'extra_cuda_cflags': ['-Xptxas="-v"', '-gencode', 'arch=compute_80,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=128', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=8', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__']}
Using /home/thetayne/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/thetayne/.cache/torch_extensions/py310_cu121/slstm_HS128BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0/build.ninja...
Building extension module slstm_HS128BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module slstm_HS128BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
>>>>>>>start training : ECL_96_96_15_emb_128_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 18221
val 2537
test 5165
	iters: 100, epoch: 1 | loss: 0.2888231
	speed: 0.0430s/iter; left time: 2441.9410s
	iters: 200, epoch: 1 | loss: 0.2740544
	speed: 0.0236s/iter; left time: 1337.8741s
	iters: 300, epoch: 1 | loss: 0.2196400
	speed: 0.0245s/iter; left time: 1388.1160s
	iters: 400, epoch: 1 | loss: 0.2056631
	speed: 0.0239s/iter; left time: 1350.0366s
	iters: 500, epoch: 1 | loss: 0.2007308
	speed: 0.0243s/iter; left time: 1367.9253s
	iters: 600, epoch: 1 | loss: 0.2002689
	speed: 0.0242s/iter; left time: 1363.8782s
	iters: 700, epoch: 1 | loss: 0.2026538
	speed: 0.0241s/iter; left time: 1353.6969s
	iters: 800, epoch: 1 | loss: 0.1982442
	speed: 0.0242s/iter; left time: 1359.1061s
	iters: 900, epoch: 1 | loss: 0.1868184
	speed: 0.0240s/iter; left time: 1344.7600s
	iters: 1000, epoch: 1 | loss: 0.1775464
	speed: 0.0253s/iter; left time: 1414.3403s
	iters: 1100, epoch: 1 | loss: 0.1860185
	speed: 0.0246s/iter; left time: 1370.0719s
Epoch: 1 cost time: 29.391957998275757
Epoch: 1, Steps: 1138 | Train Loss: 0.2334955 Vali Loss: 0.2129621 Test Loss: 0.2746752
Validation loss decreased (inf --> 0.212962).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.1807899
	speed: 0.4223s/iter; left time: 23507.9001s
	iters: 200, epoch: 2 | loss: 0.1891174
	speed: 0.0219s/iter; left time: 1214.2432s
	iters: 300, epoch: 2 | loss: 0.1774904
	speed: 0.0216s/iter; left time: 1195.4215s
	iters: 400, epoch: 2 | loss: 0.1679245
	speed: 0.0218s/iter; left time: 1208.8705s
	iters: 500, epoch: 2 | loss: 0.1689338
	speed: 0.0218s/iter; left time: 1204.8471s
	iters: 600, epoch: 2 | loss: 0.1912445
	speed: 0.0212s/iter; left time: 1167.6427s
	iters: 700, epoch: 2 | loss: 0.1842081
	speed: 0.0210s/iter; left time: 1156.0007s
	iters: 800, epoch: 2 | loss: 0.1978887
	speed: 0.0209s/iter; left time: 1151.3215s
	iters: 900, epoch: 2 | loss: 0.1737778
	speed: 0.0209s/iter; left time: 1143.9879s
	iters: 1000, epoch: 2 | loss: 0.1702024
	speed: 0.0212s/iter; left time: 1161.2770s
	iters: 1100, epoch: 2 | loss: 0.1766045
	speed: 0.0212s/iter; left time: 1156.7960s
Epoch: 2 cost time: 25.78679060935974
Epoch: 2, Steps: 1138 | Train Loss: 0.1804978 Vali Loss: 0.2179114 Test Loss: 0.2714233
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.1750304
	speed: 0.4279s/iter; left time: 23332.3567s
	iters: 200, epoch: 3 | loss: 0.1571774
	speed: 0.0212s/iter; left time: 1154.1439s
	iters: 300, epoch: 3 | loss: 0.1620436
	speed: 0.0213s/iter; left time: 1157.5239s
	iters: 400, epoch: 3 | loss: 0.1702557
	speed: 0.0217s/iter; left time: 1177.1618s
	iters: 500, epoch: 3 | loss: 0.1596379
	speed: 0.0215s/iter; left time: 1161.2358s
	iters: 600, epoch: 3 | loss: 0.1767311
	speed: 0.0213s/iter; left time: 1148.2384s
	iters: 700, epoch: 3 | loss: 0.1727232
	speed: 0.0214s/iter; left time: 1152.7618s
	iters: 800, epoch: 3 | loss: 0.1653825
	speed: 0.0212s/iter; left time: 1143.5251s
	iters: 900, epoch: 3 | loss: 0.1718354
	speed: 0.0213s/iter; left time: 1144.0710s
	iters: 1000, epoch: 3 | loss: 0.1686138
	speed: 0.0213s/iter; left time: 1143.0993s
	iters: 1100, epoch: 3 | loss: 0.1881545
	speed: 0.0211s/iter; left time: 1130.6827s
Epoch: 3 cost time: 26.013609886169434
Epoch: 3, Steps: 1138 | Train Loss: 0.1741928 Vali Loss: 0.2133021 Test Loss: 0.2759134
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.1607467
	speed: 0.4230s/iter; left time: 22585.2540s
	iters: 200, epoch: 4 | loss: 0.1714936
	speed: 0.0215s/iter; left time: 1143.1315s
	iters: 300, epoch: 4 | loss: 0.1681135
	speed: 0.0212s/iter; left time: 1128.8574s
	iters: 400, epoch: 4 | loss: 0.1614843
	speed: 0.0212s/iter; left time: 1126.7562s
	iters: 500, epoch: 4 | loss: 0.1582193
	speed: 0.0211s/iter; left time: 1117.0698s
	iters: 600, epoch: 4 | loss: 0.1777145
	speed: 0.0213s/iter; left time: 1126.0475s
	iters: 700, epoch: 4 | loss: 0.1726369
	speed: 0.0214s/iter; left time: 1130.5608s
	iters: 800, epoch: 4 | loss: 0.1757737
	speed: 0.0215s/iter; left time: 1131.4196s
	iters: 900, epoch: 4 | loss: 0.1785326
	speed: 0.0217s/iter; left time: 1139.7806s
	iters: 1000, epoch: 4 | loss: 0.1694751
	speed: 0.0211s/iter; left time: 1109.0018s
	iters: 1100, epoch: 4 | loss: 0.1719505
	speed: 0.0214s/iter; left time: 1123.1084s
Epoch: 4 cost time: 25.743529796600342
Epoch: 4, Steps: 1138 | Train Loss: 0.1721088 Vali Loss: 0.2204805 Test Loss: 0.2776449
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.1642553
	speed: 0.4226s/iter; left time: 22082.0325s
	iters: 200, epoch: 5 | loss: 0.1737538
	speed: 0.0218s/iter; left time: 1139.2411s
	iters: 300, epoch: 5 | loss: 0.1588928
	speed: 0.0216s/iter; left time: 1123.8580s
	iters: 400, epoch: 5 | loss: 0.1677686
	speed: 0.0212s/iter; left time: 1100.4234s
	iters: 500, epoch: 5 | loss: 0.1784076
	speed: 0.0215s/iter; left time: 1114.3282s
	iters: 600, epoch: 5 | loss: 0.1593696
	speed: 0.0213s/iter; left time: 1100.0300s
	iters: 700, epoch: 5 | loss: 0.1731583
	speed: 0.0212s/iter; left time: 1092.8520s
	iters: 800, epoch: 5 | loss: 0.1714474
	speed: 0.0209s/iter; left time: 1076.2354s
	iters: 900, epoch: 5 | loss: 0.1768703
	speed: 0.0212s/iter; left time: 1089.1197s
	iters: 1000, epoch: 5 | loss: 0.1827396
	speed: 0.0211s/iter; left time: 1085.2259s
	iters: 1100, epoch: 5 | loss: 0.1725864
	speed: 0.0210s/iter; left time: 1073.9056s
Epoch: 5 cost time: 25.68337368965149
Epoch: 5, Steps: 1138 | Train Loss: 0.1710759 Vali Loss: 0.2158325 Test Loss: 0.2764596
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.1679756
	speed: 0.4321s/iter; left time: 22083.3580s
	iters: 200, epoch: 6 | loss: 0.1779697
	speed: 0.0217s/iter; left time: 1106.3503s
	iters: 300, epoch: 6 | loss: 0.1602084
	speed: 0.0213s/iter; left time: 1082.3361s
	iters: 400, epoch: 6 | loss: 0.1883814
	speed: 0.0217s/iter; left time: 1102.5722s
	iters: 500, epoch: 6 | loss: 0.1743558
	speed: 0.0216s/iter; left time: 1093.4169s
	iters: 600, epoch: 6 | loss: 0.1661404
	speed: 0.0218s/iter; left time: 1101.8994s
	iters: 700, epoch: 6 | loss: 0.1735893
	speed: 0.0224s/iter; left time: 1132.2280s
	iters: 800, epoch: 6 | loss: 0.1800674
	speed: 0.0213s/iter; left time: 1071.6247s
	iters: 900, epoch: 6 | loss: 0.1732809
	speed: 0.0213s/iter; left time: 1072.9094s
	iters: 1000, epoch: 6 | loss: 0.1597433
	speed: 0.0213s/iter; left time: 1070.7100s
	iters: 1100, epoch: 6 | loss: 0.1622598
	speed: 0.0213s/iter; left time: 1065.3486s
Epoch: 6 cost time: 26.00097417831421
Epoch: 6, Steps: 1138 | Train Loss: 0.1705794 Vali Loss: 0.2177078 Test Loss: 0.2760279
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.1701842
	speed: 0.4234s/iter; left time: 21159.7508s
	iters: 200, epoch: 7 | loss: 0.1682876
	speed: 0.0218s/iter; left time: 1087.2947s
	iters: 300, epoch: 7 | loss: 0.1536656
	speed: 0.0215s/iter; left time: 1071.4536s
	iters: 400, epoch: 7 | loss: 0.1789774
	speed: 0.0207s/iter; left time: 1027.8709s
	iters: 500, epoch: 7 | loss: 0.1791651
	speed: 0.0213s/iter; left time: 1053.5819s
	iters: 600, epoch: 7 | loss: 0.1702932
	speed: 0.0215s/iter; left time: 1061.2779s
	iters: 700, epoch: 7 | loss: 0.1735366
	speed: 0.0212s/iter; left time: 1048.0533s
	iters: 800, epoch: 7 | loss: 0.1703426
	speed: 0.0213s/iter; left time: 1050.4346s
	iters: 900, epoch: 7 | loss: 0.1764656
	speed: 0.0216s/iter; left time: 1059.7989s
	iters: 1000, epoch: 7 | loss: 0.1743767
	speed: 0.0221s/iter; left time: 1082.9221s
	iters: 1100, epoch: 7 | loss: 0.1715067
	speed: 0.0214s/iter; left time: 1050.1338s
Epoch: 7 cost time: 26.00164270401001
Epoch: 7, Steps: 1138 | Train Loss: 0.1702442 Vali Loss: 0.2188472 Test Loss: 0.2773055
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.1676090
	speed: 0.4283s/iter; left time: 20916.2601s
	iters: 200, epoch: 8 | loss: 0.1638307
	speed: 0.0217s/iter; left time: 1058.1626s
	iters: 300, epoch: 8 | loss: 0.1786000
	speed: 0.0216s/iter; left time: 1049.5399s
	iters: 400, epoch: 8 | loss: 0.1627059
	speed: 0.0215s/iter; left time: 1045.4788s
	iters: 500, epoch: 8 | loss: 0.1632281
	speed: 0.0215s/iter; left time: 1043.6070s
	iters: 600, epoch: 8 | loss: 0.1869797
	speed: 0.0212s/iter; left time: 1024.4316s
	iters: 700, epoch: 8 | loss: 0.1594839
	speed: 0.0214s/iter; left time: 1033.6171s
	iters: 800, epoch: 8 | loss: 0.1717891
	speed: 0.0214s/iter; left time: 1030.1859s
	iters: 900, epoch: 8 | loss: 0.1570144
	speed: 0.0213s/iter; left time: 1025.5096s
	iters: 1000, epoch: 8 | loss: 0.1731026
	speed: 0.0218s/iter; left time: 1043.6297s
	iters: 1100, epoch: 8 | loss: 0.1610121
	speed: 0.0220s/iter; left time: 1052.1142s
Epoch: 8 cost time: 26.070053339004517
Epoch: 8, Steps: 1138 | Train Loss: 0.1700911 Vali Loss: 0.2192595 Test Loss: 0.2774500
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 0.1621580
	speed: 0.4320s/iter; left time: 20604.3605s
	iters: 200, epoch: 9 | loss: 0.2067225
	speed: 0.0214s/iter; left time: 1017.4216s
	iters: 300, epoch: 9 | loss: 0.1746039
	speed: 0.0211s/iter; left time: 1002.6932s
	iters: 400, epoch: 9 | loss: 0.1915711
	speed: 0.0212s/iter; left time: 1004.2560s
	iters: 500, epoch: 9 | loss: 0.1689031
	speed: 0.0214s/iter; left time: 1010.2961s
	iters: 600, epoch: 9 | loss: 0.1796635
	speed: 0.0216s/iter; left time: 1018.9605s
	iters: 700, epoch: 9 | loss: 0.1614577
	speed: 0.0214s/iter; left time: 1009.6979s
	iters: 800, epoch: 9 | loss: 0.1680116
	speed: 0.0215s/iter; left time: 1012.6426s
	iters: 900, epoch: 9 | loss: 0.1830538
	speed: 0.0218s/iter; left time: 1024.1029s
	iters: 1000, epoch: 9 | loss: 0.1904735
	speed: 0.0212s/iter; left time: 990.2573s
	iters: 1100, epoch: 9 | loss: 0.1712511
	speed: 0.0215s/iter; left time: 1004.1327s
Epoch: 9 cost time: 25.902770042419434
Epoch: 9, Steps: 1138 | Train Loss: 0.1700140 Vali Loss: 0.2193989 Test Loss: 0.2775586
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 0.1738309
	speed: 0.4230s/iter; left time: 19693.5282s
	iters: 200, epoch: 10 | loss: 0.1633651
	speed: 0.0210s/iter; left time: 973.6038s
	iters: 300, epoch: 10 | loss: 0.1658196
	speed: 0.0210s/iter; left time: 974.3229s
	iters: 400, epoch: 10 | loss: 0.1762087
	speed: 0.0213s/iter; left time: 983.1209s
	iters: 500, epoch: 10 | loss: 0.1659295
	speed: 0.0212s/iter; left time: 979.6516s
	iters: 600, epoch: 10 | loss: 0.1648915
	speed: 0.0214s/iter; left time: 984.0515s
	iters: 700, epoch: 10 | loss: 0.1686744
	speed: 0.0218s/iter; left time: 1003.6971s
	iters: 800, epoch: 10 | loss: 0.1638358
	speed: 0.0212s/iter; left time: 972.9164s
	iters: 900, epoch: 10 | loss: 0.1797466
	speed: 0.0218s/iter; left time: 995.5869s
	iters: 1000, epoch: 10 | loss: 0.1777214
	speed: 0.0213s/iter; left time: 970.7351s
	iters: 1100, epoch: 10 | loss: 0.1661920
	speed: 0.0213s/iter; left time: 968.1681s
Epoch: 10 cost time: 25.75839591026306
Epoch: 10, Steps: 1138 | Train Loss: 0.1699808 Vali Loss: 0.2195290 Test Loss: 0.2779657
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 0.1636413
	speed: 0.4253s/iter; left time: 19319.0013s
	iters: 200, epoch: 11 | loss: 0.1602450
	speed: 0.0213s/iter; left time: 963.2625s
	iters: 300, epoch: 11 | loss: 0.1711184
	speed: 0.0215s/iter; left time: 970.9486s
	iters: 400, epoch: 11 | loss: 0.1574302
	speed: 0.0216s/iter; left time: 972.4242s
	iters: 500, epoch: 11 | loss: 0.1774464
	speed: 0.0211s/iter; left time: 951.8861s
	iters: 600, epoch: 11 | loss: 0.1751796
	speed: 0.0212s/iter; left time: 952.3635s
	iters: 700, epoch: 11 | loss: 0.1680316
	speed: 0.0217s/iter; left time: 973.2382s
	iters: 800, epoch: 11 | loss: 0.1615915
	speed: 0.0214s/iter; left time: 955.0842s
	iters: 900, epoch: 11 | loss: 0.1735856
	speed: 0.0211s/iter; left time: 943.6427s
	iters: 1000, epoch: 11 | loss: 0.1741965
	speed: 0.0215s/iter; left time: 955.6219s
	iters: 1100, epoch: 11 | loss: 0.1673410
	speed: 0.0216s/iter; left time: 959.6504s
Epoch: 11 cost time: 26.131085872650146
Epoch: 11, Steps: 1138 | Train Loss: 0.1699477 Vali Loss: 0.2193291 Test Loss: 0.2780127
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : ECL_96_96_15_emb_128_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (5165, 1, 96, 321) (5165, 1, 96, 321)
test shape: (5165, 96, 321) (5165, 96, 321)
mse:0.2746749818325043, mae:0.3680371642112732
Args in experiment:
Namespace(is_training=1, model_id='ECL_96_96_16_emb_128', model='xLSTM', data='custom', root_path='./data/electricity/', data_path='/input-data/electricity.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, enc_in=321, dec_in=7, c_out=321, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.3, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=50, batch_size=16, patience=10, learning_rate=0.0001, des='test', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, use_norm=True, partial_start_index=0, hidden_size=512, num_layers=2, mark_enc_in=4, embedding_dim=128, weight_decay=1e-05, kernal_size=3, num_heads_xlstm=4, qkv_proj_blocksize=8, proj_factor=1.3, num_blocks=7, slstm_at=1, grad_clip_norm=5.0, d_state=16, d_conv=4, expand=2)
Use GPU: cuda:0
{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-L/usr/local/cuda/lib', '-lcublas'], 'extra_cflags': ['-DSLSTM_HIDDEN_SIZE=128', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__'], 'extra_cuda_cflags': ['-Xptxas="-v"', '-gencode', 'arch=compute_80,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=128', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__']}
Using /home/thetayne/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/thetayne/.cache/torch_extensions/py310_cu121/slstm_HS128BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0/build.ninja...
Building extension module slstm_HS128BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module slstm_HS128BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
>>>>>>>start training : ECL_96_96_16_emb_128_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 18221
val 2537
test 5165
	iters: 100, epoch: 1 | loss: 0.6303578
	speed: 0.0667s/iter; left time: 3788.9733s
	iters: 200, epoch: 1 | loss: 0.4645554
	speed: 0.0459s/iter; left time: 2601.6748s
	iters: 300, epoch: 1 | loss: 0.4292583
	speed: 0.0475s/iter; left time: 2688.0054s
	iters: 400, epoch: 1 | loss: 0.3474161
	speed: 0.0466s/iter; left time: 2633.5678s
	iters: 500, epoch: 1 | loss: 0.3202416
	speed: 0.0498s/iter; left time: 2807.7504s
	iters: 600, epoch: 1 | loss: 0.2982958
	speed: 0.0472s/iter; left time: 2656.8512s
	iters: 700, epoch: 1 | loss: 0.2824731
	speed: 0.0465s/iter; left time: 2613.6233s
	iters: 800, epoch: 1 | loss: 0.2388710
	speed: 0.0483s/iter; left time: 2710.3702s
	iters: 900, epoch: 1 | loss: 0.2460158
	speed: 0.0485s/iter; left time: 2714.0569s
	iters: 1000, epoch: 1 | loss: 0.2006243
	speed: 0.0485s/iter; left time: 2712.7601s
	iters: 1100, epoch: 1 | loss: 0.2258897
	speed: 0.0488s/iter; left time: 2720.6860s
Epoch: 1 cost time: 56.22659206390381
Epoch: 1, Steps: 1138 | Train Loss: 0.3619412 Vali Loss: 0.2611021 Test Loss: 0.3341726
Validation loss decreased (inf --> 0.261102).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.2213752
	speed: 0.8334s/iter; left time: 46389.3134s
	iters: 200, epoch: 2 | loss: 0.2121380
	speed: 0.0495s/iter; left time: 2750.2897s
	iters: 300, epoch: 2 | loss: 0.2000961
	speed: 0.0522s/iter; left time: 2893.6963s
	iters: 400, epoch: 2 | loss: 0.2026809
	speed: 0.0478s/iter; left time: 2644.0745s
	iters: 500, epoch: 2 | loss: 0.1850688
	speed: 0.0481s/iter; left time: 2658.3469s
	iters: 600, epoch: 2 | loss: 0.1663865
	speed: 0.0466s/iter; left time: 2572.0468s
	iters: 700, epoch: 2 | loss: 0.1829312
	speed: 0.0473s/iter; left time: 2605.9337s
	iters: 800, epoch: 2 | loss: 0.1856729
	speed: 0.0457s/iter; left time: 2509.9078s
	iters: 900, epoch: 2 | loss: 0.1771306
	speed: 0.0481s/iter; left time: 2641.0186s
	iters: 1000, epoch: 2 | loss: 0.1661647
	speed: 0.0485s/iter; left time: 2657.1193s
	iters: 1100, epoch: 2 | loss: 0.1688992
	speed: 0.0489s/iter; left time: 2671.2548s
Epoch: 2 cost time: 57.10235142707825
Epoch: 2, Steps: 1138 | Train Loss: 0.1861606 Vali Loss: 0.2408222 Test Loss: 0.3306280
Validation loss decreased (0.261102 --> 0.240822).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.1744741
	speed: 0.8185s/iter; left time: 44627.1548s
	iters: 200, epoch: 3 | loss: 0.1714725
	speed: 0.0492s/iter; left time: 2678.7649s
	iters: 300, epoch: 3 | loss: 0.1653066
	speed: 0.0485s/iter; left time: 2637.2248s
	iters: 400, epoch: 3 | loss: 0.1500841
	speed: 0.0479s/iter; left time: 2596.6209s
	iters: 500, epoch: 3 | loss: 0.1738407
	speed: 0.0481s/iter; left time: 2604.7335s
	iters: 600, epoch: 3 | loss: 0.1630380
	speed: 0.0488s/iter; left time: 2635.1902s
	iters: 700, epoch: 3 | loss: 0.1667442
	speed: 0.0493s/iter; left time: 2659.7583s
	iters: 800, epoch: 3 | loss: 0.1694725
	speed: 0.0502s/iter; left time: 2699.8256s
	iters: 900, epoch: 3 | loss: 0.1582310
	speed: 0.0516s/iter; left time: 2773.9487s
	iters: 1000, epoch: 3 | loss: 0.1470529
	speed: 0.0517s/iter; left time: 2773.2290s
	iters: 1100, epoch: 3 | loss: 0.1511006
	speed: 0.0470s/iter; left time: 2514.0337s
Epoch: 3 cost time: 57.46071648597717
Epoch: 3, Steps: 1138 | Train Loss: 0.1614076 Vali Loss: 0.2357339 Test Loss: 0.3233984
Validation loss decreased (0.240822 --> 0.235734).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.1484121
	speed: 0.8217s/iter; left time: 43865.7046s
	iters: 200, epoch: 4 | loss: 0.1551862
	speed: 0.0477s/iter; left time: 2543.1734s
	iters: 300, epoch: 4 | loss: 0.1595110
	speed: 0.0486s/iter; left time: 2586.8505s
	iters: 400, epoch: 4 | loss: 0.1561301
	speed: 0.0502s/iter; left time: 2664.6165s
	iters: 500, epoch: 4 | loss: 0.1551222
	speed: 0.0510s/iter; left time: 2703.1277s
	iters: 600, epoch: 4 | loss: 0.1560876
	speed: 0.0515s/iter; left time: 2726.2572s
	iters: 700, epoch: 4 | loss: 0.1550388
	speed: 0.0485s/iter; left time: 2559.7222s
	iters: 800, epoch: 4 | loss: 0.1530446
	speed: 0.0485s/iter; left time: 2557.2531s
	iters: 900, epoch: 4 | loss: 0.1509668
	speed: 0.0476s/iter; left time: 2504.8528s
	iters: 1000, epoch: 4 | loss: 0.1515570
	speed: 0.0488s/iter; left time: 2561.4942s
	iters: 1100, epoch: 4 | loss: 0.1513340
	speed: 0.0478s/iter; left time: 2504.6147s
Epoch: 4 cost time: 57.053537368774414
Epoch: 4, Steps: 1138 | Train Loss: 0.1537054 Vali Loss: 0.2347837 Test Loss: 0.3244042
Validation loss decreased (0.235734 --> 0.234784).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.1511378
	speed: 0.7802s/iter; left time: 40764.7696s
	iters: 200, epoch: 5 | loss: 0.1450001
	speed: 0.0462s/iter; left time: 2411.5671s
	iters: 300, epoch: 5 | loss: 0.1579796
	speed: 0.0513s/iter; left time: 2670.3060s
	iters: 400, epoch: 5 | loss: 0.1526518
	speed: 0.0469s/iter; left time: 2436.3679s
	iters: 500, epoch: 5 | loss: 0.1519442
	speed: 0.0492s/iter; left time: 2549.6741s
	iters: 600, epoch: 5 | loss: 0.1408719
	speed: 0.0478s/iter; left time: 2472.2031s
	iters: 700, epoch: 5 | loss: 0.1510184
	speed: 0.0493s/iter; left time: 2543.9652s
	iters: 800, epoch: 5 | loss: 0.1498750
	speed: 0.0480s/iter; left time: 2472.6123s
	iters: 900, epoch: 5 | loss: 0.1542095
	speed: 0.0487s/iter; left time: 2507.3903s
	iters: 1000, epoch: 5 | loss: 0.1426396
	speed: 0.0476s/iter; left time: 2443.5273s
	iters: 1100, epoch: 5 | loss: 0.1589811
	speed: 0.0480s/iter; left time: 2458.6876s
Epoch: 5 cost time: 56.52357292175293
Epoch: 5, Steps: 1138 | Train Loss: 0.1502620 Vali Loss: 0.2330447 Test Loss: 0.3198237
Validation loss decreased (0.234784 --> 0.233045).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.1492814
	speed: 0.8247s/iter; left time: 42152.4956s
	iters: 200, epoch: 6 | loss: 0.1585059
	speed: 0.0464s/iter; left time: 2367.4176s
	iters: 300, epoch: 6 | loss: 0.1535613
	speed: 0.0488s/iter; left time: 2485.8058s
	iters: 400, epoch: 6 | loss: 0.1486462
	speed: 0.0488s/iter; left time: 2481.5491s
	iters: 500, epoch: 6 | loss: 0.1540069
	speed: 0.0485s/iter; left time: 2461.6631s
	iters: 600, epoch: 6 | loss: 0.1457266
	speed: 0.0461s/iter; left time: 2334.0399s
	iters: 700, epoch: 6 | loss: 0.1509402
	speed: 0.0473s/iter; left time: 2387.7183s
	iters: 800, epoch: 6 | loss: 0.1447808
	speed: 0.0471s/iter; left time: 2372.4273s
	iters: 900, epoch: 6 | loss: 0.1392488
	speed: 0.0465s/iter; left time: 2341.8048s
	iters: 1000, epoch: 6 | loss: 0.1379730
	speed: 0.0472s/iter; left time: 2370.9968s
	iters: 1100, epoch: 6 | loss: 0.1567785
	speed: 0.0493s/iter; left time: 2470.8529s
Epoch: 6 cost time: 56.112608909606934
Epoch: 6, Steps: 1138 | Train Loss: 0.1486353 Vali Loss: 0.2360762 Test Loss: 0.3260177
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.1366043
	speed: 0.8296s/iter; left time: 41459.1681s
	iters: 200, epoch: 7 | loss: 0.1490897
	speed: 0.0497s/iter; left time: 2476.5266s
	iters: 300, epoch: 7 | loss: 0.1375246
	speed: 0.0454s/iter; left time: 2261.2842s
	iters: 400, epoch: 7 | loss: 0.1489812
	speed: 0.0460s/iter; left time: 2283.8358s
	iters: 500, epoch: 7 | loss: 0.1443296
	speed: 0.0489s/iter; left time: 2422.7055s
	iters: 600, epoch: 7 | loss: 0.1466661
	speed: 0.0499s/iter; left time: 2467.5268s
	iters: 700, epoch: 7 | loss: 0.1460605
	speed: 0.0487s/iter; left time: 2405.2464s
	iters: 800, epoch: 7 | loss: 0.1398109
	speed: 0.0483s/iter; left time: 2378.3346s
	iters: 900, epoch: 7 | loss: 0.1411576
	speed: 0.0507s/iter; left time: 2491.2998s
	iters: 1000, epoch: 7 | loss: 0.1449542
	speed: 0.0485s/iter; left time: 2382.2724s
	iters: 1100, epoch: 7 | loss: 0.1435445
	speed: 0.0480s/iter; left time: 2349.6829s
Epoch: 7 cost time: 56.963003635406494
Epoch: 7, Steps: 1138 | Train Loss: 0.1477613 Vali Loss: 0.2350632 Test Loss: 0.3251886
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.1594763
	speed: 0.8287s/iter; left time: 40468.4826s
	iters: 200, epoch: 8 | loss: 0.1424278
	speed: 0.0474s/iter; left time: 2308.3505s
	iters: 300, epoch: 8 | loss: 0.1360657
	speed: 0.0517s/iter; left time: 2512.4947s
	iters: 400, epoch: 8 | loss: 0.1391393
	speed: 0.0454s/iter; left time: 2202.7323s
	iters: 500, epoch: 8 | loss: 0.1516600
	speed: 0.0497s/iter; left time: 2408.5455s
	iters: 600, epoch: 8 | loss: 0.1527714
	speed: 0.0478s/iter; left time: 2311.4705s
	iters: 700, epoch: 8 | loss: 0.1510915
	speed: 0.0465s/iter; left time: 2242.4240s
	iters: 800, epoch: 8 | loss: 0.1427773
	speed: 0.0470s/iter; left time: 2261.9350s
	iters: 900, epoch: 8 | loss: 0.1466412
	speed: 0.0464s/iter; left time: 2229.2029s
	iters: 1000, epoch: 8 | loss: 0.1398630
	speed: 0.0464s/iter; left time: 2224.5361s
	iters: 1100, epoch: 8 | loss: 0.1485127
	speed: 0.0475s/iter; left time: 2273.5676s
Epoch: 8 cost time: 55.829981565475464
Epoch: 8, Steps: 1138 | Train Loss: 0.1473384 Vali Loss: 0.2350303 Test Loss: 0.3237449
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.1656051
	speed: 0.8278s/iter; left time: 39485.6612s
	iters: 200, epoch: 9 | loss: 0.1408194
	speed: 0.0474s/iter; left time: 2254.7823s
	iters: 300, epoch: 9 | loss: 0.1473050
	speed: 0.0519s/iter; left time: 2464.5262s
	iters: 400, epoch: 9 | loss: 0.1284903
	speed: 0.0544s/iter; left time: 2577.5399s
	iters: 500, epoch: 9 | loss: 0.1388269
	speed: 0.0532s/iter; left time: 2516.4691s
	iters: 600, epoch: 9 | loss: 0.1444502
	speed: 0.0509s/iter; left time: 2401.3985s
	iters: 700, epoch: 9 | loss: 0.1391903
	speed: 0.0496s/iter; left time: 2337.7319s
	iters: 800, epoch: 9 | loss: 0.1457228
	speed: 0.0497s/iter; left time: 2338.0717s
	iters: 900, epoch: 9 | loss: 0.1487259
	speed: 0.0510s/iter; left time: 2390.5689s
	iters: 1000, epoch: 9 | loss: 0.1434227
	speed: 0.0492s/iter; left time: 2301.5784s
	iters: 1100, epoch: 9 | loss: 0.1599410
	speed: 0.0479s/iter; left time: 2238.8058s
Epoch: 9 cost time: 58.6484637260437
Epoch: 9, Steps: 1138 | Train Loss: 0.1471559 Vali Loss: 0.2353035 Test Loss: 0.3244072
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.1521376
	speed: 0.8553s/iter; left time: 39821.2206s
	iters: 200, epoch: 10 | loss: 0.1340924
	speed: 0.0497s/iter; left time: 2308.6661s
	iters: 300, epoch: 10 | loss: 0.1496761
	speed: 0.0507s/iter; left time: 2350.3065s
	iters: 400, epoch: 10 | loss: 0.1446432
	speed: 0.0506s/iter; left time: 2342.6671s
	iters: 500, epoch: 10 | loss: 0.1444227
	speed: 0.0479s/iter; left time: 2212.5240s
	iters: 600, epoch: 10 | loss: 0.1518304
	speed: 0.0492s/iter; left time: 2265.9015s
	iters: 700, epoch: 10 | loss: 0.1494088
	speed: 0.0505s/iter; left time: 2322.0260s
	iters: 800, epoch: 10 | loss: 0.1604211
	speed: 0.0524s/iter; left time: 2403.4498s
	iters: 900, epoch: 10 | loss: 0.1531276
	speed: 0.0489s/iter; left time: 2239.4646s
	iters: 1000, epoch: 10 | loss: 0.1453401
	speed: 0.0493s/iter; left time: 2252.4857s
	iters: 1100, epoch: 10 | loss: 0.1511402
	speed: 0.0508s/iter; left time: 2315.5960s
Epoch: 10 cost time: 58.415443420410156
Epoch: 10, Steps: 1138 | Train Loss: 0.1470221 Vali Loss: 0.2349889 Test Loss: 0.3239348
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.1472913
	speed: 0.8570s/iter; left time: 38925.0498s
	iters: 200, epoch: 11 | loss: 0.1458140
	speed: 0.0532s/iter; left time: 2409.7390s
	iters: 300, epoch: 11 | loss: 0.1439153
	speed: 0.0469s/iter; left time: 2121.3680s
	iters: 400, epoch: 11 | loss: 0.1404437
	speed: 0.0476s/iter; left time: 2147.2469s
	iters: 500, epoch: 11 | loss: 0.1416376
	speed: 0.0474s/iter; left time: 2132.7317s
	iters: 600, epoch: 11 | loss: 0.1567622
	speed: 0.0478s/iter; left time: 2146.2718s
	iters: 700, epoch: 11 | loss: 0.1508458
	speed: 0.0480s/iter; left time: 2152.7886s
	iters: 800, epoch: 11 | loss: 0.1443631
	speed: 0.0479s/iter; left time: 2142.7994s
	iters: 900, epoch: 11 | loss: 0.1367450
	speed: 0.0476s/iter; left time: 2122.3046s
	iters: 1000, epoch: 11 | loss: 0.1418681
	speed: 0.0487s/iter; left time: 2170.2184s
	iters: 1100, epoch: 11 | loss: 0.1465916
	speed: 0.0465s/iter; left time: 2067.4265s
Epoch: 11 cost time: 56.27330493927002
Epoch: 11, Steps: 1138 | Train Loss: 0.1470100 Vali Loss: 0.2354298 Test Loss: 0.3243388
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.1429943
	speed: 0.8251s/iter; left time: 36538.2845s
	iters: 200, epoch: 12 | loss: 0.1479912
	speed: 0.0476s/iter; left time: 2102.4011s
	iters: 300, epoch: 12 | loss: 0.1404615
	speed: 0.0482s/iter; left time: 2125.2712s
	iters: 400, epoch: 12 | loss: 0.1490660
	speed: 0.0508s/iter; left time: 2232.5218s
	iters: 500, epoch: 12 | loss: 0.1467347
	speed: 0.0497s/iter; left time: 2180.0161s
	iters: 600, epoch: 12 | loss: 0.1436814
	speed: 0.0487s/iter; left time: 2130.3340s
	iters: 700, epoch: 12 | loss: 0.1400609
	speed: 0.0484s/iter; left time: 2114.4771s
	iters: 800, epoch: 12 | loss: 0.1432908
	speed: 0.0494s/iter; left time: 2152.0367s
	iters: 900, epoch: 12 | loss: 0.1397391
	speed: 0.0509s/iter; left time: 2212.6577s
	iters: 1000, epoch: 12 | loss: 0.1439678
	speed: 0.0515s/iter; left time: 2235.3520s
	iters: 1100, epoch: 12 | loss: 0.1375344
	speed: 0.0483s/iter; left time: 2089.9676s
Epoch: 12 cost time: 57.517751693725586
Epoch: 12, Steps: 1138 | Train Loss: 0.1469628 Vali Loss: 0.2354338 Test Loss: 0.3243685
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.1567619
	speed: 0.8317s/iter; left time: 35885.6954s
	iters: 200, epoch: 13 | loss: 0.1466107
	speed: 0.0487s/iter; left time: 2096.3545s
	iters: 300, epoch: 13 | loss: 0.1411529
	speed: 0.0459s/iter; left time: 1971.5263s
	iters: 400, epoch: 13 | loss: 0.1428676
	speed: 0.0465s/iter; left time: 1992.6546s
	iters: 500, epoch: 13 | loss: 0.1381953
	speed: 0.0453s/iter; left time: 1934.3689s
	iters: 600, epoch: 13 | loss: 0.1445139
	speed: 0.0465s/iter; left time: 1981.3167s
	iters: 700, epoch: 13 | loss: 0.1359874
	speed: 0.0468s/iter; left time: 1989.2133s
	iters: 800, epoch: 13 | loss: 0.1373247
	speed: 0.0461s/iter; left time: 1955.1398s
	iters: 900, epoch: 13 | loss: 0.1523136
	speed: 0.0451s/iter; left time: 1911.8197s
	iters: 1000, epoch: 13 | loss: 0.1507240
	speed: 0.0462s/iter; left time: 1952.8237s
	iters: 1100, epoch: 13 | loss: 0.1435645
	speed: 0.0458s/iter; left time: 1931.7651s
Epoch: 13 cost time: 54.27322697639465
Epoch: 13, Steps: 1138 | Train Loss: 0.1469409 Vali Loss: 0.2351654 Test Loss: 0.3243128
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.1441146
	speed: 0.8645s/iter; left time: 36314.1822s
	iters: 200, epoch: 14 | loss: 0.1356358
	speed: 0.0654s/iter; left time: 2742.0222s
	iters: 300, epoch: 14 | loss: 0.1436921
	speed: 0.0597s/iter; left time: 2495.8607s
	iters: 400, epoch: 14 | loss: 0.1472366
	speed: 0.0602s/iter; left time: 2510.4900s
	iters: 500, epoch: 14 | loss: 0.1516050
	speed: 0.0586s/iter; left time: 2440.1289s
	iters: 600, epoch: 14 | loss: 0.1513719
	speed: 0.0593s/iter; left time: 2461.9552s
	iters: 700, epoch: 14 | loss: 0.1511001
	speed: 0.0605s/iter; left time: 2504.1979s
	iters: 800, epoch: 14 | loss: 0.1495768
	speed: 0.0595s/iter; left time: 2456.2517s
	iters: 900, epoch: 14 | loss: 0.1444783
	speed: 0.0578s/iter; left time: 2383.2070s
	iters: 1000, epoch: 14 | loss: 0.1578763
	speed: 0.0588s/iter; left time: 2415.8459s
	iters: 1100, epoch: 14 | loss: 0.1354015
	speed: 0.0578s/iter; left time: 2368.2923s
Epoch: 14 cost time: 69.3941342830658
Epoch: 14, Steps: 1138 | Train Loss: 0.1469584 Vali Loss: 0.2352729 Test Loss: 0.3244253
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.1524526
	speed: 0.8990s/iter; left time: 36742.5014s
	iters: 200, epoch: 15 | loss: 0.1343203
	speed: 0.0500s/iter; left time: 2039.8788s
	iters: 300, epoch: 15 | loss: 0.1559066
	speed: 0.0478s/iter; left time: 1945.3972s
	iters: 400, epoch: 15 | loss: 0.1370616
	speed: 0.0491s/iter; left time: 1990.8324s
	iters: 500, epoch: 15 | loss: 0.1504170
	speed: 0.0476s/iter; left time: 1926.6623s
	iters: 600, epoch: 15 | loss: 0.1450207
	speed: 0.0504s/iter; left time: 2033.3037s
	iters: 700, epoch: 15 | loss: 0.1382992
	speed: 0.0473s/iter; left time: 1904.7257s
	iters: 800, epoch: 15 | loss: 0.1454200
	speed: 0.0483s/iter; left time: 1940.3630s
	iters: 900, epoch: 15 | loss: 0.1406074
	speed: 0.0517s/iter; left time: 2073.1688s
	iters: 1000, epoch: 15 | loss: 0.1482803
	speed: 0.0490s/iter; left time: 1960.3739s
	iters: 1100, epoch: 15 | loss: 0.1386522
	speed: 0.0469s/iter; left time: 1870.2811s
Epoch: 15 cost time: 57.581589460372925
Epoch: 15, Steps: 1138 | Train Loss: 0.1469121 Vali Loss: 0.2353106 Test Loss: 0.3243186
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : ECL_96_96_16_emb_128_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (5165, 1, 96, 321) (5165, 1, 96, 321)
test shape: (5165, 96, 321) (5165, 96, 321)
mse:0.31982317566871643, mae:0.40287330746650696
Args in experiment:
Namespace(is_training=1, model_id='ECL_96_96_17_emb_128', model='xLSTM', data='custom', root_path='./data/electricity/', data_path='/input-data/electricity.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, enc_in=321, dec_in=7, c_out=321, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.3, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=32, patience=10, learning_rate=0.0005, des='test', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, use_norm=True, partial_start_index=0, hidden_size=512, num_layers=2, mark_enc_in=4, embedding_dim=128, weight_decay=0.0001, kernal_size=3, num_heads_xlstm=4, qkv_proj_blocksize=8, proj_factor=1.3, num_blocks=7, slstm_at=1, grad_clip_norm=5.0, d_state=16, d_conv=4, expand=2)
Use GPU: cuda:0
{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-L/usr/local/cuda/lib', '-lcublas'], 'extra_cflags': ['-DSLSTM_HIDDEN_SIZE=128', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__'], 'extra_cuda_cflags': ['-Xptxas="-v"', '-gencode', 'arch=compute_80,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=128', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__']}
Using /home/thetayne/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/thetayne/.cache/torch_extensions/py310_cu121/slstm_HS128BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0/build.ninja...
Building extension module slstm_HS128BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module slstm_HS128BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
>>>>>>>start training : ECL_96_96_17_emb_128_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 18221
val 2537
test 5165
	iters: 100, epoch: 1 | loss: 0.3406011
	speed: 0.0891s/iter; left time: 1511.3444s
	iters: 200, epoch: 1 | loss: 0.2363333
	speed: 0.0718s/iter; left time: 1212.1082s
	iters: 300, epoch: 1 | loss: 0.2071549
	speed: 0.0707s/iter; left time: 1185.1908s
	iters: 400, epoch: 1 | loss: 0.1779732
	speed: 0.0678s/iter; left time: 1130.5618s
	iters: 500, epoch: 1 | loss: 0.1699660
	speed: 0.0668s/iter; left time: 1107.5562s
Epoch: 1 cost time: 40.95955538749695
Epoch: 1, Steps: 569 | Train Loss: 0.2689416 Vali Loss: 0.2178010 Test Loss: 0.2973584
Validation loss decreased (inf --> 0.217801).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.1629877
	speed: 0.8935s/iter; left time: 14655.5507s
	iters: 200, epoch: 2 | loss: 0.1668817
	speed: 0.0641s/iter; left time: 1045.6858s
	iters: 300, epoch: 2 | loss: 0.1515846
	speed: 0.0660s/iter; left time: 1069.7587s
	iters: 400, epoch: 2 | loss: 0.1503883
	speed: 0.0660s/iter; left time: 1063.4809s
	iters: 500, epoch: 2 | loss: 0.1449330
	speed: 0.0663s/iter; left time: 1060.6165s
Epoch: 2 cost time: 38.954747915267944
Epoch: 2, Steps: 569 | Train Loss: 0.1543634 Vali Loss: 0.2082841 Test Loss: 0.2858844
Validation loss decreased (0.217801 --> 0.208284).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.1550374
	speed: 1.0141s/iter; left time: 16056.9232s
	iters: 200, epoch: 3 | loss: 0.1436383
	speed: 0.0663s/iter; left time: 1042.5720s
	iters: 300, epoch: 3 | loss: 0.1371830
	speed: 0.0663s/iter; left time: 1037.0301s
	iters: 400, epoch: 3 | loss: 0.1427552
	speed: 0.0657s/iter; left time: 1019.8147s
	iters: 500, epoch: 3 | loss: 0.1368668
	speed: 0.0659s/iter; left time: 1017.5207s
Epoch: 3 cost time: 39.033872842788696
Epoch: 3, Steps: 569 | Train Loss: 0.1419415 Vali Loss: 0.2060473 Test Loss: 0.2770043
Validation loss decreased (0.208284 --> 0.206047).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.1380715
	speed: 1.0005s/iter; left time: 15271.6325s
	iters: 200, epoch: 4 | loss: 0.1376426
	speed: 0.0661s/iter; left time: 1002.0584s
	iters: 300, epoch: 4 | loss: 0.1430390
	speed: 0.0661s/iter; left time: 996.2897s
	iters: 400, epoch: 4 | loss: 0.1410689
	speed: 0.0643s/iter; left time: 962.1484s
	iters: 500, epoch: 4 | loss: 0.1396403
	speed: 0.0653s/iter; left time: 969.9976s
Epoch: 4 cost time: 38.85662364959717
Epoch: 4, Steps: 569 | Train Loss: 0.1382067 Vali Loss: 0.2051370 Test Loss: 0.2800952
Validation loss decreased (0.206047 --> 0.205137).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.1351659
	speed: 0.9840s/iter; left time: 14459.8730s
	iters: 200, epoch: 5 | loss: 0.1375832
	speed: 0.0658s/iter; left time: 960.6406s
	iters: 300, epoch: 5 | loss: 0.1427496
	speed: 0.0654s/iter; left time: 948.3432s
	iters: 400, epoch: 5 | loss: 0.1346672
	speed: 0.0655s/iter; left time: 943.4971s
	iters: 500, epoch: 5 | loss: 0.1289846
	speed: 0.0650s/iter; left time: 928.8450s
Epoch: 5 cost time: 38.38328266143799
Epoch: 5, Steps: 569 | Train Loss: 0.1362888 Vali Loss: 0.2084779 Test Loss: 0.2817791
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.1426016
	speed: 1.0021s/iter; left time: 14155.8828s
	iters: 200, epoch: 6 | loss: 0.1354385
	speed: 0.0653s/iter; left time: 915.2680s
	iters: 300, epoch: 6 | loss: 0.1332542
	speed: 0.0649s/iter; left time: 903.6651s
	iters: 400, epoch: 6 | loss: 0.1376300
	speed: 0.0651s/iter; left time: 900.7275s
	iters: 500, epoch: 6 | loss: 0.1341445
	speed: 0.0661s/iter; left time: 907.5952s
Epoch: 6 cost time: 38.738975286483765
Epoch: 6, Steps: 569 | Train Loss: 0.1352792 Vali Loss: 0.2083268 Test Loss: 0.2815751
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.1317820
	speed: 1.0030s/iter; left time: 13597.7468s
	iters: 200, epoch: 7 | loss: 0.1351310
	speed: 0.0655s/iter; left time: 882.0889s
	iters: 300, epoch: 7 | loss: 0.1327983
	speed: 0.0663s/iter; left time: 885.0325s
	iters: 400, epoch: 7 | loss: 0.1270042
	speed: 0.0663s/iter; left time: 878.6689s
	iters: 500, epoch: 7 | loss: 0.1361813
	speed: 0.0660s/iter; left time: 867.7549s
Epoch: 7 cost time: 38.89589214324951
Epoch: 7, Steps: 569 | Train Loss: 0.1347034 Vali Loss: 0.2079624 Test Loss: 0.2826566
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.1314052
	speed: 1.0066s/iter; left time: 13073.3823s
	iters: 200, epoch: 8 | loss: 0.1265322
	speed: 0.0697s/iter; left time: 897.6901s
	iters: 300, epoch: 8 | loss: 0.1425643
	speed: 0.0686s/iter; left time: 877.6260s
	iters: 400, epoch: 8 | loss: 0.1311723
	speed: 0.0694s/iter; left time: 881.0214s
	iters: 500, epoch: 8 | loss: 0.1265623
	speed: 0.0652s/iter; left time: 820.9014s
Epoch: 8 cost time: 40.27958297729492
Epoch: 8, Steps: 569 | Train Loss: 0.1344329 Vali Loss: 0.2067905 Test Loss: 0.2812720
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.1343041
	speed: 0.9842s/iter; left time: 12223.3909s
	iters: 200, epoch: 9 | loss: 0.1202257
	speed: 0.0640s/iter; left time: 787.8879s
	iters: 300, epoch: 9 | loss: 0.1297023
	speed: 0.0653s/iter; left time: 798.3918s
	iters: 400, epoch: 9 | loss: 0.1344927
	speed: 0.0664s/iter; left time: 804.5270s
	iters: 500, epoch: 9 | loss: 0.1312087
	speed: 0.0663s/iter; left time: 797.1491s
Epoch: 9 cost time: 38.74257302284241
Epoch: 9, Steps: 569 | Train Loss: 0.1343031 Vali Loss: 0.2071100 Test Loss: 0.2810203
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.1309723
	speed: 0.9781s/iter; left time: 11590.7279s
	iters: 200, epoch: 10 | loss: 0.1343641
	speed: 0.0648s/iter; left time: 760.8417s
	iters: 300, epoch: 10 | loss: 0.1273406
	speed: 0.0641s/iter; left time: 746.3620s
	iters: 400, epoch: 10 | loss: 0.1315247
	speed: 0.0640s/iter; left time: 738.7749s
	iters: 500, epoch: 10 | loss: 0.1302200
	speed: 0.0640s/iter; left time: 732.4216s
Epoch: 10 cost time: 38.06508803367615
Epoch: 10, Steps: 569 | Train Loss: 0.1342088 Vali Loss: 0.2072921 Test Loss: 0.2812481
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.1363112
	speed: 1.0040s/iter; left time: 11325.7088s
	iters: 200, epoch: 11 | loss: 0.1379277
	speed: 0.0647s/iter; left time: 723.6766s
	iters: 300, epoch: 11 | loss: 0.1385439
	speed: 0.0636s/iter; left time: 705.0389s
	iters: 400, epoch: 11 | loss: 0.1302011
	speed: 0.0640s/iter; left time: 702.8036s
	iters: 500, epoch: 11 | loss: 0.1292969
	speed: 0.0645s/iter; left time: 701.3810s
Epoch: 11 cost time: 38.00183963775635
Epoch: 11, Steps: 569 | Train Loss: 0.1341541 Vali Loss: 0.2074197 Test Loss: 0.2817077
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.1292930
	speed: 0.9037s/iter; left time: 9680.9101s
	iters: 200, epoch: 12 | loss: 0.1294972
	speed: 0.0658s/iter; left time: 698.4950s
	iters: 300, epoch: 12 | loss: 0.1330085
	speed: 0.0665s/iter; left time: 698.5302s
	iters: 400, epoch: 12 | loss: 0.1379603
	speed: 0.0668s/iter; left time: 695.0601s
	iters: 500, epoch: 12 | loss: 0.1316072
	speed: 0.0664s/iter; left time: 684.7377s
Epoch: 12 cost time: 39.235860109329224
Epoch: 12, Steps: 569 | Train Loss: 0.1341610 Vali Loss: 0.2074993 Test Loss: 0.2816845
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 0.1291137
	speed: 0.9611s/iter; left time: 9748.2537s
	iters: 200, epoch: 13 | loss: 0.1341962
	speed: 0.0690s/iter; left time: 692.7327s
	iters: 300, epoch: 13 | loss: 0.1369271
	speed: 0.0701s/iter; left time: 696.9063s
	iters: 400, epoch: 13 | loss: 0.1305805
	speed: 0.0705s/iter; left time: 694.2287s
	iters: 500, epoch: 13 | loss: 0.1366850
	speed: 0.0710s/iter; left time: 691.7017s
Epoch: 13 cost time: 41.347588539123535
Epoch: 13, Steps: 569 | Train Loss: 0.1341326 Vali Loss: 0.2071937 Test Loss: 0.2816136
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 0.1291961
	speed: 0.8954s/iter; left time: 8572.8929s
	iters: 200, epoch: 14 | loss: 0.1275707
	speed: 0.0694s/iter; left time: 657.1755s
	iters: 300, epoch: 14 | loss: 0.1398155
	speed: 0.0709s/iter; left time: 664.9490s
	iters: 400, epoch: 14 | loss: 0.1352783
	speed: 0.0717s/iter; left time: 664.6312s
	iters: 500, epoch: 14 | loss: 0.1366374
	speed: 0.0722s/iter; left time: 661.9750s
Epoch: 14 cost time: 41.562867879867554
Epoch: 14, Steps: 569 | Train Loss: 0.1341368 Vali Loss: 0.2071728 Test Loss: 0.2815753
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : ECL_96_96_17_emb_128_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (5165, 1, 96, 321) (5165, 1, 96, 321)
test shape: (5165, 96, 321) (5165, 96, 321)
mse:0.28009557723999023, mae:0.37097597122192383
Args in experiment:
Namespace(is_training=1, model_id='ECL_96_96_18_emb_128', model='xLSTM', data='custom', root_path='./data/electricity/', data_path='/input-data/electricity.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, enc_in=321, dec_in=7, c_out=321, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.3, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=10, batch_size=16, patience=10, learning_rate=0.0005, des='test', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, use_norm=True, partial_start_index=0, hidden_size=512, num_layers=2, mark_enc_in=4, embedding_dim=128, weight_decay=0.0001, kernal_size=7, num_heads_xlstm=8, qkv_proj_blocksize=2, proj_factor=1.3, num_blocks=2, slstm_at=1, grad_clip_norm=1.0, d_state=16, d_conv=4, expand=2)
Use GPU: cuda:0
{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-L/usr/local/cuda/lib', '-lcublas'], 'extra_cflags': ['-DSLSTM_HIDDEN_SIZE=128', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=8', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__'], 'extra_cuda_cflags': ['-Xptxas="-v"', '-gencode', 'arch=compute_80,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=128', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=8', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__']}
Using /home/thetayne/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/thetayne/.cache/torch_extensions/py310_cu121/slstm_HS128BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0/build.ninja...
Building extension module slstm_HS128BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module slstm_HS128BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
>>>>>>>start training : ECL_96_96_18_emb_128_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 18221
val 2537
test 5165
	iters: 100, epoch: 1 | loss: 0.3600976
	speed: 0.0464s/iter; left time: 523.8653s
	iters: 200, epoch: 1 | loss: 0.2805470
	speed: 0.0239s/iter; left time: 266.8969s
	iters: 300, epoch: 1 | loss: 0.2136728
	speed: 0.0234s/iter; left time: 259.1914s
	iters: 400, epoch: 1 | loss: 0.2256326
	speed: 0.0234s/iter; left time: 256.6306s
	iters: 500, epoch: 1 | loss: 0.1808588
	speed: 0.0230s/iter; left time: 249.8113s
	iters: 600, epoch: 1 | loss: 0.1829752
	speed: 0.0233s/iter; left time: 251.0162s
	iters: 700, epoch: 1 | loss: 0.1797162
	speed: 0.0233s/iter; left time: 249.2355s
	iters: 800, epoch: 1 | loss: 0.1728739
	speed: 0.0229s/iter; left time: 242.1099s
	iters: 900, epoch: 1 | loss: 0.1587231
	speed: 0.0234s/iter; left time: 245.3390s
	iters: 1000, epoch: 1 | loss: 0.1609391
	speed: 0.0231s/iter; left time: 239.5422s
	iters: 1100, epoch: 1 | loss: 0.1623673
	speed: 0.0230s/iter; left time: 236.3471s
Epoch: 1 cost time: 28.75679612159729
Epoch: 1, Steps: 1138 | Train Loss: 0.2278766 Vali Loss: 0.2047952 Test Loss: 0.2653081
Validation loss decreased (inf --> 0.204795).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.1522246
	speed: 0.4293s/iter; left time: 4354.0301s
	iters: 200, epoch: 2 | loss: 0.1480381
	speed: 0.0218s/iter; left time: 218.9238s
	iters: 300, epoch: 2 | loss: 0.1531841
	speed: 0.0217s/iter; left time: 215.9565s
	iters: 400, epoch: 2 | loss: 0.1471803
	speed: 0.0218s/iter; left time: 214.4936s
	iters: 500, epoch: 2 | loss: 0.1462041
	speed: 0.0216s/iter; left time: 210.3750s
	iters: 600, epoch: 2 | loss: 0.1363317
	speed: 0.0216s/iter; left time: 207.9803s
	iters: 700, epoch: 2 | loss: 0.1505425
	speed: 0.0214s/iter; left time: 204.1634s
	iters: 800, epoch: 2 | loss: 0.1452172
	speed: 0.0218s/iter; left time: 206.3111s
	iters: 900, epoch: 2 | loss: 0.1417962
	speed: 0.0213s/iter; left time: 198.5915s
	iters: 1000, epoch: 2 | loss: 0.1394526
	speed: 0.0217s/iter; left time: 201.0054s
	iters: 1100, epoch: 2 | loss: 0.1417112
	speed: 0.0217s/iter; left time: 198.1919s
Epoch: 2 cost time: 26.058109045028687
Epoch: 2, Steps: 1138 | Train Loss: 0.1465123 Vali Loss: 0.2010833 Test Loss: 0.2600210
Validation loss decreased (0.204795 --> 0.201083).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.1464656
	speed: 0.4297s/iter; left time: 3869.2811s
	iters: 200, epoch: 3 | loss: 0.1585383
	speed: 0.0214s/iter; left time: 190.6773s
	iters: 300, epoch: 3 | loss: 0.1278753
	speed: 0.0217s/iter; left time: 191.1654s
	iters: 400, epoch: 3 | loss: 0.1397144
	speed: 0.0211s/iter; left time: 183.9146s
	iters: 500, epoch: 3 | loss: 0.1361343
	speed: 0.0215s/iter; left time: 185.2592s
	iters: 600, epoch: 3 | loss: 0.1388019
	speed: 0.0211s/iter; left time: 179.3060s
	iters: 700, epoch: 3 | loss: 0.1454371
	speed: 0.0214s/iter; left time: 179.9036s
	iters: 800, epoch: 3 | loss: 0.1356675
	speed: 0.0213s/iter; left time: 177.1336s
	iters: 900, epoch: 3 | loss: 0.1551864
	speed: 0.0211s/iter; left time: 173.0386s
	iters: 1000, epoch: 3 | loss: 0.1382481
	speed: 0.0212s/iter; left time: 171.6462s
	iters: 1100, epoch: 3 | loss: 0.1459222
	speed: 0.0213s/iter; left time: 170.7139s
Epoch: 3 cost time: 26.063950300216675
Epoch: 3, Steps: 1138 | Train Loss: 0.1385097 Vali Loss: 0.2063991 Test Loss: 0.2605764
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.1349835
	speed: 0.4247s/iter; left time: 3341.1654s
	iters: 200, epoch: 4 | loss: 0.1366661
	speed: 0.0215s/iter; left time: 167.2376s
	iters: 300, epoch: 4 | loss: 0.1382963
	speed: 0.0213s/iter; left time: 163.4966s
	iters: 400, epoch: 4 | loss: 0.1425482
	speed: 0.0217s/iter; left time: 164.0787s
	iters: 500, epoch: 4 | loss: 0.1268232
	speed: 0.0213s/iter; left time: 158.7213s
	iters: 600, epoch: 4 | loss: 0.1330324
	speed: 0.0213s/iter; left time: 156.9419s
	iters: 700, epoch: 4 | loss: 0.1463579
	speed: 0.0210s/iter; left time: 152.5817s
	iters: 800, epoch: 4 | loss: 0.1303632
	speed: 0.0216s/iter; left time: 154.7808s
	iters: 900, epoch: 4 | loss: 0.1375907
	speed: 0.0212s/iter; left time: 149.7351s
	iters: 1000, epoch: 4 | loss: 0.1536949
	speed: 0.0211s/iter; left time: 146.9094s
	iters: 1100, epoch: 4 | loss: 0.1426193
	speed: 0.0211s/iter; left time: 145.0865s
Epoch: 4 cost time: 25.83238911628723
Epoch: 4, Steps: 1138 | Train Loss: 0.1357601 Vali Loss: 0.2081410 Test Loss: 0.2623345
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.1278660
	speed: 0.4243s/iter; left time: 2855.0333s
	iters: 200, epoch: 5 | loss: 0.1388408
	speed: 0.0215s/iter; left time: 142.4676s
	iters: 300, epoch: 5 | loss: 0.1304854
	speed: 0.0213s/iter; left time: 138.9236s
	iters: 400, epoch: 5 | loss: 0.1316311
	speed: 0.0212s/iter; left time: 136.1290s
	iters: 500, epoch: 5 | loss: 0.1303944
	speed: 0.0216s/iter; left time: 136.6887s
	iters: 600, epoch: 5 | loss: 0.1353992
	speed: 0.0212s/iter; left time: 132.2515s
	iters: 700, epoch: 5 | loss: 0.1321668
	speed: 0.0215s/iter; left time: 131.6197s
	iters: 800, epoch: 5 | loss: 0.1337183
	speed: 0.0216s/iter; left time: 130.4147s
	iters: 900, epoch: 5 | loss: 0.1335521
	speed: 0.0213s/iter; left time: 126.2520s
	iters: 1000, epoch: 5 | loss: 0.1456392
	speed: 0.0213s/iter; left time: 124.1750s
	iters: 1100, epoch: 5 | loss: 0.1274721
	speed: 0.0213s/iter; left time: 121.7573s
Epoch: 5 cost time: 25.901240348815918
Epoch: 5, Steps: 1138 | Train Loss: 0.1342620 Vali Loss: 0.2099510 Test Loss: 0.2619818
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.1443001
	speed: 0.4262s/iter; left time: 2382.9996s
	iters: 200, epoch: 6 | loss: 0.1369485
	speed: 0.0218s/iter; left time: 119.5215s
	iters: 300, epoch: 6 | loss: 0.1349081
	speed: 0.0213s/iter; left time: 114.9826s
	iters: 400, epoch: 6 | loss: 0.1223321
	speed: 0.0213s/iter; left time: 112.5442s
	iters: 500, epoch: 6 | loss: 0.1220903
	speed: 0.0215s/iter; left time: 111.7167s
	iters: 600, epoch: 6 | loss: 0.1420525
	speed: 0.0217s/iter; left time: 110.4202s
	iters: 700, epoch: 6 | loss: 0.1275973
	speed: 0.0214s/iter; left time: 106.6752s
	iters: 800, epoch: 6 | loss: 0.1315919
	speed: 0.0215s/iter; left time: 104.9933s
	iters: 900, epoch: 6 | loss: 0.1380688
	speed: 0.0216s/iter; left time: 103.4291s
	iters: 1000, epoch: 6 | loss: 0.1401857
	speed: 0.0215s/iter; left time: 100.8937s
	iters: 1100, epoch: 6 | loss: 0.1372065
	speed: 0.0217s/iter; left time: 99.4916s
Epoch: 6 cost time: 26.21540641784668
Epoch: 6, Steps: 1138 | Train Loss: 0.1334565 Vali Loss: 0.2111052 Test Loss: 0.2629824
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.1327082
	speed: 0.4239s/iter; left time: 1887.7244s
	iters: 200, epoch: 7 | loss: 0.1171376
	speed: 0.0217s/iter; left time: 94.6474s
	iters: 300, epoch: 7 | loss: 0.1347373
	speed: 0.0217s/iter; left time: 92.1203s
	iters: 400, epoch: 7 | loss: 0.1332875
	speed: 0.0217s/iter; left time: 90.2063s
	iters: 500, epoch: 7 | loss: 0.1379593
	speed: 0.0220s/iter; left time: 89.2816s
	iters: 600, epoch: 7 | loss: 0.1262576
	speed: 0.0214s/iter; left time: 84.4386s
	iters: 700, epoch: 7 | loss: 0.1337699
	speed: 0.0214s/iter; left time: 82.5466s
	iters: 800, epoch: 7 | loss: 0.1202988
	speed: 0.0219s/iter; left time: 82.2158s
	iters: 900, epoch: 7 | loss: 0.1430137
	speed: 0.0223s/iter; left time: 81.4520s
	iters: 1000, epoch: 7 | loss: 0.1239591
	speed: 0.0218s/iter; left time: 77.5102s
	iters: 1100, epoch: 7 | loss: 0.1265528
	speed: 0.0214s/iter; left time: 74.0534s
Epoch: 7 cost time: 26.246957778930664
Epoch: 7, Steps: 1138 | Train Loss: 0.1330396 Vali Loss: 0.2110060 Test Loss: 0.2625067
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.1334299
	speed: 0.4242s/iter; left time: 1406.1184s
	iters: 200, epoch: 8 | loss: 0.1262277
	speed: 0.0217s/iter; left time: 69.6854s
	iters: 300, epoch: 8 | loss: 0.1276671
	speed: 0.0216s/iter; left time: 67.3470s
	iters: 400, epoch: 8 | loss: 0.1489879
	speed: 0.0215s/iter; left time: 64.7059s
	iters: 500, epoch: 8 | loss: 0.1283758
	speed: 0.0229s/iter; left time: 66.7144s
	iters: 600, epoch: 8 | loss: 0.1383604
	speed: 0.0253s/iter; left time: 71.3294s
	iters: 700, epoch: 8 | loss: 0.1445792
	speed: 0.0265s/iter; left time: 71.9428s
	iters: 800, epoch: 8 | loss: 0.1273415
	speed: 0.0279s/iter; left time: 72.8793s
	iters: 900, epoch: 8 | loss: 0.1302322
	speed: 0.0272s/iter; left time: 68.4195s
	iters: 1000, epoch: 8 | loss: 0.1236180
	speed: 0.0273s/iter; left time: 65.8214s
	iters: 1100, epoch: 8 | loss: 0.1342798
	speed: 0.0281s/iter; left time: 65.0975s
Epoch: 8 cost time: 29.8145649433136
Epoch: 8, Steps: 1138 | Train Loss: 0.1328404 Vali Loss: 0.2120348 Test Loss: 0.2631728
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.1375873
	speed: 0.4519s/iter; left time: 983.8000s
	iters: 200, epoch: 9 | loss: 0.1261337
	speed: 0.0214s/iter; left time: 44.3890s
	iters: 300, epoch: 9 | loss: 0.1301050
	speed: 0.0219s/iter; left time: 43.2496s
	iters: 400, epoch: 9 | loss: 0.1430473
	speed: 0.0216s/iter; left time: 40.5681s
	iters: 500, epoch: 9 | loss: 0.1346108
	speed: 0.0219s/iter; left time: 38.8740s
	iters: 600, epoch: 9 | loss: 0.1525357
	speed: 0.0216s/iter; left time: 36.2735s
	iters: 700, epoch: 9 | loss: 0.1372500
	speed: 0.0217s/iter; left time: 34.2799s
	iters: 800, epoch: 9 | loss: 0.1314677
	speed: 0.0218s/iter; left time: 32.2128s
	iters: 900, epoch: 9 | loss: 0.1276496
	speed: 0.0218s/iter; left time: 30.0654s
	iters: 1000, epoch: 9 | loss: 0.1274440
	speed: 0.0215s/iter; left time: 27.4222s
	iters: 1100, epoch: 9 | loss: 0.1305848
	speed: 0.0216s/iter; left time: 25.4495s
Epoch: 9 cost time: 26.3574857711792
Epoch: 9, Steps: 1138 | Train Loss: 0.1327238 Vali Loss: 0.2122517 Test Loss: 0.2629675
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.1289393
	speed: 0.4191s/iter; left time: 435.4295s
	iters: 200, epoch: 10 | loss: 0.1319095
	speed: 0.0216s/iter; left time: 20.3020s
	iters: 300, epoch: 10 | loss: 0.1284500
	speed: 0.0218s/iter; left time: 18.2978s
	iters: 400, epoch: 10 | loss: 0.1327414
	speed: 0.0216s/iter; left time: 15.9801s
	iters: 500, epoch: 10 | loss: 0.1448964
	speed: 0.0218s/iter; left time: 13.9328s
	iters: 600, epoch: 10 | loss: 0.1298194
	speed: 0.0217s/iter; left time: 11.7037s
	iters: 700, epoch: 10 | loss: 0.1253141
	speed: 0.0217s/iter; left time: 9.5287s
	iters: 800, epoch: 10 | loss: 0.1258407
	speed: 0.0219s/iter; left time: 7.4370s
	iters: 900, epoch: 10 | loss: 0.1223452
	speed: 0.0217s/iter; left time: 5.1951s
	iters: 1000, epoch: 10 | loss: 0.1326686
	speed: 0.0217s/iter; left time: 3.0196s
	iters: 1100, epoch: 10 | loss: 0.1283026
	speed: 0.0217s/iter; left time: 0.8470s
Epoch: 10 cost time: 26.262521505355835
Epoch: 10, Steps: 1138 | Train Loss: 0.1327108 Vali Loss: 0.2124396 Test Loss: 0.2630740
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
>>>>>>>testing : ECL_96_96_18_emb_128_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (5165, 1, 96, 321) (5165, 1, 96, 321)
test shape: (5165, 96, 321) (5165, 96, 321)
mse:0.26002100110054016, mae:0.3546055853366852
Args in experiment:
Namespace(is_training=1, model_id='ECL_96_96_19_emb_128', model='xLSTM', data='custom', root_path='./data/electricity/', data_path='/input-data/electricity.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, enc_in=321, dec_in=7, c_out=321, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.3, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=16, patience=10, learning_rate=0.0005, des='test', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, use_norm=True, partial_start_index=0, hidden_size=512, num_layers=2, mark_enc_in=4, embedding_dim=128, weight_decay=1e-06, kernal_size=5, num_heads_xlstm=8, qkv_proj_blocksize=4, proj_factor=1.3, num_blocks=3, slstm_at=1, grad_clip_norm=1.0, d_state=16, d_conv=4, expand=2)
Use GPU: cuda:0
{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-L/usr/local/cuda/lib', '-lcublas'], 'extra_cflags': ['-DSLSTM_HIDDEN_SIZE=128', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=8', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__'], 'extra_cuda_cflags': ['-Xptxas="-v"', '-gencode', 'arch=compute_80,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=128', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=8', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__']}
Using /home/thetayne/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/thetayne/.cache/torch_extensions/py310_cu121/slstm_HS128BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0/build.ninja...
Building extension module slstm_HS128BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module slstm_HS128BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
>>>>>>>start training : ECL_96_96_19_emb_128_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 18221
val 2537
test 5165
	iters: 100, epoch: 1 | loss: 0.3328454
	speed: 0.0523s/iter; left time: 1779.3076s
	iters: 200, epoch: 1 | loss: 0.2447966
	speed: 0.0328s/iter; left time: 1114.0126s
	iters: 300, epoch: 1 | loss: 0.2126614
	speed: 0.0327s/iter; left time: 1106.5535s
	iters: 400, epoch: 1 | loss: 0.2046913
	speed: 0.0326s/iter; left time: 1099.1134s
	iters: 500, epoch: 1 | loss: 0.1873956
	speed: 0.0326s/iter; left time: 1097.7844s
	iters: 600, epoch: 1 | loss: 0.1807308
	speed: 0.0323s/iter; left time: 1082.2621s
	iters: 700, epoch: 1 | loss: 0.1670383
	speed: 0.0332s/iter; left time: 1108.6463s
	iters: 800, epoch: 1 | loss: 0.1558463
	speed: 0.0324s/iter; left time: 1081.3330s
	iters: 900, epoch: 1 | loss: 0.1542585
	speed: 0.0337s/iter; left time: 1119.7902s
	iters: 1000, epoch: 1 | loss: 0.1497044
	speed: 0.0344s/iter; left time: 1140.3165s
	iters: 1100, epoch: 1 | loss: 0.1491518
	speed: 0.0345s/iter; left time: 1138.8673s
Epoch: 1 cost time: 39.49262356758118
Epoch: 1, Steps: 1138 | Train Loss: 0.2238268 Vali Loss: 0.2098330 Test Loss: 0.2820507
Validation loss decreased (inf --> 0.209833).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.1514300
	speed: 0.5445s/iter; left time: 17915.7071s
	iters: 200, epoch: 2 | loss: 0.1483047
	speed: 0.0308s/iter; left time: 1009.5077s
	iters: 300, epoch: 2 | loss: 0.1420973
	speed: 0.0353s/iter; left time: 1155.9081s
	iters: 400, epoch: 2 | loss: 0.1422298
	speed: 0.0354s/iter; left time: 1155.5875s
	iters: 500, epoch: 2 | loss: 0.1459174
	speed: 0.0337s/iter; left time: 1094.6963s
	iters: 600, epoch: 2 | loss: 0.1617414
	speed: 0.0334s/iter; left time: 1082.4325s
	iters: 700, epoch: 2 | loss: 0.1352310
	speed: 0.0332s/iter; left time: 1071.8638s
	iters: 800, epoch: 2 | loss: 0.1408102
	speed: 0.0323s/iter; left time: 1040.3717s
	iters: 900, epoch: 2 | loss: 0.1407551
	speed: 0.0328s/iter; left time: 1051.7849s
	iters: 1000, epoch: 2 | loss: 0.1349669
	speed: 0.0330s/iter; left time: 1055.8872s
	iters: 1100, epoch: 2 | loss: 0.1435806
	speed: 0.0337s/iter; left time: 1076.6689s
Epoch: 2 cost time: 38.78402638435364
Epoch: 2, Steps: 1138 | Train Loss: 0.1444231 Vali Loss: 0.2123450 Test Loss: 0.2740911
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.1353087
	speed: 0.5762s/iter; left time: 18303.6146s
	iters: 200, epoch: 3 | loss: 0.1390957
	speed: 0.0306s/iter; left time: 969.1350s
	iters: 300, epoch: 3 | loss: 0.1389111
	speed: 0.0329s/iter; left time: 1037.4506s
	iters: 400, epoch: 3 | loss: 0.1430986
	speed: 0.0334s/iter; left time: 1051.1088s
	iters: 500, epoch: 3 | loss: 0.1345828
	speed: 0.0327s/iter; left time: 1026.9249s
	iters: 600, epoch: 3 | loss: 0.1359706
	speed: 0.0327s/iter; left time: 1023.8903s
	iters: 700, epoch: 3 | loss: 0.1349472
	speed: 0.0333s/iter; left time: 1036.5954s
	iters: 800, epoch: 3 | loss: 0.1321020
	speed: 0.0340s/iter; left time: 1055.2053s
	iters: 900, epoch: 3 | loss: 0.1487221
	speed: 0.0340s/iter; left time: 1053.2312s
	iters: 1000, epoch: 3 | loss: 0.1335738
	speed: 0.0338s/iter; left time: 1042.0169s
	iters: 1100, epoch: 3 | loss: 0.1313507
	speed: 0.0325s/iter; left time: 998.5541s
Epoch: 3 cost time: 38.43545460700989
Epoch: 3, Steps: 1138 | Train Loss: 0.1357885 Vali Loss: 0.2122745 Test Loss: 0.2718436
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.1304313
	speed: 0.5707s/iter; left time: 17479.0748s
	iters: 200, epoch: 4 | loss: 0.1486099
	speed: 0.0266s/iter; left time: 811.9372s
	iters: 300, epoch: 4 | loss: 0.1392297
	speed: 0.0263s/iter; left time: 800.2896s
	iters: 400, epoch: 4 | loss: 0.1262558
	speed: 0.0257s/iter; left time: 780.8860s
	iters: 500, epoch: 4 | loss: 0.1463244
	speed: 0.0262s/iter; left time: 793.2524s
	iters: 600, epoch: 4 | loss: 0.1340011
	speed: 0.0263s/iter; left time: 791.3187s
	iters: 700, epoch: 4 | loss: 0.1261465
	speed: 0.0262s/iter; left time: 788.0774s
	iters: 800, epoch: 4 | loss: 0.1232825
	speed: 0.0260s/iter; left time: 778.6711s
	iters: 900, epoch: 4 | loss: 0.1242456
	speed: 0.0266s/iter; left time: 792.6049s
	iters: 1000, epoch: 4 | loss: 0.1285840
	speed: 0.0262s/iter; left time: 778.1166s
	iters: 1100, epoch: 4 | loss: 0.1238515
	speed: 0.0264s/iter; left time: 783.2639s
Epoch: 4 cost time: 31.393895864486694
Epoch: 4, Steps: 1138 | Train Loss: 0.1329110 Vali Loss: 0.2198999 Test Loss: 0.2754021
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.1353860
	speed: 0.5574s/iter; left time: 16438.3427s
	iters: 200, epoch: 5 | loss: 0.1212522
	speed: 0.0276s/iter; left time: 811.4371s
	iters: 300, epoch: 5 | loss: 0.1247802
	speed: 0.0270s/iter; left time: 791.3943s
	iters: 400, epoch: 5 | loss: 0.1366868
	speed: 0.0280s/iter; left time: 816.3288s
	iters: 500, epoch: 5 | loss: 0.1343204
	speed: 0.0351s/iter; left time: 1020.1904s
	iters: 600, epoch: 5 | loss: 0.1263077
	speed: 0.0347s/iter; left time: 1006.8324s
	iters: 700, epoch: 5 | loss: 0.1413275
	speed: 0.0352s/iter; left time: 1016.8562s
	iters: 800, epoch: 5 | loss: 0.1236975
	speed: 0.0353s/iter; left time: 1014.8839s
	iters: 900, epoch: 5 | loss: 0.1364636
	speed: 0.0352s/iter; left time: 1011.2433s
	iters: 1000, epoch: 5 | loss: 0.1238125
	speed: 0.0349s/iter; left time: 999.0493s
	iters: 1100, epoch: 5 | loss: 0.1449378
	speed: 0.0353s/iter; left time: 1004.7993s
Epoch: 5 cost time: 38.35275673866272
Epoch: 5, Steps: 1138 | Train Loss: 0.1314900 Vali Loss: 0.2211465 Test Loss: 0.2786307
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.1268575
	speed: 0.5848s/iter; left time: 16580.8687s
	iters: 200, epoch: 6 | loss: 0.1237648
	speed: 0.0335s/iter; left time: 947.6738s
	iters: 300, epoch: 6 | loss: 0.1331016
	speed: 0.0342s/iter; left time: 964.0569s
	iters: 400, epoch: 6 | loss: 0.1342027
	speed: 0.0329s/iter; left time: 923.1365s
	iters: 500, epoch: 6 | loss: 0.1336260
	speed: 0.0333s/iter; left time: 932.1070s
	iters: 600, epoch: 6 | loss: 0.1214105
	speed: 0.0332s/iter; left time: 923.7597s
	iters: 700, epoch: 6 | loss: 0.1270407
	speed: 0.0328s/iter; left time: 910.2674s
	iters: 800, epoch: 6 | loss: 0.1362359
	speed: 0.0334s/iter; left time: 922.9269s
	iters: 900, epoch: 6 | loss: 0.1326516
	speed: 0.0324s/iter; left time: 892.7766s
	iters: 1000, epoch: 6 | loss: 0.1324245
	speed: 0.0327s/iter; left time: 896.3465s
	iters: 1100, epoch: 6 | loss: 0.1325621
	speed: 0.0332s/iter; left time: 907.8943s
Epoch: 6 cost time: 38.96216535568237
Epoch: 6, Steps: 1138 | Train Loss: 0.1307804 Vali Loss: 0.2245173 Test Loss: 0.2804374
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.1232824
	speed: 0.5568s/iter; left time: 15153.1588s
	iters: 200, epoch: 7 | loss: 0.1305172
	speed: 0.0342s/iter; left time: 926.3532s
	iters: 300, epoch: 7 | loss: 0.1301814
	speed: 0.0340s/iter; left time: 917.8266s
	iters: 400, epoch: 7 | loss: 0.1296022
	speed: 0.0344s/iter; left time: 924.9034s
	iters: 500, epoch: 7 | loss: 0.1270212
	speed: 0.0353s/iter; left time: 945.6628s
	iters: 600, epoch: 7 | loss: 0.1138188
	speed: 0.0344s/iter; left time: 918.1395s
	iters: 700, epoch: 7 | loss: 0.1269018
	speed: 0.0333s/iter; left time: 886.0425s
	iters: 800, epoch: 7 | loss: 0.1309350
	speed: 0.0339s/iter; left time: 900.0318s
	iters: 900, epoch: 7 | loss: 0.1321379
	speed: 0.0345s/iter; left time: 910.1043s
	iters: 1000, epoch: 7 | loss: 0.1326577
	speed: 0.0342s/iter; left time: 900.8317s
	iters: 1100, epoch: 7 | loss: 0.1379215
	speed: 0.0345s/iter; left time: 904.7370s
Epoch: 7 cost time: 39.90332841873169
Epoch: 7, Steps: 1138 | Train Loss: 0.1303694 Vali Loss: 0.2223841 Test Loss: 0.2795276
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.1427616
	speed: 0.5391s/iter; left time: 14057.1340s
	iters: 200, epoch: 8 | loss: 0.1251661
	speed: 0.0324s/iter; left time: 840.5121s
	iters: 300, epoch: 8 | loss: 0.1307780
	speed: 0.0332s/iter; left time: 858.9022s
	iters: 400, epoch: 8 | loss: 0.1312978
	speed: 0.0334s/iter; left time: 861.6860s
	iters: 500, epoch: 8 | loss: 0.1397403
	speed: 0.0338s/iter; left time: 868.7734s
	iters: 600, epoch: 8 | loss: 0.1262529
	speed: 0.0341s/iter; left time: 871.7558s
	iters: 700, epoch: 8 | loss: 0.1473692
	speed: 0.0342s/iter; left time: 872.4658s
	iters: 800, epoch: 8 | loss: 0.1349240
	speed: 0.0349s/iter; left time: 886.0798s
	iters: 900, epoch: 8 | loss: 0.1330876
	speed: 0.0339s/iter; left time: 858.0169s
	iters: 1000, epoch: 8 | loss: 0.1203422
	speed: 0.0345s/iter; left time: 869.4868s
	iters: 1100, epoch: 8 | loss: 0.1332626
	speed: 0.0343s/iter; left time: 859.2825s
Epoch: 8 cost time: 39.6727089881897
Epoch: 8, Steps: 1138 | Train Loss: 0.1301753 Vali Loss: 0.2233138 Test Loss: 0.2800549
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.1206552
	speed: 0.5743s/iter; left time: 14322.5266s
	iters: 200, epoch: 9 | loss: 0.1324531
	speed: 0.0352s/iter; left time: 874.2848s
	iters: 300, epoch: 9 | loss: 0.1283440
	speed: 0.0355s/iter; left time: 877.3651s
	iters: 400, epoch: 9 | loss: 0.1315886
	speed: 0.0356s/iter; left time: 878.1610s
	iters: 500, epoch: 9 | loss: 0.1273097
	speed: 0.0354s/iter; left time: 867.6495s
	iters: 600, epoch: 9 | loss: 0.1326344
	speed: 0.0359s/iter; left time: 878.0601s
	iters: 700, epoch: 9 | loss: 0.1299317
	speed: 0.0354s/iter; left time: 861.6576s
	iters: 800, epoch: 9 | loss: 0.1284128
	speed: 0.0354s/iter; left time: 858.1271s
	iters: 900, epoch: 9 | loss: 0.1248771
	speed: 0.0343s/iter; left time: 828.2328s
	iters: 1000, epoch: 9 | loss: 0.1171067
	speed: 0.0329s/iter; left time: 790.3106s
	iters: 1100, epoch: 9 | loss: 0.1279920
	speed: 0.0327s/iter; left time: 782.9535s
Epoch: 9 cost time: 40.40567088127136
Epoch: 9, Steps: 1138 | Train Loss: 0.1300861 Vali Loss: 0.2231925 Test Loss: 0.2798872
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.1399429
	speed: 0.5329s/iter; left time: 12682.0795s
	iters: 200, epoch: 10 | loss: 0.1226842
	speed: 0.0275s/iter; left time: 650.9360s
	iters: 300, epoch: 10 | loss: 0.1176504
	speed: 0.0327s/iter; left time: 771.5830s
	iters: 400, epoch: 10 | loss: 0.1321897
	speed: 0.0326s/iter; left time: 765.6869s
	iters: 500, epoch: 10 | loss: 0.1336786
	speed: 0.0326s/iter; left time: 763.8947s
	iters: 600, epoch: 10 | loss: 0.1328317
	speed: 0.0326s/iter; left time: 759.3421s
	iters: 700, epoch: 10 | loss: 0.1251511
	speed: 0.0323s/iter; left time: 748.2837s
	iters: 800, epoch: 10 | loss: 0.1349337
	speed: 0.0330s/iter; left time: 763.0775s
	iters: 900, epoch: 10 | loss: 0.1339964
	speed: 0.0326s/iter; left time: 750.2903s
	iters: 1000, epoch: 10 | loss: 0.1272578
	speed: 0.0338s/iter; left time: 773.2994s
	iters: 1100, epoch: 10 | loss: 0.1405315
	speed: 0.0324s/iter; left time: 738.8320s
Epoch: 10 cost time: 37.70276498794556
Epoch: 10, Steps: 1138 | Train Loss: 0.1300328 Vali Loss: 0.2232847 Test Loss: 0.2800313
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.1171421
	speed: 0.5656s/iter; left time: 12816.1379s
	iters: 200, epoch: 11 | loss: 0.1279089
	speed: 0.0284s/iter; left time: 639.7041s
	iters: 300, epoch: 11 | loss: 0.1242360
	speed: 0.0326s/iter; left time: 731.3688s
	iters: 400, epoch: 11 | loss: 0.1205009
	speed: 0.0329s/iter; left time: 735.0770s
	iters: 500, epoch: 11 | loss: 0.1232607
	speed: 0.0326s/iter; left time: 726.2067s
	iters: 600, epoch: 11 | loss: 0.1356527
	speed: 0.0330s/iter; left time: 731.6766s
	iters: 700, epoch: 11 | loss: 0.1359215
	speed: 0.0325s/iter; left time: 716.9727s
	iters: 800, epoch: 11 | loss: 0.1338219
	speed: 0.0326s/iter; left time: 715.0707s
	iters: 900, epoch: 11 | loss: 0.1316194
	speed: 0.0324s/iter; left time: 708.4232s
	iters: 1000, epoch: 11 | loss: 0.1275376
	speed: 0.0330s/iter; left time: 718.9214s
	iters: 1100, epoch: 11 | loss: 0.1347580
	speed: 0.0320s/iter; left time: 692.0817s
Epoch: 11 cost time: 37.916051387786865
Epoch: 11, Steps: 1138 | Train Loss: 0.1300269 Vali Loss: 0.2232041 Test Loss: 0.2799376
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : ECL_96_96_19_emb_128_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (5165, 1, 96, 321) (5165, 1, 96, 321)
test shape: (5165, 96, 321) (5165, 96, 321)
mse:0.28205201029777527, mae:0.37319567799568176
Args in experiment:
Namespace(is_training=1, model_id='ECL_96_96_20_emb_128', model='xLSTM', data='custom', root_path='./data/electricity/', data_path='/input-data/electricity.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, enc_in=321, dec_in=7, c_out=321, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.5, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=32, patience=10, learning_rate=0.0005, des='test', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, use_norm=True, partial_start_index=0, hidden_size=512, num_layers=2, mark_enc_in=4, embedding_dim=128, weight_decay=1e-06, kernal_size=5, num_heads_xlstm=4, qkv_proj_blocksize=2, proj_factor=1.3, num_blocks=3, slstm_at=1, grad_clip_norm=1.0, d_state=16, d_conv=4, expand=2)
Use GPU: cuda:0
{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-L/usr/local/cuda/lib', '-lcublas'], 'extra_cflags': ['-DSLSTM_HIDDEN_SIZE=128', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__'], 'extra_cuda_cflags': ['-Xptxas="-v"', '-gencode', 'arch=compute_80,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=128', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__']}
Using /home/thetayne/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/thetayne/.cache/torch_extensions/py310_cu121/slstm_HS128BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0/build.ninja...
Building extension module slstm_HS128BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module slstm_HS128BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
>>>>>>>start training : ECL_96_96_20_emb_128_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 18221
val 2537
test 5165
	iters: 100, epoch: 1 | loss: 0.4116617
	speed: 0.0670s/iter; left time: 1136.6463s
	iters: 200, epoch: 1 | loss: 0.2770340
	speed: 0.0450s/iter; left time: 759.3341s
	iters: 300, epoch: 1 | loss: 0.2529317
	speed: 0.0468s/iter; left time: 784.1728s
	iters: 400, epoch: 1 | loss: 0.2309876
	speed: 0.0474s/iter; left time: 790.7470s
	iters: 500, epoch: 1 | loss: 0.2076103
	speed: 0.0471s/iter; left time: 781.0690s
Epoch: 1 cost time: 28.330042839050293
Epoch: 1, Steps: 569 | Train Loss: 0.3264293 Vali Loss: 0.2350105 Test Loss: 0.2966824
Validation loss decreased (inf --> 0.235011).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.1983934
	speed: 0.5973s/iter; left time: 9797.3044s
	iters: 200, epoch: 2 | loss: 0.1928144
	speed: 0.0452s/iter; left time: 736.1680s
	iters: 300, epoch: 2 | loss: 0.1878495
	speed: 0.0488s/iter; left time: 791.4087s
	iters: 400, epoch: 2 | loss: 0.1902948
	speed: 0.0494s/iter; left time: 795.1639s
	iters: 500, epoch: 2 | loss: 0.1893973
	speed: 0.0498s/iter; left time: 796.7490s
Epoch: 2 cost time: 27.72259020805359
Epoch: 2, Steps: 569 | Train Loss: 0.1914539 Vali Loss: 0.2270864 Test Loss: 0.2862670
Validation loss decreased (0.235011 --> 0.227086).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.1855187
	speed: 0.5989s/iter; left time: 9481.7878s
	iters: 200, epoch: 3 | loss: 0.1740436
	speed: 0.0441s/iter; left time: 694.5667s
	iters: 300, epoch: 3 | loss: 0.1921382
	speed: 0.0453s/iter; left time: 707.4334s
	iters: 400, epoch: 3 | loss: 0.1776937
	speed: 0.0454s/iter; left time: 705.3451s
	iters: 500, epoch: 3 | loss: 0.1803255
	speed: 0.0452s/iter; left time: 698.3077s
Epoch: 3 cost time: 26.394438982009888
Epoch: 3, Steps: 569 | Train Loss: 0.1802089 Vali Loss: 0.2289668 Test Loss: 0.2843427
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.1677362
	speed: 0.6045s/iter; left time: 9226.7452s
	iters: 200, epoch: 4 | loss: 0.1711877
	speed: 0.0442s/iter; left time: 670.5995s
	iters: 300, epoch: 4 | loss: 0.1676005
	speed: 0.0458s/iter; left time: 689.8683s
	iters: 400, epoch: 4 | loss: 0.1866265
	speed: 0.0457s/iter; left time: 684.3721s
	iters: 500, epoch: 4 | loss: 0.1792325
	speed: 0.0469s/iter; left time: 697.0682s
Epoch: 4 cost time: 27.059603214263916
Epoch: 4, Steps: 569 | Train Loss: 0.1772959 Vali Loss: 0.2337386 Test Loss: 0.2888322
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.1775851
	speed: 0.6072s/iter; left time: 8922.2271s
	iters: 200, epoch: 5 | loss: 0.1683699
	speed: 0.0412s/iter; left time: 601.6075s
	iters: 300, epoch: 5 | loss: 0.1843979
	speed: 0.0471s/iter; left time: 682.7409s
	iters: 400, epoch: 5 | loss: 0.1866239
	speed: 0.0474s/iter; left time: 681.8251s
	iters: 500, epoch: 5 | loss: 0.1747614
	speed: 0.0480s/iter; left time: 686.1697s
Epoch: 5 cost time: 27.252626419067383
Epoch: 5, Steps: 569 | Train Loss: 0.1761884 Vali Loss: 0.2345736 Test Loss: 0.2897492
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.1758506
	speed: 0.5840s/iter; left time: 8248.8866s
	iters: 200, epoch: 6 | loss: 0.1698373
	speed: 0.0482s/iter; left time: 676.0866s
	iters: 300, epoch: 6 | loss: 0.1738212
	speed: 0.0424s/iter; left time: 590.8868s
	iters: 400, epoch: 6 | loss: 0.1833045
	speed: 0.0422s/iter; left time: 583.8614s
	iters: 500, epoch: 6 | loss: 0.1801366
	speed: 0.0418s/iter; left time: 573.0631s
Epoch: 6 cost time: 25.870086669921875
Epoch: 6, Steps: 569 | Train Loss: 0.1756090 Vali Loss: 0.2346249 Test Loss: 0.2894098
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.1734144
	speed: 0.5991s/iter; left time: 8121.3329s
	iters: 200, epoch: 7 | loss: 0.1755314
	speed: 0.0474s/iter; left time: 637.6016s
	iters: 300, epoch: 7 | loss: 0.1779653
	speed: 0.0478s/iter; left time: 638.1486s
	iters: 400, epoch: 7 | loss: 0.1737388
	speed: 0.0482s/iter; left time: 639.0715s
	iters: 500, epoch: 7 | loss: 0.1747525
	speed: 0.0471s/iter; left time: 619.6077s
Epoch: 7 cost time: 28.08580446243286
Epoch: 7, Steps: 569 | Train Loss: 0.1752696 Vali Loss: 0.2335479 Test Loss: 0.2888545
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.1690539
	speed: 0.5891s/iter; left time: 7650.6208s
	iters: 200, epoch: 8 | loss: 0.1769020
	speed: 0.0467s/iter; left time: 602.3889s
	iters: 300, epoch: 8 | loss: 0.1741329
	speed: 0.0468s/iter; left time: 598.5362s
	iters: 400, epoch: 8 | loss: 0.1742430
	speed: 0.0484s/iter; left time: 613.5237s
	iters: 500, epoch: 8 | loss: 0.1942264
	speed: 0.0490s/iter; left time: 616.9439s
Epoch: 8 cost time: 28.08255386352539
Epoch: 8, Steps: 569 | Train Loss: 0.1751453 Vali Loss: 0.2341951 Test Loss: 0.2899183
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.1785806
	speed: 0.5945s/iter; left time: 7383.2589s
	iters: 200, epoch: 9 | loss: 0.1817985
	speed: 0.0503s/iter; left time: 619.1587s
	iters: 300, epoch: 9 | loss: 0.1770345
	speed: 0.0494s/iter; left time: 603.3717s
	iters: 400, epoch: 9 | loss: 0.1789278
	speed: 0.0498s/iter; left time: 604.0011s
	iters: 500, epoch: 9 | loss: 0.1704975
	speed: 0.0495s/iter; left time: 595.4748s
Epoch: 9 cost time: 28.901291608810425
Epoch: 9, Steps: 569 | Train Loss: 0.1751371 Vali Loss: 0.2343865 Test Loss: 0.2899881
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.1743144
	speed: 0.6060s/iter; left time: 7180.6622s
	iters: 200, epoch: 10 | loss: 0.1762126
	speed: 0.0483s/iter; left time: 567.4891s
	iters: 300, epoch: 10 | loss: 0.1736156
	speed: 0.0477s/iter; left time: 555.7191s
	iters: 400, epoch: 10 | loss: 0.1616234
	speed: 0.0469s/iter; left time: 541.5888s
	iters: 500, epoch: 10 | loss: 0.1708439
	speed: 0.0459s/iter; left time: 525.7859s
Epoch: 10 cost time: 27.549118995666504
Epoch: 10, Steps: 569 | Train Loss: 0.1750045 Vali Loss: 0.2345293 Test Loss: 0.2894699
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.1777948
	speed: 0.5950s/iter; left time: 6712.0809s
	iters: 200, epoch: 11 | loss: 0.1884383
	speed: 0.0489s/iter; left time: 546.4056s
	iters: 300, epoch: 11 | loss: 0.1742843
	speed: 0.0483s/iter; left time: 534.9256s
	iters: 400, epoch: 11 | loss: 0.1781051
	speed: 0.0476s/iter; left time: 522.3000s
	iters: 500, epoch: 11 | loss: 0.1830282
	speed: 0.0475s/iter; left time: 517.2975s
Epoch: 11 cost time: 27.9599027633667
Epoch: 11, Steps: 569 | Train Loss: 0.1750256 Vali Loss: 0.2346587 Test Loss: 0.2898342
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.1707346
	speed: 0.5852s/iter; left time: 6269.1343s
	iters: 200, epoch: 12 | loss: 0.1687633
	speed: 0.0484s/iter; left time: 513.4962s
	iters: 300, epoch: 12 | loss: 0.1700196
	speed: 0.0477s/iter; left time: 501.4315s
	iters: 400, epoch: 12 | loss: 0.1668847
	speed: 0.0483s/iter; left time: 502.5023s
	iters: 500, epoch: 12 | loss: 0.1705617
	speed: 0.0479s/iter; left time: 494.2598s
Epoch: 12 cost time: 27.99778413772583
Epoch: 12, Steps: 569 | Train Loss: 0.1749680 Vali Loss: 0.2343967 Test Loss: 0.2895181
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : ECL_96_96_20_emb_128_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (5165, 1, 96, 321) (5165, 1, 96, 321)
test shape: (5165, 96, 321) (5165, 96, 321)
mse:0.2862670123577118, mae:0.3788622319698334
Args in experiment:
Namespace(is_training=1, model_id='ECL_96_96_21_emb_256', model='xLSTM', data='custom', root_path='./data/electricity/', data_path='/input-data/electricity.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, enc_in=321, dec_in=7, c_out=321, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=8, patience=10, learning_rate=0.0005, des='test', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, use_norm=True, partial_start_index=0, hidden_size=512, num_layers=2, mark_enc_in=4, embedding_dim=256, weight_decay=0.0001, kernal_size=3, num_heads_xlstm=8, qkv_proj_blocksize=2, proj_factor=1.3, num_blocks=3, slstm_at=1, grad_clip_norm=1.0, d_state=16, d_conv=4, expand=2)
Use GPU: cuda:0
{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-L/usr/local/cuda/lib', '-lcublas'], 'extra_cflags': ['-DSLSTM_HIDDEN_SIZE=256', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=8', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__'], 'extra_cuda_cflags': ['-Xptxas="-v"', '-gencode', 'arch=compute_80,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=256', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=8', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__']}
Using /home/thetayne/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Creating extension directory /home/thetayne/.cache/torch_extensions/py310_cu121/slstm_HS256BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/thetayne/.cache/torch_extensions/py310_cu121/slstm_HS256BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0/build.ninja...
Building extension module slstm_HS256BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[1/8] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output cuda_error.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS256BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=256 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=8 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/util/cuda_error.cu -o cuda_error.cuda.o 
ptxas info    : 0 bytes gmem
[2/8] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output slstm_pointwise.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS256BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=256 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=8 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/cuda/slstm_pointwise.cu -o slstm_pointwise.cuda.o 
ptxas info    : 0 bytes gmem
ptxas info    : Compiling entry function '_ZN5slstm21SLSTMPointwiseForwardILb0EEEviiiPK13__nv_bfloat16S3_PKfS3_jPS1_jS6_S6_' for 'sm_80'
ptxas info    : Function properties for _ZN5slstm21SLSTMPointwiseForwardILb0EEEviiiPK13__nv_bfloat16S3_PKfS3_jPS1_jS6_S6_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 32 registers, 440 bytes cmem[0]
ptxas info    : Compiling entry function '_ZN5slstm21SLSTMPointwiseForwardILb1EEEviiiPK13__nv_bfloat16S3_PKfS3_jPS1_jS6_S6_' for 'sm_80'
ptxas info    : Function properties for _ZN5slstm21SLSTMPointwiseForwardILb1EEEviiiPK13__nv_bfloat16S3_PKfS3_jPS1_jS6_S6_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 32 registers, 440 bytes cmem[0]
ptxas info    : Compiling entry function '_ZN5slstm22SLSTMPointwiseBackwardEiiiPK13__nv_bfloat16jS2_S2_PKfS2_jS2_jPS0_jS5_S5_S5_' for 'sm_80'
ptxas info    : Function properties for _ZN5slstm22SLSTMPointwiseBackwardEiiiPK13__nv_bfloat16jS2_S2_PKfS2_jS2_jPS0_jS5_S5_S5_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 32 registers, 480 bytes cmem[0]
[3/8] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output slstm_forward.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS256BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=256 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=8 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/cuda/slstm_forward.cu -o slstm_forward.cuda.o 
ptxas info    : 0 bytes gmem
[4/8] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output slstm_backward_cut.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS256BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=256 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=8 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/cuda/slstm_backward_cut.cu -o slstm_backward_cut.cuda.o 
ptxas info    : 0 bytes gmem
ptxas info    : Compiling entry function '_ZN54_GLOBAL__N__2085b59d_21_slstm_backward_cut_cu_1c2c4d0129gradientBiasAggregationKernelEjjjjjjPK13__nv_bfloat16S2_Pf' for 'sm_80'
ptxas info    : Function properties for _ZN54_GLOBAL__N__2085b59d_21_slstm_backward_cut_cu_1c2c4d0129gradientBiasAggregationKernelEjjjjjjPK13__nv_bfloat16S2_Pf
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 32 registers, 400 bytes cmem[0]
[5/8] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output slstm_backward.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS256BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=256 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=8 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/cuda/slstm_backward.cu -o slstm_backward.cuda.o 
ptxas info    : 0 bytes gmem
ptxas info    : Compiling entry function '_ZN50_GLOBAL__N__d983f13f_17_slstm_backward_cu_3639fa5e29gradientBiasAggregationKernelEjjjjjjPK13__nv_bfloat16S2_Pf' for 'sm_80'
ptxas info    : Function properties for _ZN50_GLOBAL__N__d983f13f_17_slstm_backward_cu_3639fa5e29gradientBiasAggregationKernelEjjjjjjPK13__nv_bfloat16S2_Pf
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 32 registers, 400 bytes cmem[0]
[6/8] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output blas.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS256BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=256 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=8 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/util/blas.cu -o blas.cuda.o 
ptxas info    : 0 bytes gmem
ptxas info    : Compiling entry function '_Z10initKernelI13__nv_bfloat16EvPT_iS1_' for 'sm_80'
ptxas info    : Function properties for _Z10initKernelI13__nv_bfloat16EvPT_iS1_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 8 registers, 366 bytes cmem[0]
ptxas info    : Compiling entry function '_Z10initKernelI6__halfEvPT_iS1_' for 'sm_80'
ptxas info    : Function properties for _Z10initKernelI6__halfEvPT_iS1_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 8 registers, 366 bytes cmem[0]
ptxas info    : Compiling entry function '_Z10initKernelIfEvPT_iS0_' for 'sm_80'
ptxas info    : Function properties for _Z10initKernelIfEvPT_iS0_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 8 registers, 368 bytes cmem[0]
ptxas info    : Compiling entry function '_Z10initKernelIdEvPT_iS0_' for 'sm_80'
ptxas info    : Function properties for _Z10initKernelIdEvPT_iS0_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 8 registers, 376 bytes cmem[0]
[7/8] c++ -MMD -MF slstm.o.d -DTORCH_EXTENSION_NAME=slstm_HS256BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -DSLSTM_HIDDEN_SIZE=256 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=8 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/cuda/slstm.cc -o slstm.o 
[8/8] c++ slstm.o slstm_forward.cuda.o slstm_backward.cuda.o slstm_backward_cut.cuda.o slstm_pointwise.cuda.o blas.cuda.o cuda_error.cuda.o -shared -L/usr/local/cuda/lib -lcublas -L/usr/local/lib/python3.10/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o slstm_HS256BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0.so
Loading extension module slstm_HS256BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
>>>>>>>start training : ECL_96_96_21_emb_256_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 18221
val 2537
test 5165
	iters: 100, epoch: 1 | loss: 0.2155467
	speed: 0.0458s/iter; left time: 3124.6769s
	iters: 200, epoch: 1 | loss: 0.2144068
	speed: 0.0261s/iter; left time: 1780.7295s
	iters: 300, epoch: 1 | loss: 0.1706155
	speed: 0.0283s/iter; left time: 1923.1638s
	iters: 400, epoch: 1 | loss: 0.1743590
	speed: 0.0270s/iter; left time: 1832.5174s
	iters: 500, epoch: 1 | loss: 0.1520845
	speed: 0.0274s/iter; left time: 1857.2079s
	iters: 600, epoch: 1 | loss: 0.1217758
	speed: 0.0272s/iter; left time: 1844.5869s
	iters: 700, epoch: 1 | loss: 0.1264802
	speed: 0.0272s/iter; left time: 1840.4302s
	iters: 800, epoch: 1 | loss: 0.1171606
	speed: 0.0273s/iter; left time: 1842.9724s
	iters: 900, epoch: 1 | loss: 0.1279671
	speed: 0.0274s/iter; left time: 1846.0767s
	iters: 1000, epoch: 1 | loss: 0.1149499
	speed: 0.0286s/iter; left time: 1922.7521s
	iters: 1100, epoch: 1 | loss: 0.1074298
	speed: 0.0273s/iter; left time: 1836.7441s
	iters: 1200, epoch: 1 | loss: 0.1178975
	speed: 0.0271s/iter; left time: 1821.5777s
	iters: 1300, epoch: 1 | loss: 0.1066584
	speed: 0.0270s/iter; left time: 1807.0018s
	iters: 1400, epoch: 1 | loss: 0.1080542
	speed: 0.0271s/iter; left time: 1810.7224s
	iters: 1500, epoch: 1 | loss: 0.1034981
	speed: 0.0271s/iter; left time: 1812.9887s
	iters: 1600, epoch: 1 | loss: 0.0899185
	speed: 0.0271s/iter; left time: 1810.6526s
	iters: 1700, epoch: 1 | loss: 0.0949977
	speed: 0.0278s/iter; left time: 1854.3994s
	iters: 1800, epoch: 1 | loss: 0.0850807
	speed: 0.0291s/iter; left time: 1936.5608s
	iters: 1900, epoch: 1 | loss: 0.0950049
	speed: 0.0271s/iter; left time: 1796.4194s
	iters: 2000, epoch: 1 | loss: 0.1122263
	speed: 0.0269s/iter; left time: 1784.7735s
	iters: 2100, epoch: 1 | loss: 0.1037591
	speed: 0.0282s/iter; left time: 1869.8383s
	iters: 2200, epoch: 1 | loss: 0.1136349
	speed: 0.0278s/iter; left time: 1838.9084s
Epoch: 1 cost time: 64.32954454421997
Epoch: 1, Steps: 2277 | Train Loss: 0.1358612 Vali Loss: 0.1909930 Test Loss: 0.2558299
Validation loss decreased (inf --> 0.190993).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.0933176
	speed: 0.5714s/iter; left time: 37677.6715s
	iters: 200, epoch: 2 | loss: 0.0927950
	speed: 0.0223s/iter; left time: 1468.1861s
	iters: 300, epoch: 2 | loss: 0.0938429
	speed: 0.0223s/iter; left time: 1464.8716s
	iters: 400, epoch: 2 | loss: 0.1013310
	speed: 0.0247s/iter; left time: 1621.6014s
	iters: 500, epoch: 2 | loss: 0.0802866
	speed: 0.0268s/iter; left time: 1756.0720s
	iters: 600, epoch: 2 | loss: 0.1040907
	speed: 0.0269s/iter; left time: 1758.4061s
	iters: 700, epoch: 2 | loss: 0.0865019
	speed: 0.0267s/iter; left time: 1746.3087s
	iters: 800, epoch: 2 | loss: 0.1030575
	speed: 0.0255s/iter; left time: 1662.2302s
	iters: 900, epoch: 2 | loss: 0.0888558
	speed: 0.0268s/iter; left time: 1747.7372s
	iters: 1000, epoch: 2 | loss: 0.0822448
	speed: 0.0274s/iter; left time: 1780.7611s
	iters: 1100, epoch: 2 | loss: 0.0817941
	speed: 0.0295s/iter; left time: 1914.7947s
	iters: 1200, epoch: 2 | loss: 0.0851338
	speed: 0.0290s/iter; left time: 1878.9991s
	iters: 1300, epoch: 2 | loss: 0.1101914
	speed: 0.0261s/iter; left time: 1692.0207s
	iters: 1400, epoch: 2 | loss: 0.0784813
	speed: 0.0266s/iter; left time: 1721.5585s
	iters: 1500, epoch: 2 | loss: 0.1001366
	speed: 0.0264s/iter; left time: 1702.1560s
	iters: 1600, epoch: 2 | loss: 0.0827928
	speed: 0.0257s/iter; left time: 1654.8678s
	iters: 1700, epoch: 2 | loss: 0.0804452
	speed: 0.0271s/iter; left time: 1740.6022s
	iters: 1800, epoch: 2 | loss: 0.0812406
	speed: 0.0277s/iter; left time: 1778.0920s
	iters: 1900, epoch: 2 | loss: 0.0896995
	speed: 0.0263s/iter; left time: 1689.7173s
	iters: 2000, epoch: 2 | loss: 0.0791285
	speed: 0.0280s/iter; left time: 1792.2314s
	iters: 2100, epoch: 2 | loss: 0.1130557
	speed: 0.0275s/iter; left time: 1759.0301s
	iters: 2200, epoch: 2 | loss: 0.0867912
	speed: 0.0249s/iter; left time: 1590.9532s
Epoch: 2 cost time: 61.74571752548218
Epoch: 2, Steps: 2277 | Train Loss: 0.0881656 Vali Loss: 0.2098064 Test Loss: 0.2578449
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.0781376
	speed: 0.6121s/iter; left time: 38964.7650s
	iters: 200, epoch: 3 | loss: 0.0672712
	speed: 0.0242s/iter; left time: 1539.0429s
	iters: 300, epoch: 3 | loss: 0.0793858
	speed: 0.0246s/iter; left time: 1562.6547s
	iters: 400, epoch: 3 | loss: 0.0727157
	speed: 0.0253s/iter; left time: 1604.9999s
	iters: 500, epoch: 3 | loss: 0.0739956
	speed: 0.0249s/iter; left time: 1574.9203s
	iters: 600, epoch: 3 | loss: 0.0742455
	speed: 0.0254s/iter; left time: 1604.7943s
	iters: 700, epoch: 3 | loss: 0.0670667
	speed: 0.0247s/iter; left time: 1559.9843s
	iters: 800, epoch: 3 | loss: 0.0728948
	speed: 0.0250s/iter; left time: 1572.5100s
	iters: 900, epoch: 3 | loss: 0.0809320
	speed: 0.0256s/iter; left time: 1610.7745s
	iters: 1000, epoch: 3 | loss: 0.0759948
	speed: 0.0271s/iter; left time: 1703.0038s
	iters: 1100, epoch: 3 | loss: 0.0654926
	speed: 0.0292s/iter; left time: 1828.2752s
	iters: 1200, epoch: 3 | loss: 0.0791414
	speed: 0.0276s/iter; left time: 1724.3164s
	iters: 1300, epoch: 3 | loss: 0.0791679
	speed: 0.0265s/iter; left time: 1653.2164s
	iters: 1400, epoch: 3 | loss: 0.0729981
	speed: 0.0261s/iter; left time: 1628.7751s
	iters: 1500, epoch: 3 | loss: 0.0739812
	speed: 0.0273s/iter; left time: 1702.0743s
	iters: 1600, epoch: 3 | loss: 0.0716323
	speed: 0.0300s/iter; left time: 1864.0579s
	iters: 1700, epoch: 3 | loss: 0.0756281
	speed: 0.0283s/iter; left time: 1757.1003s
	iters: 1800, epoch: 3 | loss: 0.0743142
	speed: 0.0273s/iter; left time: 1689.7005s
	iters: 1900, epoch: 3 | loss: 0.0725963
	speed: 0.0289s/iter; left time: 1786.0109s
	iters: 2000, epoch: 3 | loss: 0.0729605
	speed: 0.0288s/iter; left time: 1778.1779s
	iters: 2100, epoch: 3 | loss: 0.0742701
	speed: 0.0277s/iter; left time: 1704.9934s
	iters: 2200, epoch: 3 | loss: 0.0832415
	speed: 0.0268s/iter; left time: 1647.3178s
Epoch: 3 cost time: 62.09209179878235
Epoch: 3, Steps: 2277 | Train Loss: 0.0749792 Vali Loss: 0.2007226 Test Loss: 0.2730938
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.0640726
	speed: 0.6240s/iter; left time: 38301.1580s
	iters: 200, epoch: 4 | loss: 0.0674883
	speed: 0.0310s/iter; left time: 1900.6978s
	iters: 300, epoch: 4 | loss: 0.0684920
	speed: 0.0314s/iter; left time: 1919.9347s
	iters: 400, epoch: 4 | loss: 0.0702922
	speed: 0.0268s/iter; left time: 1634.3494s
	iters: 500, epoch: 4 | loss: 0.0630969
	speed: 0.0277s/iter; left time: 1689.2210s
	iters: 600, epoch: 4 | loss: 0.0691242
	speed: 0.0275s/iter; left time: 1676.6092s
	iters: 700, epoch: 4 | loss: 0.0708790
	speed: 0.0272s/iter; left time: 1654.2076s
	iters: 800, epoch: 4 | loss: 0.0734625
	speed: 0.0293s/iter; left time: 1775.1964s
	iters: 900, epoch: 4 | loss: 0.0734408
	speed: 0.0266s/iter; left time: 1614.3202s
	iters: 1000, epoch: 4 | loss: 0.0773286
	speed: 0.0301s/iter; left time: 1818.4855s
	iters: 1100, epoch: 4 | loss: 0.0693834
	speed: 0.0298s/iter; left time: 1796.3984s
	iters: 1200, epoch: 4 | loss: 0.0695831
	speed: 0.0276s/iter; left time: 1664.0716s
	iters: 1300, epoch: 4 | loss: 0.0715387
	speed: 0.0296s/iter; left time: 1780.4287s
	iters: 1400, epoch: 4 | loss: 0.0728603
	speed: 0.0269s/iter; left time: 1613.6572s
	iters: 1500, epoch: 4 | loss: 0.0654772
	speed: 0.0266s/iter; left time: 1596.7019s
	iters: 1600, epoch: 4 | loss: 0.0700448
	speed: 0.0272s/iter; left time: 1631.3623s
	iters: 1700, epoch: 4 | loss: 0.0676065
	speed: 0.0274s/iter; left time: 1638.0886s
	iters: 1800, epoch: 4 | loss: 0.0715302
	speed: 0.0292s/iter; left time: 1743.4002s
	iters: 1900, epoch: 4 | loss: 0.0699075
	speed: 0.0267s/iter; left time: 1593.2532s
	iters: 2000, epoch: 4 | loss: 0.0675652
	speed: 0.0276s/iter; left time: 1644.0523s
	iters: 2100, epoch: 4 | loss: 0.0679440
	speed: 0.0283s/iter; left time: 1682.6563s
	iters: 2200, epoch: 4 | loss: 0.0709837
	speed: 0.0278s/iter; left time: 1646.3931s
Epoch: 4 cost time: 65.92230701446533
Epoch: 4, Steps: 2277 | Train Loss: 0.0692229 Vali Loss: 0.2038179 Test Loss: 0.2696930
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.0656665
	speed: 0.6225s/iter; left time: 36790.3883s
	iters: 200, epoch: 5 | loss: 0.0705482
	speed: 0.0277s/iter; left time: 1634.8937s
	iters: 300, epoch: 5 | loss: 0.0665238
	speed: 0.0278s/iter; left time: 1640.1572s
	iters: 400, epoch: 5 | loss: 0.0648608
	speed: 0.0279s/iter; left time: 1639.0642s
	iters: 500, epoch: 5 | loss: 0.0695081
	speed: 0.0274s/iter; left time: 1610.1511s
	iters: 600, epoch: 5 | loss: 0.0702634
	speed: 0.0274s/iter; left time: 1606.4933s
	iters: 700, epoch: 5 | loss: 0.0682275
	speed: 0.0262s/iter; left time: 1533.8085s
	iters: 800, epoch: 5 | loss: 0.0630093
	speed: 0.0270s/iter; left time: 1576.5009s
	iters: 900, epoch: 5 | loss: 0.0602843
	speed: 0.0268s/iter; left time: 1565.1411s
	iters: 1000, epoch: 5 | loss: 0.0665733
	speed: 0.0268s/iter; left time: 1557.4216s
	iters: 1100, epoch: 5 | loss: 0.0627649
	speed: 0.0271s/iter; left time: 1576.6662s
	iters: 1200, epoch: 5 | loss: 0.0639999
	speed: 0.0267s/iter; left time: 1549.4403s
	iters: 1300, epoch: 5 | loss: 0.0685102
	speed: 0.0273s/iter; left time: 1579.5132s
	iters: 1400, epoch: 5 | loss: 0.0745668
	speed: 0.0263s/iter; left time: 1522.0877s
	iters: 1500, epoch: 5 | loss: 0.0706789
	speed: 0.0260s/iter; left time: 1500.8276s
	iters: 1600, epoch: 5 | loss: 0.0721461
	speed: 0.0264s/iter; left time: 1520.1835s
	iters: 1700, epoch: 5 | loss: 0.0742854
	speed: 0.0262s/iter; left time: 1507.8243s
	iters: 1800, epoch: 5 | loss: 0.0710670
	speed: 0.0265s/iter; left time: 1523.2704s
	iters: 1900, epoch: 5 | loss: 0.0583635
	speed: 0.0268s/iter; left time: 1535.6926s
	iters: 2000, epoch: 5 | loss: 0.0597345
	speed: 0.0269s/iter; left time: 1538.5643s
	iters: 2100, epoch: 5 | loss: 0.0624084
	speed: 0.0270s/iter; left time: 1539.0859s
	iters: 2200, epoch: 5 | loss: 0.0686018
	speed: 0.0267s/iter; left time: 1523.6512s
Epoch: 5 cost time: 62.83170533180237
Epoch: 5, Steps: 2277 | Train Loss: 0.0662744 Vali Loss: 0.2054312 Test Loss: 0.2724022
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.0616952
	speed: 0.6116s/iter; left time: 34755.1487s
	iters: 200, epoch: 6 | loss: 0.0697344
	speed: 0.0246s/iter; left time: 1394.9204s
	iters: 300, epoch: 6 | loss: 0.0650847
	speed: 0.0261s/iter; left time: 1476.3834s
	iters: 400, epoch: 6 | loss: 0.0675042
	speed: 0.0259s/iter; left time: 1464.4923s
	iters: 500, epoch: 6 | loss: 0.0696658
	speed: 0.0267s/iter; left time: 1503.8756s
	iters: 600, epoch: 6 | loss: 0.0649035
	speed: 0.0263s/iter; left time: 1482.6484s
	iters: 700, epoch: 6 | loss: 0.0651837
	speed: 0.0264s/iter; left time: 1483.9250s
	iters: 800, epoch: 6 | loss: 0.0655053
	speed: 0.0269s/iter; left time: 1510.2453s
	iters: 900, epoch: 6 | loss: 0.0646458
	speed: 0.0258s/iter; left time: 1445.9193s
	iters: 1000, epoch: 6 | loss: 0.0657796
	speed: 0.0254s/iter; left time: 1420.9472s
	iters: 1100, epoch: 6 | loss: 0.0628720
	speed: 0.0254s/iter; left time: 1420.7297s
	iters: 1200, epoch: 6 | loss: 0.0658421
	speed: 0.0250s/iter; left time: 1391.9258s
	iters: 1300, epoch: 6 | loss: 0.0594090
	speed: 0.0251s/iter; left time: 1398.6353s
	iters: 1400, epoch: 6 | loss: 0.0580323
	speed: 0.0245s/iter; left time: 1361.6498s
	iters: 1500, epoch: 6 | loss: 0.0722001
	speed: 0.0253s/iter; left time: 1400.3150s
	iters: 1600, epoch: 6 | loss: 0.0649229
	speed: 0.0251s/iter; left time: 1389.7161s
	iters: 1700, epoch: 6 | loss: 0.0702063
	speed: 0.0250s/iter; left time: 1379.1201s
	iters: 1800, epoch: 6 | loss: 0.0601372
	speed: 0.0252s/iter; left time: 1389.8864s
	iters: 1900, epoch: 6 | loss: 0.0619668
	speed: 0.0249s/iter; left time: 1369.5842s
	iters: 2000, epoch: 6 | loss: 0.0575615
	speed: 0.0250s/iter; left time: 1372.8262s
	iters: 2100, epoch: 6 | loss: 0.0644465
	speed: 0.0252s/iter; left time: 1381.1547s
	iters: 2200, epoch: 6 | loss: 0.0671881
	speed: 0.0281s/iter; left time: 1537.9835s
Epoch: 6 cost time: 60.14588165283203
Epoch: 6, Steps: 2277 | Train Loss: 0.0647606 Vali Loss: 0.2051383 Test Loss: 0.2745531
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.0650863
	speed: 0.6090s/iter; left time: 33219.3057s
	iters: 200, epoch: 7 | loss: 0.0593431
	speed: 0.0245s/iter; left time: 1333.8416s
	iters: 300, epoch: 7 | loss: 0.0634600
	speed: 0.0251s/iter; left time: 1366.1422s
	iters: 400, epoch: 7 | loss: 0.0605644
	speed: 0.0249s/iter; left time: 1353.3116s
	iters: 500, epoch: 7 | loss: 0.0635994
	speed: 0.0260s/iter; left time: 1408.9221s
	iters: 600, epoch: 7 | loss: 0.0601429
	speed: 0.0263s/iter; left time: 1419.7885s
	iters: 700, epoch: 7 | loss: 0.0764415
	speed: 0.0272s/iter; left time: 1468.3032s
	iters: 800, epoch: 7 | loss: 0.0656221
	speed: 0.0268s/iter; left time: 1445.6863s
	iters: 900, epoch: 7 | loss: 0.0644337
	speed: 0.0258s/iter; left time: 1388.7773s
	iters: 1000, epoch: 7 | loss: 0.0632681
	speed: 0.0251s/iter; left time: 1344.8053s
	iters: 1100, epoch: 7 | loss: 0.0618602
	speed: 0.0250s/iter; left time: 1340.4404s
	iters: 1200, epoch: 7 | loss: 0.0606631
	speed: 0.0245s/iter; left time: 1307.4004s
	iters: 1300, epoch: 7 | loss: 0.0613569
	speed: 0.0265s/iter; left time: 1414.6824s
	iters: 1400, epoch: 7 | loss: 0.0657783
	speed: 0.0278s/iter; left time: 1477.8893s
	iters: 1500, epoch: 7 | loss: 0.0545961
	speed: 0.0266s/iter; left time: 1412.9815s
	iters: 1600, epoch: 7 | loss: 0.0591327
	speed: 0.0275s/iter; left time: 1457.7648s
	iters: 1700, epoch: 7 | loss: 0.0625106
	speed: 0.0268s/iter; left time: 1420.6818s
	iters: 1800, epoch: 7 | loss: 0.0638789
	speed: 0.0266s/iter; left time: 1403.9046s
	iters: 1900, epoch: 7 | loss: 0.0593709
	speed: 0.0270s/iter; left time: 1422.6246s
	iters: 2000, epoch: 7 | loss: 0.0618810
	speed: 0.0260s/iter; left time: 1368.2904s
	iters: 2100, epoch: 7 | loss: 0.0667980
	speed: 0.0258s/iter; left time: 1357.3029s
	iters: 2200, epoch: 7 | loss: 0.0607890
	speed: 0.0242s/iter; left time: 1271.8636s
Epoch: 7 cost time: 60.977049112319946
Epoch: 7, Steps: 2277 | Train Loss: 0.0639955 Vali Loss: 0.2067727 Test Loss: 0.2751779
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.0690703
	speed: 0.6072s/iter; left time: 31741.1702s
	iters: 200, epoch: 8 | loss: 0.0662779
	speed: 0.0294s/iter; left time: 1532.6204s
	iters: 300, epoch: 8 | loss: 0.0582813
	speed: 0.0291s/iter; left time: 1513.1853s
	iters: 400, epoch: 8 | loss: 0.0675821
	speed: 0.0279s/iter; left time: 1450.8710s
	iters: 500, epoch: 8 | loss: 0.0617229
	speed: 0.0271s/iter; left time: 1405.1989s
	iters: 600, epoch: 8 | loss: 0.0604016
	speed: 0.0271s/iter; left time: 1400.8041s
	iters: 700, epoch: 8 | loss: 0.0667455
	speed: 0.0305s/iter; left time: 1575.2416s
	iters: 800, epoch: 8 | loss: 0.0774058
	speed: 0.0301s/iter; left time: 1550.5323s
	iters: 900, epoch: 8 | loss: 0.0606177
	speed: 0.0280s/iter; left time: 1439.7572s
	iters: 1000, epoch: 8 | loss: 0.0607256
	speed: 0.0281s/iter; left time: 1442.7535s
	iters: 1100, epoch: 8 | loss: 0.0617539
	speed: 0.0288s/iter; left time: 1475.1276s
	iters: 1200, epoch: 8 | loss: 0.0655237
	speed: 0.0281s/iter; left time: 1439.0569s
	iters: 1300, epoch: 8 | loss: 0.0620511
	speed: 0.0271s/iter; left time: 1386.2770s
	iters: 1400, epoch: 8 | loss: 0.0715529
	speed: 0.0267s/iter; left time: 1363.0811s
	iters: 1500, epoch: 8 | loss: 0.0622116
	speed: 0.0259s/iter; left time: 1319.5437s
	iters: 1600, epoch: 8 | loss: 0.0641921
	speed: 0.0266s/iter; left time: 1352.8990s
	iters: 1700, epoch: 8 | loss: 0.0656008
	speed: 0.0270s/iter; left time: 1367.0913s
	iters: 1800, epoch: 8 | loss: 0.0615616
	speed: 0.0282s/iter; left time: 1424.7071s
	iters: 1900, epoch: 8 | loss: 0.0613940
	speed: 0.0265s/iter; left time: 1336.5070s
	iters: 2000, epoch: 8 | loss: 0.0595153
	speed: 0.0260s/iter; left time: 1311.6409s
	iters: 2100, epoch: 8 | loss: 0.0655493
	speed: 0.0248s/iter; left time: 1247.2298s
	iters: 2200, epoch: 8 | loss: 0.0760747
	speed: 0.0247s/iter; left time: 1237.6139s
Epoch: 8 cost time: 64.18710398674011
Epoch: 8, Steps: 2277 | Train Loss: 0.0635736 Vali Loss: 0.2077868 Test Loss: 0.2761369
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.0666860
	speed: 0.6163s/iter; left time: 30813.1199s
	iters: 200, epoch: 9 | loss: 0.0625449
	speed: 0.0251s/iter; left time: 1252.6455s
	iters: 300, epoch: 9 | loss: 0.0642095
	speed: 0.0269s/iter; left time: 1341.6712s
	iters: 400, epoch: 9 | loss: 0.0681692
	speed: 0.0293s/iter; left time: 1455.6593s
	iters: 500, epoch: 9 | loss: 0.0638202
	speed: 0.0287s/iter; left time: 1424.7370s
	iters: 600, epoch: 9 | loss: 0.0641062
	speed: 0.0293s/iter; left time: 1450.2807s
	iters: 700, epoch: 9 | loss: 0.0595732
	speed: 0.0278s/iter; left time: 1374.1533s
	iters: 800, epoch: 9 | loss: 0.0645686
	speed: 0.0304s/iter; left time: 1497.8748s
	iters: 900, epoch: 9 | loss: 0.0595918
	speed: 0.0293s/iter; left time: 1443.5882s
	iters: 1000, epoch: 9 | loss: 0.0609384
	speed: 0.0284s/iter; left time: 1392.7600s
	iters: 1100, epoch: 9 | loss: 0.0613656
	speed: 0.0277s/iter; left time: 1356.1043s
	iters: 1200, epoch: 9 | loss: 0.0637355
	speed: 0.0261s/iter; left time: 1278.3124s
	iters: 1300, epoch: 9 | loss: 0.0628921
	speed: 0.0264s/iter; left time: 1289.1079s
	iters: 1400, epoch: 9 | loss: 0.0653050
	speed: 0.0277s/iter; left time: 1347.8556s
	iters: 1500, epoch: 9 | loss: 0.0616314
	speed: 0.0289s/iter; left time: 1404.4609s
	iters: 1600, epoch: 9 | loss: 0.0623003
	speed: 0.0274s/iter; left time: 1329.4831s
	iters: 1700, epoch: 9 | loss: 0.0638533
	speed: 0.0269s/iter; left time: 1302.4981s
	iters: 1800, epoch: 9 | loss: 0.0592320
	speed: 0.0272s/iter; left time: 1314.5820s
	iters: 1900, epoch: 9 | loss: 0.0658764
	speed: 0.0268s/iter; left time: 1293.2887s
	iters: 2000, epoch: 9 | loss: 0.0612720
	speed: 0.0271s/iter; left time: 1305.3068s
	iters: 2100, epoch: 9 | loss: 0.0614037
	speed: 0.0261s/iter; left time: 1254.5844s
	iters: 2200, epoch: 9 | loss: 0.0648739
	speed: 0.0289s/iter; left time: 1382.3742s
Epoch: 9 cost time: 64.52576875686646
Epoch: 9, Steps: 2277 | Train Loss: 0.0633688 Vali Loss: 0.2076108 Test Loss: 0.2762684
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.0616940
	speed: 0.6256s/iter; left time: 29852.0696s
	iters: 200, epoch: 10 | loss: 0.0600660
	speed: 0.0244s/iter; left time: 1162.4485s
	iters: 300, epoch: 10 | loss: 0.0700862
	speed: 0.0284s/iter; left time: 1349.0341s
	iters: 400, epoch: 10 | loss: 0.0666455
	speed: 0.0284s/iter; left time: 1345.1824s
	iters: 500, epoch: 10 | loss: 0.0643215
	speed: 0.0302s/iter; left time: 1430.4864s
	iters: 600, epoch: 10 | loss: 0.0625109
	speed: 0.0283s/iter; left time: 1336.2821s
	iters: 700, epoch: 10 | loss: 0.0618127
	speed: 0.0273s/iter; left time: 1287.6722s
	iters: 800, epoch: 10 | loss: 0.0648641
	speed: 0.0278s/iter; left time: 1305.3627s
	iters: 900, epoch: 10 | loss: 0.0631217
	speed: 0.0265s/iter; left time: 1243.5174s
	iters: 1000, epoch: 10 | loss: 0.0637737
	speed: 0.0276s/iter; left time: 1292.6905s
	iters: 1100, epoch: 10 | loss: 0.0643654
	speed: 0.0262s/iter; left time: 1224.1882s
	iters: 1200, epoch: 10 | loss: 0.0622452
	speed: 0.0264s/iter; left time: 1232.1131s
	iters: 1300, epoch: 10 | loss: 0.0607798
	speed: 0.0274s/iter; left time: 1274.1984s
	iters: 1400, epoch: 10 | loss: 0.0592545
	speed: 0.0271s/iter; left time: 1257.9761s
	iters: 1500, epoch: 10 | loss: 0.0589753
	speed: 0.0268s/iter; left time: 1243.3322s
	iters: 1600, epoch: 10 | loss: 0.0653818
	speed: 0.0265s/iter; left time: 1225.6997s
	iters: 1700, epoch: 10 | loss: 0.0736492
	speed: 0.0263s/iter; left time: 1213.6228s
	iters: 1800, epoch: 10 | loss: 0.0665135
	speed: 0.0270s/iter; left time: 1243.9809s
	iters: 1900, epoch: 10 | loss: 0.0612075
	speed: 0.0277s/iter; left time: 1271.7616s
	iters: 2000, epoch: 10 | loss: 0.0678574
	speed: 0.0268s/iter; left time: 1229.6036s
	iters: 2100, epoch: 10 | loss: 0.0646192
	speed: 0.0264s/iter; left time: 1206.5771s
	iters: 2200, epoch: 10 | loss: 0.0643066
	speed: 0.0278s/iter; left time: 1266.3418s
Epoch: 10 cost time: 63.32907199859619
Epoch: 10, Steps: 2277 | Train Loss: 0.0632635 Vali Loss: 0.2074410 Test Loss: 0.2766647
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.0618378
	speed: 0.6256s/iter; left time: 28426.5885s
	iters: 200, epoch: 11 | loss: 0.0635420
	speed: 0.0254s/iter; left time: 1151.0421s
	iters: 300, epoch: 11 | loss: 0.0624433
	speed: 0.0258s/iter; left time: 1169.4432s
	iters: 400, epoch: 11 | loss: 0.0660364
	speed: 0.0293s/iter; left time: 1320.9375s
	iters: 500, epoch: 11 | loss: 0.0650136
	speed: 0.0265s/iter; left time: 1191.4889s
	iters: 600, epoch: 11 | loss: 0.0682705
	speed: 0.0271s/iter; left time: 1217.9696s
	iters: 700, epoch: 11 | loss: 0.0606545
	speed: 0.0258s/iter; left time: 1157.5812s
	iters: 800, epoch: 11 | loss: 0.0657211
	speed: 0.0273s/iter; left time: 1221.8762s
	iters: 900, epoch: 11 | loss: 0.0626193
	speed: 0.0271s/iter; left time: 1210.9996s
	iters: 1000, epoch: 11 | loss: 0.0620438
	speed: 0.0287s/iter; left time: 1276.1048s
	iters: 1100, epoch: 11 | loss: 0.0596084
	speed: 0.0272s/iter; left time: 1208.3507s
	iters: 1200, epoch: 11 | loss: 0.0672370
	speed: 0.0292s/iter; left time: 1293.5074s
	iters: 1300, epoch: 11 | loss: 0.0667875
	speed: 0.0288s/iter; left time: 1275.0845s
	iters: 1400, epoch: 11 | loss: 0.0641433
	speed: 0.0267s/iter; left time: 1177.2619s
	iters: 1500, epoch: 11 | loss: 0.0616174
	speed: 0.0268s/iter; left time: 1180.7974s
	iters: 1600, epoch: 11 | loss: 0.0642082
	speed: 0.0290s/iter; left time: 1274.0549s
	iters: 1700, epoch: 11 | loss: 0.0626309
	speed: 0.0291s/iter; left time: 1276.3275s
	iters: 1800, epoch: 11 | loss: 0.0615497
	speed: 0.0269s/iter; left time: 1177.0730s
	iters: 1900, epoch: 11 | loss: 0.0659542
	speed: 0.0267s/iter; left time: 1165.8300s
	iters: 2000, epoch: 11 | loss: 0.0587668
	speed: 0.0272s/iter; left time: 1184.0279s
	iters: 2100, epoch: 11 | loss: 0.0640555
	speed: 0.0266s/iter; left time: 1154.7843s
	iters: 2200, epoch: 11 | loss: 0.0607801
	speed: 0.0275s/iter; left time: 1191.2007s
Epoch: 11 cost time: 64.01317691802979
Epoch: 11, Steps: 2277 | Train Loss: 0.0632089 Vali Loss: 0.2074807 Test Loss: 0.2765337
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : ECL_96_96_21_emb_256_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (5165, 1, 96, 321) (5165, 1, 96, 321)
test shape: (5165, 96, 321) (5165, 96, 321)
mse:0.2558300495147705, mae:0.350603312253952
Args in experiment:
Namespace(is_training=1, model_id='ECL_96_96_22_emb_256', model='xLSTM', data='custom', root_path='./data/electricity/', data_path='/input-data/electricity.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, enc_in=321, dec_in=7, c_out=321, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.3, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=10, batch_size=16, patience=10, learning_rate=0.0001, des='test', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, use_norm=True, partial_start_index=0, hidden_size=512, num_layers=2, mark_enc_in=4, embedding_dim=256, weight_decay=0.0001, kernal_size=5, num_heads_xlstm=4, qkv_proj_blocksize=4, proj_factor=1.3, num_blocks=2, slstm_at=1, grad_clip_norm=0.5, d_state=16, d_conv=4, expand=2)
Use GPU: cuda:0
{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-L/usr/local/cuda/lib', '-lcublas'], 'extra_cflags': ['-DSLSTM_HIDDEN_SIZE=256', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__'], 'extra_cuda_cflags': ['-Xptxas="-v"', '-gencode', 'arch=compute_80,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=256', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__']}
Using /home/thetayne/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Creating extension directory /home/thetayne/.cache/torch_extensions/py310_cu121/slstm_HS256BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/thetayne/.cache/torch_extensions/py310_cu121/slstm_HS256BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0/build.ninja...
Building extension module slstm_HS256BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[1/8] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output cuda_error.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS256BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=256 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=4 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/util/cuda_error.cu -o cuda_error.cuda.o 
ptxas info    : 0 bytes gmem
[2/8] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output slstm_forward.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS256BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=256 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=4 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/cuda/slstm_forward.cu -o slstm_forward.cuda.o 
ptxas info    : 0 bytes gmem
[3/8] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output slstm_pointwise.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS256BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=256 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=4 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/cuda/slstm_pointwise.cu -o slstm_pointwise.cuda.o 
ptxas info    : 0 bytes gmem
ptxas info    : Compiling entry function '_ZN5slstm21SLSTMPointwiseForwardILb0EEEviiiPK13__nv_bfloat16S3_PKfS3_jPS1_jS6_S6_' for 'sm_80'
ptxas info    : Function properties for _ZN5slstm21SLSTMPointwiseForwardILb0EEEviiiPK13__nv_bfloat16S3_PKfS3_jPS1_jS6_S6_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 32 registers, 440 bytes cmem[0]
ptxas info    : Compiling entry function '_ZN5slstm21SLSTMPointwiseForwardILb1EEEviiiPK13__nv_bfloat16S3_PKfS3_jPS1_jS6_S6_' for 'sm_80'
ptxas info    : Function properties for _ZN5slstm21SLSTMPointwiseForwardILb1EEEviiiPK13__nv_bfloat16S3_PKfS3_jPS1_jS6_S6_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 32 registers, 440 bytes cmem[0]
ptxas info    : Compiling entry function '_ZN5slstm22SLSTMPointwiseBackwardEiiiPK13__nv_bfloat16jS2_S2_PKfS2_jS2_jPS0_jS5_S5_S5_' for 'sm_80'
ptxas info    : Function properties for _ZN5slstm22SLSTMPointwiseBackwardEiiiPK13__nv_bfloat16jS2_S2_PKfS2_jS2_jPS0_jS5_S5_S5_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 32 registers, 480 bytes cmem[0]
[4/8] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output blas.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS256BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=256 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=4 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/util/blas.cu -o blas.cuda.o 
ptxas info    : 0 bytes gmem
ptxas info    : Compiling entry function '_Z10initKernelI13__nv_bfloat16EvPT_iS1_' for 'sm_80'
ptxas info    : Function properties for _Z10initKernelI13__nv_bfloat16EvPT_iS1_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 8 registers, 366 bytes cmem[0]
ptxas info    : Compiling entry function '_Z10initKernelI6__halfEvPT_iS1_' for 'sm_80'
ptxas info    : Function properties for _Z10initKernelI6__halfEvPT_iS1_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 8 registers, 366 bytes cmem[0]
ptxas info    : Compiling entry function '_Z10initKernelIfEvPT_iS0_' for 'sm_80'
ptxas info    : Function properties for _Z10initKernelIfEvPT_iS0_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 8 registers, 368 bytes cmem[0]
ptxas info    : Compiling entry function '_Z10initKernelIdEvPT_iS0_' for 'sm_80'
ptxas info    : Function properties for _Z10initKernelIdEvPT_iS0_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 8 registers, 376 bytes cmem[0]
[5/8] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output slstm_backward.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS256BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=256 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=4 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/cuda/slstm_backward.cu -o slstm_backward.cuda.o 
ptxas info    : 0 bytes gmem
ptxas info    : Compiling entry function '_ZN50_GLOBAL__N__d983f13f_17_slstm_backward_cu_3639fa5e29gradientBiasAggregationKernelEjjjjjjPK13__nv_bfloat16S2_Pf' for 'sm_80'
ptxas info    : Function properties for _ZN50_GLOBAL__N__d983f13f_17_slstm_backward_cu_3639fa5e29gradientBiasAggregationKernelEjjjjjjPK13__nv_bfloat16S2_Pf
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 32 registers, 400 bytes cmem[0]
[6/8] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output slstm_backward_cut.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS256BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=256 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=4 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/cuda/slstm_backward_cut.cu -o slstm_backward_cut.cuda.o 
ptxas info    : 0 bytes gmem
ptxas info    : Compiling entry function '_ZN54_GLOBAL__N__2085b59d_21_slstm_backward_cut_cu_1c2c4d0129gradientBiasAggregationKernelEjjjjjjPK13__nv_bfloat16S2_Pf' for 'sm_80'
ptxas info    : Function properties for _ZN54_GLOBAL__N__2085b59d_21_slstm_backward_cut_cu_1c2c4d0129gradientBiasAggregationKernelEjjjjjjPK13__nv_bfloat16S2_Pf
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 32 registers, 400 bytes cmem[0]
[7/8] c++ -MMD -MF slstm.o.d -DTORCH_EXTENSION_NAME=slstm_HS256BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -DSLSTM_HIDDEN_SIZE=256 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=4 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/cuda/slstm.cc -o slstm.o 
[8/8] c++ slstm.o slstm_forward.cuda.o slstm_backward.cuda.o slstm_backward_cut.cuda.o slstm_pointwise.cuda.o blas.cuda.o cuda_error.cuda.o -shared -L/usr/local/cuda/lib -lcublas -L/usr/local/lib/python3.10/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o slstm_HS256BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0.so
Loading extension module slstm_HS256BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
>>>>>>>start training : ECL_96_96_22_emb_256_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 18221
val 2537
test 5165
	iters: 100, epoch: 1 | loss: 0.4324058
	speed: 0.0465s/iter; left time: 524.1089s
	iters: 200, epoch: 1 | loss: 0.3709711
	speed: 0.0285s/iter; left time: 318.7142s
	iters: 300, epoch: 1 | loss: 0.3049004
	speed: 0.0283s/iter; left time: 313.4026s
	iters: 400, epoch: 1 | loss: 0.2959913
	speed: 0.0282s/iter; left time: 309.6016s
	iters: 500, epoch: 1 | loss: 0.2917644
	speed: 0.0283s/iter; left time: 307.9278s
	iters: 600, epoch: 1 | loss: 0.1976279
	speed: 0.0284s/iter; left time: 305.8308s
	iters: 700, epoch: 1 | loss: 0.1822533
	speed: 0.0282s/iter; left time: 300.7277s
	iters: 800, epoch: 1 | loss: 0.1737043
	speed: 0.0281s/iter; left time: 297.7460s
	iters: 900, epoch: 1 | loss: 0.1801922
	speed: 0.0282s/iter; left time: 295.8657s
	iters: 1000, epoch: 1 | loss: 0.1571908
	speed: 0.0280s/iter; left time: 290.9984s
	iters: 1100, epoch: 1 | loss: 0.1587401
	speed: 0.0281s/iter; left time: 289.0339s
Epoch: 1 cost time: 33.82985210418701
Epoch: 1, Steps: 1138 | Train Loss: 0.2768612 Vali Loss: 0.2289079 Test Loss: 0.3080771
Validation loss decreased (inf --> 0.228908).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.1542323
	speed: 0.5712s/iter; left time: 5794.1094s
	iters: 200, epoch: 2 | loss: 0.1503097
	speed: 0.0250s/iter; left time: 251.1533s
	iters: 300, epoch: 2 | loss: 0.1490181
	speed: 0.0261s/iter; left time: 259.2480s
	iters: 400, epoch: 2 | loss: 0.1382911
	speed: 0.0278s/iter; left time: 273.5193s
	iters: 500, epoch: 2 | loss: 0.1460554
	speed: 0.0278s/iter; left time: 270.5564s
	iters: 600, epoch: 2 | loss: 0.1429426
	speed: 0.0277s/iter; left time: 267.4850s
	iters: 700, epoch: 2 | loss: 0.1292255
	speed: 0.0274s/iter; left time: 261.4341s
	iters: 800, epoch: 2 | loss: 0.1385360
	speed: 0.0279s/iter; left time: 263.4122s
	iters: 900, epoch: 2 | loss: 0.1272590
	speed: 0.0275s/iter; left time: 256.7835s
	iters: 1000, epoch: 2 | loss: 0.1382886
	speed: 0.0281s/iter; left time: 259.3767s
	iters: 1100, epoch: 2 | loss: 0.1356509
	speed: 0.0275s/iter; left time: 251.5670s
Epoch: 2 cost time: 32.10115194320679
Epoch: 2, Steps: 1138 | Train Loss: 0.1431700 Vali Loss: 0.2191756 Test Loss: 0.2942478
Validation loss decreased (0.228908 --> 0.219176).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.1293004
	speed: 0.5627s/iter; left time: 5066.8755s
	iters: 200, epoch: 3 | loss: 0.1356234
	speed: 0.0252s/iter; left time: 224.0911s
	iters: 300, epoch: 3 | loss: 0.1345074
	speed: 0.0255s/iter; left time: 224.6113s
	iters: 400, epoch: 3 | loss: 0.1236112
	speed: 0.0262s/iter; left time: 227.7104s
	iters: 500, epoch: 3 | loss: 0.1184666
	speed: 0.0278s/iter; left time: 239.6168s
	iters: 600, epoch: 3 | loss: 0.1339959
	speed: 0.0274s/iter; left time: 232.9211s
	iters: 700, epoch: 3 | loss: 0.1253676
	speed: 0.0279s/iter; left time: 234.3996s
	iters: 800, epoch: 3 | loss: 0.1214406
	speed: 0.0277s/iter; left time: 229.9227s
	iters: 900, epoch: 3 | loss: 0.1192890
	speed: 0.0279s/iter; left time: 228.8421s
	iters: 1000, epoch: 3 | loss: 0.1212701
	speed: 0.0272s/iter; left time: 220.3614s
	iters: 1100, epoch: 3 | loss: 0.1234816
	speed: 0.0280s/iter; left time: 223.9703s
Epoch: 3 cost time: 31.973961114883423
Epoch: 3, Steps: 1138 | Train Loss: 0.1267387 Vali Loss: 0.2172250 Test Loss: 0.2938825
Validation loss decreased (0.219176 --> 0.217225).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.1215197
	speed: 0.5711s/iter; left time: 4492.9486s
	iters: 200, epoch: 4 | loss: 0.1193601
	speed: 0.0241s/iter; left time: 187.0482s
	iters: 300, epoch: 4 | loss: 0.1263951
	speed: 0.0253s/iter; left time: 194.3140s
	iters: 400, epoch: 4 | loss: 0.1197753
	speed: 0.0264s/iter; left time: 199.4579s
	iters: 500, epoch: 4 | loss: 0.1271680
	speed: 0.0281s/iter; left time: 210.1451s
	iters: 600, epoch: 4 | loss: 0.1199978
	speed: 0.0276s/iter; left time: 203.1613s
	iters: 700, epoch: 4 | loss: 0.1172387
	speed: 0.0276s/iter; left time: 200.8713s
	iters: 800, epoch: 4 | loss: 0.1290671
	speed: 0.0279s/iter; left time: 199.8161s
	iters: 900, epoch: 4 | loss: 0.1242193
	speed: 0.0271s/iter; left time: 191.5733s
	iters: 1000, epoch: 4 | loss: 0.1236231
	speed: 0.0275s/iter; left time: 191.6965s
	iters: 1100, epoch: 4 | loss: 0.1196047
	speed: 0.0280s/iter; left time: 192.4584s
Epoch: 4 cost time: 32.09083437919617
Epoch: 4, Steps: 1138 | Train Loss: 0.1215068 Vali Loss: 0.2154740 Test Loss: 0.2933953
Validation loss decreased (0.217225 --> 0.215474).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.1217532
	speed: 0.5556s/iter; left time: 3738.5154s
	iters: 200, epoch: 5 | loss: 0.1122806
	speed: 0.0248s/iter; left time: 164.4026s
	iters: 300, epoch: 5 | loss: 0.1274324
	speed: 0.0252s/iter; left time: 164.6494s
	iters: 400, epoch: 5 | loss: 0.1255364
	speed: 0.0275s/iter; left time: 177.0343s
	iters: 500, epoch: 5 | loss: 0.1160384
	speed: 0.0277s/iter; left time: 175.0448s
	iters: 600, epoch: 5 | loss: 0.1280699
	speed: 0.0285s/iter; left time: 177.5838s
	iters: 700, epoch: 5 | loss: 0.1233486
	speed: 0.0278s/iter; left time: 170.0867s
	iters: 800, epoch: 5 | loss: 0.1243183
	speed: 0.0275s/iter; left time: 165.5613s
	iters: 900, epoch: 5 | loss: 0.1192737
	speed: 0.0279s/iter; left time: 165.1327s
	iters: 1000, epoch: 5 | loss: 0.1227116
	speed: 0.0276s/iter; left time: 161.0120s
	iters: 1100, epoch: 5 | loss: 0.1155935
	speed: 0.0276s/iter; left time: 157.9989s
Epoch: 5 cost time: 32.36770939826965
Epoch: 5, Steps: 1138 | Train Loss: 0.1191303 Vali Loss: 0.2161908 Test Loss: 0.2947047
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.1093995
	speed: 0.5735s/iter; left time: 3206.3047s
	iters: 200, epoch: 6 | loss: 0.1181284
	speed: 0.0252s/iter; left time: 138.2934s
	iters: 300, epoch: 6 | loss: 0.1176361
	speed: 0.0249s/iter; left time: 134.3248s
	iters: 400, epoch: 6 | loss: 0.1155894
	speed: 0.0274s/iter; left time: 144.8545s
	iters: 500, epoch: 6 | loss: 0.1151588
	speed: 0.0279s/iter; left time: 144.9229s
	iters: 600, epoch: 6 | loss: 0.1166404
	speed: 0.0275s/iter; left time: 139.9828s
	iters: 700, epoch: 6 | loss: 0.1307589
	speed: 0.0282s/iter; left time: 140.4973s
	iters: 800, epoch: 6 | loss: 0.1222260
	speed: 0.0282s/iter; left time: 137.8873s
	iters: 900, epoch: 6 | loss: 0.1109372
	speed: 0.0272s/iter; left time: 130.3402s
	iters: 1000, epoch: 6 | loss: 0.1082050
	speed: 0.0276s/iter; left time: 129.6354s
	iters: 1100, epoch: 6 | loss: 0.1255658
	speed: 0.0282s/iter; left time: 129.6582s
Epoch: 6 cost time: 32.270153760910034
Epoch: 6, Steps: 1138 | Train Loss: 0.1179886 Vali Loss: 0.2176672 Test Loss: 0.2945486
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.1188530
	speed: 0.5692s/iter; left time: 2534.5040s
	iters: 200, epoch: 7 | loss: 0.1132691
	speed: 0.0249s/iter; left time: 108.4206s
	iters: 300, epoch: 7 | loss: 0.1153409
	speed: 0.0258s/iter; left time: 109.8468s
	iters: 400, epoch: 7 | loss: 0.1304921
	speed: 0.0279s/iter; left time: 115.6943s
	iters: 500, epoch: 7 | loss: 0.1164396
	speed: 0.0273s/iter; left time: 110.6985s
	iters: 600, epoch: 7 | loss: 0.1152967
	speed: 0.0275s/iter; left time: 108.8129s
	iters: 700, epoch: 7 | loss: 0.1115638
	speed: 0.0287s/iter; left time: 110.7292s
	iters: 800, epoch: 7 | loss: 0.1148780
	speed: 0.0275s/iter; left time: 103.3638s
	iters: 900, epoch: 7 | loss: 0.1164315
	speed: 0.0276s/iter; left time: 100.9610s
	iters: 1000, epoch: 7 | loss: 0.1137266
	speed: 0.0286s/iter; left time: 101.5399s
	iters: 1100, epoch: 7 | loss: 0.1213152
	speed: 0.0269s/iter; left time: 92.9582s
Epoch: 7 cost time: 32.5192015171051
Epoch: 7, Steps: 1138 | Train Loss: 0.1173947 Vali Loss: 0.2175002 Test Loss: 0.2944218
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.1102010
	speed: 0.5650s/iter; left time: 1872.8155s
	iters: 200, epoch: 8 | loss: 0.1137942
	speed: 0.0252s/iter; left time: 80.9905s
	iters: 300, epoch: 8 | loss: 0.1192388
	speed: 0.0251s/iter; left time: 78.3280s
	iters: 400, epoch: 8 | loss: 0.1241668
	speed: 0.0253s/iter; left time: 76.2730s
	iters: 500, epoch: 8 | loss: 0.1213565
	speed: 0.0256s/iter; left time: 74.5471s
	iters: 600, epoch: 8 | loss: 0.1186770
	speed: 0.0248s/iter; left time: 69.8170s
	iters: 700, epoch: 8 | loss: 0.1222887
	speed: 0.0253s/iter; left time: 68.6525s
	iters: 800, epoch: 8 | loss: 0.1169435
	speed: 0.0262s/iter; left time: 68.6193s
	iters: 900, epoch: 8 | loss: 0.1159270
	speed: 0.0280s/iter; left time: 70.4475s
	iters: 1000, epoch: 8 | loss: 0.1108433
	speed: 0.0282s/iter; left time: 68.1573s
	iters: 1100, epoch: 8 | loss: 0.1140631
	speed: 0.0269s/iter; left time: 62.3141s
Epoch: 8 cost time: 30.98396325111389
Epoch: 8, Steps: 1138 | Train Loss: 0.1171193 Vali Loss: 0.2172854 Test Loss: 0.2942122
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.1153218
	speed: 0.5554s/iter; left time: 1209.0545s
	iters: 200, epoch: 9 | loss: 0.1218964
	speed: 0.0255s/iter; left time: 52.8815s
	iters: 300, epoch: 9 | loss: 0.1100452
	speed: 0.0258s/iter; left time: 50.9349s
	iters: 400, epoch: 9 | loss: 0.1185066
	speed: 0.0277s/iter; left time: 52.0181s
	iters: 500, epoch: 9 | loss: 0.1119018
	speed: 0.0275s/iter; left time: 48.8254s
	iters: 600, epoch: 9 | loss: 0.1055688
	speed: 0.0279s/iter; left time: 46.8311s
	iters: 700, epoch: 9 | loss: 0.1168427
	speed: 0.0278s/iter; left time: 43.8710s
	iters: 800, epoch: 9 | loss: 0.1213828
	speed: 0.0280s/iter; left time: 41.3633s
	iters: 900, epoch: 9 | loss: 0.1189709
	speed: 0.0279s/iter; left time: 38.3775s
	iters: 1000, epoch: 9 | loss: 0.1252749
	speed: 0.0276s/iter; left time: 35.1860s
	iters: 1100, epoch: 9 | loss: 0.1146289
	speed: 0.0273s/iter; left time: 32.1863s
Epoch: 9 cost time: 32.23674917221069
Epoch: 9, Steps: 1138 | Train Loss: 0.1169728 Vali Loss: 0.2173846 Test Loss: 0.2946214
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.1233704
	speed: 0.5705s/iter; left time: 592.7654s
	iters: 200, epoch: 10 | loss: 0.1160308
	speed: 0.0266s/iter; left time: 24.9793s
	iters: 300, epoch: 10 | loss: 0.1196902
	speed: 0.0284s/iter; left time: 23.8263s
	iters: 400, epoch: 10 | loss: 0.1108928
	speed: 0.0285s/iter; left time: 21.0429s
	iters: 500, epoch: 10 | loss: 0.1208215
	speed: 0.0287s/iter; left time: 18.3164s
	iters: 600, epoch: 10 | loss: 0.1201642
	speed: 0.0284s/iter; left time: 15.2819s
	iters: 700, epoch: 10 | loss: 0.1122937
	speed: 0.0287s/iter; left time: 12.5998s
	iters: 800, epoch: 10 | loss: 0.1176840
	speed: 0.0281s/iter; left time: 9.5366s
	iters: 900, epoch: 10 | loss: 0.1282316
	speed: 0.0285s/iter; left time: 6.8039s
	iters: 1000, epoch: 10 | loss: 0.1236929
	speed: 0.0282s/iter; left time: 3.9226s
	iters: 1100, epoch: 10 | loss: 0.1154547
	speed: 0.0278s/iter; left time: 1.0841s
Epoch: 10 cost time: 33.32600450515747
Epoch: 10, Steps: 1138 | Train Loss: 0.1168841 Vali Loss: 0.2175171 Test Loss: 0.2946118
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-07
>>>>>>>testing : ECL_96_96_22_emb_256_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (5165, 1, 96, 321) (5165, 1, 96, 321)
test shape: (5165, 96, 321) (5165, 96, 321)
mse:0.29339444637298584, mae:0.3771956264972687
Args in experiment:
Namespace(is_training=1, model_id='ECL_96_96_23_emb_256', model='xLSTM', data='custom', root_path='./data/electricity/', data_path='/input-data/electricity.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, enc_in=321, dec_in=7, c_out=321, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=32, patience=10, learning_rate=0.0001, des='test', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, use_norm=True, partial_start_index=0, hidden_size=512, num_layers=2, mark_enc_in=4, embedding_dim=256, weight_decay=0.0001, kernal_size=3, num_heads_xlstm=4, qkv_proj_blocksize=4, proj_factor=1.3, num_blocks=7, slstm_at=1, grad_clip_norm=0.5, d_state=16, d_conv=4, expand=2)
Use GPU: cuda:0
{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-L/usr/local/cuda/lib', '-lcublas'], 'extra_cflags': ['-DSLSTM_HIDDEN_SIZE=256', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__'], 'extra_cuda_cflags': ['-Xptxas="-v"', '-gencode', 'arch=compute_80,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=256', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__']}
Using /home/thetayne/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/thetayne/.cache/torch_extensions/py310_cu121/slstm_HS256BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0/build.ninja...
Building extension module slstm_HS256BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module slstm_HS256BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
>>>>>>>start training : ECL_96_96_23_emb_256_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 18221
val 2537
test 5165
	iters: 100, epoch: 1 | loss: 0.3366697
	speed: 0.1017s/iter; left time: 1726.3430s
	iters: 200, epoch: 1 | loss: 0.2491683
	speed: 0.0811s/iter; left time: 1368.3769s
	iters: 300, epoch: 1 | loss: 0.2116786
	speed: 0.0808s/iter; left time: 1355.4874s
	iters: 400, epoch: 1 | loss: 0.1884995
	speed: 0.0812s/iter; left time: 1353.7676s
	iters: 500, epoch: 1 | loss: 0.1655328
	speed: 0.0823s/iter; left time: 1364.4902s
Epoch: 1 cost time: 48.21705389022827
Epoch: 1, Steps: 569 | Train Loss: 0.2631944 Vali Loss: 0.2314952 Test Loss: 0.3251433
Validation loss decreased (inf --> 0.231495).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.1596128
	speed: 1.0467s/iter; left time: 17168.1270s
	iters: 200, epoch: 2 | loss: 0.1470166
	speed: 0.0818s/iter; left time: 1332.8465s
	iters: 300, epoch: 2 | loss: 0.1393407
	speed: 0.0824s/iter; left time: 1334.4079s
	iters: 400, epoch: 2 | loss: 0.1424232
	speed: 0.0801s/iter; left time: 1289.9046s
	iters: 500, epoch: 2 | loss: 0.1288193
	speed: 0.0801s/iter; left time: 1281.3264s
Epoch: 2 cost time: 47.74784469604492
Epoch: 2, Steps: 569 | Train Loss: 0.1398438 Vali Loss: 0.2201380 Test Loss: 0.3205983
Validation loss decreased (0.231495 --> 0.220138).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.1218036
	speed: 1.0277s/iter; left time: 16270.9443s
	iters: 200, epoch: 3 | loss: 0.1176251
	speed: 0.0820s/iter; left time: 1289.4143s
	iters: 300, epoch: 3 | loss: 0.1080951
	speed: 0.0816s/iter; left time: 1275.5580s
	iters: 400, epoch: 3 | loss: 0.1164303
	speed: 0.0825s/iter; left time: 1281.6111s
	iters: 500, epoch: 3 | loss: 0.1172558
	speed: 0.0827s/iter; left time: 1275.7067s
Epoch: 3 cost time: 48.6357855796814
Epoch: 3, Steps: 569 | Train Loss: 0.1147708 Vali Loss: 0.2213730 Test Loss: 0.3236597
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.1006586
	speed: 1.0728s/iter; left time: 16375.6889s
	iters: 200, epoch: 4 | loss: 0.1025913
	speed: 0.0814s/iter; left time: 1234.8465s
	iters: 300, epoch: 4 | loss: 0.1068349
	speed: 0.0802s/iter; left time: 1207.5203s
	iters: 400, epoch: 4 | loss: 0.1045499
	speed: 0.0801s/iter; left time: 1197.9772s
	iters: 500, epoch: 4 | loss: 0.1084519
	speed: 0.0781s/iter; left time: 1160.3354s
Epoch: 4 cost time: 47.40924906730652
Epoch: 4, Steps: 569 | Train Loss: 0.1064704 Vali Loss: 0.2181152 Test Loss: 0.3180964
Validation loss decreased (0.220138 --> 0.218115).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.1081348
	speed: 1.0981s/iter; left time: 16136.3260s
	iters: 200, epoch: 5 | loss: 0.1062400
	speed: 0.0810s/iter; left time: 1181.7366s
	iters: 300, epoch: 5 | loss: 0.0990085
	speed: 0.0814s/iter; left time: 1179.9031s
	iters: 400, epoch: 5 | loss: 0.1114799
	speed: 0.0814s/iter; left time: 1171.2615s
	iters: 500, epoch: 5 | loss: 0.1026810
	speed: 0.0825s/iter; left time: 1179.9010s
Epoch: 5 cost time: 48.067206382751465
Epoch: 5, Steps: 569 | Train Loss: 0.1026121 Vali Loss: 0.2219937 Test Loss: 0.3209981
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.1060208
	speed: 1.0454s/iter; left time: 14767.6516s
	iters: 200, epoch: 6 | loss: 0.1073622
	speed: 0.0816s/iter; left time: 1145.0701s
	iters: 300, epoch: 6 | loss: 0.1006246
	speed: 0.0816s/iter; left time: 1136.9193s
	iters: 400, epoch: 6 | loss: 0.1025683
	speed: 0.0813s/iter; left time: 1124.0325s
	iters: 500, epoch: 6 | loss: 0.1018567
	speed: 0.0813s/iter; left time: 1115.2518s
Epoch: 6 cost time: 47.92782926559448
Epoch: 6, Steps: 569 | Train Loss: 0.1006172 Vali Loss: 0.2230711 Test Loss: 0.3212027
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.0954282
	speed: 1.0720s/iter; left time: 14533.5041s
	iters: 200, epoch: 7 | loss: 0.1035429
	speed: 0.0819s/iter; left time: 1102.3637s
	iters: 300, epoch: 7 | loss: 0.1042562
	speed: 0.0807s/iter; left time: 1077.5464s
	iters: 400, epoch: 7 | loss: 0.0959815
	speed: 0.0805s/iter; left time: 1067.4448s
	iters: 500, epoch: 7 | loss: 0.0964613
	speed: 0.0830s/iter; left time: 1092.1306s
Epoch: 7 cost time: 47.92607355117798
Epoch: 7, Steps: 569 | Train Loss: 0.0995664 Vali Loss: 0.2228404 Test Loss: 0.3207841
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.1029520
	speed: 1.0672s/iter; left time: 13860.7062s
	iters: 200, epoch: 8 | loss: 0.0931931
	speed: 0.0829s/iter; left time: 1068.1125s
	iters: 300, epoch: 8 | loss: 0.0943663
	speed: 0.0817s/iter; left time: 1045.3575s
	iters: 400, epoch: 8 | loss: 0.0994974
	speed: 0.0817s/iter; left time: 1036.4701s
	iters: 500, epoch: 8 | loss: 0.1006711
	speed: 0.0824s/iter; left time: 1037.0628s
Epoch: 8 cost time: 48.552146911621094
Epoch: 8, Steps: 569 | Train Loss: 0.0990161 Vali Loss: 0.2227964 Test Loss: 0.3200929
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.1025229
	speed: 1.0594s/iter; left time: 13156.1657s
	iters: 200, epoch: 9 | loss: 0.0953250
	speed: 0.0816s/iter; left time: 1005.3281s
	iters: 300, epoch: 9 | loss: 0.1049053
	speed: 0.0817s/iter; left time: 997.8984s
	iters: 400, epoch: 9 | loss: 0.0989260
	speed: 0.0814s/iter; left time: 986.4059s
	iters: 500, epoch: 9 | loss: 0.0946559
	speed: 0.0787s/iter; left time: 945.3479s
Epoch: 9 cost time: 47.67813801765442
Epoch: 9, Steps: 569 | Train Loss: 0.0987114 Vali Loss: 0.2226596 Test Loss: 0.3202707
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.0969348
	speed: 1.0610s/iter; left time: 12573.2778s
	iters: 200, epoch: 10 | loss: 0.0958867
	speed: 0.0821s/iter; left time: 964.4922s
	iters: 300, epoch: 10 | loss: 0.0975371
	speed: 0.0802s/iter; left time: 934.0998s
	iters: 400, epoch: 10 | loss: 0.0951662
	speed: 0.0806s/iter; left time: 930.9278s
	iters: 500, epoch: 10 | loss: 0.0954982
	speed: 0.0814s/iter; left time: 931.8486s
Epoch: 10 cost time: 47.503992319107056
Epoch: 10, Steps: 569 | Train Loss: 0.0985474 Vali Loss: 0.2231744 Test Loss: 0.3206261
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.0915486
	speed: 1.0616s/iter; left time: 11975.9763s
	iters: 200, epoch: 11 | loss: 0.0964515
	speed: 0.0819s/iter; left time: 915.9776s
	iters: 300, epoch: 11 | loss: 0.0992574
	speed: 0.0808s/iter; left time: 895.8622s
	iters: 400, epoch: 11 | loss: 0.0943267
	speed: 0.0816s/iter; left time: 896.1673s
	iters: 500, epoch: 11 | loss: 0.0958050
	speed: 0.0816s/iter; left time: 887.3744s
Epoch: 11 cost time: 48.025495529174805
Epoch: 11, Steps: 569 | Train Loss: 0.0984597 Vali Loss: 0.2231094 Test Loss: 0.3207305
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.0969950
	speed: 1.0713s/iter; left time: 11476.1586s
	iters: 200, epoch: 12 | loss: 0.0948046
	speed: 0.0821s/iter; left time: 871.6942s
	iters: 300, epoch: 12 | loss: 0.0929440
	speed: 0.0804s/iter; left time: 845.0043s
	iters: 400, epoch: 12 | loss: 0.1015722
	speed: 0.0825s/iter; left time: 858.8072s
	iters: 500, epoch: 12 | loss: 0.0992985
	speed: 0.0818s/iter; left time: 843.1789s
Epoch: 12 cost time: 48.19377398490906
Epoch: 12, Steps: 569 | Train Loss: 0.0984290 Vali Loss: 0.2231172 Test Loss: 0.3207637
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.0976949
	speed: 1.0496s/iter; left time: 10645.6582s
	iters: 200, epoch: 13 | loss: 0.1021636
	speed: 0.0826s/iter; left time: 829.8876s
	iters: 300, epoch: 13 | loss: 0.0994096
	speed: 0.0809s/iter; left time: 804.1532s
	iters: 400, epoch: 13 | loss: 0.1008846
	speed: 0.0815s/iter; left time: 802.4902s
	iters: 500, epoch: 13 | loss: 0.0960446
	speed: 0.0813s/iter; left time: 792.4210s
Epoch: 13 cost time: 47.986395597457886
Epoch: 13, Steps: 569 | Train Loss: 0.0984008 Vali Loss: 0.2232760 Test Loss: 0.3208247
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.1015707
	speed: 1.0374s/iter; left time: 9932.2289s
	iters: 200, epoch: 14 | loss: 0.1036630
	speed: 0.0816s/iter; left time: 772.6105s
	iters: 300, epoch: 14 | loss: 0.0972551
	speed: 0.0830s/iter; left time: 777.6369s
	iters: 400, epoch: 14 | loss: 0.1040358
	speed: 0.0826s/iter; left time: 766.3683s
	iters: 500, epoch: 14 | loss: 0.1042193
	speed: 0.0820s/iter; left time: 752.6550s
Epoch: 14 cost time: 48.43337035179138
Epoch: 14, Steps: 569 | Train Loss: 0.0983944 Vali Loss: 0.2231526 Test Loss: 0.3207837
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : ECL_96_96_23_emb_256_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (5165, 1, 96, 321) (5165, 1, 96, 321)
test shape: (5165, 96, 321) (5165, 96, 321)
mse:0.31809642910957336, mae:0.39533594250679016
Args in experiment:
Namespace(is_training=1, model_id='ECL_96_96_24_emb_256', model='xLSTM', data='custom', root_path='./data/electricity/', data_path='/input-data/electricity.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, enc_in=321, dec_in=7, c_out=321, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.5, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=10, batch_size=32, patience=10, learning_rate=0.0005, des='test', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, use_norm=True, partial_start_index=0, hidden_size=512, num_layers=2, mark_enc_in=4, embedding_dim=256, weight_decay=0.0001, kernal_size=7, num_heads_xlstm=4, qkv_proj_blocksize=8, proj_factor=1.3, num_blocks=7, slstm_at=1, grad_clip_norm=5.0, d_state=16, d_conv=4, expand=2)
Use GPU: cuda:0
{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-L/usr/local/cuda/lib', '-lcublas'], 'extra_cflags': ['-DSLSTM_HIDDEN_SIZE=256', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__'], 'extra_cuda_cflags': ['-Xptxas="-v"', '-gencode', 'arch=compute_80,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=256', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__']}
Using /home/thetayne/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/thetayne/.cache/torch_extensions/py310_cu121/slstm_HS256BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0/build.ninja...
Building extension module slstm_HS256BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module slstm_HS256BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
>>>>>>>start training : ECL_96_96_24_emb_256_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 18221
val 2537
test 5165
	iters: 100, epoch: 1 | loss: 0.2963741
	speed: 0.0923s/iter; left time: 516.3231s
	iters: 200, epoch: 1 | loss: 0.2240689
	speed: 0.0726s/iter; left time: 398.6126s
	iters: 300, epoch: 1 | loss: 0.1767018
	speed: 0.0700s/iter; left time: 377.4391s
	iters: 400, epoch: 1 | loss: 0.1756325
	speed: 0.0702s/iter; left time: 371.1735s
	iters: 500, epoch: 1 | loss: 0.1737648
	speed: 0.0699s/iter; left time: 362.8648s
Epoch: 1 cost time: 41.98461842536926
Epoch: 1, Steps: 569 | Train Loss: 0.2496089 Vali Loss: 0.2014817 Test Loss: 0.2805966
Validation loss decreased (inf --> 0.201482).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.1629722
	speed: 1.0277s/iter; left time: 5160.9011s
	iters: 200, epoch: 2 | loss: 0.1518016
	speed: 0.0708s/iter; left time: 348.4435s
	iters: 300, epoch: 2 | loss: 0.1493924
	speed: 0.0703s/iter; left time: 339.1177s
	iters: 400, epoch: 2 | loss: 0.1364765
	speed: 0.0694s/iter; left time: 327.8214s
	iters: 500, epoch: 2 | loss: 0.1440220
	speed: 0.0688s/iter; left time: 317.9928s
Epoch: 2 cost time: 41.196505546569824
Epoch: 2, Steps: 569 | Train Loss: 0.1516905 Vali Loss: 0.2112019 Test Loss: 0.2697535
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.1377519
	speed: 1.0195s/iter; left time: 4539.9250s
	iters: 200, epoch: 3 | loss: 0.1410694
	speed: 0.0688s/iter; left time: 299.3781s
	iters: 300, epoch: 3 | loss: 0.1539012
	speed: 0.0703s/iter; left time: 298.7990s
	iters: 400, epoch: 3 | loss: 0.1406349
	speed: 0.0692s/iter; left time: 287.4549s
	iters: 500, epoch: 3 | loss: 0.1335604
	speed: 0.0694s/iter; left time: 281.3165s
Epoch: 3 cost time: 40.961731910705566
Epoch: 3, Steps: 569 | Train Loss: 0.1411057 Vali Loss: 0.2078367 Test Loss: 0.2727755
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.1404669
	speed: 1.0234s/iter; left time: 3974.8951s
	iters: 200, epoch: 4 | loss: 0.1363363
	speed: 0.0698s/iter; left time: 264.1355s
	iters: 300, epoch: 4 | loss: 0.1389683
	speed: 0.0705s/iter; left time: 259.5823s
	iters: 400, epoch: 4 | loss: 0.1361414
	speed: 0.0698s/iter; left time: 250.2891s
	iters: 500, epoch: 4 | loss: 0.1382890
	speed: 0.0700s/iter; left time: 243.8044s
Epoch: 4 cost time: 41.430684328079224
Epoch: 4, Steps: 569 | Train Loss: 0.1378631 Vali Loss: 0.2222958 Test Loss: 0.2701746
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.1314255
	speed: 1.0337s/iter; left time: 3426.6841s
	iters: 200, epoch: 5 | loss: 0.1395115
	speed: 0.0700s/iter; left time: 225.1971s
	iters: 300, epoch: 5 | loss: 0.1290254
	speed: 0.0701s/iter; left time: 218.2764s
	iters: 400, epoch: 5 | loss: 0.1331584
	speed: 0.0707s/iter; left time: 213.0770s
	iters: 500, epoch: 5 | loss: 0.1409471
	speed: 0.0706s/iter; left time: 205.7695s
Epoch: 5 cost time: 41.734495639801025
Epoch: 5, Steps: 569 | Train Loss: 0.1361714 Vali Loss: 0.2198618 Test Loss: 0.2736990
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.1341024
	speed: 1.0458s/iter; left time: 2871.8713s
	iters: 200, epoch: 6 | loss: 0.1409260
	speed: 0.0696s/iter; left time: 184.2376s
	iters: 300, epoch: 6 | loss: 0.1336925
	speed: 0.0704s/iter; left time: 179.1533s
	iters: 400, epoch: 6 | loss: 0.1379485
	speed: 0.0696s/iter; left time: 170.3130s
	iters: 500, epoch: 6 | loss: 0.1385155
	speed: 0.0704s/iter; left time: 165.2444s
Epoch: 6 cost time: 41.239757776260376
Epoch: 6, Steps: 569 | Train Loss: 0.1352180 Vali Loss: 0.2232234 Test Loss: 0.2743991
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.1390627
	speed: 1.0405s/iter; left time: 2265.2300s
	iters: 200, epoch: 7 | loss: 0.1322322
	speed: 0.0703s/iter; left time: 145.9697s
	iters: 300, epoch: 7 | loss: 0.1280386
	speed: 0.0704s/iter; left time: 139.1915s
	iters: 400, epoch: 7 | loss: 0.1326234
	speed: 0.0702s/iter; left time: 131.7362s
	iters: 500, epoch: 7 | loss: 0.1304473
	speed: 0.0713s/iter; left time: 126.6700s
Epoch: 7 cost time: 41.703328132629395
Epoch: 7, Steps: 569 | Train Loss: 0.1347385 Vali Loss: 0.2219713 Test Loss: 0.2745135
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.1282510
	speed: 1.0224s/iter; left time: 1644.0320s
	iters: 200, epoch: 8 | loss: 0.1344032
	speed: 0.0698s/iter; left time: 105.3211s
	iters: 300, epoch: 8 | loss: 0.1361056
	speed: 0.0701s/iter; left time: 98.6637s
	iters: 400, epoch: 8 | loss: 0.1352384
	speed: 0.0693s/iter; left time: 90.6321s
	iters: 500, epoch: 8 | loss: 0.1339431
	speed: 0.0711s/iter; left time: 85.8321s
Epoch: 8 cost time: 41.48058366775513
Epoch: 8, Steps: 569 | Train Loss: 0.1344881 Vali Loss: 0.2237159 Test Loss: 0.2750750
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.1350176
	speed: 1.0594s/iter; left time: 1100.6811s
	iters: 200, epoch: 9 | loss: 0.1346475
	speed: 0.0702s/iter; left time: 65.9087s
	iters: 300, epoch: 9 | loss: 0.1334561
	speed: 0.0690s/iter; left time: 57.8822s
	iters: 400, epoch: 9 | loss: 0.1348953
	speed: 0.0694s/iter; left time: 51.2833s
	iters: 500, epoch: 9 | loss: 0.1377169
	speed: 0.0708s/iter; left time: 45.2413s
Epoch: 9 cost time: 41.25387382507324
Epoch: 9, Steps: 569 | Train Loss: 0.1343315 Vali Loss: 0.2224832 Test Loss: 0.2747902
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.1308656
	speed: 1.0135s/iter; left time: 476.3613s
	iters: 200, epoch: 10 | loss: 0.1420882
	speed: 0.0700s/iter; left time: 25.9174s
	iters: 300, epoch: 10 | loss: 0.1406344
	speed: 0.0699s/iter; left time: 18.8861s
	iters: 400, epoch: 10 | loss: 0.1298558
	speed: 0.0700s/iter; left time: 11.8983s
	iters: 500, epoch: 10 | loss: 0.1334339
	speed: 0.0709s/iter; left time: 4.9605s
Epoch: 10 cost time: 41.54897427558899
Epoch: 10, Steps: 569 | Train Loss: 0.1342822 Vali Loss: 0.2223214 Test Loss: 0.2744549
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-07
>>>>>>>testing : ECL_96_96_24_emb_256_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (5165, 1, 96, 321) (5165, 1, 96, 321)
test shape: (5165, 96, 321) (5165, 96, 321)
mse:0.28059595823287964, mae:0.36869165301322937
Args in experiment:
Namespace(is_training=1, model_id='ECL_96_96_25_emb_256', model='xLSTM', data='custom', root_path='./data/electricity/', data_path='/input-data/electricity.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, enc_in=321, dec_in=7, c_out=321, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.5, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=10, batch_size=16, patience=10, learning_rate=0.001, des='test', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, use_norm=True, partial_start_index=0, hidden_size=512, num_layers=2, mark_enc_in=4, embedding_dim=256, weight_decay=0.0001, kernal_size=7, num_heads_xlstm=2, qkv_proj_blocksize=4, proj_factor=1.3, num_blocks=3, slstm_at=1, grad_clip_norm=5.0, d_state=16, d_conv=4, expand=2)
Use GPU: cuda:0
{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-L/usr/local/cuda/lib', '-lcublas'], 'extra_cflags': ['-DSLSTM_HIDDEN_SIZE=256', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=2', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__'], 'extra_cuda_cflags': ['-Xptxas="-v"', '-gencode', 'arch=compute_80,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=256', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=2', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__']}
Using /home/thetayne/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Creating extension directory /home/thetayne/.cache/torch_extensions/py310_cu121/slstm_HS256BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/thetayne/.cache/torch_extensions/py310_cu121/slstm_HS256BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0/build.ninja...
Building extension module slstm_HS256BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[1/8] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output cuda_error.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS256BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=256 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=2 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/util/cuda_error.cu -o cuda_error.cuda.o 
ptxas info    : 0 bytes gmem
[2/8] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output slstm_forward.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS256BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=256 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=2 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/cuda/slstm_forward.cu -o slstm_forward.cuda.o 
ptxas info    : 0 bytes gmem
[3/8] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output slstm_backward_cut.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS256BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=256 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=2 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/cuda/slstm_backward_cut.cu -o slstm_backward_cut.cuda.o 
ptxas info    : 0 bytes gmem
ptxas info    : Compiling entry function '_ZN54_GLOBAL__N__2085b59d_21_slstm_backward_cut_cu_1c2c4d0129gradientBiasAggregationKernelEjjjjjjPK13__nv_bfloat16S2_Pf' for 'sm_80'
ptxas info    : Function properties for _ZN54_GLOBAL__N__2085b59d_21_slstm_backward_cut_cu_1c2c4d0129gradientBiasAggregationKernelEjjjjjjPK13__nv_bfloat16S2_Pf
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 32 registers, 400 bytes cmem[0]
[4/8] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output slstm_pointwise.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS256BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=256 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=2 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/cuda/slstm_pointwise.cu -o slstm_pointwise.cuda.o 
ptxas info    : 0 bytes gmem
ptxas info    : Compiling entry function '_ZN5slstm21SLSTMPointwiseForwardILb0EEEviiiPK13__nv_bfloat16S3_PKfS3_jPS1_jS6_S6_' for 'sm_80'
ptxas info    : Function properties for _ZN5slstm21SLSTMPointwiseForwardILb0EEEviiiPK13__nv_bfloat16S3_PKfS3_jPS1_jS6_S6_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 32 registers, 440 bytes cmem[0]
ptxas info    : Compiling entry function '_ZN5slstm21SLSTMPointwiseForwardILb1EEEviiiPK13__nv_bfloat16S3_PKfS3_jPS1_jS6_S6_' for 'sm_80'
ptxas info    : Function properties for _ZN5slstm21SLSTMPointwiseForwardILb1EEEviiiPK13__nv_bfloat16S3_PKfS3_jPS1_jS6_S6_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 32 registers, 440 bytes cmem[0]
ptxas info    : Compiling entry function '_ZN5slstm22SLSTMPointwiseBackwardEiiiPK13__nv_bfloat16jS2_S2_PKfS2_jS2_jPS0_jS5_S5_S5_' for 'sm_80'
ptxas info    : Function properties for _ZN5slstm22SLSTMPointwiseBackwardEiiiPK13__nv_bfloat16jS2_S2_PKfS2_jS2_jPS0_jS5_S5_S5_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 32 registers, 480 bytes cmem[0]
[5/8] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output slstm_backward.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS256BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=256 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=2 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/cuda/slstm_backward.cu -o slstm_backward.cuda.o 
ptxas info    : 0 bytes gmem
ptxas info    : Compiling entry function '_ZN50_GLOBAL__N__d983f13f_17_slstm_backward_cu_3639fa5e29gradientBiasAggregationKernelEjjjjjjPK13__nv_bfloat16S2_Pf' for 'sm_80'
ptxas info    : Function properties for _ZN50_GLOBAL__N__d983f13f_17_slstm_backward_cu_3639fa5e29gradientBiasAggregationKernelEjjjjjjPK13__nv_bfloat16S2_Pf
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 32 registers, 400 bytes cmem[0]
[6/8] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output blas.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS256BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=256 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=2 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/util/blas.cu -o blas.cuda.o 
ptxas info    : 0 bytes gmem
ptxas info    : Compiling entry function '_Z10initKernelI13__nv_bfloat16EvPT_iS1_' for 'sm_80'
ptxas info    : Function properties for _Z10initKernelI13__nv_bfloat16EvPT_iS1_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 8 registers, 366 bytes cmem[0]
ptxas info    : Compiling entry function '_Z10initKernelI6__halfEvPT_iS1_' for 'sm_80'
ptxas info    : Function properties for _Z10initKernelI6__halfEvPT_iS1_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 8 registers, 366 bytes cmem[0]
ptxas info    : Compiling entry function '_Z10initKernelIfEvPT_iS0_' for 'sm_80'
ptxas info    : Function properties for _Z10initKernelIfEvPT_iS0_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 8 registers, 368 bytes cmem[0]
ptxas info    : Compiling entry function '_Z10initKernelIdEvPT_iS0_' for 'sm_80'
ptxas info    : Function properties for _Z10initKernelIdEvPT_iS0_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 8 registers, 376 bytes cmem[0]
[7/8] c++ -MMD -MF slstm.o.d -DTORCH_EXTENSION_NAME=slstm_HS256BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -DSLSTM_HIDDEN_SIZE=256 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=2 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/cuda/slstm.cc -o slstm.o 
[8/8] c++ slstm.o slstm_forward.cuda.o slstm_backward.cuda.o slstm_backward_cut.cuda.o slstm_pointwise.cuda.o blas.cuda.o cuda_error.cuda.o -shared -L/usr/local/cuda/lib -lcublas -L/usr/local/lib/python3.10/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o slstm_HS256BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0.so
Loading extension module slstm_HS256BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
>>>>>>>start training : ECL_96_96_25_emb_256_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 18221
val 2537
test 5165
	iters: 100, epoch: 1 | loss: 0.2585647
	speed: 0.0557s/iter; left time: 628.7401s
	iters: 200, epoch: 1 | loss: 0.2432657
	speed: 0.0359s/iter; left time: 400.9018s
	iters: 300, epoch: 1 | loss: 0.2312210
	speed: 0.0354s/iter; left time: 392.7392s
	iters: 400, epoch: 1 | loss: 0.1823549
	speed: 0.0358s/iter; left time: 392.5995s
	iters: 500, epoch: 1 | loss: 0.1634462
	speed: 0.0356s/iter; left time: 387.8349s
	iters: 600, epoch: 1 | loss: 0.1523448
	speed: 0.0349s/iter; left time: 376.1561s
	iters: 700, epoch: 1 | loss: 0.1671713
	speed: 0.0345s/iter; left time: 368.8658s
	iters: 800, epoch: 1 | loss: 0.1662066
	speed: 0.0351s/iter; left time: 371.3778s
	iters: 900, epoch: 1 | loss: 0.1504994
	speed: 0.0335s/iter; left time: 351.2762s
	iters: 1000, epoch: 1 | loss: 0.1636949
	speed: 0.0358s/iter; left time: 371.2855s
	iters: 1100, epoch: 1 | loss: 0.1646829
	speed: 0.0350s/iter; left time: 359.7102s
Epoch: 1 cost time: 41.93204593658447
Epoch: 1, Steps: 1138 | Train Loss: 0.1972055 Vali Loss: 0.2030557 Test Loss: 0.2638516
Validation loss decreased (inf --> 0.203056).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.1622750
	speed: 0.6057s/iter; left time: 6143.2334s
	iters: 200, epoch: 2 | loss: 0.1613058
	speed: 0.0355s/iter; left time: 356.0343s
	iters: 300, epoch: 2 | loss: 0.1477022
	speed: 0.0349s/iter; left time: 346.5155s
	iters: 400, epoch: 2 | loss: 0.1498062
	speed: 0.0356s/iter; left time: 350.0364s
	iters: 500, epoch: 2 | loss: 0.1519236
	speed: 0.0341s/iter; left time: 332.4307s
	iters: 600, epoch: 2 | loss: 0.1349468
	speed: 0.0351s/iter; left time: 338.5962s
	iters: 700, epoch: 2 | loss: 0.1628324
	speed: 0.0350s/iter; left time: 333.9485s
	iters: 800, epoch: 2 | loss: 0.1470655
	speed: 0.0346s/iter; left time: 327.0636s
	iters: 900, epoch: 2 | loss: 0.1389922
	speed: 0.0347s/iter; left time: 324.3810s
	iters: 1000, epoch: 2 | loss: 0.1530884
	speed: 0.0341s/iter; left time: 315.4387s
	iters: 1100, epoch: 2 | loss: 0.1632598
	speed: 0.0350s/iter; left time: 320.3060s
Epoch: 2 cost time: 40.768205881118774
Epoch: 2, Steps: 1138 | Train Loss: 0.1503007 Vali Loss: 0.2129796 Test Loss: 0.2678568
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.1549991
	speed: 0.6090s/iter; left time: 5484.4575s
	iters: 200, epoch: 3 | loss: 0.1495811
	speed: 0.0320s/iter; left time: 285.2586s
	iters: 300, epoch: 3 | loss: 0.1333061
	speed: 0.0334s/iter; left time: 293.8366s
	iters: 400, epoch: 3 | loss: 0.1440028
	speed: 0.0364s/iter; left time: 316.4762s
	iters: 500, epoch: 3 | loss: 0.1449327
	speed: 0.0355s/iter; left time: 305.3560s
	iters: 600, epoch: 3 | loss: 0.1398493
	speed: 0.0358s/iter; left time: 304.7789s
	iters: 700, epoch: 3 | loss: 0.1448243
	speed: 0.0347s/iter; left time: 291.3159s
	iters: 800, epoch: 3 | loss: 0.1496296
	speed: 0.0358s/iter; left time: 297.5229s
	iters: 900, epoch: 3 | loss: 0.1385617
	speed: 0.0347s/iter; left time: 284.4148s
	iters: 1000, epoch: 3 | loss: 0.1419367
	speed: 0.0356s/iter; left time: 288.3737s
	iters: 1100, epoch: 3 | loss: 0.1389109
	speed: 0.0356s/iter; left time: 285.0465s
Epoch: 3 cost time: 41.35152888298035
Epoch: 3, Steps: 1138 | Train Loss: 0.1409822 Vali Loss: 0.2291945 Test Loss: 0.2709895
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.1389462
	speed: 0.6542s/iter; left time: 5146.8143s
	iters: 200, epoch: 4 | loss: 0.1447835
	speed: 0.0331s/iter; left time: 257.3217s
	iters: 300, epoch: 4 | loss: 0.1393973
	speed: 0.0350s/iter; left time: 268.5534s
	iters: 400, epoch: 4 | loss: 0.1377957
	speed: 0.0347s/iter; left time: 262.6838s
	iters: 500, epoch: 4 | loss: 0.1367988
	speed: 0.0343s/iter; left time: 255.9343s
	iters: 600, epoch: 4 | loss: 0.1396359
	speed: 0.0348s/iter; left time: 256.3884s
	iters: 700, epoch: 4 | loss: 0.1283408
	speed: 0.0354s/iter; left time: 257.3249s
	iters: 800, epoch: 4 | loss: 0.1337569
	speed: 0.0353s/iter; left time: 252.8344s
	iters: 900, epoch: 4 | loss: 0.1351337
	speed: 0.0355s/iter; left time: 251.1227s
	iters: 1000, epoch: 4 | loss: 0.1363761
	speed: 0.0355s/iter; left time: 247.0948s
	iters: 1100, epoch: 4 | loss: 0.1512647
	speed: 0.0363s/iter; left time: 249.1499s
Epoch: 4 cost time: 41.38212251663208
Epoch: 4, Steps: 1138 | Train Loss: 0.1371748 Vali Loss: 0.2283995 Test Loss: 0.2791028
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.1318183
	speed: 0.6215s/iter; left time: 4181.8663s
	iters: 200, epoch: 5 | loss: 0.1473851
	speed: 0.0348s/iter; left time: 230.8496s
	iters: 300, epoch: 5 | loss: 0.1348312
	speed: 0.0352s/iter; left time: 229.7183s
	iters: 400, epoch: 5 | loss: 0.1322614
	speed: 0.0357s/iter; left time: 229.4141s
	iters: 500, epoch: 5 | loss: 0.1322553
	speed: 0.0361s/iter; left time: 228.5696s
	iters: 600, epoch: 5 | loss: 0.1338915
	speed: 0.0356s/iter; left time: 221.6723s
	iters: 700, epoch: 5 | loss: 0.1258817
	speed: 0.0354s/iter; left time: 217.2402s
	iters: 800, epoch: 5 | loss: 0.1322453
	speed: 0.0344s/iter; left time: 207.2681s
	iters: 900, epoch: 5 | loss: 0.1277250
	speed: 0.0349s/iter; left time: 207.0511s
	iters: 1000, epoch: 5 | loss: 0.1349197
	speed: 0.0350s/iter; left time: 204.0289s
	iters: 1100, epoch: 5 | loss: 0.1345672
	speed: 0.0358s/iter; left time: 205.3038s
Epoch: 5 cost time: 41.423128843307495
Epoch: 5, Steps: 1138 | Train Loss: 0.1351315 Vali Loss: 0.2298971 Test Loss: 0.2732879
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.1451134
	speed: 0.6125s/iter; left time: 3424.2154s
	iters: 200, epoch: 6 | loss: 0.1355300
	speed: 0.0350s/iter; left time: 191.9756s
	iters: 300, epoch: 6 | loss: 0.1243042
	speed: 0.0349s/iter; left time: 188.0916s
	iters: 400, epoch: 6 | loss: 0.1311036
	speed: 0.0354s/iter; left time: 187.4170s
	iters: 500, epoch: 6 | loss: 0.1340925
	speed: 0.0348s/iter; left time: 180.7757s
	iters: 600, epoch: 6 | loss: 0.1288325
	speed: 0.0353s/iter; left time: 179.9264s
	iters: 700, epoch: 6 | loss: 0.1461683
	speed: 0.0350s/iter; left time: 174.4543s
	iters: 800, epoch: 6 | loss: 0.1270257
	speed: 0.0351s/iter; left time: 171.7852s
	iters: 900, epoch: 6 | loss: 0.1381012
	speed: 0.0346s/iter; left time: 165.5405s
	iters: 1000, epoch: 6 | loss: 0.1423611
	speed: 0.0348s/iter; left time: 163.4004s
	iters: 1100, epoch: 6 | loss: 0.1279938
	speed: 0.0346s/iter; left time: 158.8910s
Epoch: 6 cost time: 41.09685969352722
Epoch: 6, Steps: 1138 | Train Loss: 0.1339523 Vali Loss: 0.2336175 Test Loss: 0.2767436
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.1358965
	speed: 0.6067s/iter; left time: 2701.8132s
	iters: 200, epoch: 7 | loss: 0.1333997
	speed: 0.0350s/iter; left time: 152.4815s
	iters: 300, epoch: 7 | loss: 0.1221886
	speed: 0.0348s/iter; left time: 148.1537s
	iters: 400, epoch: 7 | loss: 0.1316262
	speed: 0.0350s/iter; left time: 145.3861s
	iters: 500, epoch: 7 | loss: 0.1230331
	speed: 0.0356s/iter; left time: 144.4319s
	iters: 600, epoch: 7 | loss: 0.1294551
	speed: 0.0348s/iter; left time: 137.3809s
	iters: 700, epoch: 7 | loss: 0.1373442
	speed: 0.0344s/iter; left time: 132.6166s
	iters: 800, epoch: 7 | loss: 0.1261749
	speed: 0.0356s/iter; left time: 133.6965s
	iters: 900, epoch: 7 | loss: 0.1473551
	speed: 0.0346s/iter; left time: 126.4360s
	iters: 1000, epoch: 7 | loss: 0.1444004
	speed: 0.0351s/iter; left time: 124.6280s
	iters: 1100, epoch: 7 | loss: 0.1362951
	speed: 0.0350s/iter; left time: 121.0118s
Epoch: 7 cost time: 41.620229959487915
Epoch: 7, Steps: 1138 | Train Loss: 0.1333982 Vali Loss: 0.2363664 Test Loss: 0.2783587
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.1277943
	speed: 0.6049s/iter; left time: 2005.3051s
	iters: 200, epoch: 8 | loss: 0.1177944
	speed: 0.0347s/iter; left time: 111.6913s
	iters: 300, epoch: 8 | loss: 0.1290670
	speed: 0.0356s/iter; left time: 111.0150s
	iters: 400, epoch: 8 | loss: 0.1363869
	speed: 0.0357s/iter; left time: 107.5972s
	iters: 500, epoch: 8 | loss: 0.1398069
	speed: 0.0357s/iter; left time: 104.0109s
	iters: 600, epoch: 8 | loss: 0.1445180
	speed: 0.0356s/iter; left time: 100.2898s
	iters: 700, epoch: 8 | loss: 0.1492245
	speed: 0.0351s/iter; left time: 95.4088s
	iters: 800, epoch: 8 | loss: 0.1293512
	speed: 0.0350s/iter; left time: 91.6460s
	iters: 900, epoch: 8 | loss: 0.1359781
	speed: 0.0348s/iter; left time: 87.6361s
	iters: 1000, epoch: 8 | loss: 0.1280804
	speed: 0.0364s/iter; left time: 87.8789s
	iters: 1100, epoch: 8 | loss: 0.1278594
	speed: 0.0353s/iter; left time: 81.6519s
Epoch: 8 cost time: 41.750296115875244
Epoch: 8, Steps: 1138 | Train Loss: 0.1330337 Vali Loss: 0.2354828 Test Loss: 0.2767408
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 0.1476253
	speed: 0.6246s/iter; left time: 1359.8544s
	iters: 200, epoch: 9 | loss: 0.1514877
	speed: 0.0350s/iter; left time: 72.6660s
	iters: 300, epoch: 9 | loss: 0.1381377
	speed: 0.0349s/iter; left time: 68.9339s
	iters: 400, epoch: 9 | loss: 0.1335835
	speed: 0.0349s/iter; left time: 65.4597s
	iters: 500, epoch: 9 | loss: 0.1330298
	speed: 0.0346s/iter; left time: 61.5644s
	iters: 600, epoch: 9 | loss: 0.1261750
	speed: 0.0345s/iter; left time: 57.8707s
	iters: 700, epoch: 9 | loss: 0.1204089
	speed: 0.0343s/iter; left time: 54.0525s
	iters: 800, epoch: 9 | loss: 0.1458095
	speed: 0.0342s/iter; left time: 50.5736s
	iters: 900, epoch: 9 | loss: 0.1328944
	speed: 0.0345s/iter; left time: 47.4975s
	iters: 1000, epoch: 9 | loss: 0.1156190
	speed: 0.0341s/iter; left time: 43.6027s
	iters: 1100, epoch: 9 | loss: 0.1317544
	speed: 0.0350s/iter; left time: 41.2481s
Epoch: 9 cost time: 40.693233489990234
Epoch: 9, Steps: 1138 | Train Loss: 0.1328668 Vali Loss: 0.2365562 Test Loss: 0.2777237
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 0.1369465
	speed: 0.5920s/iter; left time: 615.0836s
	iters: 200, epoch: 10 | loss: 0.1318478
	speed: 0.0349s/iter; left time: 32.7523s
	iters: 300, epoch: 10 | loss: 0.1509426
	speed: 0.0364s/iter; left time: 30.5311s
	iters: 400, epoch: 10 | loss: 0.1295958
	speed: 0.0348s/iter; left time: 25.7419s
	iters: 500, epoch: 10 | loss: 0.1293245
	speed: 0.0348s/iter; left time: 22.2083s
	iters: 600, epoch: 10 | loss: 0.1406167
	speed: 0.0346s/iter; left time: 18.6696s
	iters: 700, epoch: 10 | loss: 0.1285637
	speed: 0.0355s/iter; left time: 15.5712s
	iters: 800, epoch: 10 | loss: 0.1364181
	speed: 0.0356s/iter; left time: 12.0780s
	iters: 900, epoch: 10 | loss: 0.1406638
	speed: 0.0348s/iter; left time: 8.3061s
	iters: 1000, epoch: 10 | loss: 0.1350622
	speed: 0.0345s/iter; left time: 4.7968s
	iters: 1100, epoch: 10 | loss: 0.1398515
	speed: 0.0353s/iter; left time: 1.3756s
Epoch: 10 cost time: 41.11741232872009
Epoch: 10, Steps: 1138 | Train Loss: 0.1327799 Vali Loss: 0.2372372 Test Loss: 0.2775228
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.953125e-06
>>>>>>>testing : ECL_96_96_25_emb_256_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (5165, 1, 96, 321) (5165, 1, 96, 321)
test shape: (5165, 96, 321) (5165, 96, 321)
mse:0.26385167241096497, mae:0.3598674237728119
Args in experiment:
Namespace(is_training=1, model_id='ECL_96_96_26_emb_256', model='xLSTM', data='custom', root_path='./data/electricity/', data_path='/input-data/electricity.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, enc_in=321, dec_in=7, c_out=321, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.5, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=10, batch_size=32, patience=10, learning_rate=0.001, des='test', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, use_norm=True, partial_start_index=0, hidden_size=512, num_layers=2, mark_enc_in=4, embedding_dim=256, weight_decay=1e-06, kernal_size=5, num_heads_xlstm=8, qkv_proj_blocksize=8, proj_factor=1.3, num_blocks=7, slstm_at=1, grad_clip_norm=5.0, d_state=16, d_conv=4, expand=2)
Use GPU: cuda:0
{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-L/usr/local/cuda/lib', '-lcublas'], 'extra_cflags': ['-DSLSTM_HIDDEN_SIZE=256', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=8', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__'], 'extra_cuda_cflags': ['-Xptxas="-v"', '-gencode', 'arch=compute_80,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=256', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=8', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__']}
Using /home/thetayne/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/thetayne/.cache/torch_extensions/py310_cu121/slstm_HS256BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0/build.ninja...
Building extension module slstm_HS256BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module slstm_HS256BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
>>>>>>>start training : ECL_96_96_26_emb_256_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 18221
val 2537
test 5165
	iters: 100, epoch: 1 | loss: 0.2634942
	speed: 0.0926s/iter; left time: 517.9599s
	iters: 200, epoch: 1 | loss: 0.1854887
	speed: 0.0720s/iter; left time: 395.1939s
	iters: 300, epoch: 1 | loss: 0.1642236
	speed: 0.0706s/iter; left time: 380.5985s
	iters: 400, epoch: 1 | loss: 0.1503795
	speed: 0.0708s/iter; left time: 374.4337s
	iters: 500, epoch: 1 | loss: 0.1476485
	speed: 0.0705s/iter; left time: 366.1023s
Epoch: 1 cost time: 42.29435729980469
Epoch: 1, Steps: 569 | Train Loss: 0.2162188 Vali Loss: 0.2241221 Test Loss: 0.2769517
Validation loss decreased (inf --> 0.224122).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.1430603
	speed: 1.0051s/iter; left time: 5047.8628s
	iters: 200, epoch: 2 | loss: 0.1430884
	speed: 0.0698s/iter; left time: 343.4061s
	iters: 300, epoch: 2 | loss: 0.1457690
	speed: 0.0716s/iter; left time: 345.3971s
	iters: 400, epoch: 2 | loss: 0.1431670
	speed: 0.0703s/iter; left time: 331.9821s
	iters: 500, epoch: 2 | loss: 0.1299891
	speed: 0.0706s/iter; left time: 326.2819s
Epoch: 2 cost time: 41.488889932632446
Epoch: 2, Steps: 569 | Train Loss: 0.1415553 Vali Loss: 0.2119930 Test Loss: 0.2682455
Validation loss decreased (0.224122 --> 0.211993).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.1344519
	speed: 1.0181s/iter; left time: 4533.4937s
	iters: 200, epoch: 3 | loss: 0.1361614
	speed: 0.0705s/iter; left time: 306.6935s
	iters: 300, epoch: 3 | loss: 0.1343501
	speed: 0.0701s/iter; left time: 298.2484s
	iters: 400, epoch: 3 | loss: 0.1280689
	speed: 0.0704s/iter; left time: 292.3575s
	iters: 500, epoch: 3 | loss: 0.1310765
	speed: 0.0699s/iter; left time: 283.4679s
Epoch: 3 cost time: 41.764501094818115
Epoch: 3, Steps: 569 | Train Loss: 0.1325005 Vali Loss: 0.2137599 Test Loss: 0.2686751
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.1261565
	speed: 1.0022s/iter; left time: 3892.4836s
	iters: 200, epoch: 4 | loss: 0.1318192
	speed: 0.0720s/iter; left time: 272.5715s
	iters: 300, epoch: 4 | loss: 0.1360107
	speed: 0.0706s/iter; left time: 260.1177s
	iters: 400, epoch: 4 | loss: 0.1341354
	speed: 0.0708s/iter; left time: 253.7783s
	iters: 500, epoch: 4 | loss: 0.1297168
	speed: 0.0719s/iter; left time: 250.6172s
Epoch: 4 cost time: 42.31549310684204
Epoch: 4, Steps: 569 | Train Loss: 0.1295094 Vali Loss: 0.2145205 Test Loss: 0.2695936
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.1285163
	speed: 1.0227s/iter; left time: 3390.3687s
	iters: 200, epoch: 5 | loss: 0.1282116
	speed: 0.0725s/iter; left time: 233.0563s
	iters: 300, epoch: 5 | loss: 0.1283238
	speed: 0.0712s/iter; left time: 221.8110s
	iters: 400, epoch: 5 | loss: 0.1241649
	speed: 0.0725s/iter; left time: 218.4513s
	iters: 500, epoch: 5 | loss: 0.1224406
	speed: 0.0707s/iter; left time: 205.9468s
Epoch: 5 cost time: 42.43886709213257
Epoch: 5, Steps: 569 | Train Loss: 0.1280329 Vali Loss: 0.2153113 Test Loss: 0.2699397
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.1240834
	speed: 1.0041s/iter; left time: 2757.2398s
	iters: 200, epoch: 6 | loss: 0.1251539
	speed: 0.0723s/iter; left time: 191.3495s
	iters: 300, epoch: 6 | loss: 0.1260734
	speed: 0.0701s/iter; left time: 178.4136s
	iters: 400, epoch: 6 | loss: 0.1236359
	speed: 0.0717s/iter; left time: 175.3051s
	iters: 500, epoch: 6 | loss: 0.1216595
	speed: 0.0712s/iter; left time: 167.0256s
Epoch: 6 cost time: 41.954115867614746
Epoch: 6, Steps: 569 | Train Loss: 0.1271767 Vali Loss: 0.2181737 Test Loss: 0.2712455
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.1203552
	speed: 1.0044s/iter; left time: 2186.5477s
	iters: 200, epoch: 7 | loss: 0.1247225
	speed: 0.0718s/iter; left time: 149.0353s
	iters: 300, epoch: 7 | loss: 0.1314058
	speed: 0.0703s/iter; left time: 139.0134s
	iters: 400, epoch: 7 | loss: 0.1267472
	speed: 0.0710s/iter; left time: 133.2343s
	iters: 500, epoch: 7 | loss: 0.1259924
	speed: 0.0716s/iter; left time: 127.1641s
Epoch: 7 cost time: 41.94819784164429
Epoch: 7, Steps: 569 | Train Loss: 0.1267226 Vali Loss: 0.2162885 Test Loss: 0.2704648
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.1246762
	speed: 1.0223s/iter; left time: 1643.9333s
	iters: 200, epoch: 8 | loss: 0.1326210
	speed: 0.0715s/iter; left time: 107.7931s
	iters: 300, epoch: 8 | loss: 0.1281886
	speed: 0.0710s/iter; left time: 100.0231s
	iters: 400, epoch: 8 | loss: 0.1306246
	speed: 0.0728s/iter; left time: 95.1933s
	iters: 500, epoch: 8 | loss: 0.1309540
	speed: 0.0713s/iter; left time: 86.1837s
Epoch: 8 cost time: 42.22239279747009
Epoch: 8, Steps: 569 | Train Loss: 0.1264856 Vali Loss: 0.2162163 Test Loss: 0.2710048
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 0.1283734
	speed: 1.0375s/iter; left time: 1077.9740s
	iters: 200, epoch: 9 | loss: 0.1251896
	speed: 0.0712s/iter; left time: 66.8998s
	iters: 300, epoch: 9 | loss: 0.1243569
	speed: 0.0701s/iter; left time: 58.8140s
	iters: 400, epoch: 9 | loss: 0.1276210
	speed: 0.0709s/iter; left time: 52.4248s
	iters: 500, epoch: 9 | loss: 0.1221252
	speed: 0.0713s/iter; left time: 45.5845s
Epoch: 9 cost time: 41.67744421958923
Epoch: 9, Steps: 569 | Train Loss: 0.1263735 Vali Loss: 0.2170485 Test Loss: 0.2713716
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 0.1183347
	speed: 1.0385s/iter; left time: 488.0988s
	iters: 200, epoch: 10 | loss: 0.1210122
	speed: 0.0709s/iter; left time: 26.2308s
	iters: 300, epoch: 10 | loss: 0.1331863
	speed: 0.0723s/iter; left time: 19.5130s
	iters: 400, epoch: 10 | loss: 0.1192376
	speed: 0.0726s/iter; left time: 12.3382s
	iters: 500, epoch: 10 | loss: 0.1262132
	speed: 0.0699s/iter; left time: 4.8912s
Epoch: 10 cost time: 41.81817030906677
Epoch: 10, Steps: 569 | Train Loss: 0.1262850 Vali Loss: 0.2167295 Test Loss: 0.2712432
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-06
>>>>>>>testing : ECL_96_96_26_emb_256_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (5165, 1, 96, 321) (5165, 1, 96, 321)
test shape: (5165, 96, 321) (5165, 96, 321)
mse:0.2682463824748993, mae:0.360029935836792
Args in experiment:
Namespace(is_training=1, model_id='ECL_96_96_27_emb_256', model='xLSTM', data='custom', root_path='./data/electricity/', data_path='/input-data/electricity.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, enc_in=321, dec_in=7, c_out=321, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.5, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=10, batch_size=8, patience=10, learning_rate=0.0005, des='test', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, use_norm=True, partial_start_index=0, hidden_size=512, num_layers=2, mark_enc_in=4, embedding_dim=256, weight_decay=0.0001, kernal_size=7, num_heads_xlstm=8, qkv_proj_blocksize=4, proj_factor=1.3, num_blocks=7, slstm_at=1, grad_clip_norm=1.0, d_state=16, d_conv=4, expand=2)
Use GPU: cuda:0
{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-L/usr/local/cuda/lib', '-lcublas'], 'extra_cflags': ['-DSLSTM_HIDDEN_SIZE=256', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=8', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__'], 'extra_cuda_cflags': ['-Xptxas="-v"', '-gencode', 'arch=compute_80,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=256', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=8', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__']}
Using /home/thetayne/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/thetayne/.cache/torch_extensions/py310_cu121/slstm_HS256BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0/build.ninja...
Building extension module slstm_HS256BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module slstm_HS256BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
>>>>>>>start training : ECL_96_96_27_emb_256_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 18221
val 2537
test 5165
	iters: 100, epoch: 1 | loss: 0.3340885
	speed: 0.0679s/iter; left time: 1539.8884s
	iters: 200, epoch: 1 | loss: 0.2611881
	speed: 0.0452s/iter; left time: 1019.3906s
	iters: 300, epoch: 1 | loss: 0.2181328
	speed: 0.0448s/iter; left time: 1007.7027s
	iters: 400, epoch: 1 | loss: 0.2113301
	speed: 0.0445s/iter; left time: 996.5053s
	iters: 500, epoch: 1 | loss: 0.1771601
	speed: 0.0445s/iter; left time: 989.9898s
	iters: 600, epoch: 1 | loss: 0.1885743
	speed: 0.0445s/iter; left time: 986.7487s
	iters: 700, epoch: 1 | loss: 0.1727904
	speed: 0.0470s/iter; left time: 1038.0195s
	iters: 800, epoch: 1 | loss: 0.1640245
	speed: 0.0438s/iter; left time: 963.0193s
	iters: 900, epoch: 1 | loss: 0.1645950
	speed: 0.0463s/iter; left time: 1012.8586s
	iters: 1000, epoch: 1 | loss: 0.1651175
	speed: 0.0447s/iter; left time: 972.6404s
	iters: 1100, epoch: 1 | loss: 0.1585528
	speed: 0.0448s/iter; left time: 970.1579s
	iters: 1200, epoch: 1 | loss: 0.1652465
	speed: 0.0455s/iter; left time: 980.5327s
	iters: 1300, epoch: 1 | loss: 0.1619755
	speed: 0.0451s/iter; left time: 968.3872s
	iters: 1400, epoch: 1 | loss: 0.1522914
	speed: 0.0462s/iter; left time: 986.6001s
	iters: 1500, epoch: 1 | loss: 0.1911496
	speed: 0.0458s/iter; left time: 973.4101s
	iters: 1600, epoch: 1 | loss: 0.1492504
	speed: 0.0436s/iter; left time: 923.9309s
	iters: 1700, epoch: 1 | loss: 0.1466591
	speed: 0.0443s/iter; left time: 933.7717s
	iters: 1800, epoch: 1 | loss: 0.1554901
	speed: 0.0447s/iter; left time: 937.2125s
	iters: 1900, epoch: 1 | loss: 0.1462263
	speed: 0.0441s/iter; left time: 920.0381s
	iters: 2000, epoch: 1 | loss: 0.1467379
	speed: 0.0449s/iter; left time: 932.8348s
	iters: 2100, epoch: 1 | loss: 0.1445846
	speed: 0.0436s/iter; left time: 901.5685s
	iters: 2200, epoch: 1 | loss: 0.1478165
	speed: 0.0446s/iter; left time: 916.7539s
Epoch: 1 cost time: 104.46642804145813
Epoch: 1, Steps: 2277 | Train Loss: 0.1902067 Vali Loss: 0.2059156 Test Loss: 0.2646053
Validation loss decreased (inf --> 0.205916).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.1355373
	speed: 1.0109s/iter; left time: 20617.1085s
	iters: 200, epoch: 2 | loss: 0.1614457
	speed: 0.0435s/iter; left time: 883.6588s
	iters: 300, epoch: 2 | loss: 0.1681191
	speed: 0.0445s/iter; left time: 898.3452s
	iters: 400, epoch: 2 | loss: 0.1412836
	speed: 0.0431s/iter; left time: 866.1876s
	iters: 500, epoch: 2 | loss: 0.1693954
	speed: 0.0445s/iter; left time: 890.5271s
	iters: 600, epoch: 2 | loss: 0.1381294
	speed: 0.0440s/iter; left time: 875.2821s
	iters: 700, epoch: 2 | loss: 0.1501565
	speed: 0.0453s/iter; left time: 897.1037s
	iters: 800, epoch: 2 | loss: 0.1488016
	speed: 0.0452s/iter; left time: 889.4754s
	iters: 900, epoch: 2 | loss: 0.1534851
	speed: 0.0446s/iter; left time: 873.2747s
	iters: 1000, epoch: 2 | loss: 0.1678165
	speed: 0.0443s/iter; left time: 864.3170s
	iters: 1100, epoch: 2 | loss: 0.1665807
	speed: 0.0450s/iter; left time: 873.3054s
	iters: 1200, epoch: 2 | loss: 0.1323031
	speed: 0.0448s/iter; left time: 864.7389s
	iters: 1300, epoch: 2 | loss: 0.1536049
	speed: 0.0469s/iter; left time: 900.5126s
	iters: 1400, epoch: 2 | loss: 0.1479888
	speed: 0.0448s/iter; left time: 854.6821s
	iters: 1500, epoch: 2 | loss: 0.1439779
	speed: 0.0445s/iter; left time: 845.7152s
	iters: 1600, epoch: 2 | loss: 0.1662106
	speed: 0.0437s/iter; left time: 826.2988s
	iters: 1700, epoch: 2 | loss: 0.1662399
	speed: 0.0459s/iter; left time: 862.0819s
	iters: 1800, epoch: 2 | loss: 0.1366131
	speed: 0.0442s/iter; left time: 826.0334s
	iters: 1900, epoch: 2 | loss: 0.1201053
	speed: 0.0444s/iter; left time: 825.8532s
	iters: 2000, epoch: 2 | loss: 0.1235417
	speed: 0.0462s/iter; left time: 854.6495s
	iters: 2100, epoch: 2 | loss: 0.1438753
	speed: 0.0449s/iter; left time: 826.6395s
	iters: 2200, epoch: 2 | loss: 0.1471851
	speed: 0.0443s/iter; left time: 809.7560s
Epoch: 2 cost time: 103.73244619369507
Epoch: 2, Steps: 2277 | Train Loss: 0.1486769 Vali Loss: 0.2134124 Test Loss: 0.2638944
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.1452073
	speed: 0.9970s/iter; left time: 18062.9899s
	iters: 200, epoch: 3 | loss: 0.1442149
	speed: 0.0446s/iter; left time: 804.4124s
	iters: 300, epoch: 3 | loss: 0.1362089
	speed: 0.0446s/iter; left time: 798.3309s
	iters: 400, epoch: 3 | loss: 0.1451303
	speed: 0.0440s/iter; left time: 783.5623s
	iters: 500, epoch: 3 | loss: 0.1487100
	speed: 0.0452s/iter; left time: 801.2937s
	iters: 600, epoch: 3 | loss: 0.1481404
	speed: 0.0444s/iter; left time: 781.6221s
	iters: 700, epoch: 3 | loss: 0.1755244
	speed: 0.0443s/iter; left time: 775.5385s
	iters: 800, epoch: 3 | loss: 0.1472575
	speed: 0.0441s/iter; left time: 768.2106s
	iters: 900, epoch: 3 | loss: 0.1424824
	speed: 0.0456s/iter; left time: 790.4073s
	iters: 1000, epoch: 3 | loss: 0.1439609
	speed: 0.0438s/iter; left time: 754.3940s
	iters: 1100, epoch: 3 | loss: 0.1493728
	speed: 0.0458s/iter; left time: 784.3413s
	iters: 1200, epoch: 3 | loss: 0.1472197
	speed: 0.0446s/iter; left time: 759.1310s
	iters: 1300, epoch: 3 | loss: 0.1446059
	speed: 0.0439s/iter; left time: 743.1085s
	iters: 1400, epoch: 3 | loss: 0.1333282
	speed: 0.0443s/iter; left time: 745.2314s
	iters: 1500, epoch: 3 | loss: 0.1384237
	speed: 0.0444s/iter; left time: 741.7387s
	iters: 1600, epoch: 3 | loss: 0.1244359
	speed: 0.0451s/iter; left time: 750.0272s
	iters: 1700, epoch: 3 | loss: 0.1345839
	speed: 0.0526s/iter; left time: 868.3368s
	iters: 1800, epoch: 3 | loss: 0.1437395
	speed: 0.0464s/iter; left time: 762.1883s
	iters: 1900, epoch: 3 | loss: 0.1340452
	speed: 0.0445s/iter; left time: 726.0031s
	iters: 2000, epoch: 3 | loss: 0.1366141
	speed: 0.0435s/iter; left time: 706.2030s
	iters: 2100, epoch: 3 | loss: 0.1556929
	speed: 0.0447s/iter; left time: 720.3771s
	iters: 2200, epoch: 3 | loss: 0.1398326
	speed: 0.0470s/iter; left time: 753.0958s
Epoch: 3 cost time: 104.48427772521973
Epoch: 3, Steps: 2277 | Train Loss: 0.1397524 Vali Loss: 0.2099627 Test Loss: 0.2681383
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.1406138
	speed: 1.0269s/iter; left time: 16265.6596s
	iters: 200, epoch: 4 | loss: 0.1311533
	speed: 0.0440s/iter; left time: 692.0028s
	iters: 300, epoch: 4 | loss: 0.1467299
	speed: 0.0454s/iter; left time: 709.7802s
	iters: 400, epoch: 4 | loss: 0.1419062
	speed: 0.0455s/iter; left time: 707.7483s
	iters: 500, epoch: 4 | loss: 0.1462284
	speed: 0.0457s/iter; left time: 705.5724s
	iters: 600, epoch: 4 | loss: 0.1379712
	speed: 0.0435s/iter; left time: 666.9305s
	iters: 700, epoch: 4 | loss: 0.1310956
	speed: 0.0435s/iter; left time: 663.5318s
	iters: 800, epoch: 4 | loss: 0.1515097
	speed: 0.0460s/iter; left time: 696.6360s
	iters: 900, epoch: 4 | loss: 0.1398866
	speed: 0.0445s/iter; left time: 669.4763s
	iters: 1000, epoch: 4 | loss: 0.1349967
	speed: 0.0443s/iter; left time: 661.1966s
	iters: 1100, epoch: 4 | loss: 0.1297614
	speed: 0.0454s/iter; left time: 673.6476s
	iters: 1200, epoch: 4 | loss: 0.1157974
	speed: 0.0448s/iter; left time: 660.1235s
	iters: 1300, epoch: 4 | loss: 0.1544562
	speed: 0.0438s/iter; left time: 641.7984s
	iters: 1400, epoch: 4 | loss: 0.1412555
	speed: 0.0446s/iter; left time: 648.6224s
	iters: 1500, epoch: 4 | loss: 0.1323385
	speed: 0.0438s/iter; left time: 631.8224s
	iters: 1600, epoch: 4 | loss: 0.1553767
	speed: 0.0447s/iter; left time: 640.8210s
	iters: 1700, epoch: 4 | loss: 0.1446747
	speed: 0.0434s/iter; left time: 617.4385s
	iters: 1800, epoch: 4 | loss: 0.1457573
	speed: 0.0446s/iter; left time: 630.9576s
	iters: 1900, epoch: 4 | loss: 0.1369216
	speed: 0.0443s/iter; left time: 621.3197s
	iters: 2000, epoch: 4 | loss: 0.1355976
	speed: 0.0442s/iter; left time: 615.8112s
	iters: 2100, epoch: 4 | loss: 0.1391227
	speed: 0.0440s/iter; left time: 608.9005s
	iters: 2200, epoch: 4 | loss: 0.1271021
	speed: 0.0442s/iter; left time: 607.3490s
Epoch: 4 cost time: 103.27031421661377
Epoch: 4, Steps: 2277 | Train Loss: 0.1360266 Vali Loss: 0.2118331 Test Loss: 0.2690144
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.1447258
	speed: 1.0224s/iter; left time: 13866.9226s
	iters: 200, epoch: 5 | loss: 0.1276435
	speed: 0.0435s/iter; left time: 585.9895s
	iters: 300, epoch: 5 | loss: 0.1241191
	speed: 0.0440s/iter; left time: 587.8773s
	iters: 400, epoch: 5 | loss: 0.1223957
	speed: 0.0433s/iter; left time: 573.9092s
	iters: 500, epoch: 5 | loss: 0.1245817
	speed: 0.0434s/iter; left time: 571.7379s
	iters: 600, epoch: 5 | loss: 0.1307559
	speed: 0.0442s/iter; left time: 577.5315s
	iters: 700, epoch: 5 | loss: 0.1214898
	speed: 0.0450s/iter; left time: 583.6615s
	iters: 800, epoch: 5 | loss: 0.1289449
	speed: 0.0465s/iter; left time: 598.5076s
	iters: 900, epoch: 5 | loss: 0.1299872
	speed: 0.0455s/iter; left time: 580.5088s
	iters: 1000, epoch: 5 | loss: 0.1334370
	speed: 0.0452s/iter; left time: 572.9748s
	iters: 1100, epoch: 5 | loss: 0.1366401
	speed: 0.0444s/iter; left time: 558.3302s
	iters: 1200, epoch: 5 | loss: 0.1288834
	speed: 0.0439s/iter; left time: 547.2969s
	iters: 1300, epoch: 5 | loss: 0.1190879
	speed: 0.0440s/iter; left time: 544.3082s
	iters: 1400, epoch: 5 | loss: 0.1370288
	speed: 0.0443s/iter; left time: 543.8299s
	iters: 1500, epoch: 5 | loss: 0.1375611
	speed: 0.0494s/iter; left time: 601.1763s
	iters: 1600, epoch: 5 | loss: 0.1422315
	speed: 0.0449s/iter; left time: 541.2312s
	iters: 1700, epoch: 5 | loss: 0.1220500
	speed: 0.0454s/iter; left time: 542.5316s
	iters: 1800, epoch: 5 | loss: 0.1364599
	speed: 0.0452s/iter; left time: 535.8264s
	iters: 1900, epoch: 5 | loss: 0.1257404
	speed: 0.0450s/iter; left time: 529.8515s
	iters: 2000, epoch: 5 | loss: 0.1318019
	speed: 0.0450s/iter; left time: 525.0328s
	iters: 2100, epoch: 5 | loss: 0.1278601
	speed: 0.0450s/iter; left time: 520.8667s
	iters: 2200, epoch: 5 | loss: 0.1158353
	speed: 0.0432s/iter; left time: 495.3424s
Epoch: 5 cost time: 103.72702074050903
Epoch: 5, Steps: 2277 | Train Loss: 0.1341487 Vali Loss: 0.2138835 Test Loss: 0.2686947
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.1202563
	speed: 0.9807s/iter; left time: 11068.5633s
	iters: 200, epoch: 6 | loss: 0.1362597
	speed: 0.0442s/iter; left time: 494.3006s
	iters: 300, epoch: 6 | loss: 0.1439296
	speed: 0.0441s/iter; left time: 488.3921s
	iters: 400, epoch: 6 | loss: 0.1270051
	speed: 0.0445s/iter; left time: 488.6206s
	iters: 500, epoch: 6 | loss: 0.1247151
	speed: 0.0458s/iter; left time: 498.1628s
	iters: 600, epoch: 6 | loss: 0.1572905
	speed: 0.0506s/iter; left time: 546.2228s
	iters: 700, epoch: 6 | loss: 0.1349329
	speed: 0.0440s/iter; left time: 470.1027s
	iters: 800, epoch: 6 | loss: 0.1317647
	speed: 0.0449s/iter; left time: 475.6429s
	iters: 900, epoch: 6 | loss: 0.1257697
	speed: 0.0435s/iter; left time: 455.8814s
	iters: 1000, epoch: 6 | loss: 0.1495848
	speed: 0.0445s/iter; left time: 461.8900s
	iters: 1100, epoch: 6 | loss: 0.1339068
	speed: 0.0437s/iter; left time: 449.2130s
	iters: 1200, epoch: 6 | loss: 0.1467923
	speed: 0.0450s/iter; left time: 458.5326s
	iters: 1300, epoch: 6 | loss: 0.1214985
	speed: 0.0440s/iter; left time: 443.3061s
	iters: 1400, epoch: 6 | loss: 0.1525048
	speed: 0.0457s/iter; left time: 456.5467s
	iters: 1500, epoch: 6 | loss: 0.1307781
	speed: 0.0454s/iter; left time: 448.4376s
	iters: 1600, epoch: 6 | loss: 0.1299188
	speed: 0.0459s/iter; left time: 449.3149s
	iters: 1700, epoch: 6 | loss: 0.1399585
	speed: 0.0480s/iter; left time: 465.3255s
	iters: 1800, epoch: 6 | loss: 0.1483040
	speed: 0.0449s/iter; left time: 430.0487s
	iters: 1900, epoch: 6 | loss: 0.1564698
	speed: 0.0449s/iter; left time: 425.6809s
	iters: 2000, epoch: 6 | loss: 0.1369572
	speed: 0.0454s/iter; left time: 426.1023s
	iters: 2100, epoch: 6 | loss: 0.1308869
	speed: 0.0433s/iter; left time: 401.7008s
	iters: 2200, epoch: 6 | loss: 0.1150725
	speed: 0.0469s/iter; left time: 430.8038s
Epoch: 6 cost time: 104.48089408874512
Epoch: 6, Steps: 2277 | Train Loss: 0.1331271 Vali Loss: 0.2159537 Test Loss: 0.2701508
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.1416698
	speed: 1.0360s/iter; left time: 9333.1696s
	iters: 200, epoch: 7 | loss: 0.1230986
	speed: 0.0461s/iter; left time: 410.3717s
	iters: 300, epoch: 7 | loss: 0.1245906
	speed: 0.0448s/iter; left time: 394.9536s
	iters: 400, epoch: 7 | loss: 0.1419459
	speed: 0.0444s/iter; left time: 386.5094s
	iters: 500, epoch: 7 | loss: 0.1188040
	speed: 0.0456s/iter; left time: 392.8415s
	iters: 600, epoch: 7 | loss: 0.1295513
	speed: 0.0443s/iter; left time: 376.5327s
	iters: 700, epoch: 7 | loss: 0.1272021
	speed: 0.0440s/iter; left time: 369.7570s
	iters: 800, epoch: 7 | loss: 0.1232745
	speed: 0.0453s/iter; left time: 376.1683s
	iters: 900, epoch: 7 | loss: 0.1441385
	speed: 0.0484s/iter; left time: 397.3732s
	iters: 1000, epoch: 7 | loss: 0.1274691
	speed: 0.0445s/iter; left time: 360.8372s
	iters: 1100, epoch: 7 | loss: 0.1366789
	speed: 0.0440s/iter; left time: 352.5322s
	iters: 1200, epoch: 7 | loss: 0.1189515
	speed: 0.0431s/iter; left time: 341.2060s
	iters: 1300, epoch: 7 | loss: 0.1423580
	speed: 0.0439s/iter; left time: 342.7579s
	iters: 1400, epoch: 7 | loss: 0.1357968
	speed: 0.0432s/iter; left time: 333.3749s
	iters: 1500, epoch: 7 | loss: 0.1294322
	speed: 0.0446s/iter; left time: 339.1377s
	iters: 1600, epoch: 7 | loss: 0.1448486
	speed: 0.0446s/iter; left time: 334.8357s
	iters: 1700, epoch: 7 | loss: 0.1388225
	speed: 0.0447s/iter; left time: 331.2789s
	iters: 1800, epoch: 7 | loss: 0.1634163
	speed: 0.0458s/iter; left time: 334.5266s
	iters: 1900, epoch: 7 | loss: 0.1464851
	speed: 0.0439s/iter; left time: 316.1840s
	iters: 2000, epoch: 7 | loss: 0.1534747
	speed: 0.0458s/iter; left time: 325.7331s
	iters: 2100, epoch: 7 | loss: 0.1401479
	speed: 0.0464s/iter; left time: 324.9868s
	iters: 2200, epoch: 7 | loss: 0.1170180
	speed: 0.0445s/iter; left time: 307.3909s
Epoch: 7 cost time: 104.42070603370667
Epoch: 7, Steps: 2277 | Train Loss: 0.1325869 Vali Loss: 0.2179097 Test Loss: 0.2731780
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.1276514
	speed: 1.0046s/iter; left time: 6763.1736s
	iters: 200, epoch: 8 | loss: 0.1303741
	speed: 0.0445s/iter; left time: 295.3596s
	iters: 300, epoch: 8 | loss: 0.1193829
	speed: 0.0442s/iter; left time: 288.8165s
	iters: 400, epoch: 8 | loss: 0.1377484
	speed: 0.0442s/iter; left time: 284.0839s
	iters: 500, epoch: 8 | loss: 0.1255089
	speed: 0.0447s/iter; left time: 282.7884s
	iters: 600, epoch: 8 | loss: 0.1481411
	speed: 0.0445s/iter; left time: 277.4741s
	iters: 700, epoch: 8 | loss: 0.1273893
	speed: 0.0438s/iter; left time: 268.7679s
	iters: 800, epoch: 8 | loss: 0.1323711
	speed: 0.0448s/iter; left time: 270.1899s
	iters: 900, epoch: 8 | loss: 0.1238805
	speed: 0.0438s/iter; left time: 259.9998s
	iters: 1000, epoch: 8 | loss: 0.1457210
	speed: 0.0446s/iter; left time: 260.1551s
	iters: 1100, epoch: 8 | loss: 0.1310559
	speed: 0.0446s/iter; left time: 255.7820s
	iters: 1200, epoch: 8 | loss: 0.1418498
	speed: 0.0441s/iter; left time: 248.5809s
	iters: 1300, epoch: 8 | loss: 0.1255787
	speed: 0.0445s/iter; left time: 246.0053s
	iters: 1400, epoch: 8 | loss: 0.1202074
	speed: 0.0442s/iter; left time: 240.3218s
	iters: 1500, epoch: 8 | loss: 0.1252631
	speed: 0.0451s/iter; left time: 240.6221s
	iters: 1600, epoch: 8 | loss: 0.1306775
	speed: 0.0451s/iter; left time: 235.9013s
	iters: 1700, epoch: 8 | loss: 0.1134030
	speed: 0.0432s/iter; left time: 221.5698s
	iters: 1800, epoch: 8 | loss: 0.1301918
	speed: 0.0446s/iter; left time: 224.6566s
	iters: 1900, epoch: 8 | loss: 0.1280288
	speed: 0.0456s/iter; left time: 224.7655s
	iters: 2000, epoch: 8 | loss: 0.1441459
	speed: 0.0434s/iter; left time: 209.5010s
	iters: 2100, epoch: 8 | loss: 0.1534156
	speed: 0.0441s/iter; left time: 208.5264s
	iters: 2200, epoch: 8 | loss: 0.1231555
	speed: 0.0442s/iter; left time: 204.6999s
Epoch: 8 cost time: 103.29963755607605
Epoch: 8, Steps: 2277 | Train Loss: 0.1323156 Vali Loss: 0.2182530 Test Loss: 0.2732990
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.1591031
	speed: 0.9950s/iter; left time: 4432.5402s
	iters: 200, epoch: 9 | loss: 0.1338902
	speed: 0.0442s/iter; left time: 192.3204s
	iters: 300, epoch: 9 | loss: 0.1380802
	speed: 0.0449s/iter; left time: 191.0846s
	iters: 400, epoch: 9 | loss: 0.1207589
	speed: 0.0448s/iter; left time: 186.1010s
	iters: 500, epoch: 9 | loss: 0.1203509
	speed: 0.0430s/iter; left time: 174.3634s
	iters: 600, epoch: 9 | loss: 0.1457030
	speed: 0.0438s/iter; left time: 173.4089s
	iters: 700, epoch: 9 | loss: 0.1410551
	speed: 0.0441s/iter; left time: 170.0358s
	iters: 800, epoch: 9 | loss: 0.1255336
	speed: 0.0431s/iter; left time: 161.8258s
	iters: 900, epoch: 9 | loss: 0.1381968
	speed: 0.0448s/iter; left time: 163.6577s
	iters: 1000, epoch: 9 | loss: 0.1154541
	speed: 0.0471s/iter; left time: 167.4916s
	iters: 1100, epoch: 9 | loss: 0.1213823
	speed: 0.0444s/iter; left time: 153.4920s
	iters: 1200, epoch: 9 | loss: 0.1356906
	speed: 0.0450s/iter; left time: 150.8240s
	iters: 1300, epoch: 9 | loss: 0.1252417
	speed: 0.0432s/iter; left time: 140.6788s
	iters: 1400, epoch: 9 | loss: 0.1300563
	speed: 0.0514s/iter; left time: 162.1098s
	iters: 1500, epoch: 9 | loss: 0.1175150
	speed: 0.0441s/iter; left time: 134.8672s
	iters: 1600, epoch: 9 | loss: 0.1254138
	speed: 0.0446s/iter; left time: 131.7014s
	iters: 1700, epoch: 9 | loss: 0.1346844
	speed: 0.0443s/iter; left time: 126.6145s
	iters: 1800, epoch: 9 | loss: 0.1305383
	speed: 0.0455s/iter; left time: 125.2660s
	iters: 1900, epoch: 9 | loss: 0.1239661
	speed: 0.0474s/iter; left time: 125.8930s
	iters: 2000, epoch: 9 | loss: 0.1410511
	speed: 0.0443s/iter; left time: 113.2858s
	iters: 2100, epoch: 9 | loss: 0.1365336
	speed: 0.0446s/iter; left time: 109.5522s
	iters: 2200, epoch: 9 | loss: 0.1158877
	speed: 0.0449s/iter; left time: 105.6682s
Epoch: 9 cost time: 104.28010272979736
Epoch: 9, Steps: 2277 | Train Loss: 0.1321681 Vali Loss: 0.2183805 Test Loss: 0.2731768
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.1343698
	speed: 0.9971s/iter; left time: 2171.5982s
	iters: 200, epoch: 10 | loss: 0.1422704
	speed: 0.0462s/iter; left time: 95.9989s
	iters: 300, epoch: 10 | loss: 0.1448070
	speed: 0.0447s/iter; left time: 88.4533s
	iters: 400, epoch: 10 | loss: 0.1235019
	speed: 0.0437s/iter; left time: 81.9809s
	iters: 500, epoch: 10 | loss: 0.1476337
	speed: 0.0451s/iter; left time: 80.1348s
	iters: 600, epoch: 10 | loss: 0.1197234
	speed: 0.0457s/iter; left time: 76.6272s
	iters: 700, epoch: 10 | loss: 0.1329804
	speed: 0.0440s/iter; left time: 69.5000s
	iters: 800, epoch: 10 | loss: 0.1211579
	speed: 0.0441s/iter; left time: 65.1974s
	iters: 900, epoch: 10 | loss: 0.1320043
	speed: 0.0454s/iter; left time: 62.5275s
	iters: 1000, epoch: 10 | loss: 0.1413667
	speed: 0.0444s/iter; left time: 56.7318s
	iters: 1100, epoch: 10 | loss: 0.1593250
	speed: 0.0445s/iter; left time: 52.4677s
	iters: 1200, epoch: 10 | loss: 0.1260418
	speed: 0.0468s/iter; left time: 50.4231s
	iters: 1300, epoch: 10 | loss: 0.1458839
	speed: 0.0437s/iter; left time: 42.7641s
	iters: 1400, epoch: 10 | loss: 0.1337522
	speed: 0.0435s/iter; left time: 38.1656s
	iters: 1500, epoch: 10 | loss: 0.1232657
	speed: 0.0438s/iter; left time: 34.0707s
	iters: 1600, epoch: 10 | loss: 0.1310199
	speed: 0.0431s/iter; left time: 29.2115s
	iters: 1700, epoch: 10 | loss: 0.1350663
	speed: 0.0435s/iter; left time: 25.1272s
	iters: 1800, epoch: 10 | loss: 0.1156717
	speed: 0.0440s/iter; left time: 21.0504s
	iters: 1900, epoch: 10 | loss: 0.1319498
	speed: 0.0450s/iter; left time: 17.0077s
	iters: 2000, epoch: 10 | loss: 0.1247031
	speed: 0.0435s/iter; left time: 12.0928s
	iters: 2100, epoch: 10 | loss: 0.1240560
	speed: 0.0446s/iter; left time: 7.9453s
	iters: 2200, epoch: 10 | loss: 0.1331868
	speed: 0.0454s/iter; left time: 3.5395s
Epoch: 10 cost time: 103.26537919044495
Epoch: 10, Steps: 2277 | Train Loss: 0.1321024 Vali Loss: 0.2179060 Test Loss: 0.2731265
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-07
>>>>>>>testing : ECL_96_96_27_emb_256_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (5165, 1, 96, 321) (5165, 1, 96, 321)
test shape: (5165, 96, 321) (5165, 96, 321)
mse:0.26460564136505127, mae:0.36209914088249207
Args in experiment:
Namespace(is_training=1, model_id='ECL_96_96_28_emb_256', model='xLSTM', data='custom', root_path='./data/electricity/', data_path='/input-data/electricity.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, enc_in=321, dec_in=7, c_out=321, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.3, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=16, patience=10, learning_rate=0.001, des='test', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, use_norm=True, partial_start_index=0, hidden_size=512, num_layers=2, mark_enc_in=4, embedding_dim=256, weight_decay=1e-05, kernal_size=3, num_heads_xlstm=4, qkv_proj_blocksize=4, proj_factor=1.3, num_blocks=3, slstm_at=1, grad_clip_norm=5.0, d_state=16, d_conv=4, expand=2)
Use GPU: cuda:0
{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-L/usr/local/cuda/lib', '-lcublas'], 'extra_cflags': ['-DSLSTM_HIDDEN_SIZE=256', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__'], 'extra_cuda_cflags': ['-Xptxas="-v"', '-gencode', 'arch=compute_80,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=256', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__']}
Using /home/thetayne/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/thetayne/.cache/torch_extensions/py310_cu121/slstm_HS256BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0/build.ninja...
Building extension module slstm_HS256BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module slstm_HS256BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
>>>>>>>start training : ECL_96_96_28_emb_256_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 18221
val 2537
test 5165
	iters: 100, epoch: 1 | loss: 0.2200426
	speed: 0.0545s/iter; left time: 1853.8520s
	iters: 200, epoch: 1 | loss: 0.1992828
	speed: 0.0358s/iter; left time: 1215.5026s
	iters: 300, epoch: 1 | loss: 0.1925739
	speed: 0.0351s/iter; left time: 1187.5952s
	iters: 400, epoch: 1 | loss: 0.1544495
	speed: 0.0355s/iter; left time: 1196.7500s
	iters: 500, epoch: 1 | loss: 0.1446764
	speed: 0.0356s/iter; left time: 1197.1959s
	iters: 600, epoch: 1 | loss: 0.1155770
	speed: 0.0357s/iter; left time: 1198.0534s
	iters: 700, epoch: 1 | loss: 0.1180601
	speed: 0.0347s/iter; left time: 1159.6883s
	iters: 800, epoch: 1 | loss: 0.1143773
	speed: 0.0347s/iter; left time: 1157.7244s
	iters: 900, epoch: 1 | loss: 0.1178786
	speed: 0.0348s/iter; left time: 1155.6460s
	iters: 1000, epoch: 1 | loss: 0.1177224
	speed: 0.0351s/iter; left time: 1162.0087s
	iters: 1100, epoch: 1 | loss: 0.1108100
	speed: 0.0350s/iter; left time: 1155.0389s
Epoch: 1 cost time: 41.80194115638733
Epoch: 1, Steps: 1138 | Train Loss: 0.1604362 Vali Loss: 0.2080748 Test Loss: 0.2594271
Validation loss decreased (inf --> 0.208075).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.1162231
	speed: 0.6085s/iter; left time: 20022.7307s
	iters: 200, epoch: 2 | loss: 0.1133124
	speed: 0.0348s/iter; left time: 1141.5085s
	iters: 300, epoch: 2 | loss: 0.1150417
	speed: 0.0350s/iter; left time: 1144.4116s
	iters: 400, epoch: 2 | loss: 0.1018181
	speed: 0.0339s/iter; left time: 1105.0104s
	iters: 500, epoch: 2 | loss: 0.1043529
	speed: 0.0352s/iter; left time: 1143.0212s
	iters: 600, epoch: 2 | loss: 0.1057234
	speed: 0.0348s/iter; left time: 1126.6984s
	iters: 700, epoch: 2 | loss: 0.1070587
	speed: 0.0352s/iter; left time: 1136.7768s
	iters: 800, epoch: 2 | loss: 0.1012063
	speed: 0.0351s/iter; left time: 1130.5192s
	iters: 900, epoch: 2 | loss: 0.0996321
	speed: 0.0345s/iter; left time: 1109.0103s
	iters: 1000, epoch: 2 | loss: 0.0933149
	speed: 0.0349s/iter; left time: 1115.8037s
	iters: 1100, epoch: 2 | loss: 0.1002005
	speed: 0.0349s/iter; left time: 1114.3365s
Epoch: 2 cost time: 41.18310260772705
Epoch: 2, Steps: 1138 | Train Loss: 0.1076743 Vali Loss: 0.2018538 Test Loss: 0.2636900
Validation loss decreased (0.208075 --> 0.201854).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.0997802
	speed: 0.6017s/iter; left time: 19114.0409s
	iters: 200, epoch: 3 | loss: 0.0905292
	speed: 0.0342s/iter; left time: 1082.8807s
	iters: 300, epoch: 3 | loss: 0.1043951
	speed: 0.0350s/iter; left time: 1103.5373s
	iters: 400, epoch: 3 | loss: 0.0996917
	speed: 0.0354s/iter; left time: 1115.3508s
	iters: 500, epoch: 3 | loss: 0.0947418
	speed: 0.0357s/iter; left time: 1118.6602s
	iters: 600, epoch: 3 | loss: 0.0957947
	speed: 0.0360s/iter; left time: 1125.1932s
	iters: 700, epoch: 3 | loss: 0.0933189
	speed: 0.0347s/iter; left time: 1080.4424s
	iters: 800, epoch: 3 | loss: 0.0935979
	speed: 0.0346s/iter; left time: 1073.9566s
	iters: 900, epoch: 3 | loss: 0.0922256
	speed: 0.0347s/iter; left time: 1074.9541s
	iters: 1000, epoch: 3 | loss: 0.0967887
	speed: 0.0353s/iter; left time: 1089.5106s
	iters: 1100, epoch: 3 | loss: 0.0976460
	speed: 0.0355s/iter; left time: 1090.7852s
Epoch: 3 cost time: 41.12799572944641
Epoch: 3, Steps: 1138 | Train Loss: 0.0964265 Vali Loss: 0.2102352 Test Loss: 0.2704062
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.0863312
	speed: 0.6344s/iter; left time: 19431.0030s
	iters: 200, epoch: 4 | loss: 0.0897865
	speed: 0.0351s/iter; left time: 1070.7411s
	iters: 300, epoch: 4 | loss: 0.0872942
	speed: 0.0342s/iter; left time: 1040.9297s
	iters: 400, epoch: 4 | loss: 0.0924950
	speed: 0.0351s/iter; left time: 1064.6925s
	iters: 500, epoch: 4 | loss: 0.0916657
	speed: 0.0348s/iter; left time: 1050.5368s
	iters: 600, epoch: 4 | loss: 0.0855885
	speed: 0.0351s/iter; left time: 1056.1667s
	iters: 700, epoch: 4 | loss: 0.0969349
	speed: 0.0346s/iter; left time: 1039.0461s
	iters: 800, epoch: 4 | loss: 0.0902624
	speed: 0.0348s/iter; left time: 1041.8135s
	iters: 900, epoch: 4 | loss: 0.0915785
	speed: 0.0341s/iter; left time: 1016.5945s
	iters: 1000, epoch: 4 | loss: 0.0901686
	speed: 0.0346s/iter; left time: 1027.4808s
	iters: 1100, epoch: 4 | loss: 0.0900336
	speed: 0.0353s/iter; left time: 1046.8695s
Epoch: 4 cost time: 41.03730034828186
Epoch: 4, Steps: 1138 | Train Loss: 0.0922363 Vali Loss: 0.2086874 Test Loss: 0.2736181
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.0868455
	speed: 0.6300s/iter; left time: 18579.3602s
	iters: 200, epoch: 5 | loss: 0.0836776
	speed: 0.0355s/iter; left time: 1042.4731s
	iters: 300, epoch: 5 | loss: 0.0831002
	speed: 0.0344s/iter; left time: 1008.3942s
	iters: 400, epoch: 5 | loss: 0.0926932
	speed: 0.0349s/iter; left time: 1017.7403s
	iters: 500, epoch: 5 | loss: 0.0840228
	speed: 0.0344s/iter; left time: 1000.9838s
	iters: 600, epoch: 5 | loss: 0.0943101
	speed: 0.0344s/iter; left time: 996.9470s
	iters: 700, epoch: 5 | loss: 0.0906231
	speed: 0.0352s/iter; left time: 1017.7211s
	iters: 800, epoch: 5 | loss: 0.0872507
	speed: 0.0351s/iter; left time: 1011.5413s
	iters: 900, epoch: 5 | loss: 0.0992624
	speed: 0.0353s/iter; left time: 1011.5892s
	iters: 1000, epoch: 5 | loss: 0.0970200
	speed: 0.0347s/iter; left time: 991.4531s
	iters: 1100, epoch: 5 | loss: 0.0937566
	speed: 0.0350s/iter; left time: 997.6671s
Epoch: 5 cost time: 41.00401544570923
Epoch: 5, Steps: 1138 | Train Loss: 0.0900488 Vali Loss: 0.2103609 Test Loss: 0.2773901
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.0836460
	speed: 0.6040s/iter; left time: 17123.7417s
	iters: 200, epoch: 6 | loss: 0.0954362
	speed: 0.0346s/iter; left time: 976.1102s
	iters: 300, epoch: 6 | loss: 0.0884939
	speed: 0.0349s/iter; left time: 981.8730s
	iters: 400, epoch: 6 | loss: 0.0806055
	speed: 0.0352s/iter; left time: 987.7878s
	iters: 500, epoch: 6 | loss: 0.0862944
	speed: 0.0345s/iter; left time: 964.6876s
	iters: 600, epoch: 6 | loss: 0.0832221
	speed: 0.0351s/iter; left time: 976.8712s
	iters: 700, epoch: 6 | loss: 0.0876191
	speed: 0.0345s/iter; left time: 958.6077s
	iters: 800, epoch: 6 | loss: 0.1038340
	speed: 0.0352s/iter; left time: 973.8969s
	iters: 900, epoch: 6 | loss: 0.0902052
	speed: 0.0354s/iter; left time: 974.9241s
	iters: 1000, epoch: 6 | loss: 0.0905247
	speed: 0.0348s/iter; left time: 954.9979s
	iters: 1100, epoch: 6 | loss: 0.0867947
	speed: 0.0348s/iter; left time: 952.2003s
Epoch: 6 cost time: 41.4060115814209
Epoch: 6, Steps: 1138 | Train Loss: 0.0889159 Vali Loss: 0.2145935 Test Loss: 0.2802347
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.0851588
	speed: 0.6078s/iter; left time: 16539.8010s
	iters: 200, epoch: 7 | loss: 0.0979611
	speed: 0.0344s/iter; left time: 932.7877s
	iters: 300, epoch: 7 | loss: 0.0880025
	speed: 0.0350s/iter; left time: 945.3870s
	iters: 400, epoch: 7 | loss: 0.0865155
	speed: 0.0349s/iter; left time: 939.7400s
	iters: 500, epoch: 7 | loss: 0.0903552
	speed: 0.0346s/iter; left time: 928.1832s
	iters: 600, epoch: 7 | loss: 0.0922288
	speed: 0.0345s/iter; left time: 921.9161s
	iters: 700, epoch: 7 | loss: 0.0883774
	speed: 0.0350s/iter; left time: 932.4133s
	iters: 800, epoch: 7 | loss: 0.0851927
	speed: 0.0359s/iter; left time: 951.4650s
	iters: 900, epoch: 7 | loss: 0.0861998
	speed: 0.0353s/iter; left time: 932.4907s
	iters: 1000, epoch: 7 | loss: 0.0859789
	speed: 0.0354s/iter; left time: 931.5624s
	iters: 1100, epoch: 7 | loss: 0.0830343
	speed: 0.0349s/iter; left time: 914.7822s
Epoch: 7 cost time: 41.020684480667114
Epoch: 7, Steps: 1138 | Train Loss: 0.0882936 Vali Loss: 0.2155746 Test Loss: 0.2821698
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.0886962
	speed: 0.6182s/iter; left time: 16119.6136s
	iters: 200, epoch: 8 | loss: 0.0876373
	speed: 0.0356s/iter; left time: 925.9203s
	iters: 300, epoch: 8 | loss: 0.0899958
	speed: 0.0361s/iter; left time: 934.2645s
	iters: 400, epoch: 8 | loss: 0.0882201
	speed: 0.0359s/iter; left time: 924.0353s
	iters: 500, epoch: 8 | loss: 0.0864716
	speed: 0.0358s/iter; left time: 919.4110s
	iters: 600, epoch: 8 | loss: 0.0833148
	speed: 0.0355s/iter; left time: 907.1710s
	iters: 700, epoch: 8 | loss: 0.0862466
	speed: 0.0355s/iter; left time: 905.0236s
	iters: 800, epoch: 8 | loss: 0.0848170
	speed: 0.0355s/iter; left time: 899.5792s
	iters: 900, epoch: 8 | loss: 0.0856315
	speed: 0.0352s/iter; left time: 890.1278s
	iters: 1000, epoch: 8 | loss: 0.0887439
	speed: 0.0355s/iter; left time: 894.5653s
	iters: 1100, epoch: 8 | loss: 0.0825379
	speed: 0.0353s/iter; left time: 885.7646s
Epoch: 8 cost time: 41.877299547195435
Epoch: 8, Steps: 1138 | Train Loss: 0.0879845 Vali Loss: 0.2161506 Test Loss: 0.2828054
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 0.0851208
	speed: 0.6099s/iter; left time: 15210.1897s
	iters: 200, epoch: 9 | loss: 0.0951363
	speed: 0.0341s/iter; left time: 846.0233s
	iters: 300, epoch: 9 | loss: 0.0833340
	speed: 0.0351s/iter; left time: 867.7325s
	iters: 400, epoch: 9 | loss: 0.0884644
	speed: 0.0353s/iter; left time: 869.6728s
	iters: 500, epoch: 9 | loss: 0.0855363
	speed: 0.0355s/iter; left time: 869.9802s
	iters: 600, epoch: 9 | loss: 0.0962296
	speed: 0.0357s/iter; left time: 871.5364s
	iters: 700, epoch: 9 | loss: 0.0845127
	speed: 0.0357s/iter; left time: 868.3010s
	iters: 800, epoch: 9 | loss: 0.1003971
	speed: 0.0346s/iter; left time: 839.3290s
	iters: 900, epoch: 9 | loss: 0.0791703
	speed: 0.0347s/iter; left time: 837.1298s
	iters: 1000, epoch: 9 | loss: 0.0875847
	speed: 0.0359s/iter; left time: 862.7645s
	iters: 1100, epoch: 9 | loss: 0.0888841
	speed: 0.0360s/iter; left time: 862.4801s
Epoch: 9 cost time: 41.32710146903992
Epoch: 9, Steps: 1138 | Train Loss: 0.0878070 Vali Loss: 0.2161448 Test Loss: 0.2829463
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 0.0843968
	speed: 0.6089s/iter; left time: 14490.3479s
	iters: 200, epoch: 10 | loss: 0.0919514
	speed: 0.0353s/iter; left time: 835.9003s
	iters: 300, epoch: 10 | loss: 0.0838849
	speed: 0.0352s/iter; left time: 831.2009s
	iters: 400, epoch: 10 | loss: 0.0939568
	speed: 0.0352s/iter; left time: 826.0965s
	iters: 500, epoch: 10 | loss: 0.0851550
	speed: 0.0359s/iter; left time: 840.9483s
	iters: 600, epoch: 10 | loss: 0.0806780
	speed: 0.0360s/iter; left time: 838.9749s
	iters: 700, epoch: 10 | loss: 0.0860496
	speed: 0.0354s/iter; left time: 822.1671s
	iters: 800, epoch: 10 | loss: 0.0839236
	speed: 0.0348s/iter; left time: 804.0530s
	iters: 900, epoch: 10 | loss: 0.0863412
	speed: 0.0356s/iter; left time: 819.7269s
	iters: 1000, epoch: 10 | loss: 0.0887225
	speed: 0.0353s/iter; left time: 807.6750s
	iters: 1100, epoch: 10 | loss: 0.0870417
	speed: 0.0352s/iter; left time: 802.3832s
Epoch: 10 cost time: 41.61802577972412
Epoch: 10, Steps: 1138 | Train Loss: 0.0877220 Vali Loss: 0.2164701 Test Loss: 0.2830552
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 0.0955195
	speed: 0.5927s/iter; left time: 13431.3877s
	iters: 200, epoch: 11 | loss: 0.0875960
	speed: 0.0318s/iter; left time: 717.8019s
	iters: 300, epoch: 11 | loss: 0.0932331
	speed: 0.0334s/iter; left time: 751.0472s
	iters: 400, epoch: 11 | loss: 0.0919561
	speed: 0.0340s/iter; left time: 759.3557s
	iters: 500, epoch: 11 | loss: 0.0906077
	speed: 0.0352s/iter; left time: 784.3185s
	iters: 600, epoch: 11 | loss: 0.0900863
	speed: 0.0350s/iter; left time: 775.0892s
	iters: 700, epoch: 11 | loss: 0.0922143
	speed: 0.0348s/iter; left time: 768.4407s
	iters: 800, epoch: 11 | loss: 0.0868052
	speed: 0.0358s/iter; left time: 785.5196s
	iters: 900, epoch: 11 | loss: 0.0939456
	speed: 0.0351s/iter; left time: 766.4758s
	iters: 1000, epoch: 11 | loss: 0.0871894
	speed: 0.0346s/iter; left time: 752.0694s
	iters: 1100, epoch: 11 | loss: 0.0851385
	speed: 0.0352s/iter; left time: 761.8427s
Epoch: 11 cost time: 40.74810552597046
Epoch: 11, Steps: 1138 | Train Loss: 0.0877075 Vali Loss: 0.2168200 Test Loss: 0.2833666
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 0.0899626
	speed: 0.6336s/iter; left time: 13636.6192s
	iters: 200, epoch: 12 | loss: 0.0809799
	speed: 0.0329s/iter; left time: 705.6198s
	iters: 300, epoch: 12 | loss: 0.0870266
	speed: 0.0336s/iter; left time: 716.0863s
	iters: 400, epoch: 12 | loss: 0.0915808
	speed: 0.0353s/iter; left time: 749.9756s
	iters: 500, epoch: 12 | loss: 0.0841268
	speed: 0.0347s/iter; left time: 732.0104s
	iters: 600, epoch: 12 | loss: 0.0799336
	speed: 0.0352s/iter; left time: 740.8965s
	iters: 700, epoch: 12 | loss: 0.0894608
	speed: 0.0346s/iter; left time: 724.0465s
	iters: 800, epoch: 12 | loss: 0.0836323
	speed: 0.0345s/iter; left time: 719.1626s
	iters: 900, epoch: 12 | loss: 0.0826724
	speed: 0.0355s/iter; left time: 736.5556s
	iters: 1000, epoch: 12 | loss: 0.0875083
	speed: 0.0349s/iter; left time: 719.6295s
	iters: 1100, epoch: 12 | loss: 0.0916092
	speed: 0.0353s/iter; left time: 723.8153s
Epoch: 12 cost time: 40.79763627052307
Epoch: 12, Steps: 1138 | Train Loss: 0.0876785 Vali Loss: 0.2168465 Test Loss: 0.2835178
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : ECL_96_96_28_emb_256_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (5165, 1, 96, 321) (5165, 1, 96, 321)
test shape: (5165, 96, 321) (5165, 96, 321)
mse:0.2636902332305908, mae:0.35772690176963806
Args in experiment:
Namespace(is_training=1, model_id='ECL_96_96_29_emb_256', model='xLSTM', data='custom', root_path='./data/electricity/', data_path='/input-data/electricity.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, enc_in=321, dec_in=7, c_out=321, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.3, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=10, batch_size=32, patience=10, learning_rate=0.001, des='test', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, use_norm=True, partial_start_index=0, hidden_size=512, num_layers=2, mark_enc_in=4, embedding_dim=256, weight_decay=1e-05, kernal_size=3, num_heads_xlstm=2, qkv_proj_blocksize=2, proj_factor=1.3, num_blocks=7, slstm_at=1, grad_clip_norm=0.5, d_state=16, d_conv=4, expand=2)
Use GPU: cuda:0
{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-L/usr/local/cuda/lib', '-lcublas'], 'extra_cflags': ['-DSLSTM_HIDDEN_SIZE=256', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=2', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__'], 'extra_cuda_cflags': ['-Xptxas="-v"', '-gencode', 'arch=compute_80,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=256', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=2', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__']}
Using /home/thetayne/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/thetayne/.cache/torch_extensions/py310_cu121/slstm_HS256BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0/build.ninja...
Building extension module slstm_HS256BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module slstm_HS256BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
>>>>>>>start training : ECL_96_96_29_emb_256_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 18221
val 2537
test 5165
	iters: 100, epoch: 1 | loss: 0.2162745
	speed: 0.1180s/iter; left time: 659.7545s
	iters: 200, epoch: 1 | loss: 0.1552328
	speed: 0.0939s/iter; left time: 515.5647s
	iters: 300, epoch: 1 | loss: 0.1335082
	speed: 0.0943s/iter; left time: 508.5392s
	iters: 400, epoch: 1 | loss: 0.1253800
	speed: 0.0942s/iter; left time: 498.6388s
	iters: 500, epoch: 1 | loss: 0.1165671
	speed: 0.0934s/iter; left time: 484.6606s
Epoch: 1 cost time: 55.761313915252686
Epoch: 1, Steps: 569 | Train Loss: 0.1726432 Vali Loss: 0.2017748 Test Loss: 0.2574572
Validation loss decreased (inf --> 0.201775).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.1191556
	speed: 1.0589s/iter; left time: 5317.8119s
	iters: 200, epoch: 2 | loss: 0.1017234
	speed: 0.0958s/iter; left time: 471.6115s
	iters: 300, epoch: 2 | loss: 0.1079535
	speed: 0.0959s/iter; left time: 462.3839s
	iters: 400, epoch: 2 | loss: 0.1236112
	speed: 0.0930s/iter; left time: 438.9379s
	iters: 500, epoch: 2 | loss: 0.1005330
	speed: 0.0937s/iter; left time: 433.2076s
Epoch: 2 cost time: 55.29206895828247
Epoch: 2, Steps: 569 | Train Loss: 0.1079779 Vali Loss: 0.2022398 Test Loss: 0.2601853
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.0963701
	speed: 1.0816s/iter; left time: 4816.4366s
	iters: 200, epoch: 3 | loss: 0.0995646
	speed: 0.0956s/iter; left time: 415.9570s
	iters: 300, epoch: 3 | loss: 0.0950153
	speed: 0.0962s/iter; left time: 408.9680s
	iters: 400, epoch: 3 | loss: 0.0940905
	speed: 0.0949s/iter; left time: 394.0338s
	iters: 500, epoch: 3 | loss: 0.0984176
	speed: 0.0947s/iter; left time: 383.7636s
Epoch: 3 cost time: 55.493919134140015
Epoch: 3, Steps: 569 | Train Loss: 0.0959590 Vali Loss: 0.2051796 Test Loss: 0.2627898
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.0966361
	speed: 1.0871s/iter; left time: 4222.1710s
	iters: 200, epoch: 4 | loss: 0.0915488
	speed: 0.0943s/iter; left time: 356.6865s
	iters: 300, epoch: 4 | loss: 0.0925528
	speed: 0.0948s/iter; left time: 349.1084s
	iters: 400, epoch: 4 | loss: 0.0938464
	speed: 0.0941s/iter; left time: 337.3637s
	iters: 500, epoch: 4 | loss: 0.0890031
	speed: 0.0937s/iter; left time: 326.5046s
Epoch: 4 cost time: 55.62821173667908
Epoch: 4, Steps: 569 | Train Loss: 0.0916654 Vali Loss: 0.2049356 Test Loss: 0.2626283
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.0926389
	speed: 1.0132s/iter; left time: 3358.6110s
	iters: 200, epoch: 5 | loss: 0.0943194
	speed: 0.0946s/iter; left time: 304.0754s
	iters: 300, epoch: 5 | loss: 0.0918485
	speed: 0.0951s/iter; left time: 296.1514s
	iters: 400, epoch: 5 | loss: 0.0879129
	speed: 0.0953s/iter; left time: 287.4307s
	iters: 500, epoch: 5 | loss: 0.0916976
	speed: 0.0950s/iter; left time: 276.8265s
Epoch: 5 cost time: 56.32659196853638
Epoch: 5, Steps: 569 | Train Loss: 0.0894877 Vali Loss: 0.2091959 Test Loss: 0.2667411
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.0943527
	speed: 1.0957s/iter; left time: 3008.9185s
	iters: 200, epoch: 6 | loss: 0.0904916
	speed: 0.1004s/iter; left time: 265.7107s
	iters: 300, epoch: 6 | loss: 0.0859032
	speed: 0.0976s/iter; left time: 248.3913s
	iters: 400, epoch: 6 | loss: 0.0902601
	speed: 0.0982s/iter; left time: 240.0976s
	iters: 500, epoch: 6 | loss: 0.0865008
	speed: 0.0985s/iter; left time: 231.1055s
Epoch: 6 cost time: 58.06887340545654
Epoch: 6, Steps: 569 | Train Loss: 0.0882976 Vali Loss: 0.2110181 Test Loss: 0.2669742
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.0884277
	speed: 1.0976s/iter; left time: 2389.5770s
	iters: 200, epoch: 7 | loss: 0.0901727
	speed: 0.0944s/iter; left time: 196.1108s
	iters: 300, epoch: 7 | loss: 0.0878287
	speed: 0.0939s/iter; left time: 185.6940s
	iters: 400, epoch: 7 | loss: 0.0881225
	speed: 0.0937s/iter; left time: 175.8715s
	iters: 500, epoch: 7 | loss: 0.0851725
	speed: 0.0948s/iter; left time: 168.4356s
Epoch: 7 cost time: 55.37090587615967
Epoch: 7, Steps: 569 | Train Loss: 0.0876650 Vali Loss: 0.2103075 Test Loss: 0.2673793
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.0848123
	speed: 1.0902s/iter; left time: 1753.0438s
	iters: 200, epoch: 8 | loss: 0.0898085
	speed: 0.0949s/iter; left time: 143.1576s
	iters: 300, epoch: 8 | loss: 0.0843863
	speed: 0.0957s/iter; left time: 134.7134s
	iters: 400, epoch: 8 | loss: 0.0911907
	speed: 0.0951s/iter; left time: 124.3336s
	iters: 500, epoch: 8 | loss: 0.0915943
	speed: 0.0946s/iter; left time: 114.3308s
Epoch: 8 cost time: 55.627036809921265
Epoch: 8, Steps: 569 | Train Loss: 0.0873149 Vali Loss: 0.2106911 Test Loss: 0.2676215
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 0.0864386
	speed: 1.0595s/iter; left time: 1100.7942s
	iters: 200, epoch: 9 | loss: 0.0899287
	speed: 0.0924s/iter; left time: 86.7808s
	iters: 300, epoch: 9 | loss: 0.0869110
	speed: 0.0931s/iter; left time: 78.1316s
	iters: 400, epoch: 9 | loss: 0.0904961
	speed: 0.0945s/iter; left time: 69.8045s
	iters: 500, epoch: 9 | loss: 0.0857548
	speed: 0.0931s/iter; left time: 59.4914s
Epoch: 9 cost time: 54.750757694244385
Epoch: 9, Steps: 569 | Train Loss: 0.0871470 Vali Loss: 0.2114635 Test Loss: 0.2679842
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 0.0873763
	speed: 1.0478s/iter; left time: 492.4711s
	iters: 200, epoch: 10 | loss: 0.0847297
	speed: 0.0930s/iter; left time: 34.4246s
	iters: 300, epoch: 10 | loss: 0.0848159
	speed: 0.0925s/iter; left time: 24.9782s
	iters: 400, epoch: 10 | loss: 0.0837380
	speed: 0.0942s/iter; left time: 16.0130s
	iters: 500, epoch: 10 | loss: 0.0840379
	speed: 0.0941s/iter; left time: 6.5859s
Epoch: 10 cost time: 54.95055103302002
Epoch: 10, Steps: 569 | Train Loss: 0.0870466 Vali Loss: 0.2116606 Test Loss: 0.2682207
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.953125e-06
>>>>>>>testing : ECL_96_96_29_emb_256_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (5165, 1, 96, 321) (5165, 1, 96, 321)
test shape: (5165, 96, 321) (5165, 96, 321)
mse:0.25745752453804016, mae:0.3514529764652252
Args in experiment:
Namespace(is_training=1, model_id='ECL_96_96_30_emb_256', model='xLSTM', data='custom', root_path='./data/electricity/', data_path='/input-data/electricity.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, enc_in=321, dec_in=7, c_out=321, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.5, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=50, batch_size=16, patience=10, learning_rate=0.0005, des='test', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, use_norm=True, partial_start_index=0, hidden_size=512, num_layers=2, mark_enc_in=4, embedding_dim=256, weight_decay=1e-05, kernal_size=7, num_heads_xlstm=4, qkv_proj_blocksize=2, proj_factor=1.3, num_blocks=2, slstm_at=1, grad_clip_norm=5.0, d_state=16, d_conv=4, expand=2)
Use GPU: cuda:0
{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-L/usr/local/cuda/lib', '-lcublas'], 'extra_cflags': ['-DSLSTM_HIDDEN_SIZE=256', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__'], 'extra_cuda_cflags': ['-Xptxas="-v"', '-gencode', 'arch=compute_80,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=256', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__']}
Using /home/thetayne/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/thetayne/.cache/torch_extensions/py310_cu121/slstm_HS256BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0/build.ninja...
Building extension module slstm_HS256BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module slstm_HS256BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
>>>>>>>start training : ECL_96_96_30_emb_256_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 18221
val 2537
test 5165
	iters: 100, epoch: 1 | loss: 0.3187210
	speed: 0.0492s/iter; left time: 2792.0851s
	iters: 200, epoch: 1 | loss: 0.2484150
	speed: 0.0262s/iter; left time: 1484.7841s
	iters: 300, epoch: 1 | loss: 0.2283831
	speed: 0.0256s/iter; left time: 1450.1044s
	iters: 400, epoch: 1 | loss: 0.1772964
	speed: 0.0267s/iter; left time: 1509.5576s
	iters: 500, epoch: 1 | loss: 0.1716780
	speed: 0.0277s/iter; left time: 1561.3594s
	iters: 600, epoch: 1 | loss: 0.1611816
	speed: 0.0277s/iter; left time: 1560.4243s
	iters: 700, epoch: 1 | loss: 0.1759060
	speed: 0.0278s/iter; left time: 1564.8333s
	iters: 800, epoch: 1 | loss: 0.1698430
	speed: 0.0275s/iter; left time: 1544.0704s
	iters: 900, epoch: 1 | loss: 0.1540132
	speed: 0.0285s/iter; left time: 1594.0755s
	iters: 1000, epoch: 1 | loss: 0.1571365
	speed: 0.0277s/iter; left time: 1547.4778s
	iters: 1100, epoch: 1 | loss: 0.1488647
	speed: 0.0283s/iter; left time: 1579.0793s
Epoch: 1 cost time: 33.190423250198364
Epoch: 1, Steps: 1138 | Train Loss: 0.2143717 Vali Loss: 0.1990095 Test Loss: 0.2685800
Validation loss decreased (inf --> 0.199010).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.1447342
	speed: 0.5182s/iter; left time: 28842.1782s
	iters: 200, epoch: 2 | loss: 0.1475789
	speed: 0.0241s/iter; left time: 1337.7431s
	iters: 300, epoch: 2 | loss: 0.1409869
	speed: 0.0241s/iter; left time: 1334.3308s
	iters: 400, epoch: 2 | loss: 0.1464530
	speed: 0.0250s/iter; left time: 1383.1785s
	iters: 500, epoch: 2 | loss: 0.1369028
	speed: 0.0264s/iter; left time: 1457.7966s
	iters: 600, epoch: 2 | loss: 0.1557553
	speed: 0.0259s/iter; left time: 1426.4758s
	iters: 700, epoch: 2 | loss: 0.1418545
	speed: 0.0249s/iter; left time: 1372.0475s
	iters: 800, epoch: 2 | loss: 0.1522284
	speed: 0.0259s/iter; left time: 1425.6016s
	iters: 900, epoch: 2 | loss: 0.1319175
	speed: 0.0271s/iter; left time: 1485.1988s
	iters: 1000, epoch: 2 | loss: 0.1369596
	speed: 0.0277s/iter; left time: 1518.1594s
	iters: 1100, epoch: 2 | loss: 0.1466912
	speed: 0.0283s/iter; left time: 1545.6661s
Epoch: 2 cost time: 30.83259344100952
Epoch: 2, Steps: 1138 | Train Loss: 0.1427969 Vali Loss: 0.1933027 Test Loss: 0.2682157
Validation loss decreased (0.199010 --> 0.193303).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.1364282
	speed: 0.5694s/iter; left time: 31047.0758s
	iters: 200, epoch: 3 | loss: 0.1339497
	speed: 0.0256s/iter; left time: 1393.1375s
	iters: 300, epoch: 3 | loss: 0.1263265
	speed: 0.0260s/iter; left time: 1410.1927s
	iters: 400, epoch: 3 | loss: 0.1597210
	speed: 0.0250s/iter; left time: 1356.6863s
	iters: 500, epoch: 3 | loss: 0.1385047
	speed: 0.0267s/iter; left time: 1444.2646s
	iters: 600, epoch: 3 | loss: 0.1339818
	speed: 0.0273s/iter; left time: 1476.4297s
	iters: 700, epoch: 3 | loss: 0.1303654
	speed: 0.0284s/iter; left time: 1529.6492s
	iters: 800, epoch: 3 | loss: 0.1323566
	speed: 0.0277s/iter; left time: 1488.2748s
	iters: 900, epoch: 3 | loss: 0.1390451
	speed: 0.0272s/iter; left time: 1461.4817s
	iters: 1000, epoch: 3 | loss: 0.1373149
	speed: 0.0272s/iter; left time: 1459.9026s
	iters: 1100, epoch: 3 | loss: 0.1293198
	speed: 0.0282s/iter; left time: 1507.9956s
Epoch: 3 cost time: 32.20472002029419
Epoch: 3, Steps: 1138 | Train Loss: 0.1354132 Vali Loss: 0.2001417 Test Loss: 0.2694455
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.1464637
	speed: 0.5761s/iter; left time: 30754.6770s
	iters: 200, epoch: 4 | loss: 0.1314730
	speed: 0.0243s/iter; left time: 1295.7006s
	iters: 300, epoch: 4 | loss: 0.1378114
	speed: 0.0272s/iter; left time: 1446.2070s
	iters: 400, epoch: 4 | loss: 0.1289233
	speed: 0.0277s/iter; left time: 1468.4725s
	iters: 500, epoch: 4 | loss: 0.1255292
	speed: 0.0270s/iter; left time: 1429.0189s
	iters: 600, epoch: 4 | loss: 0.1301251
	speed: 0.0280s/iter; left time: 1483.4755s
	iters: 700, epoch: 4 | loss: 0.1332327
	speed: 0.0273s/iter; left time: 1439.5092s
	iters: 800, epoch: 4 | loss: 0.1290912
	speed: 0.0281s/iter; left time: 1481.9859s
	iters: 900, epoch: 4 | loss: 0.1279628
	speed: 0.0280s/iter; left time: 1472.4832s
	iters: 1000, epoch: 4 | loss: 0.1284571
	speed: 0.0274s/iter; left time: 1437.8088s
	iters: 1100, epoch: 4 | loss: 0.1315449
	speed: 0.0276s/iter; left time: 1447.5385s
Epoch: 4 cost time: 32.3300986289978
Epoch: 4, Steps: 1138 | Train Loss: 0.1327978 Vali Loss: 0.2008300 Test Loss: 0.2703576
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.1335910
	speed: 0.5752s/iter; left time: 30051.0732s
	iters: 200, epoch: 5 | loss: 0.1215505
	speed: 0.0251s/iter; left time: 1308.1326s
	iters: 300, epoch: 5 | loss: 0.1350145
	speed: 0.0261s/iter; left time: 1356.7250s
	iters: 400, epoch: 5 | loss: 0.1357603
	speed: 0.0283s/iter; left time: 1471.3412s
	iters: 500, epoch: 5 | loss: 0.1371664
	speed: 0.0281s/iter; left time: 1457.9861s
	iters: 600, epoch: 5 | loss: 0.1318291
	speed: 0.0282s/iter; left time: 1459.8815s
	iters: 700, epoch: 5 | loss: 0.1388069
	speed: 0.0278s/iter; left time: 1436.9649s
	iters: 800, epoch: 5 | loss: 0.1198072
	speed: 0.0272s/iter; left time: 1403.3656s
	iters: 900, epoch: 5 | loss: 0.1395484
	speed: 0.0279s/iter; left time: 1437.9077s
	iters: 1000, epoch: 5 | loss: 0.1198005
	speed: 0.0281s/iter; left time: 1441.5314s
	iters: 1100, epoch: 5 | loss: 0.1256131
	speed: 0.0277s/iter; left time: 1419.9395s
Epoch: 5 cost time: 32.616196393966675
Epoch: 5, Steps: 1138 | Train Loss: 0.1315173 Vali Loss: 0.2013625 Test Loss: 0.2716657
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.1439510
	speed: 0.5603s/iter; left time: 28636.0116s
	iters: 200, epoch: 6 | loss: 0.1244210
	speed: 0.0246s/iter; left time: 1252.4768s
	iters: 300, epoch: 6 | loss: 0.1309037
	speed: 0.0252s/iter; left time: 1280.6818s
	iters: 400, epoch: 6 | loss: 0.1340483
	speed: 0.0253s/iter; left time: 1285.7558s
	iters: 500, epoch: 6 | loss: 0.1273834
	speed: 0.0250s/iter; left time: 1266.5795s
	iters: 600, epoch: 6 | loss: 0.1337383
	speed: 0.0250s/iter; left time: 1263.4730s
	iters: 700, epoch: 6 | loss: 0.1227760
	speed: 0.0243s/iter; left time: 1228.7322s
	iters: 800, epoch: 6 | loss: 0.1266524
	speed: 0.0254s/iter; left time: 1279.7942s
	iters: 900, epoch: 6 | loss: 0.1304137
	speed: 0.0256s/iter; left time: 1287.9214s
	iters: 1000, epoch: 6 | loss: 0.1368810
	speed: 0.0252s/iter; left time: 1265.4110s
	iters: 1100, epoch: 6 | loss: 0.1279942
	speed: 0.0251s/iter; left time: 1255.6921s
Epoch: 6 cost time: 30.116928815841675
Epoch: 6, Steps: 1138 | Train Loss: 0.1308619 Vali Loss: 0.2008709 Test Loss: 0.2723050
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.1327369
	speed: 0.5605s/iter; left time: 28007.5935s
	iters: 200, epoch: 7 | loss: 0.1265812
	speed: 0.0247s/iter; left time: 1231.4505s
	iters: 300, epoch: 7 | loss: 0.1229661
	speed: 0.0253s/iter; left time: 1257.3355s
	iters: 400, epoch: 7 | loss: 0.1322886
	speed: 0.0268s/iter; left time: 1332.6116s
	iters: 500, epoch: 7 | loss: 0.1257437
	speed: 0.0282s/iter; left time: 1395.6985s
	iters: 600, epoch: 7 | loss: 0.1308935
	speed: 0.0279s/iter; left time: 1381.7837s
	iters: 700, epoch: 7 | loss: 0.1256062
	speed: 0.0273s/iter; left time: 1346.7711s
	iters: 800, epoch: 7 | loss: 0.1359895
	speed: 0.0282s/iter; left time: 1391.4139s
	iters: 900, epoch: 7 | loss: 0.1308594
	speed: 0.0273s/iter; left time: 1343.2160s
	iters: 1000, epoch: 7 | loss: 0.1221268
	speed: 0.0277s/iter; left time: 1357.8944s
	iters: 1100, epoch: 7 | loss: 0.1275522
	speed: 0.0274s/iter; left time: 1340.9488s
Epoch: 7 cost time: 32.0779013633728
Epoch: 7, Steps: 1138 | Train Loss: 0.1304974 Vali Loss: 0.2009754 Test Loss: 0.2723483
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.1357396
	speed: 0.5668s/iter; left time: 27678.9892s
	iters: 200, epoch: 8 | loss: 0.1367937
	speed: 0.0250s/iter; left time: 1215.9803s
	iters: 300, epoch: 8 | loss: 0.1301288
	speed: 0.0266s/iter; left time: 1294.7389s
	iters: 400, epoch: 8 | loss: 0.1185740
	speed: 0.0281s/iter; left time: 1362.0976s
	iters: 500, epoch: 8 | loss: 0.1267336
	speed: 0.0277s/iter; left time: 1340.0642s
	iters: 600, epoch: 8 | loss: 0.1298145
	speed: 0.0278s/iter; left time: 1344.0380s
	iters: 700, epoch: 8 | loss: 0.1274513
	speed: 0.0279s/iter; left time: 1345.4393s
	iters: 800, epoch: 8 | loss: 0.1266800
	speed: 0.0277s/iter; left time: 1332.0562s
	iters: 900, epoch: 8 | loss: 0.1252237
	speed: 0.0284s/iter; left time: 1363.7603s
	iters: 1000, epoch: 8 | loss: 0.1405623
	speed: 0.0280s/iter; left time: 1343.8019s
	iters: 1100, epoch: 8 | loss: 0.1299167
	speed: 0.0275s/iter; left time: 1316.8881s
Epoch: 8 cost time: 32.44272065162659
Epoch: 8, Steps: 1138 | Train Loss: 0.1303173 Vali Loss: 0.2008503 Test Loss: 0.2728387
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.1284647
	speed: 0.5657s/iter; left time: 26983.2353s
	iters: 200, epoch: 9 | loss: 0.1312570
	speed: 0.0259s/iter; left time: 1232.6887s
	iters: 300, epoch: 9 | loss: 0.1330210
	speed: 0.0271s/iter; left time: 1286.5191s
	iters: 400, epoch: 9 | loss: 0.1351008
	speed: 0.0279s/iter; left time: 1322.4996s
	iters: 500, epoch: 9 | loss: 0.1352317
	speed: 0.0279s/iter; left time: 1319.5272s
	iters: 600, epoch: 9 | loss: 0.1377247
	speed: 0.0266s/iter; left time: 1255.0559s
	iters: 700, epoch: 9 | loss: 0.1383240
	speed: 0.0280s/iter; left time: 1319.8153s
	iters: 800, epoch: 9 | loss: 0.1325978
	speed: 0.0279s/iter; left time: 1312.7213s
	iters: 900, epoch: 9 | loss: 0.1164271
	speed: 0.0282s/iter; left time: 1321.0438s
	iters: 1000, epoch: 9 | loss: 0.1435633
	speed: 0.0268s/iter; left time: 1253.9233s
	iters: 1100, epoch: 9 | loss: 0.1385335
	speed: 0.0271s/iter; left time: 1267.7555s
Epoch: 9 cost time: 32.49527978897095
Epoch: 9, Steps: 1138 | Train Loss: 0.1302193 Vali Loss: 0.2002931 Test Loss: 0.2724138
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.1192421
	speed: 0.5609s/iter; left time: 26112.6298s
	iters: 200, epoch: 10 | loss: 0.1234482
	speed: 0.0255s/iter; left time: 1185.3749s
	iters: 300, epoch: 10 | loss: 0.1266049
	speed: 0.0259s/iter; left time: 1198.8145s
	iters: 400, epoch: 10 | loss: 0.1231621
	speed: 0.0263s/iter; left time: 1217.3409s
	iters: 500, epoch: 10 | loss: 0.1260930
	speed: 0.0274s/iter; left time: 1264.7950s
	iters: 600, epoch: 10 | loss: 0.1410034
	speed: 0.0276s/iter; left time: 1272.8954s
	iters: 700, epoch: 10 | loss: 0.1371353
	speed: 0.0281s/iter; left time: 1293.6008s
	iters: 800, epoch: 10 | loss: 0.1348460
	speed: 0.0275s/iter; left time: 1260.2850s
	iters: 900, epoch: 10 | loss: 0.1209543
	speed: 0.0273s/iter; left time: 1248.9556s
	iters: 1000, epoch: 10 | loss: 0.1313506
	speed: 0.0280s/iter; left time: 1279.0801s
	iters: 1100, epoch: 10 | loss: 0.1310570
	speed: 0.0275s/iter; left time: 1251.6395s
Epoch: 10 cost time: 32.23795008659363
Epoch: 10, Steps: 1138 | Train Loss: 0.1301767 Vali Loss: 0.2003615 Test Loss: 0.2727582
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.1230995
	speed: 0.5500s/iter; left time: 24979.5454s
	iters: 200, epoch: 11 | loss: 0.1321262
	speed: 0.0253s/iter; left time: 1148.7501s
	iters: 300, epoch: 11 | loss: 0.1252578
	speed: 0.0249s/iter; left time: 1128.0987s
	iters: 400, epoch: 11 | loss: 0.1288626
	speed: 0.0243s/iter; left time: 1096.5492s
	iters: 500, epoch: 11 | loss: 0.1236966
	speed: 0.0259s/iter; left time: 1165.8691s
	iters: 600, epoch: 11 | loss: 0.1433232
	speed: 0.0283s/iter; left time: 1273.2313s
	iters: 700, epoch: 11 | loss: 0.1250172
	speed: 0.0276s/iter; left time: 1236.3304s
	iters: 800, epoch: 11 | loss: 0.1327235
	speed: 0.0274s/iter; left time: 1224.5096s
	iters: 900, epoch: 11 | loss: 0.1273708
	speed: 0.0276s/iter; left time: 1232.7140s
	iters: 1000, epoch: 11 | loss: 0.1275195
	speed: 0.0276s/iter; left time: 1226.8983s
	iters: 1100, epoch: 11 | loss: 0.1224994
	speed: 0.0281s/iter; left time: 1246.3252s
Epoch: 11 cost time: 31.686357259750366
Epoch: 11, Steps: 1138 | Train Loss: 0.1301608 Vali Loss: 0.2001705 Test Loss: 0.2725767
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.1280041
	speed: 0.5556s/iter; left time: 24604.6054s
	iters: 200, epoch: 12 | loss: 0.1207683
	speed: 0.0244s/iter; left time: 1077.5402s
	iters: 300, epoch: 12 | loss: 0.1294698
	speed: 0.0250s/iter; left time: 1100.5330s
	iters: 400, epoch: 12 | loss: 0.1419965
	speed: 0.0260s/iter; left time: 1144.7136s
	iters: 500, epoch: 12 | loss: 0.1199475
	speed: 0.0280s/iter; left time: 1226.7023s
	iters: 600, epoch: 12 | loss: 0.1364281
	speed: 0.0277s/iter; left time: 1211.4972s
	iters: 700, epoch: 12 | loss: 0.1225693
	speed: 0.0273s/iter; left time: 1192.5217s
	iters: 800, epoch: 12 | loss: 0.1311896
	speed: 0.0274s/iter; left time: 1192.9912s
	iters: 900, epoch: 12 | loss: 0.1335256
	speed: 0.0269s/iter; left time: 1171.4923s
	iters: 1000, epoch: 12 | loss: 0.1277424
	speed: 0.0283s/iter; left time: 1227.1135s
	iters: 1100, epoch: 12 | loss: 0.1311933
	speed: 0.0277s/iter; left time: 1198.6225s
Epoch: 12 cost time: 31.8836350440979
Epoch: 12, Steps: 1138 | Train Loss: 0.1301564 Vali Loss: 0.2003892 Test Loss: 0.2727470
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : ECL_96_96_30_emb_256_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (5165, 1, 96, 321) (5165, 1, 96, 321)
test shape: (5165, 96, 321) (5165, 96, 321)
mse:0.26821544766426086, mae:0.3585520088672638
Args in experiment:
Namespace(is_training=1, model_id='ECL_96_96_31_emb_512', model='xLSTM', data='custom', root_path='./data/electricity/', data_path='/input-data/electricity.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, enc_in=321, dec_in=7, c_out=321, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=50, batch_size=32, patience=10, learning_rate=0.0005, des='test', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, use_norm=True, partial_start_index=0, hidden_size=512, num_layers=2, mark_enc_in=4, embedding_dim=512, weight_decay=1e-05, kernal_size=5, num_heads_xlstm=2, qkv_proj_blocksize=4, proj_factor=1.3, num_blocks=3, slstm_at=1, grad_clip_norm=0.5, d_state=16, d_conv=4, expand=2)
Use GPU: cuda:0
{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-L/usr/local/cuda/lib', '-lcublas'], 'extra_cflags': ['-DSLSTM_HIDDEN_SIZE=512', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=2', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__'], 'extra_cuda_cflags': ['-Xptxas="-v"', '-gencode', 'arch=compute_80,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=512', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=2', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__']}
Using /home/thetayne/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Creating extension directory /home/thetayne/.cache/torch_extensions/py310_cu121/slstm_HS512BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/thetayne/.cache/torch_extensions/py310_cu121/slstm_HS512BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0/build.ninja...
Building extension module slstm_HS512BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[1/8] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output cuda_error.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS512BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=512 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=2 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/util/cuda_error.cu -o cuda_error.cuda.o 
ptxas info    : 0 bytes gmem
[2/8] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output slstm_pointwise.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS512BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=512 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=2 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/cuda/slstm_pointwise.cu -o slstm_pointwise.cuda.o 
ptxas info    : 0 bytes gmem
ptxas info    : Compiling entry function '_ZN5slstm21SLSTMPointwiseForwardILb0EEEviiiPK13__nv_bfloat16S3_PKfS3_jPS1_jS6_S6_' for 'sm_80'
ptxas info    : Function properties for _ZN5slstm21SLSTMPointwiseForwardILb0EEEviiiPK13__nv_bfloat16S3_PKfS3_jPS1_jS6_S6_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 32 registers, 440 bytes cmem[0]
ptxas info    : Compiling entry function '_ZN5slstm21SLSTMPointwiseForwardILb1EEEviiiPK13__nv_bfloat16S3_PKfS3_jPS1_jS6_S6_' for 'sm_80'
ptxas info    : Function properties for _ZN5slstm21SLSTMPointwiseForwardILb1EEEviiiPK13__nv_bfloat16S3_PKfS3_jPS1_jS6_S6_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 32 registers, 440 bytes cmem[0]
ptxas info    : Compiling entry function '_ZN5slstm22SLSTMPointwiseBackwardEiiiPK13__nv_bfloat16jS2_S2_PKfS2_jS2_jPS0_jS5_S5_S5_' for 'sm_80'
ptxas info    : Function properties for _ZN5slstm22SLSTMPointwiseBackwardEiiiPK13__nv_bfloat16jS2_S2_PKfS2_jS2_jPS0_jS5_S5_S5_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 32 registers, 480 bytes cmem[0]
[3/8] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output slstm_backward_cut.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS512BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=512 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=2 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/cuda/slstm_backward_cut.cu -o slstm_backward_cut.cuda.o 
ptxas info    : 0 bytes gmem
ptxas info    : Compiling entry function '_ZN54_GLOBAL__N__2085b59d_21_slstm_backward_cut_cu_1c2c4d0129gradientBiasAggregationKernelEjjjjjjPK13__nv_bfloat16S2_Pf' for 'sm_80'
ptxas info    : Function properties for _ZN54_GLOBAL__N__2085b59d_21_slstm_backward_cut_cu_1c2c4d0129gradientBiasAggregationKernelEjjjjjjPK13__nv_bfloat16S2_Pf
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 32 registers, 400 bytes cmem[0]
[4/8] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output slstm_forward.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS512BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=512 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=2 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/cuda/slstm_forward.cu -o slstm_forward.cuda.o 
ptxas info    : 0 bytes gmem
[5/8] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output blas.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS512BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=512 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=2 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/util/blas.cu -o blas.cuda.o 
ptxas info    : 0 bytes gmem
ptxas info    : Compiling entry function '_Z10initKernelI13__nv_bfloat16EvPT_iS1_' for 'sm_80'
ptxas info    : Function properties for _Z10initKernelI13__nv_bfloat16EvPT_iS1_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 8 registers, 366 bytes cmem[0]
ptxas info    : Compiling entry function '_Z10initKernelI6__halfEvPT_iS1_' for 'sm_80'
ptxas info    : Function properties for _Z10initKernelI6__halfEvPT_iS1_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 8 registers, 366 bytes cmem[0]
ptxas info    : Compiling entry function '_Z10initKernelIfEvPT_iS0_' for 'sm_80'
ptxas info    : Function properties for _Z10initKernelIfEvPT_iS0_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 8 registers, 368 bytes cmem[0]
ptxas info    : Compiling entry function '_Z10initKernelIdEvPT_iS0_' for 'sm_80'
ptxas info    : Function properties for _Z10initKernelIdEvPT_iS0_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 8 registers, 376 bytes cmem[0]
[6/8] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output slstm_backward.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS512BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=512 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=2 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/cuda/slstm_backward.cu -o slstm_backward.cuda.o 
ptxas info    : 0 bytes gmem
ptxas info    : Compiling entry function '_ZN50_GLOBAL__N__d983f13f_17_slstm_backward_cu_3639fa5e29gradientBiasAggregationKernelEjjjjjjPK13__nv_bfloat16S2_Pf' for 'sm_80'
ptxas info    : Function properties for _ZN50_GLOBAL__N__d983f13f_17_slstm_backward_cu_3639fa5e29gradientBiasAggregationKernelEjjjjjjPK13__nv_bfloat16S2_Pf
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 32 registers, 400 bytes cmem[0]
[7/8] c++ -MMD -MF slstm.o.d -DTORCH_EXTENSION_NAME=slstm_HS512BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -DSLSTM_HIDDEN_SIZE=512 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=2 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/cuda/slstm.cc -o slstm.o 
[8/8] c++ slstm.o slstm_forward.cuda.o slstm_backward.cuda.o slstm_backward_cut.cuda.o slstm_pointwise.cuda.o blas.cuda.o cuda_error.cuda.o -shared -L/usr/local/cuda/lib -lcublas -L/usr/local/lib/python3.10/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o slstm_HS512BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0.so
Loading extension module slstm_HS512BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
>>>>>>>start training : ECL_96_96_31_emb_512_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 18221
val 2537
test 5165
	iters: 100, epoch: 1 | loss: 0.1771947
	speed: 0.0757s/iter; left time: 2147.2545s
	iters: 200, epoch: 1 | loss: 0.1178746
	speed: 0.0525s/iter; left time: 1483.8837s
	iters: 300, epoch: 1 | loss: 0.0976196
	speed: 0.0526s/iter; left time: 1482.1405s
	iters: 400, epoch: 1 | loss: 0.0856926
	speed: 0.0520s/iter; left time: 1459.6006s
	iters: 500, epoch: 1 | loss: 0.0751497
	speed: 0.0523s/iter; left time: 1460.9201s
Epoch: 1 cost time: 31.934853076934814
Epoch: 1, Steps: 569 | Train Loss: 0.1314792 Vali Loss: 0.2167983 Test Loss: 0.2871776
Validation loss decreased (inf --> 0.216798).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.0638063
	speed: 0.6433s/iter; left time: 17872.7072s
	iters: 200, epoch: 2 | loss: 0.0608557
	speed: 0.0516s/iter; left time: 1428.5802s
	iters: 300, epoch: 2 | loss: 0.0597639
	speed: 0.0519s/iter; left time: 1431.0801s
	iters: 400, epoch: 2 | loss: 0.0579162
	speed: 0.0525s/iter; left time: 1442.4477s
	iters: 500, epoch: 2 | loss: 0.0522800
	speed: 0.0520s/iter; left time: 1422.9655s
Epoch: 2 cost time: 30.890337228775024
Epoch: 2, Steps: 569 | Train Loss: 0.0593325 Vali Loss: 0.2175225 Test Loss: 0.2805620
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.0458746
	speed: 0.6186s/iter; left time: 16833.7817s
	iters: 200, epoch: 3 | loss: 0.0453960
	speed: 0.0515s/iter; left time: 1395.8488s
	iters: 300, epoch: 3 | loss: 0.0435096
	speed: 0.0523s/iter; left time: 1412.0476s
	iters: 400, epoch: 3 | loss: 0.0440759
	speed: 0.0524s/iter; left time: 1410.5949s
	iters: 500, epoch: 3 | loss: 0.0427349
	speed: 0.0518s/iter; left time: 1389.3756s
Epoch: 3 cost time: 30.750845670700073
Epoch: 3, Steps: 569 | Train Loss: 0.0451270 Vali Loss: 0.2241810 Test Loss: 0.2913397
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.0407701
	speed: 0.6504s/iter; left time: 17328.9377s
	iters: 200, epoch: 4 | loss: 0.0384384
	speed: 0.0524s/iter; left time: 1391.4681s
	iters: 300, epoch: 4 | loss: 0.0390423
	speed: 0.0522s/iter; left time: 1379.3327s
	iters: 400, epoch: 4 | loss: 0.0389994
	speed: 0.0527s/iter; left time: 1387.0957s
	iters: 500, epoch: 4 | loss: 0.0394594
	speed: 0.0527s/iter; left time: 1382.7155s
Epoch: 4 cost time: 31.29653573036194
Epoch: 4, Steps: 569 | Train Loss: 0.0400831 Vali Loss: 0.2299935 Test Loss: 0.2995542
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.0387300
	speed: 0.6315s/iter; left time: 16467.6184s
	iters: 200, epoch: 5 | loss: 0.0384764
	speed: 0.0517s/iter; left time: 1341.6255s
	iters: 300, epoch: 5 | loss: 0.0378468
	speed: 0.0516s/iter; left time: 1335.2485s
	iters: 400, epoch: 5 | loss: 0.0367877
	speed: 0.0513s/iter; left time: 1323.0583s
	iters: 500, epoch: 5 | loss: 0.0378565
	speed: 0.0517s/iter; left time: 1326.2068s
Epoch: 5 cost time: 30.672068119049072
Epoch: 5, Steps: 569 | Train Loss: 0.0376883 Vali Loss: 0.2318810 Test Loss: 0.3026065
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.0355498
	speed: 0.6406s/iter; left time: 16339.9811s
	iters: 200, epoch: 6 | loss: 0.0373542
	speed: 0.0519s/iter; left time: 1319.7572s
	iters: 300, epoch: 6 | loss: 0.0357821
	speed: 0.0521s/iter; left time: 1317.5814s
	iters: 400, epoch: 6 | loss: 0.0369900
	speed: 0.0524s/iter; left time: 1320.0037s
	iters: 500, epoch: 6 | loss: 0.0346650
	speed: 0.0519s/iter; left time: 1304.0754s
Epoch: 6 cost time: 30.99074959754944
Epoch: 6, Steps: 569 | Train Loss: 0.0364462 Vali Loss: 0.2335777 Test Loss: 0.3044368
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.0361734
	speed: 0.6366s/iter; left time: 15874.5705s
	iters: 200, epoch: 7 | loss: 0.0351021
	speed: 0.0516s/iter; left time: 1281.7357s
	iters: 300, epoch: 7 | loss: 0.0372574
	speed: 0.0523s/iter; left time: 1294.9429s
	iters: 400, epoch: 7 | loss: 0.0352547
	speed: 0.0520s/iter; left time: 1281.0592s
	iters: 500, epoch: 7 | loss: 0.0367505
	speed: 0.0523s/iter; left time: 1284.0729s
Epoch: 7 cost time: 30.921705961227417
Epoch: 7, Steps: 569 | Train Loss: 0.0357764 Vali Loss: 0.2349718 Test Loss: 0.3055876
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.0350613
	speed: 0.6440s/iter; left time: 15692.8180s
	iters: 200, epoch: 8 | loss: 0.0365853
	speed: 0.0509s/iter; left time: 1235.5195s
	iters: 300, epoch: 8 | loss: 0.0344468
	speed: 0.0526s/iter; left time: 1272.0100s
	iters: 400, epoch: 8 | loss: 0.0360427
	speed: 0.0528s/iter; left time: 1269.8353s
	iters: 500, epoch: 8 | loss: 0.0351478
	speed: 0.0515s/iter; left time: 1234.2329s
Epoch: 8 cost time: 30.856895208358765
Epoch: 8, Steps: 569 | Train Loss: 0.0354177 Vali Loss: 0.2357922 Test Loss: 0.3061571
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.0342849
	speed: 0.6389s/iter; left time: 15204.6026s
	iters: 200, epoch: 9 | loss: 0.0350045
	speed: 0.0519s/iter; left time: 1228.8987s
	iters: 300, epoch: 9 | loss: 0.0343326
	speed: 0.0520s/iter; left time: 1227.8456s
	iters: 400, epoch: 9 | loss: 0.0359543
	speed: 0.0529s/iter; left time: 1244.0927s
	iters: 500, epoch: 9 | loss: 0.0338955
	speed: 0.0528s/iter; left time: 1234.6610s
Epoch: 9 cost time: 31.109249591827393
Epoch: 9, Steps: 569 | Train Loss: 0.0352239 Vali Loss: 0.2357887 Test Loss: 0.3064375
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.0352724
	speed: 0.6381s/iter; left time: 14822.6123s
	iters: 200, epoch: 10 | loss: 0.0345131
	speed: 0.0509s/iter; left time: 1178.1285s
	iters: 300, epoch: 10 | loss: 0.0367176
	speed: 0.0519s/iter; left time: 1195.5816s
	iters: 400, epoch: 10 | loss: 0.0353476
	speed: 0.0516s/iter; left time: 1184.1082s
	iters: 500, epoch: 10 | loss: 0.0353848
	speed: 0.0518s/iter; left time: 1182.8018s
Epoch: 10 cost time: 30.830359935760498
Epoch: 10, Steps: 569 | Train Loss: 0.0351248 Vali Loss: 0.2359943 Test Loss: 0.3067750
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.0360448
	speed: 0.6300s/iter; left time: 14276.3397s
	iters: 200, epoch: 11 | loss: 0.0361846
	speed: 0.0515s/iter; left time: 1162.4430s
	iters: 300, epoch: 11 | loss: 0.0342046
	speed: 0.0520s/iter; left time: 1167.0185s
	iters: 400, epoch: 11 | loss: 0.0342538
	speed: 0.0509s/iter; left time: 1138.0703s
	iters: 500, epoch: 11 | loss: 0.0350869
	speed: 0.0514s/iter; left time: 1144.0100s
Epoch: 11 cost time: 30.69383955001831
Epoch: 11, Steps: 569 | Train Loss: 0.0350619 Vali Loss: 0.2358874 Test Loss: 0.3068333
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : ECL_96_96_31_emb_512_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (5165, 1, 96, 321) (5165, 1, 96, 321)
test shape: (5165, 96, 321) (5165, 96, 321)
mse:0.28717824816703796, mae:0.3737681806087494
Args in experiment:
Namespace(is_training=1, model_id='ECL_96_96_32_emb_512', model='xLSTM', data='custom', root_path='./data/electricity/', data_path='/input-data/electricity.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, enc_in=321, dec_in=7, c_out=321, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.5, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=50, batch_size=16, patience=10, learning_rate=0.0005, des='test', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, use_norm=True, partial_start_index=0, hidden_size=512, num_layers=2, mark_enc_in=4, embedding_dim=512, weight_decay=1e-05, kernal_size=7, num_heads_xlstm=8, qkv_proj_blocksize=2, proj_factor=1.3, num_blocks=7, slstm_at=1, grad_clip_norm=5.0, d_state=16, d_conv=4, expand=2)
Use GPU: cuda:0
{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-L/usr/local/cuda/lib', '-lcublas'], 'extra_cflags': ['-DSLSTM_HIDDEN_SIZE=512', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=8', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__'], 'extra_cuda_cflags': ['-Xptxas="-v"', '-gencode', 'arch=compute_80,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=512', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=8', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__']}
Using /home/thetayne/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Creating extension directory /home/thetayne/.cache/torch_extensions/py310_cu121/slstm_HS512BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/thetayne/.cache/torch_extensions/py310_cu121/slstm_HS512BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0/build.ninja...
Building extension module slstm_HS512BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[1/8] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output cuda_error.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS512BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=512 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=8 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/util/cuda_error.cu -o cuda_error.cuda.o 
ptxas info    : 0 bytes gmem
[2/8] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output slstm_pointwise.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS512BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=512 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=8 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/cuda/slstm_pointwise.cu -o slstm_pointwise.cuda.o 
ptxas info    : 0 bytes gmem
ptxas info    : Compiling entry function '_ZN5slstm21SLSTMPointwiseForwardILb0EEEviiiPK13__nv_bfloat16S3_PKfS3_jPS1_jS6_S6_' for 'sm_80'
ptxas info    : Function properties for _ZN5slstm21SLSTMPointwiseForwardILb0EEEviiiPK13__nv_bfloat16S3_PKfS3_jPS1_jS6_S6_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 32 registers, 440 bytes cmem[0]
ptxas info    : Compiling entry function '_ZN5slstm21SLSTMPointwiseForwardILb1EEEviiiPK13__nv_bfloat16S3_PKfS3_jPS1_jS6_S6_' for 'sm_80'
ptxas info    : Function properties for _ZN5slstm21SLSTMPointwiseForwardILb1EEEviiiPK13__nv_bfloat16S3_PKfS3_jPS1_jS6_S6_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 32 registers, 440 bytes cmem[0]
ptxas info    : Compiling entry function '_ZN5slstm22SLSTMPointwiseBackwardEiiiPK13__nv_bfloat16jS2_S2_PKfS2_jS2_jPS0_jS5_S5_S5_' for 'sm_80'
ptxas info    : Function properties for _ZN5slstm22SLSTMPointwiseBackwardEiiiPK13__nv_bfloat16jS2_S2_PKfS2_jS2_jPS0_jS5_S5_S5_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 32 registers, 480 bytes cmem[0]
[3/8] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output slstm_forward.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS512BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=512 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=8 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/cuda/slstm_forward.cu -o slstm_forward.cuda.o 
ptxas info    : 0 bytes gmem
[4/8] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output slstm_backward_cut.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS512BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=512 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=8 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/cuda/slstm_backward_cut.cu -o slstm_backward_cut.cuda.o 
ptxas info    : 0 bytes gmem
ptxas info    : Compiling entry function '_ZN54_GLOBAL__N__2085b59d_21_slstm_backward_cut_cu_1c2c4d0129gradientBiasAggregationKernelEjjjjjjPK13__nv_bfloat16S2_Pf' for 'sm_80'
ptxas info    : Function properties for _ZN54_GLOBAL__N__2085b59d_21_slstm_backward_cut_cu_1c2c4d0129gradientBiasAggregationKernelEjjjjjjPK13__nv_bfloat16S2_Pf
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 32 registers, 400 bytes cmem[0]
[5/8] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output slstm_backward.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS512BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=512 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=8 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/cuda/slstm_backward.cu -o slstm_backward.cuda.o 
ptxas info    : 0 bytes gmem
ptxas info    : Compiling entry function '_ZN50_GLOBAL__N__d983f13f_17_slstm_backward_cu_3639fa5e29gradientBiasAggregationKernelEjjjjjjPK13__nv_bfloat16S2_Pf' for 'sm_80'
ptxas info    : Function properties for _ZN50_GLOBAL__N__d983f13f_17_slstm_backward_cu_3639fa5e29gradientBiasAggregationKernelEjjjjjjPK13__nv_bfloat16S2_Pf
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 32 registers, 400 bytes cmem[0]
[6/8] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output blas.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS512BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=512 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=8 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/util/blas.cu -o blas.cuda.o 
ptxas info    : 0 bytes gmem
ptxas info    : Compiling entry function '_Z10initKernelI13__nv_bfloat16EvPT_iS1_' for 'sm_80'
ptxas info    : Function properties for _Z10initKernelI13__nv_bfloat16EvPT_iS1_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 8 registers, 366 bytes cmem[0]
ptxas info    : Compiling entry function '_Z10initKernelI6__halfEvPT_iS1_' for 'sm_80'
ptxas info    : Function properties for _Z10initKernelI6__halfEvPT_iS1_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 8 registers, 366 bytes cmem[0]
ptxas info    : Compiling entry function '_Z10initKernelIfEvPT_iS0_' for 'sm_80'
ptxas info    : Function properties for _Z10initKernelIfEvPT_iS0_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 8 registers, 368 bytes cmem[0]
ptxas info    : Compiling entry function '_Z10initKernelIdEvPT_iS0_' for 'sm_80'
ptxas info    : Function properties for _Z10initKernelIdEvPT_iS0_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 8 registers, 376 bytes cmem[0]
[7/8] c++ -MMD -MF slstm.o.d -DTORCH_EXTENSION_NAME=slstm_HS512BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -DSLSTM_HIDDEN_SIZE=512 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=8 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/cuda/slstm.cc -o slstm.o 
[8/8] c++ slstm.o slstm_forward.cuda.o slstm_backward.cuda.o slstm_backward_cut.cuda.o slstm_pointwise.cuda.o blas.cuda.o cuda_error.cuda.o -shared -L/usr/local/cuda/lib -lcublas -L/usr/local/lib/python3.10/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o slstm_HS512BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0.so
Loading extension module slstm_HS512BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
>>>>>>>start training : ECL_96_96_32_emb_512_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 18221
val 2537
test 5165
	iters: 100, epoch: 1 | loss: 0.2656609
	speed: 0.1045s/iter; left time: 5937.9394s
	iters: 200, epoch: 1 | loss: 0.1809652
	speed: 0.0848s/iter; left time: 4810.7887s
	iters: 300, epoch: 1 | loss: 0.1589485
	speed: 0.0863s/iter; left time: 4882.6969s
	iters: 400, epoch: 1 | loss: 0.1473885
	speed: 0.0856s/iter; left time: 4835.8818s
	iters: 500, epoch: 1 | loss: 0.1434212
	speed: 0.0850s/iter; left time: 4796.2653s
	iters: 600, epoch: 1 | loss: 0.1209388
	speed: 0.0852s/iter; left time: 4797.6966s
	iters: 700, epoch: 1 | loss: 0.1273544
	speed: 0.0852s/iter; left time: 4787.8617s
	iters: 800, epoch: 1 | loss: 0.1221512
	speed: 0.0833s/iter; left time: 4670.7930s
	iters: 900, epoch: 1 | loss: 0.1122877
	speed: 0.0859s/iter; left time: 4809.8826s
	iters: 1000, epoch: 1 | loss: 0.1139513
	speed: 0.0847s/iter; left time: 4732.3684s
	iters: 1100, epoch: 1 | loss: 0.1143965
	speed: 0.0851s/iter; left time: 4745.9160s
Epoch: 1 cost time: 98.72432804107666
Epoch: 1, Steps: 1138 | Train Loss: 0.1658176 Vali Loss: 0.2097513 Test Loss: 0.2599869
Validation loss decreased (inf --> 0.209751).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.1050856
	speed: 1.0664s/iter; left time: 59361.0898s
	iters: 200, epoch: 2 | loss: 0.1106717
	speed: 0.0847s/iter; left time: 4704.5307s
	iters: 300, epoch: 2 | loss: 0.1012504
	speed: 0.0848s/iter; left time: 4704.8318s
	iters: 400, epoch: 2 | loss: 0.1107166
	speed: 0.0847s/iter; left time: 4689.3101s
	iters: 500, epoch: 2 | loss: 0.1129161
	speed: 0.0836s/iter; left time: 4622.1502s
	iters: 600, epoch: 2 | loss: 0.1148721
	speed: 0.0834s/iter; left time: 4600.2201s
	iters: 700, epoch: 2 | loss: 0.1188833
	speed: 0.0824s/iter; left time: 4539.3244s
	iters: 800, epoch: 2 | loss: 0.1138963
	speed: 0.0834s/iter; left time: 4586.1860s
	iters: 900, epoch: 2 | loss: 0.1141779
	speed: 0.0824s/iter; left time: 4519.9412s
	iters: 1000, epoch: 2 | loss: 0.1005339
	speed: 0.0839s/iter; left time: 4593.9975s
	iters: 1100, epoch: 2 | loss: 0.1073079
	speed: 0.0852s/iter; left time: 4655.9527s
Epoch: 2 cost time: 97.06453275680542
Epoch: 2, Steps: 1138 | Train Loss: 0.1070200 Vali Loss: 0.2060598 Test Loss: 0.2670355
Validation loss decreased (0.209751 --> 0.206060).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.0990188
	speed: 1.0365s/iter; left time: 56514.3831s
	iters: 200, epoch: 3 | loss: 0.0950825
	speed: 0.0836s/iter; left time: 4549.7654s
	iters: 300, epoch: 3 | loss: 0.1037462
	speed: 0.0819s/iter; left time: 4450.1910s
	iters: 400, epoch: 3 | loss: 0.0971305
	speed: 0.0816s/iter; left time: 4426.0194s
	iters: 500, epoch: 3 | loss: 0.0940956
	speed: 0.0822s/iter; left time: 4450.7984s
	iters: 600, epoch: 3 | loss: 0.0975453
	speed: 0.0818s/iter; left time: 4419.0190s
	iters: 700, epoch: 3 | loss: 0.0962764
	speed: 0.0844s/iter; left time: 4550.4948s
	iters: 800, epoch: 3 | loss: 0.1047321
	speed: 0.0846s/iter; left time: 4553.7124s
	iters: 900, epoch: 3 | loss: 0.1019151
	speed: 0.0839s/iter; left time: 4505.2750s
	iters: 1000, epoch: 3 | loss: 0.0979732
	speed: 0.0850s/iter; left time: 4556.0645s
	iters: 1100, epoch: 3 | loss: 0.0935260
	speed: 0.0827s/iter; left time: 4424.8881s
Epoch: 3 cost time: 96.26753234863281
Epoch: 3, Steps: 1138 | Train Loss: 0.0978971 Vali Loss: 0.2190317 Test Loss: 0.2680537
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.0927192
	speed: 1.0813s/iter; left time: 57725.8681s
	iters: 200, epoch: 4 | loss: 0.0975370
	speed: 0.0837s/iter; left time: 4458.2197s
	iters: 300, epoch: 4 | loss: 0.0940007
	speed: 0.0824s/iter; left time: 4383.7446s
	iters: 400, epoch: 4 | loss: 0.0977936
	speed: 0.0835s/iter; left time: 4432.6698s
	iters: 500, epoch: 4 | loss: 0.0960688
	speed: 0.0820s/iter; left time: 4344.8303s
	iters: 600, epoch: 4 | loss: 0.0981998
	speed: 0.0832s/iter; left time: 4401.4751s
	iters: 700, epoch: 4 | loss: 0.0887343
	speed: 0.0820s/iter; left time: 4330.9278s
	iters: 800, epoch: 4 | loss: 0.0937810
	speed: 0.0841s/iter; left time: 4432.7482s
	iters: 900, epoch: 4 | loss: 0.0950398
	speed: 0.0812s/iter; left time: 4272.4831s
	iters: 1000, epoch: 4 | loss: 0.0853487
	speed: 0.0826s/iter; left time: 4335.3340s
	iters: 1100, epoch: 4 | loss: 0.0968944
	speed: 0.0819s/iter; left time: 4292.2397s
Epoch: 4 cost time: 95.96544075012207
Epoch: 4, Steps: 1138 | Train Loss: 0.0945639 Vali Loss: 0.2202233 Test Loss: 0.2698174
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.0910984
	speed: 1.0694s/iter; left time: 55874.1039s
	iters: 200, epoch: 5 | loss: 0.0927512
	speed: 0.0829s/iter; left time: 4322.4949s
	iters: 300, epoch: 5 | loss: 0.0904428
	speed: 0.0840s/iter; left time: 4374.0388s
	iters: 400, epoch: 5 | loss: 0.0972562
	speed: 0.0835s/iter; left time: 4337.3522s
	iters: 500, epoch: 5 | loss: 0.0984506
	speed: 0.0812s/iter; left time: 4212.0556s
	iters: 600, epoch: 5 | loss: 0.0914686
	speed: 0.0809s/iter; left time: 4186.0258s
	iters: 700, epoch: 5 | loss: 0.0909215
	speed: 0.0806s/iter; left time: 4165.2359s
	iters: 800, epoch: 5 | loss: 0.0889685
	speed: 0.0810s/iter; left time: 4174.4734s
	iters: 900, epoch: 5 | loss: 0.0916473
	speed: 0.0818s/iter; left time: 4208.2778s
	iters: 1000, epoch: 5 | loss: 0.0919816
	speed: 0.0818s/iter; left time: 4199.1508s
	iters: 1100, epoch: 5 | loss: 0.0885533
	speed: 0.0803s/iter; left time: 4117.8139s
Epoch: 5 cost time: 95.09515428543091
Epoch: 5, Steps: 1138 | Train Loss: 0.0927674 Vali Loss: 0.2203783 Test Loss: 0.2709274
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.0881208
	speed: 1.0490s/iter; left time: 53617.5530s
	iters: 200, epoch: 6 | loss: 0.0997384
	speed: 0.0832s/iter; left time: 4245.9020s
	iters: 300, epoch: 6 | loss: 0.0863684
	speed: 0.0841s/iter; left time: 4281.3936s
	iters: 400, epoch: 6 | loss: 0.0955316
	speed: 0.0834s/iter; left time: 4237.9755s
	iters: 500, epoch: 6 | loss: 0.0885410
	speed: 0.0839s/iter; left time: 4253.8319s
	iters: 600, epoch: 6 | loss: 0.0950487
	speed: 0.0835s/iter; left time: 4225.1004s
	iters: 700, epoch: 6 | loss: 0.0923990
	speed: 0.0840s/iter; left time: 4242.7353s
	iters: 800, epoch: 6 | loss: 0.0985297
	speed: 0.0842s/iter; left time: 4246.5350s
	iters: 900, epoch: 6 | loss: 0.0889367
	speed: 0.0900s/iter; left time: 4530.3913s
	iters: 1000, epoch: 6 | loss: 0.0891035
	speed: 0.0899s/iter; left time: 4511.7946s
	iters: 1100, epoch: 6 | loss: 0.0916266
	speed: 0.0883s/iter; left time: 4424.5293s
Epoch: 6 cost time: 98.69206929206848
Epoch: 6, Steps: 1138 | Train Loss: 0.0918271 Vali Loss: 0.2198382 Test Loss: 0.2716905
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.0901572
	speed: 1.0442s/iter; left time: 52179.3652s
	iters: 200, epoch: 7 | loss: 0.0959070
	speed: 0.0825s/iter; left time: 4113.8320s
	iters: 300, epoch: 7 | loss: 0.0891997
	speed: 0.0830s/iter; left time: 4132.3015s
	iters: 400, epoch: 7 | loss: 0.0945136
	speed: 0.0831s/iter; left time: 4126.9038s
	iters: 500, epoch: 7 | loss: 0.0917066
	speed: 0.0851s/iter; left time: 4219.1329s
	iters: 600, epoch: 7 | loss: 0.0922546
	speed: 0.0838s/iter; left time: 4144.7392s
	iters: 700, epoch: 7 | loss: 0.1010329
	speed: 0.0845s/iter; left time: 4173.9924s
	iters: 800, epoch: 7 | loss: 0.0857082
	speed: 0.0841s/iter; left time: 4141.7176s
	iters: 900, epoch: 7 | loss: 0.0879721
	speed: 0.0813s/iter; left time: 3999.6975s
	iters: 1000, epoch: 7 | loss: 0.0901497
	speed: 0.0821s/iter; left time: 4029.6296s
	iters: 1100, epoch: 7 | loss: 0.0843932
	speed: 0.0814s/iter; left time: 3988.8360s
Epoch: 7 cost time: 96.2907931804657
Epoch: 7, Steps: 1138 | Train Loss: 0.0913070 Vali Loss: 0.2211482 Test Loss: 0.2719537
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.0902267
	speed: 1.0648s/iter; left time: 52001.9074s
	iters: 200, epoch: 8 | loss: 0.0941690
	speed: 0.0886s/iter; left time: 4320.2330s
	iters: 300, epoch: 8 | loss: 0.0842523
	speed: 0.0839s/iter; left time: 4078.9237s
	iters: 400, epoch: 8 | loss: 0.0825000
	speed: 0.0845s/iter; left time: 4102.8906s
	iters: 500, epoch: 8 | loss: 0.0892787
	speed: 0.0844s/iter; left time: 4085.6406s
	iters: 600, epoch: 8 | loss: 0.0920673
	speed: 0.0835s/iter; left time: 4035.9831s
	iters: 700, epoch: 8 | loss: 0.0826881
	speed: 0.0818s/iter; left time: 3944.3763s
	iters: 800, epoch: 8 | loss: 0.0893956
	speed: 0.0828s/iter; left time: 3986.0914s
	iters: 900, epoch: 8 | loss: 0.0921762
	speed: 0.0837s/iter; left time: 4019.8911s
	iters: 1000, epoch: 8 | loss: 0.0911418
	speed: 0.0820s/iter; left time: 3931.0457s
	iters: 1100, epoch: 8 | loss: 0.0860216
	speed: 0.0839s/iter; left time: 4013.9848s
Epoch: 8 cost time: 97.16136145591736
Epoch: 8, Steps: 1138 | Train Loss: 0.0910346 Vali Loss: 0.2208080 Test Loss: 0.2724800
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.0855241
	speed: 1.0990s/iter; left time: 52418.9543s
	iters: 200, epoch: 9 | loss: 0.0936420
	speed: 0.0838s/iter; left time: 3986.6910s
	iters: 300, epoch: 9 | loss: 0.0883958
	speed: 0.0839s/iter; left time: 3985.7152s
	iters: 400, epoch: 9 | loss: 0.1052772
	speed: 0.0840s/iter; left time: 3982.6408s
	iters: 500, epoch: 9 | loss: 0.0906607
	speed: 0.0839s/iter; left time: 3969.6172s
	iters: 600, epoch: 9 | loss: 0.0809736
	speed: 0.0831s/iter; left time: 3921.3703s
	iters: 700, epoch: 9 | loss: 0.0913245
	speed: 0.0839s/iter; left time: 3950.7760s
	iters: 800, epoch: 9 | loss: 0.0878294
	speed: 0.0813s/iter; left time: 3818.6732s
	iters: 900, epoch: 9 | loss: 0.0877615
	speed: 0.0824s/iter; left time: 3865.8976s
	iters: 1000, epoch: 9 | loss: 0.0933733
	speed: 0.0839s/iter; left time: 3927.6758s
	iters: 1100, epoch: 9 | loss: 0.0870776
	speed: 0.0843s/iter; left time: 3934.9585s
Epoch: 9 cost time: 96.59175038337708
Epoch: 9, Steps: 1138 | Train Loss: 0.0908903 Vali Loss: 0.2212624 Test Loss: 0.2731805
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.0910292
	speed: 1.0524s/iter; left time: 48997.8662s
	iters: 200, epoch: 10 | loss: 0.0958923
	speed: 0.0817s/iter; left time: 3794.6592s
	iters: 300, epoch: 10 | loss: 0.0857402
	speed: 0.0823s/iter; left time: 3815.9282s
	iters: 400, epoch: 10 | loss: 0.0956412
	speed: 0.0823s/iter; left time: 3805.6811s
	iters: 500, epoch: 10 | loss: 0.0881863
	speed: 0.0855s/iter; left time: 3947.7585s
	iters: 600, epoch: 10 | loss: 0.0852424
	speed: 0.0826s/iter; left time: 3803.3612s
	iters: 700, epoch: 10 | loss: 0.0825657
	speed: 0.0832s/iter; left time: 3825.5222s
	iters: 800, epoch: 10 | loss: 0.0857419
	speed: 0.0816s/iter; left time: 3741.8842s
	iters: 900, epoch: 10 | loss: 0.0886334
	speed: 0.0824s/iter; left time: 3771.0041s
	iters: 1000, epoch: 10 | loss: 0.0887842
	speed: 0.0821s/iter; left time: 3748.6232s
	iters: 1100, epoch: 10 | loss: 0.0899000
	speed: 0.0820s/iter; left time: 3735.3324s
Epoch: 10 cost time: 95.53806257247925
Epoch: 10, Steps: 1138 | Train Loss: 0.0908338 Vali Loss: 0.2215116 Test Loss: 0.2731495
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.0854003
	speed: 1.0494s/iter; left time: 47665.5780s
	iters: 200, epoch: 11 | loss: 0.0871626
	speed: 0.0803s/iter; left time: 3641.4921s
	iters: 300, epoch: 11 | loss: 0.0983570
	speed: 0.0854s/iter; left time: 3863.0070s
	iters: 400, epoch: 11 | loss: 0.0824151
	speed: 0.0819s/iter; left time: 3695.0036s
	iters: 500, epoch: 11 | loss: 0.0874041
	speed: 0.0831s/iter; left time: 3739.0550s
	iters: 600, epoch: 11 | loss: 0.0887078
	speed: 0.0836s/iter; left time: 3755.0814s
	iters: 700, epoch: 11 | loss: 0.0924914
	speed: 0.0830s/iter; left time: 3720.9419s
	iters: 800, epoch: 11 | loss: 0.0938866
	speed: 0.0839s/iter; left time: 3752.9917s
	iters: 900, epoch: 11 | loss: 0.0918900
	speed: 0.0834s/iter; left time: 3719.2843s
	iters: 1000, epoch: 11 | loss: 0.0902899
	speed: 0.0842s/iter; left time: 3746.5565s
	iters: 1100, epoch: 11 | loss: 0.0963320
	speed: 0.0888s/iter; left time: 3946.5797s
Epoch: 11 cost time: 97.22568845748901
Epoch: 11, Steps: 1138 | Train Loss: 0.0907866 Vali Loss: 0.2212104 Test Loss: 0.2730588
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.0986412
	speed: 1.0568s/iter; left time: 46796.3173s
	iters: 200, epoch: 12 | loss: 0.0921165
	speed: 0.0815s/iter; left time: 3599.9144s
	iters: 300, epoch: 12 | loss: 0.0928826
	speed: 0.0831s/iter; left time: 3663.3932s
	iters: 400, epoch: 12 | loss: 0.0934065
	speed: 0.0806s/iter; left time: 3545.9725s
	iters: 500, epoch: 12 | loss: 0.0932250
	speed: 0.0825s/iter; left time: 3618.3561s
	iters: 600, epoch: 12 | loss: 0.0850497
	speed: 0.0834s/iter; left time: 3651.5403s
	iters: 700, epoch: 12 | loss: 0.0861797
	speed: 0.0815s/iter; left time: 3561.1713s
	iters: 800, epoch: 12 | loss: 0.0892821
	speed: 0.0854s/iter; left time: 3723.6728s
	iters: 900, epoch: 12 | loss: 0.0900559
	speed: 0.0826s/iter; left time: 3590.2249s
	iters: 1000, epoch: 12 | loss: 0.0905521
	speed: 0.0817s/iter; left time: 3545.1149s
	iters: 1100, epoch: 12 | loss: 0.0869189
	speed: 0.0820s/iter; left time: 3547.1528s
Epoch: 12 cost time: 95.96518063545227
Epoch: 12, Steps: 1138 | Train Loss: 0.0907615 Vali Loss: 0.2212764 Test Loss: 0.2730888
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : ECL_96_96_32_emb_512_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (5165, 1, 96, 321) (5165, 1, 96, 321)
test shape: (5165, 96, 321) (5165, 96, 321)
mse:0.26703688502311707, mae:0.3583221733570099
Args in experiment:
Namespace(is_training=1, model_id='ECL_96_96_33_emb_512', model='xLSTM', data='custom', root_path='./data/electricity/', data_path='/input-data/electricity.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, enc_in=321, dec_in=7, c_out=321, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.5, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=16, patience=10, learning_rate=0.0005, des='test', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, use_norm=True, partial_start_index=0, hidden_size=512, num_layers=2, mark_enc_in=4, embedding_dim=512, weight_decay=1e-06, kernal_size=3, num_heads_xlstm=8, qkv_proj_blocksize=8, proj_factor=1.3, num_blocks=7, slstm_at=1, grad_clip_norm=1.0, d_state=16, d_conv=4, expand=2)
Use GPU: cuda:0
{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-L/usr/local/cuda/lib', '-lcublas'], 'extra_cflags': ['-DSLSTM_HIDDEN_SIZE=512', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=8', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__'], 'extra_cuda_cflags': ['-Xptxas="-v"', '-gencode', 'arch=compute_80,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=512', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=8', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__']}
Using /home/thetayne/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/thetayne/.cache/torch_extensions/py310_cu121/slstm_HS512BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0/build.ninja...
Building extension module slstm_HS512BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module slstm_HS512BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
>>>>>>>start training : ECL_96_96_33_emb_512_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 18221
val 2537
test 5165
	iters: 100, epoch: 1 | loss: 0.2497071
	speed: 0.0838s/iter; left time: 2853.8920s
	iters: 200, epoch: 1 | loss: 0.1890260
	speed: 0.0664s/iter; left time: 2252.9225s
	iters: 300, epoch: 1 | loss: 0.1691856
	speed: 0.0655s/iter; left time: 2218.2635s
	iters: 400, epoch: 1 | loss: 0.1630225
	speed: 0.0622s/iter; left time: 2098.2637s
	iters: 500, epoch: 1 | loss: 0.1311872
	speed: 0.0635s/iter; left time: 2137.4862s
	iters: 600, epoch: 1 | loss: 0.1209609
	speed: 0.0630s/iter; left time: 2111.8957s
	iters: 700, epoch: 1 | loss: 0.1121894
	speed: 0.0628s/iter; left time: 2100.8729s
	iters: 800, epoch: 1 | loss: 0.1208167
	speed: 0.0654s/iter; left time: 2181.8626s
	iters: 900, epoch: 1 | loss: 0.1056070
	speed: 0.0627s/iter; left time: 2085.0610s
	iters: 1000, epoch: 1 | loss: 0.1109768
	speed: 0.0614s/iter; left time: 2036.4263s
	iters: 1100, epoch: 1 | loss: 0.1046526
	speed: 0.0638s/iter; left time: 2108.9418s
Epoch: 1 cost time: 74.29255485534668
Epoch: 1, Steps: 1138 | Train Loss: 0.1614084 Vali Loss: 0.2102681 Test Loss: 0.2662195
Validation loss decreased (inf --> 0.210268).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.1012793
	speed: 1.0211s/iter; left time: 33597.4758s
	iters: 200, epoch: 2 | loss: 0.1052213
	speed: 0.0611s/iter; left time: 2002.9219s
	iters: 300, epoch: 2 | loss: 0.0987279
	speed: 0.0635s/iter; left time: 2078.0925s
	iters: 400, epoch: 2 | loss: 0.1000522
	speed: 0.0629s/iter; left time: 2050.0994s
	iters: 500, epoch: 2 | loss: 0.1146223
	speed: 0.0627s/iter; left time: 2036.8078s
	iters: 600, epoch: 2 | loss: 0.1072785
	speed: 0.0628s/iter; left time: 2035.9360s
	iters: 700, epoch: 2 | loss: 0.0972832
	speed: 0.0639s/iter; left time: 2064.1323s
	iters: 800, epoch: 2 | loss: 0.1018137
	speed: 0.0669s/iter; left time: 2154.9266s
	iters: 900, epoch: 2 | loss: 0.1105820
	speed: 0.0607s/iter; left time: 1947.0940s
	iters: 1000, epoch: 2 | loss: 0.0981535
	speed: 0.0628s/iter; left time: 2010.5577s
	iters: 1100, epoch: 2 | loss: 0.0944018
	speed: 0.0719s/iter; left time: 2294.3949s
Epoch: 2 cost time: 74.88539266586304
Epoch: 2, Steps: 1138 | Train Loss: 0.1043881 Vali Loss: 0.2029951 Test Loss: 0.2686581
Validation loss decreased (0.210268 --> 0.202995).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.1057717
	speed: 1.0006s/iter; left time: 31783.6711s
	iters: 200, epoch: 3 | loss: 0.0923820
	speed: 0.0629s/iter; left time: 1993.2302s
	iters: 300, epoch: 3 | loss: 0.0966984
	speed: 0.0661s/iter; left time: 2086.8411s
	iters: 400, epoch: 3 | loss: 0.0921359
	speed: 0.0643s/iter; left time: 2023.9718s
	iters: 500, epoch: 3 | loss: 0.0883373
	speed: 0.0644s/iter; left time: 2020.3403s
	iters: 600, epoch: 3 | loss: 0.0919078
	speed: 0.0641s/iter; left time: 2005.4129s
	iters: 700, epoch: 3 | loss: 0.0910700
	speed: 0.0654s/iter; left time: 2037.5361s
	iters: 800, epoch: 3 | loss: 0.0911868
	speed: 0.0662s/iter; left time: 2056.1152s
	iters: 900, epoch: 3 | loss: 0.0861586
	speed: 0.0649s/iter; left time: 2010.7990s
	iters: 1000, epoch: 3 | loss: 0.0892665
	speed: 0.0617s/iter; left time: 1903.2681s
	iters: 1100, epoch: 3 | loss: 0.0913695
	speed: 0.0625s/iter; left time: 1921.2912s
Epoch: 3 cost time: 74.66938877105713
Epoch: 3, Steps: 1138 | Train Loss: 0.0936188 Vali Loss: 0.2044279 Test Loss: 0.2681444
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.0952681
	speed: 1.0191s/iter; left time: 31212.9595s
	iters: 200, epoch: 4 | loss: 0.0907746
	speed: 0.0639s/iter; left time: 1949.7559s
	iters: 300, epoch: 4 | loss: 0.0907158
	speed: 0.0642s/iter; left time: 1953.0839s
	iters: 400, epoch: 4 | loss: 0.0885930
	speed: 0.0611s/iter; left time: 1853.6749s
	iters: 500, epoch: 4 | loss: 0.0917111
	speed: 0.0637s/iter; left time: 1926.0134s
	iters: 600, epoch: 4 | loss: 0.0974356
	speed: 0.0607s/iter; left time: 1827.9195s
	iters: 700, epoch: 4 | loss: 0.0884463
	speed: 0.0638s/iter; left time: 1916.8152s
	iters: 800, epoch: 4 | loss: 0.0865307
	speed: 0.0627s/iter; left time: 1876.5546s
	iters: 900, epoch: 4 | loss: 0.0884987
	speed: 0.0651s/iter; left time: 1943.1968s
	iters: 1000, epoch: 4 | loss: 0.0860751
	speed: 0.0639s/iter; left time: 1900.8871s
	iters: 1100, epoch: 4 | loss: 0.0968323
	speed: 0.0610s/iter; left time: 1807.6947s
Epoch: 4 cost time: 74.43467259407043
Epoch: 4, Steps: 1138 | Train Loss: 0.0901893 Vali Loss: 0.2047360 Test Loss: 0.2676653
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.0933630
	speed: 1.0291s/iter; left time: 30346.8749s
	iters: 200, epoch: 5 | loss: 0.0933158
	speed: 0.0606s/iter; left time: 1779.6246s
	iters: 300, epoch: 5 | loss: 0.0929730
	speed: 0.0639s/iter; left time: 1870.3344s
	iters: 400, epoch: 5 | loss: 0.0849722
	speed: 0.0623s/iter; left time: 1819.2252s
	iters: 500, epoch: 5 | loss: 0.0936075
	speed: 0.0680s/iter; left time: 1978.8191s
	iters: 600, epoch: 5 | loss: 0.0897758
	speed: 0.0653s/iter; left time: 1893.6061s
	iters: 700, epoch: 5 | loss: 0.0959810
	speed: 0.0630s/iter; left time: 1820.9509s
	iters: 800, epoch: 5 | loss: 0.0829998
	speed: 0.0657s/iter; left time: 1890.1379s
	iters: 900, epoch: 5 | loss: 0.0905837
	speed: 0.0639s/iter; left time: 1832.3331s
	iters: 1000, epoch: 5 | loss: 0.0878835
	speed: 0.0620s/iter; left time: 1771.5882s
	iters: 1100, epoch: 5 | loss: 0.0846032
	speed: 0.0601s/iter; left time: 1713.1575s
Epoch: 5 cost time: 73.54034781455994
Epoch: 5, Steps: 1138 | Train Loss: 0.0884247 Vali Loss: 0.2043005 Test Loss: 0.2695723
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.0988871
	speed: 1.0715s/iter; left time: 30378.9602s
	iters: 200, epoch: 6 | loss: 0.0882828
	speed: 0.0667s/iter; left time: 1883.6882s
	iters: 300, epoch: 6 | loss: 0.0882076
	speed: 0.0634s/iter; left time: 1785.1859s
	iters: 400, epoch: 6 | loss: 0.0960022
	speed: 0.0638s/iter; left time: 1790.1949s
	iters: 500, epoch: 6 | loss: 0.0900256
	speed: 0.0622s/iter; left time: 1739.1534s
	iters: 600, epoch: 6 | loss: 0.0829158
	speed: 0.0636s/iter; left time: 1771.9149s
	iters: 700, epoch: 6 | loss: 0.0862603
	speed: 0.0642s/iter; left time: 1781.5580s
	iters: 800, epoch: 6 | loss: 0.0839586
	speed: 0.0691s/iter; left time: 1909.4936s
	iters: 900, epoch: 6 | loss: 0.0812890
	speed: 0.0694s/iter; left time: 1910.7680s
	iters: 1000, epoch: 6 | loss: 0.0826105
	speed: 0.0644s/iter; left time: 1768.6790s
	iters: 1100, epoch: 6 | loss: 0.0944782
	speed: 0.0660s/iter; left time: 1805.5686s
Epoch: 6 cost time: 75.44861459732056
Epoch: 6, Steps: 1138 | Train Loss: 0.0874525 Vali Loss: 0.2047291 Test Loss: 0.2701682
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.0836203
	speed: 1.0467s/iter; left time: 28484.9413s
	iters: 200, epoch: 7 | loss: 0.0882865
	speed: 0.0659s/iter; left time: 1787.1383s
	iters: 300, epoch: 7 | loss: 0.0834137
	speed: 0.0636s/iter; left time: 1719.2785s
	iters: 400, epoch: 7 | loss: 0.0867052
	speed: 0.0640s/iter; left time: 1722.2792s
	iters: 500, epoch: 7 | loss: 0.0923630
	speed: 0.0689s/iter; left time: 1846.7633s
	iters: 600, epoch: 7 | loss: 0.0849200
	speed: 0.0731s/iter; left time: 1951.7762s
	iters: 700, epoch: 7 | loss: 0.0927516
	speed: 0.0732s/iter; left time: 1948.3524s
	iters: 800, epoch: 7 | loss: 0.0959598
	speed: 0.0656s/iter; left time: 1739.4549s
	iters: 900, epoch: 7 | loss: 0.0835212
	speed: 0.0654s/iter; left time: 1727.8982s
	iters: 1000, epoch: 7 | loss: 0.0794550
	speed: 0.0731s/iter; left time: 1924.0469s
	iters: 1100, epoch: 7 | loss: 0.0894195
	speed: 0.0704s/iter; left time: 1844.6582s
Epoch: 7 cost time: 78.78569221496582
Epoch: 7, Steps: 1138 | Train Loss: 0.0869733 Vali Loss: 0.2040822 Test Loss: 0.2704690
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.0803116
	speed: 0.9998s/iter; left time: 26069.3538s
	iters: 200, epoch: 8 | loss: 0.0883120
	speed: 0.0612s/iter; left time: 1589.8449s
	iters: 300, epoch: 8 | loss: 0.0821500
	speed: 0.0622s/iter; left time: 1609.0092s
	iters: 400, epoch: 8 | loss: 0.0823776
	speed: 0.0609s/iter; left time: 1570.3537s
	iters: 500, epoch: 8 | loss: 0.0924849
	speed: 0.0616s/iter; left time: 1581.2485s
	iters: 600, epoch: 8 | loss: 0.0849041
	speed: 0.0635s/iter; left time: 1624.9299s
	iters: 700, epoch: 8 | loss: 0.0892674
	speed: 0.0676s/iter; left time: 1722.7556s
	iters: 800, epoch: 8 | loss: 0.0922603
	speed: 0.0644s/iter; left time: 1635.2372s
	iters: 900, epoch: 8 | loss: 0.0842227
	speed: 0.0636s/iter; left time: 1607.0949s
	iters: 1000, epoch: 8 | loss: 0.0850880
	speed: 0.0640s/iter; left time: 1610.7019s
	iters: 1100, epoch: 8 | loss: 0.0813311
	speed: 0.0648s/iter; left time: 1624.6163s
Epoch: 8 cost time: 73.78725790977478
Epoch: 8, Steps: 1138 | Train Loss: 0.0867343 Vali Loss: 0.2046466 Test Loss: 0.2709569
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.0811942
	speed: 1.0197s/iter; left time: 25429.4248s
	iters: 200, epoch: 9 | loss: 0.0828549
	speed: 0.0621s/iter; left time: 1541.3455s
	iters: 300, epoch: 9 | loss: 0.0842202
	speed: 0.0652s/iter; left time: 1612.9443s
	iters: 400, epoch: 9 | loss: 0.0811204
	speed: 0.0606s/iter; left time: 1492.8183s
	iters: 500, epoch: 9 | loss: 0.0888331
	speed: 0.0610s/iter; left time: 1497.4068s
	iters: 600, epoch: 9 | loss: 0.0913358
	speed: 0.0623s/iter; left time: 1521.8854s
	iters: 700, epoch: 9 | loss: 0.0857125
	speed: 0.0631s/iter; left time: 1536.5921s
	iters: 800, epoch: 9 | loss: 0.0828318
	speed: 0.0636s/iter; left time: 1541.7991s
	iters: 900, epoch: 9 | loss: 0.0786271
	speed: 0.0666s/iter; left time: 1606.9132s
	iters: 1000, epoch: 9 | loss: 0.0813435
	speed: 0.0676s/iter; left time: 1624.8093s
	iters: 1100, epoch: 9 | loss: 0.0816617
	speed: 0.0649s/iter; left time: 1553.4731s
Epoch: 9 cost time: 73.81880235671997
Epoch: 9, Steps: 1138 | Train Loss: 0.0865596 Vali Loss: 0.2040072 Test Loss: 0.2705456
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.0888701
	speed: 0.9921s/iter; left time: 23611.1487s
	iters: 200, epoch: 10 | loss: 0.0798354
	speed: 0.0635s/iter; left time: 1505.1449s
	iters: 300, epoch: 10 | loss: 0.0855414
	speed: 0.0631s/iter; left time: 1489.3227s
	iters: 400, epoch: 10 | loss: 0.0867215
	speed: 0.0640s/iter; left time: 1502.8694s
	iters: 500, epoch: 10 | loss: 0.0821199
	speed: 0.0610s/iter; left time: 1427.0541s
	iters: 600, epoch: 10 | loss: 0.0878418
	speed: 0.0641s/iter; left time: 1493.8843s
	iters: 700, epoch: 10 | loss: 0.0885490
	speed: 0.0639s/iter; left time: 1482.1491s
	iters: 800, epoch: 10 | loss: 0.0908151
	speed: 0.0641s/iter; left time: 1479.7865s
	iters: 900, epoch: 10 | loss: 0.0958283
	speed: 0.0657s/iter; left time: 1510.3749s
	iters: 1000, epoch: 10 | loss: 0.0934524
	speed: 0.0674s/iter; left time: 1544.4720s
	iters: 1100, epoch: 10 | loss: 0.0887549
	speed: 0.0658s/iter; left time: 1500.4187s
Epoch: 10 cost time: 74.50235414505005
Epoch: 10, Steps: 1138 | Train Loss: 0.0864988 Vali Loss: 0.2038178 Test Loss: 0.2705615
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.0748266
	speed: 1.0297s/iter; left time: 23334.4422s
	iters: 200, epoch: 11 | loss: 0.0823424
	speed: 0.0662s/iter; left time: 1493.6639s
	iters: 300, epoch: 11 | loss: 0.0864331
	speed: 0.0630s/iter; left time: 1413.9670s
	iters: 400, epoch: 11 | loss: 0.1011852
	speed: 0.0621s/iter; left time: 1388.8448s
	iters: 500, epoch: 11 | loss: 0.0875722
	speed: 0.0666s/iter; left time: 1482.0724s
	iters: 600, epoch: 11 | loss: 0.0852034
	speed: 0.0651s/iter; left time: 1442.0062s
	iters: 700, epoch: 11 | loss: 0.0873378
	speed: 0.0627s/iter; left time: 1382.9078s
	iters: 800, epoch: 11 | loss: 0.0879946
	speed: 0.0603s/iter; left time: 1325.3296s
	iters: 900, epoch: 11 | loss: 0.0870550
	speed: 0.0620s/iter; left time: 1355.5583s
	iters: 1000, epoch: 11 | loss: 0.0872755
	speed: 0.0674s/iter; left time: 1466.0814s
	iters: 1100, epoch: 11 | loss: 0.0842448
	speed: 0.0651s/iter; left time: 1411.0787s
Epoch: 11 cost time: 74.96250104904175
Epoch: 11, Steps: 1138 | Train Loss: 0.0864836 Vali Loss: 0.2045695 Test Loss: 0.2707500
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.0909647
	speed: 1.0166s/iter; left time: 21881.1613s
	iters: 200, epoch: 12 | loss: 0.0883778
	speed: 0.0630s/iter; left time: 1349.0515s
	iters: 300, epoch: 12 | loss: 0.0797916
	speed: 0.0644s/iter; left time: 1372.7804s
	iters: 400, epoch: 12 | loss: 0.0890661
	speed: 0.0638s/iter; left time: 1353.9520s
	iters: 500, epoch: 12 | loss: 0.0888749
	speed: 0.0659s/iter; left time: 1392.8818s
	iters: 600, epoch: 12 | loss: 0.0818482
	speed: 0.0700s/iter; left time: 1471.2769s
	iters: 700, epoch: 12 | loss: 0.0898095
	speed: 0.0649s/iter; left time: 1358.6445s
	iters: 800, epoch: 12 | loss: 0.0852234
	speed: 0.0678s/iter; left time: 1412.6617s
	iters: 900, epoch: 12 | loss: 0.0919313
	speed: 0.0673s/iter; left time: 1393.8809s
	iters: 1000, epoch: 12 | loss: 0.0862232
	speed: 0.0637s/iter; left time: 1313.2549s
	iters: 1100, epoch: 12 | loss: 0.0901877
	speed: 0.0625s/iter; left time: 1281.7114s
Epoch: 12 cost time: 75.53148436546326
Epoch: 12, Steps: 1138 | Train Loss: 0.0864802 Vali Loss: 0.2043196 Test Loss: 0.2707867
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : ECL_96_96_33_emb_512_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (5165, 1, 96, 321) (5165, 1, 96, 321)
test shape: (5165, 96, 321) (5165, 96, 321)
mse:0.26865869760513306, mae:0.35999852418899536
Args in experiment:
Namespace(is_training=1, model_id='ECL_96_96_34_emb_512', model='xLSTM', data='custom', root_path='./data/electricity/', data_path='/input-data/electricity.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, enc_in=321, dec_in=7, c_out=321, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.3, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=16, patience=10, learning_rate=0.0005, des='test', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, use_norm=True, partial_start_index=0, hidden_size=512, num_layers=2, mark_enc_in=4, embedding_dim=512, weight_decay=1e-05, kernal_size=3, num_heads_xlstm=8, qkv_proj_blocksize=8, proj_factor=1.3, num_blocks=7, slstm_at=1, grad_clip_norm=0.5, d_state=16, d_conv=4, expand=2)
Use GPU: cuda:0
{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-L/usr/local/cuda/lib', '-lcublas'], 'extra_cflags': ['-DSLSTM_HIDDEN_SIZE=512', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=8', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__'], 'extra_cuda_cflags': ['-Xptxas="-v"', '-gencode', 'arch=compute_80,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=512', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=8', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__']}
Using /home/thetayne/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/thetayne/.cache/torch_extensions/py310_cu121/slstm_HS512BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0/build.ninja...
Building extension module slstm_HS512BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module slstm_HS512BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
>>>>>>>start training : ECL_96_96_34_emb_512_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 18221
val 2537
test 5165
	iters: 100, epoch: 1 | loss: 0.2304439
	speed: 0.0855s/iter; left time: 2908.9929s
	iters: 200, epoch: 1 | loss: 0.1763342
	speed: 0.0590s/iter; left time: 2002.4970s
	iters: 300, epoch: 1 | loss: 0.1418451
	speed: 0.0600s/iter; left time: 2028.9044s
	iters: 400, epoch: 1 | loss: 0.1273841
	speed: 0.0635s/iter; left time: 2143.6791s
	iters: 500, epoch: 1 | loss: 0.1099684
	speed: 0.0627s/iter; left time: 2109.8351s
	iters: 600, epoch: 1 | loss: 0.0953385
	speed: 0.0666s/iter; left time: 2234.6891s
	iters: 700, epoch: 1 | loss: 0.0873882
	speed: 0.0600s/iter; left time: 2007.0844s
	iters: 800, epoch: 1 | loss: 0.0939286
	speed: 0.0636s/iter; left time: 2120.4150s
	iters: 900, epoch: 1 | loss: 0.0971292
	speed: 0.0629s/iter; left time: 2090.5528s
	iters: 1000, epoch: 1 | loss: 0.0881318
	speed: 0.0629s/iter; left time: 2083.8728s
	iters: 1100, epoch: 1 | loss: 0.0809571
	speed: 0.0621s/iter; left time: 2051.1081s
Epoch: 1 cost time: 73.0981833934784
Epoch: 1, Steps: 1138 | Train Loss: 0.1314467 Vali Loss: 0.2037003 Test Loss: 0.2691726
Validation loss decreased (inf --> 0.203700).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.0762054
	speed: 1.0159s/iter; left time: 33425.1340s
	iters: 200, epoch: 2 | loss: 0.0772658
	speed: 0.0639s/iter; left time: 2095.7665s
	iters: 300, epoch: 2 | loss: 0.0727126
	speed: 0.0637s/iter; left time: 2081.8623s
	iters: 400, epoch: 2 | loss: 0.0741871
	speed: 0.0660s/iter; left time: 2152.9870s
	iters: 500, epoch: 2 | loss: 0.0766882
	speed: 0.0628s/iter; left time: 2042.3086s
	iters: 600, epoch: 2 | loss: 0.0754323
	speed: 0.0634s/iter; left time: 2053.2080s
	iters: 700, epoch: 2 | loss: 0.0704656
	speed: 0.0623s/iter; left time: 2012.3119s
	iters: 800, epoch: 2 | loss: 0.0846447
	speed: 0.0652s/iter; left time: 2100.0619s
	iters: 900, epoch: 2 | loss: 0.1017217
	speed: 0.0644s/iter; left time: 2067.2294s
	iters: 1000, epoch: 2 | loss: 0.0764617
	speed: 0.0699s/iter; left time: 2238.0332s
	iters: 1100, epoch: 2 | loss: 0.0699727
	speed: 0.0699s/iter; left time: 2228.4778s
Epoch: 2 cost time: 75.31990098953247
Epoch: 2, Steps: 1138 | Train Loss: 0.0783221 Vali Loss: 0.2022127 Test Loss: 0.2595503
Validation loss decreased (0.203700 --> 0.202213).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.0722569
	speed: 1.0044s/iter; left time: 31905.3298s
	iters: 200, epoch: 3 | loss: 0.0642466
	speed: 0.0629s/iter; left time: 1992.3350s
	iters: 300, epoch: 3 | loss: 0.0665160
	speed: 0.0613s/iter; left time: 1934.5291s
	iters: 400, epoch: 3 | loss: 0.0636826
	speed: 0.0615s/iter; left time: 1936.0101s
	iters: 500, epoch: 3 | loss: 0.0610127
	speed: 0.0615s/iter; left time: 1930.0169s
	iters: 600, epoch: 3 | loss: 0.0627104
	speed: 0.0587s/iter; left time: 1836.3020s
	iters: 700, epoch: 3 | loss: 0.0616373
	speed: 0.0585s/iter; left time: 1823.1222s
	iters: 800, epoch: 3 | loss: 0.0615240
	speed: 0.0583s/iter; left time: 1809.7098s
	iters: 900, epoch: 3 | loss: 0.0591746
	speed: 0.0618s/iter; left time: 1914.6969s
	iters: 1000, epoch: 3 | loss: 0.0604699
	speed: 0.0628s/iter; left time: 1938.5793s
	iters: 1100, epoch: 3 | loss: 0.0627935
	speed: 0.0656s/iter; left time: 2019.5507s
Epoch: 3 cost time: 71.4089424610138
Epoch: 3, Steps: 1138 | Train Loss: 0.0638714 Vali Loss: 0.2090326 Test Loss: 0.2677333
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.0618669
	speed: 1.0279s/iter; left time: 31481.1009s
	iters: 200, epoch: 4 | loss: 0.0596576
	speed: 0.0623s/iter; left time: 1902.5638s
	iters: 300, epoch: 4 | loss: 0.0596053
	speed: 0.0625s/iter; left time: 1902.5889s
	iters: 400, epoch: 4 | loss: 0.0577833
	speed: 0.0634s/iter; left time: 1924.0250s
	iters: 500, epoch: 4 | loss: 0.0596654
	speed: 0.0611s/iter; left time: 1847.0663s
	iters: 600, epoch: 4 | loss: 0.0623654
	speed: 0.0640s/iter; left time: 1928.7535s
	iters: 700, epoch: 4 | loss: 0.0573949
	speed: 0.0650s/iter; left time: 1952.4722s
	iters: 800, epoch: 4 | loss: 0.0564629
	speed: 0.0615s/iter; left time: 1840.8172s
	iters: 900, epoch: 4 | loss: 0.0578154
	speed: 0.0638s/iter; left time: 1901.8952s
	iters: 1000, epoch: 4 | loss: 0.0555092
	speed: 0.0603s/iter; left time: 1793.0283s
	iters: 1100, epoch: 4 | loss: 0.0629477
	speed: 0.0621s/iter; left time: 1840.4401s
Epoch: 4 cost time: 73.0848081111908
Epoch: 4, Steps: 1138 | Train Loss: 0.0586862 Vali Loss: 0.2049412 Test Loss: 0.2702601
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.0593031
	speed: 1.0216s/iter; left time: 30125.5920s
	iters: 200, epoch: 5 | loss: 0.0596572
	speed: 0.0630s/iter; left time: 1851.5046s
	iters: 300, epoch: 5 | loss: 0.0585106
	speed: 0.0690s/iter; left time: 2020.4768s
	iters: 400, epoch: 5 | loss: 0.0542869
	speed: 0.0621s/iter; left time: 1813.2696s
	iters: 500, epoch: 5 | loss: 0.0587370
	speed: 0.0620s/iter; left time: 1802.7415s
	iters: 600, epoch: 5 | loss: 0.0561212
	speed: 0.0617s/iter; left time: 1789.9623s
	iters: 700, epoch: 5 | loss: 0.0602360
	speed: 0.0639s/iter; left time: 1846.0130s
	iters: 800, epoch: 5 | loss: 0.0521422
	speed: 0.0644s/iter; left time: 1854.3972s
	iters: 900, epoch: 5 | loss: 0.0566403
	speed: 0.0631s/iter; left time: 1810.5599s
	iters: 1000, epoch: 5 | loss: 0.0550223
	speed: 0.0616s/iter; left time: 1762.0193s
	iters: 1100, epoch: 5 | loss: 0.0532280
	speed: 0.0642s/iter; left time: 1829.3462s
Epoch: 5 cost time: 73.56302332878113
Epoch: 5, Steps: 1138 | Train Loss: 0.0558389 Vali Loss: 0.2100191 Test Loss: 0.2744906
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.0611088
	speed: 1.0342s/iter; left time: 29319.6646s
	iters: 200, epoch: 6 | loss: 0.0545510
	speed: 0.0678s/iter; left time: 1914.6681s
	iters: 300, epoch: 6 | loss: 0.0554542
	speed: 0.0670s/iter; left time: 1886.6187s
	iters: 400, epoch: 6 | loss: 0.0592518
	speed: 0.0607s/iter; left time: 1703.0465s
	iters: 500, epoch: 6 | loss: 0.0555589
	speed: 0.0622s/iter; left time: 1737.6465s
	iters: 600, epoch: 6 | loss: 0.0520289
	speed: 0.0643s/iter; left time: 1791.6163s
	iters: 700, epoch: 6 | loss: 0.0531939
	speed: 0.0641s/iter; left time: 1777.7184s
	iters: 800, epoch: 6 | loss: 0.0527983
	speed: 0.0634s/iter; left time: 1754.3105s
	iters: 900, epoch: 6 | loss: 0.0508745
	speed: 0.0655s/iter; left time: 1804.9699s
	iters: 1000, epoch: 6 | loss: 0.0511431
	speed: 0.0597s/iter; left time: 1637.7206s
	iters: 1100, epoch: 6 | loss: 0.0587038
	speed: 0.0623s/iter; left time: 1703.4894s
Epoch: 6 cost time: 74.00159859657288
Epoch: 6, Steps: 1138 | Train Loss: 0.0542920 Vali Loss: 0.2091125 Test Loss: 0.2758219
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.0517103
	speed: 1.0024s/iter; left time: 27277.3837s
	iters: 200, epoch: 7 | loss: 0.0541592
	speed: 0.0606s/iter; left time: 1643.1828s
	iters: 300, epoch: 7 | loss: 0.0517422
	speed: 0.0692s/iter; left time: 1868.5773s
	iters: 400, epoch: 7 | loss: 0.0534082
	speed: 0.0656s/iter; left time: 1766.7540s
	iters: 500, epoch: 7 | loss: 0.0573667
	speed: 0.0643s/iter; left time: 1724.6671s
	iters: 600, epoch: 7 | loss: 0.0522850
	speed: 0.0601s/iter; left time: 1604.6126s
	iters: 700, epoch: 7 | loss: 0.0568147
	speed: 0.0616s/iter; left time: 1640.0104s
	iters: 800, epoch: 7 | loss: 0.0585613
	speed: 0.0644s/iter; left time: 1707.4742s
	iters: 900, epoch: 7 | loss: 0.0510644
	speed: 0.0641s/iter; left time: 1692.4624s
	iters: 1000, epoch: 7 | loss: 0.0494191
	speed: 0.0630s/iter; left time: 1656.5170s
	iters: 1100, epoch: 7 | loss: 0.0545395
	speed: 0.0624s/iter; left time: 1636.2495s
Epoch: 7 cost time: 73.6766049861908
Epoch: 7, Steps: 1138 | Train Loss: 0.0534883 Vali Loss: 0.2113858 Test Loss: 0.2769631
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.0492112
	speed: 1.0123s/iter; left time: 26395.0379s
	iters: 200, epoch: 8 | loss: 0.0536842
	speed: 0.0717s/iter; left time: 1863.0573s
	iters: 300, epoch: 8 | loss: 0.0506494
	speed: 0.0649s/iter; left time: 1679.5828s
	iters: 400, epoch: 8 | loss: 0.0509848
	speed: 0.0641s/iter; left time: 1651.3801s
	iters: 500, epoch: 8 | loss: 0.0560297
	speed: 0.0626s/iter; left time: 1608.5007s
	iters: 600, epoch: 8 | loss: 0.0521255
	speed: 0.0641s/iter; left time: 1639.6219s
	iters: 700, epoch: 8 | loss: 0.0539027
	speed: 0.0640s/iter; left time: 1630.6846s
	iters: 800, epoch: 8 | loss: 0.0569195
	speed: 0.0665s/iter; left time: 1688.6293s
	iters: 900, epoch: 8 | loss: 0.0520387
	speed: 0.0665s/iter; left time: 1680.2276s
	iters: 1000, epoch: 8 | loss: 0.0517653
	speed: 0.0673s/iter; left time: 1693.3199s
	iters: 1100, epoch: 8 | loss: 0.0494554
	speed: 0.0649s/iter; left time: 1626.7917s
Epoch: 8 cost time: 75.96630525588989
Epoch: 8, Steps: 1138 | Train Loss: 0.0530653 Vali Loss: 0.2118485 Test Loss: 0.2772036
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.0504179
	speed: 1.0334s/iter; left time: 25770.0568s
	iters: 200, epoch: 9 | loss: 0.0508604
	speed: 0.0646s/iter; left time: 1605.2067s
	iters: 300, epoch: 9 | loss: 0.0513638
	speed: 0.0655s/iter; left time: 1621.3508s
	iters: 400, epoch: 9 | loss: 0.0499579
	speed: 0.0647s/iter; left time: 1593.4206s
	iters: 500, epoch: 9 | loss: 0.0541511
	speed: 0.0617s/iter; left time: 1513.3931s
	iters: 600, epoch: 9 | loss: 0.0555043
	speed: 0.0623s/iter; left time: 1522.6523s
	iters: 700, epoch: 9 | loss: 0.0523830
	speed: 0.0628s/iter; left time: 1528.5301s
	iters: 800, epoch: 9 | loss: 0.0506647
	speed: 0.0637s/iter; left time: 1543.8060s
	iters: 900, epoch: 9 | loss: 0.0482308
	speed: 0.0618s/iter; left time: 1490.5640s
	iters: 1000, epoch: 9 | loss: 0.0491023
	speed: 0.0635s/iter; left time: 1526.6011s
	iters: 1100, epoch: 9 | loss: 0.0504762
	speed: 0.0648s/iter; left time: 1551.4710s
Epoch: 9 cost time: 74.11189579963684
Epoch: 9, Steps: 1138 | Train Loss: 0.0528237 Vali Loss: 0.2115309 Test Loss: 0.2772867
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.0542797
	speed: 0.9993s/iter; left time: 23781.4734s
	iters: 200, epoch: 10 | loss: 0.0489212
	speed: 0.0638s/iter; left time: 1510.9046s
	iters: 300, epoch: 10 | loss: 0.0517357
	speed: 0.0697s/iter; left time: 1645.6091s
	iters: 400, epoch: 10 | loss: 0.0522017
	speed: 0.0660s/iter; left time: 1550.8359s
	iters: 500, epoch: 10 | loss: 0.0502885
	speed: 0.0622s/iter; left time: 1455.8105s
	iters: 600, epoch: 10 | loss: 0.0531518
	speed: 0.0616s/iter; left time: 1434.3475s
	iters: 700, epoch: 10 | loss: 0.0533661
	speed: 0.0598s/iter; left time: 1386.4655s
	iters: 800, epoch: 10 | loss: 0.0556971
	speed: 0.0622s/iter; left time: 1436.2738s
	iters: 900, epoch: 10 | loss: 0.0576799
	speed: 0.0606s/iter; left time: 1393.7033s
	iters: 1000, epoch: 10 | loss: 0.0561925
	speed: 0.0641s/iter; left time: 1468.4454s
	iters: 1100, epoch: 10 | loss: 0.0535895
	speed: 0.0617s/iter; left time: 1405.9753s
Epoch: 10 cost time: 73.23816466331482
Epoch: 10, Steps: 1138 | Train Loss: 0.0527302 Vali Loss: 0.2113479 Test Loss: 0.2773063
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.0460179
	speed: 1.0288s/iter; left time: 23313.3514s
	iters: 200, epoch: 11 | loss: 0.0500184
	speed: 0.0695s/iter; left time: 1567.2888s
	iters: 300, epoch: 11 | loss: 0.0526551
	speed: 0.0654s/iter; left time: 1468.4355s
	iters: 400, epoch: 11 | loss: 0.0604509
	speed: 0.0622s/iter; left time: 1390.7861s
	iters: 500, epoch: 11 | loss: 0.0534150
	speed: 0.0647s/iter; left time: 1441.0473s
	iters: 600, epoch: 11 | loss: 0.0516114
	speed: 0.0622s/iter; left time: 1378.2492s
	iters: 700, epoch: 11 | loss: 0.0532842
	speed: 0.0626s/iter; left time: 1381.5727s
	iters: 800, epoch: 11 | loss: 0.0535789
	speed: 0.0643s/iter; left time: 1411.6309s
	iters: 900, epoch: 11 | loss: 0.0531030
	speed: 0.0637s/iter; left time: 1393.1040s
	iters: 1000, epoch: 11 | loss: 0.0526754
	speed: 0.0692s/iter; left time: 1506.7952s
	iters: 1100, epoch: 11 | loss: 0.0518688
	speed: 0.0645s/iter; left time: 1396.0782s
Epoch: 11 cost time: 75.91696667671204
Epoch: 11, Steps: 1138 | Train Loss: 0.0526864 Vali Loss: 0.2119474 Test Loss: 0.2775788
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.0552458
	speed: 1.0154s/iter; left time: 21854.6319s
	iters: 200, epoch: 12 | loss: 0.0535040
	speed: 0.0620s/iter; left time: 1329.2896s
	iters: 300, epoch: 12 | loss: 0.0483312
	speed: 0.0610s/iter; left time: 1300.3749s
	iters: 400, epoch: 12 | loss: 0.0545996
	speed: 0.0628s/iter; left time: 1332.9457s
	iters: 500, epoch: 12 | loss: 0.0533680
	speed: 0.0609s/iter; left time: 1287.1471s
	iters: 600, epoch: 12 | loss: 0.0499667
	speed: 0.0622s/iter; left time: 1308.6797s
	iters: 700, epoch: 12 | loss: 0.0541597
	speed: 0.0613s/iter; left time: 1281.7211s
	iters: 800, epoch: 12 | loss: 0.0520468
	speed: 0.0660s/iter; left time: 1373.3611s
	iters: 900, epoch: 12 | loss: 0.0552496
	speed: 0.0634s/iter; left time: 1313.4771s
	iters: 1000, epoch: 12 | loss: 0.0525894
	speed: 0.0624s/iter; left time: 1286.9406s
	iters: 1100, epoch: 12 | loss: 0.0547599
	speed: 0.0665s/iter; left time: 1363.8570s
Epoch: 12 cost time: 73.20478296279907
Epoch: 12, Steps: 1138 | Train Loss: 0.0526607 Vali Loss: 0.2117556 Test Loss: 0.2775705
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : ECL_96_96_34_emb_512_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (5165, 1, 96, 321) (5165, 1, 96, 321)
test shape: (5165, 96, 321) (5165, 96, 321)
mse:0.2595495879650116, mae:0.3517496585845947
Args in experiment:
Namespace(is_training=1, model_id='ECL_96_96_35_emb_512', model='xLSTM', data='custom', root_path='./data/electricity/', data_path='/input-data/electricity.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, enc_in=321, dec_in=7, c_out=321, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.3, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=10, batch_size=8, patience=10, learning_rate=0.001, des='test', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, use_norm=True, partial_start_index=0, hidden_size=512, num_layers=2, mark_enc_in=4, embedding_dim=512, weight_decay=1e-06, kernal_size=5, num_heads_xlstm=2, qkv_proj_blocksize=4, proj_factor=1.3, num_blocks=2, slstm_at=1, grad_clip_norm=0.5, d_state=16, d_conv=4, expand=2)
Use GPU: cuda:0
{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-L/usr/local/cuda/lib', '-lcublas'], 'extra_cflags': ['-DSLSTM_HIDDEN_SIZE=512', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=2', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__'], 'extra_cuda_cflags': ['-Xptxas="-v"', '-gencode', 'arch=compute_80,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=512', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=2', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__']}
Using /home/thetayne/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/thetayne/.cache/torch_extensions/py310_cu121/slstm_HS512BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0/build.ninja...
Building extension module slstm_HS512BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module slstm_HS512BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
>>>>>>>start training : ECL_96_96_35_emb_512_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 18221
val 2537
test 5165
	iters: 100, epoch: 1 | loss: 0.2331897
	speed: 0.0407s/iter; left time: 921.7811s
	iters: 200, epoch: 1 | loss: 0.1493428
	speed: 0.0232s/iter; left time: 523.4078s
	iters: 300, epoch: 1 | loss: 0.1484913
	speed: 0.0225s/iter; left time: 505.6785s
	iters: 400, epoch: 1 | loss: 0.1468960
	speed: 0.0221s/iter; left time: 494.8718s
	iters: 500, epoch: 1 | loss: 0.1391585
	speed: 0.0219s/iter; left time: 488.2830s
	iters: 600, epoch: 1 | loss: 0.1337550
	speed: 0.0223s/iter; left time: 494.8214s
	iters: 700, epoch: 1 | loss: 0.1142733
	speed: 0.0209s/iter; left time: 462.2056s
	iters: 800, epoch: 1 | loss: 0.1192251
	speed: 0.0223s/iter; left time: 489.0347s
	iters: 900, epoch: 1 | loss: 0.0963205
	speed: 0.0221s/iter; left time: 484.0770s
	iters: 1000, epoch: 1 | loss: 0.0989692
	speed: 0.0237s/iter; left time: 515.7897s
	iters: 1100, epoch: 1 | loss: 0.0846472
	speed: 0.0210s/iter; left time: 454.0515s
	iters: 1200, epoch: 1 | loss: 0.0927274
	speed: 0.0209s/iter; left time: 450.9337s
	iters: 1300, epoch: 1 | loss: 0.0961835
	speed: 0.0221s/iter; left time: 473.7098s
	iters: 1400, epoch: 1 | loss: 0.0914813
	speed: 0.0233s/iter; left time: 497.8373s
	iters: 1500, epoch: 1 | loss: 0.0911531
	speed: 0.0220s/iter; left time: 467.9850s
	iters: 1600, epoch: 1 | loss: 0.0874136
	speed: 0.0226s/iter; left time: 478.9083s
	iters: 1700, epoch: 1 | loss: 0.0913342
	speed: 0.0214s/iter; left time: 451.1314s
	iters: 1800, epoch: 1 | loss: 0.0864684
	speed: 0.0227s/iter; left time: 476.0442s
	iters: 1900, epoch: 1 | loss: 0.0946854
	speed: 0.0213s/iter; left time: 444.3000s
	iters: 2000, epoch: 1 | loss: 0.0783636
	speed: 0.0212s/iter; left time: 440.9991s
	iters: 2100, epoch: 1 | loss: 0.0855012
	speed: 0.0223s/iter; left time: 460.2243s
	iters: 2200, epoch: 1 | loss: 0.0794901
	speed: 0.0232s/iter; left time: 476.3773s
Epoch: 1 cost time: 52.25313639640808
Epoch: 1, Steps: 2277 | Train Loss: 0.1199090 Vali Loss: 0.2029119 Test Loss: 0.2580723
Validation loss decreased (inf --> 0.202912).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.0766768
	speed: 0.5758s/iter; left time: 11741.8562s
	iters: 200, epoch: 2 | loss: 0.0861318
	speed: 0.0204s/iter; left time: 413.6807s
	iters: 300, epoch: 2 | loss: 0.0814830
	speed: 0.0209s/iter; left time: 421.3677s
	iters: 400, epoch: 2 | loss: 0.0842972
	speed: 0.0221s/iter; left time: 444.2667s
	iters: 500, epoch: 2 | loss: 0.0822831
	speed: 0.0225s/iter; left time: 448.9141s
	iters: 600, epoch: 2 | loss: 0.0782621
	speed: 0.0221s/iter; left time: 439.5014s
	iters: 700, epoch: 2 | loss: 0.0734028
	speed: 0.0217s/iter; left time: 428.6568s
	iters: 800, epoch: 2 | loss: 0.0813399
	speed: 0.0228s/iter; left time: 448.2708s
	iters: 900, epoch: 2 | loss: 0.0802730
	speed: 0.0218s/iter; left time: 426.6020s
	iters: 1000, epoch: 2 | loss: 0.0767113
	speed: 0.0210s/iter; left time: 410.0757s
	iters: 1100, epoch: 2 | loss: 0.0717757
	speed: 0.0222s/iter; left time: 431.0908s
	iters: 1200, epoch: 2 | loss: 0.0752277
	speed: 0.0241s/iter; left time: 465.4411s
	iters: 1300, epoch: 2 | loss: 0.0741668
	speed: 0.0216s/iter; left time: 414.4866s
	iters: 1400, epoch: 2 | loss: 0.0773247
	speed: 0.0215s/iter; left time: 410.3972s
	iters: 1500, epoch: 2 | loss: 0.0660033
	speed: 0.0227s/iter; left time: 430.7205s
	iters: 1600, epoch: 2 | loss: 0.0726803
	speed: 0.0236s/iter; left time: 446.0139s
	iters: 1700, epoch: 2 | loss: 0.0796161
	speed: 0.0224s/iter; left time: 421.0962s
	iters: 1800, epoch: 2 | loss: 0.0726523
	speed: 0.0228s/iter; left time: 425.8878s
	iters: 1900, epoch: 2 | loss: 0.0704452
	speed: 0.0220s/iter; left time: 409.5654s
	iters: 2000, epoch: 2 | loss: 0.0811957
	speed: 0.0222s/iter; left time: 411.1243s
	iters: 2100, epoch: 2 | loss: 0.0752468
	speed: 0.0208s/iter; left time: 382.9822s
	iters: 2200, epoch: 2 | loss: 0.0772268
	speed: 0.0208s/iter; left time: 380.7022s
Epoch: 2 cost time: 51.59311652183533
Epoch: 2, Steps: 2277 | Train Loss: 0.0773453 Vali Loss: 0.2038299 Test Loss: 0.2664350
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.0704462
	speed: 0.5741s/iter; left time: 10400.8826s
	iters: 200, epoch: 3 | loss: 0.0665651
	speed: 0.0211s/iter; left time: 380.7900s
	iters: 300, epoch: 3 | loss: 0.0674862
	speed: 0.0219s/iter; left time: 391.8686s
	iters: 400, epoch: 3 | loss: 0.0588424
	speed: 0.0221s/iter; left time: 394.0944s
	iters: 500, epoch: 3 | loss: 0.0661626
	speed: 0.0229s/iter; left time: 405.5489s
	iters: 600, epoch: 3 | loss: 0.0629412
	speed: 0.0229s/iter; left time: 402.6790s
	iters: 700, epoch: 3 | loss: 0.0609575
	speed: 0.0220s/iter; left time: 384.9060s
	iters: 800, epoch: 3 | loss: 0.0669181
	speed: 0.0223s/iter; left time: 387.6828s
	iters: 900, epoch: 3 | loss: 0.0602386
	speed: 0.0224s/iter; left time: 387.5829s
	iters: 1000, epoch: 3 | loss: 0.0689509
	speed: 0.0217s/iter; left time: 373.5998s
	iters: 1100, epoch: 3 | loss: 0.0672869
	speed: 0.0210s/iter; left time: 359.9897s
	iters: 1200, epoch: 3 | loss: 0.0629695
	speed: 0.0212s/iter; left time: 360.8472s
	iters: 1300, epoch: 3 | loss: 0.0669457
	speed: 0.0224s/iter; left time: 379.3421s
	iters: 1400, epoch: 3 | loss: 0.0702534
	speed: 0.0240s/iter; left time: 403.7173s
	iters: 1500, epoch: 3 | loss: 0.0575705
	speed: 0.0212s/iter; left time: 355.1318s
	iters: 1600, epoch: 3 | loss: 0.0607784
	speed: 0.0209s/iter; left time: 348.0120s
	iters: 1700, epoch: 3 | loss: 0.0567820
	speed: 0.0226s/iter; left time: 373.8839s
	iters: 1800, epoch: 3 | loss: 0.0698514
	speed: 0.0239s/iter; left time: 392.0133s
	iters: 1900, epoch: 3 | loss: 0.0636503
	speed: 0.0220s/iter; left time: 358.7690s
	iters: 2000, epoch: 3 | loss: 0.0617922
	speed: 0.0224s/iter; left time: 362.9818s
	iters: 2100, epoch: 3 | loss: 0.0573766
	speed: 0.0219s/iter; left time: 353.6784s
	iters: 2200, epoch: 3 | loss: 0.0685450
	speed: 0.0222s/iter; left time: 356.0778s
Epoch: 3 cost time: 52.04170536994934
Epoch: 3, Steps: 2277 | Train Loss: 0.0642523 Vali Loss: 0.2030944 Test Loss: 0.2705026
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.0556251
	speed: 0.5765s/iter; left time: 9132.1086s
	iters: 200, epoch: 4 | loss: 0.0670098
	speed: 0.0206s/iter; left time: 323.7550s
	iters: 300, epoch: 4 | loss: 0.0671904
	speed: 0.0225s/iter; left time: 351.8706s
	iters: 400, epoch: 4 | loss: 0.0644893
	speed: 0.0225s/iter; left time: 349.6716s
	iters: 500, epoch: 4 | loss: 0.0598513
	speed: 0.0214s/iter; left time: 330.8619s
	iters: 600, epoch: 4 | loss: 0.0594559
	speed: 0.0223s/iter; left time: 342.2625s
	iters: 700, epoch: 4 | loss: 0.0547639
	speed: 0.0227s/iter; left time: 346.5376s
	iters: 800, epoch: 4 | loss: 0.0630893
	speed: 0.0223s/iter; left time: 338.2084s
	iters: 900, epoch: 4 | loss: 0.0561613
	speed: 0.0230s/iter; left time: 345.9990s
	iters: 1000, epoch: 4 | loss: 0.0669625
	speed: 0.0219s/iter; left time: 326.7626s
	iters: 1100, epoch: 4 | loss: 0.0597149
	speed: 0.0223s/iter; left time: 330.5315s
	iters: 1200, epoch: 4 | loss: 0.0521097
	speed: 0.0217s/iter; left time: 319.4027s
	iters: 1300, epoch: 4 | loss: 0.0597953
	speed: 0.0210s/iter; left time: 307.6003s
	iters: 1400, epoch: 4 | loss: 0.0643675
	speed: 0.0218s/iter; left time: 317.2783s
	iters: 1500, epoch: 4 | loss: 0.0615713
	speed: 0.0226s/iter; left time: 326.3637s
	iters: 1600, epoch: 4 | loss: 0.0632847
	speed: 0.0228s/iter; left time: 327.1328s
	iters: 1700, epoch: 4 | loss: 0.0561565
	speed: 0.0211s/iter; left time: 300.5206s
	iters: 1800, epoch: 4 | loss: 0.0555959
	speed: 0.0219s/iter; left time: 309.2343s
	iters: 1900, epoch: 4 | loss: 0.0542221
	speed: 0.0232s/iter; left time: 326.0493s
	iters: 2000, epoch: 4 | loss: 0.0645612
	speed: 0.0231s/iter; left time: 322.3451s
	iters: 2100, epoch: 4 | loss: 0.0585246
	speed: 0.0225s/iter; left time: 311.0141s
	iters: 2200, epoch: 4 | loss: 0.0561858
	speed: 0.0219s/iter; left time: 300.9795s
Epoch: 4 cost time: 51.54116630554199
Epoch: 4, Steps: 2277 | Train Loss: 0.0596038 Vali Loss: 0.2085638 Test Loss: 0.2802458
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.0604069
	speed: 0.5751s/iter; left time: 7799.6254s
	iters: 200, epoch: 5 | loss: 0.0584463
	speed: 0.0196s/iter; left time: 263.5648s
	iters: 300, epoch: 5 | loss: 0.0592848
	speed: 0.0192s/iter; left time: 256.4466s
	iters: 400, epoch: 5 | loss: 0.0585831
	speed: 0.0213s/iter; left time: 282.7558s
	iters: 500, epoch: 5 | loss: 0.0657657
	speed: 0.0232s/iter; left time: 305.1170s
	iters: 600, epoch: 5 | loss: 0.0525918
	speed: 0.0220s/iter; left time: 287.5959s
	iters: 700, epoch: 5 | loss: 0.0569195
	speed: 0.0213s/iter; left time: 275.7782s
	iters: 800, epoch: 5 | loss: 0.0593550
	speed: 0.0222s/iter; left time: 285.1161s
	iters: 900, epoch: 5 | loss: 0.0579701
	speed: 0.0226s/iter; left time: 288.4356s
	iters: 1000, epoch: 5 | loss: 0.0566574
	speed: 0.0229s/iter; left time: 290.1345s
	iters: 1100, epoch: 5 | loss: 0.0516313
	speed: 0.0224s/iter; left time: 281.4338s
	iters: 1200, epoch: 5 | loss: 0.0643979
	speed: 0.0214s/iter; left time: 266.1643s
	iters: 1300, epoch: 5 | loss: 0.0607324
	speed: 0.0228s/iter; left time: 281.3205s
	iters: 1400, epoch: 5 | loss: 0.0519320
	speed: 0.0216s/iter; left time: 264.4856s
	iters: 1500, epoch: 5 | loss: 0.0548282
	speed: 0.0212s/iter; left time: 257.2790s
	iters: 1600, epoch: 5 | loss: 0.0585610
	speed: 0.0219s/iter; left time: 264.6368s
	iters: 1700, epoch: 5 | loss: 0.0650846
	speed: 0.0229s/iter; left time: 274.2679s
	iters: 1800, epoch: 5 | loss: 0.0576216
	speed: 0.0224s/iter; left time: 265.8286s
	iters: 1900, epoch: 5 | loss: 0.0636433
	speed: 0.0212s/iter; left time: 249.6727s
	iters: 2000, epoch: 5 | loss: 0.0588767
	speed: 0.0222s/iter; left time: 258.4632s
	iters: 2100, epoch: 5 | loss: 0.0581069
	speed: 0.0224s/iter; left time: 259.2016s
	iters: 2200, epoch: 5 | loss: 0.0608809
	speed: 0.0232s/iter; left time: 265.8234s
Epoch: 5 cost time: 51.446284770965576
Epoch: 5, Steps: 2277 | Train Loss: 0.0572682 Vali Loss: 0.2133681 Test Loss: 0.2869627
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.0517741
	speed: 0.5748s/iter; left time: 6486.8236s
	iters: 200, epoch: 6 | loss: 0.0512311
	speed: 0.0201s/iter; left time: 225.1491s
	iters: 300, epoch: 6 | loss: 0.0643651
	speed: 0.0211s/iter; left time: 233.9138s
	iters: 400, epoch: 6 | loss: 0.0574097
	speed: 0.0198s/iter; left time: 217.0772s
	iters: 500, epoch: 6 | loss: 0.0572456
	speed: 0.0196s/iter; left time: 213.4033s
	iters: 600, epoch: 6 | loss: 0.0546998
	speed: 0.0203s/iter; left time: 219.0540s
	iters: 700, epoch: 6 | loss: 0.0541136
	speed: 0.0210s/iter; left time: 224.1213s
	iters: 800, epoch: 6 | loss: 0.0521891
	speed: 0.0217s/iter; left time: 230.0416s
	iters: 900, epoch: 6 | loss: 0.0572392
	speed: 0.0196s/iter; left time: 205.4004s
	iters: 1000, epoch: 6 | loss: 0.0614829
	speed: 0.0204s/iter; left time: 212.0303s
	iters: 1100, epoch: 6 | loss: 0.0604274
	speed: 0.0225s/iter; left time: 231.6083s
	iters: 1200, epoch: 6 | loss: 0.0530906
	speed: 0.0240s/iter; left time: 243.9825s
	iters: 1300, epoch: 6 | loss: 0.0520940
	speed: 0.0220s/iter; left time: 221.9226s
	iters: 1400, epoch: 6 | loss: 0.0510858
	speed: 0.0225s/iter; left time: 224.4986s
	iters: 1500, epoch: 6 | loss: 0.0537190
	speed: 0.0213s/iter; left time: 210.4667s
	iters: 1600, epoch: 6 | loss: 0.0571086
	speed: 0.0223s/iter; left time: 217.9744s
	iters: 1700, epoch: 6 | loss: 0.0570558
	speed: 0.0216s/iter; left time: 208.8639s
	iters: 1800, epoch: 6 | loss: 0.0600496
	speed: 0.0210s/iter; left time: 201.3534s
	iters: 1900, epoch: 6 | loss: 0.0597837
	speed: 0.0222s/iter; left time: 210.8335s
	iters: 2000, epoch: 6 | loss: 0.0564030
	speed: 0.0230s/iter; left time: 216.1412s
	iters: 2100, epoch: 6 | loss: 0.0513092
	speed: 0.0226s/iter; left time: 209.8061s
	iters: 2200, epoch: 6 | loss: 0.0548608
	speed: 0.0209s/iter; left time: 192.3446s
Epoch: 6 cost time: 50.29925322532654
Epoch: 6, Steps: 2277 | Train Loss: 0.0561203 Vali Loss: 0.2166880 Test Loss: 0.2915716
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.0542801
	speed: 0.5736s/iter; left time: 5167.3335s
	iters: 200, epoch: 7 | loss: 0.0597686
	speed: 0.0238s/iter; left time: 212.1313s
	iters: 300, epoch: 7 | loss: 0.0550033
	speed: 0.0228s/iter; left time: 200.8462s
	iters: 400, epoch: 7 | loss: 0.0563898
	speed: 0.0223s/iter; left time: 194.3131s
	iters: 500, epoch: 7 | loss: 0.0554018
	speed: 0.0223s/iter; left time: 192.3806s
	iters: 600, epoch: 7 | loss: 0.0543080
	speed: 0.0220s/iter; left time: 186.8725s
	iters: 700, epoch: 7 | loss: 0.0547259
	speed: 0.0214s/iter; left time: 179.7760s
	iters: 800, epoch: 7 | loss: 0.0532630
	speed: 0.0214s/iter; left time: 177.5319s
	iters: 900, epoch: 7 | loss: 0.0537432
	speed: 0.0224s/iter; left time: 183.8033s
	iters: 1000, epoch: 7 | loss: 0.0574417
	speed: 0.0236s/iter; left time: 191.3794s
	iters: 1100, epoch: 7 | loss: 0.0623045
	speed: 0.0214s/iter; left time: 171.6528s
	iters: 1200, epoch: 7 | loss: 0.0581030
	speed: 0.0219s/iter; left time: 172.8922s
	iters: 1300, epoch: 7 | loss: 0.0538663
	speed: 0.0226s/iter; left time: 176.2391s
	iters: 1400, epoch: 7 | loss: 0.0530038
	speed: 0.0235s/iter; left time: 180.9809s
	iters: 1500, epoch: 7 | loss: 0.0546507
	speed: 0.0221s/iter; left time: 168.2854s
	iters: 1600, epoch: 7 | loss: 0.0526066
	speed: 0.0232s/iter; left time: 174.0188s
	iters: 1700, epoch: 7 | loss: 0.0544929
	speed: 0.0218s/iter; left time: 161.8143s
	iters: 1800, epoch: 7 | loss: 0.0540918
	speed: 0.0225s/iter; left time: 164.7280s
	iters: 1900, epoch: 7 | loss: 0.0514850
	speed: 0.0217s/iter; left time: 156.4105s
	iters: 2000, epoch: 7 | loss: 0.0543921
	speed: 0.0216s/iter; left time: 153.3899s
	iters: 2100, epoch: 7 | loss: 0.0509114
	speed: 0.0225s/iter; left time: 157.7791s
	iters: 2200, epoch: 7 | loss: 0.0559442
	speed: 0.0247s/iter; left time: 170.3275s
Epoch: 7 cost time: 52.61221528053284
Epoch: 7, Steps: 2277 | Train Loss: 0.0555381 Vali Loss: 0.2171260 Test Loss: 0.2936555
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.0569525
	speed: 0.5778s/iter; left time: 3889.9479s
	iters: 200, epoch: 8 | loss: 0.0553508
	speed: 0.0202s/iter; left time: 134.2141s
	iters: 300, epoch: 8 | loss: 0.0620931
	speed: 0.0206s/iter; left time: 134.6975s
	iters: 400, epoch: 8 | loss: 0.0585634
	speed: 0.0204s/iter; left time: 131.1971s
	iters: 500, epoch: 8 | loss: 0.0545646
	speed: 0.0218s/iter; left time: 137.8891s
	iters: 600, epoch: 8 | loss: 0.0542684
	speed: 0.0220s/iter; left time: 137.2956s
	iters: 700, epoch: 8 | loss: 0.0589779
	speed: 0.0225s/iter; left time: 137.8170s
	iters: 800, epoch: 8 | loss: 0.0562434
	speed: 0.0226s/iter; left time: 136.4380s
	iters: 900, epoch: 8 | loss: 0.0548703
	speed: 0.0224s/iter; left time: 133.1171s
	iters: 1000, epoch: 8 | loss: 0.0634948
	speed: 0.0218s/iter; left time: 126.8751s
	iters: 1100, epoch: 8 | loss: 0.0521306
	speed: 0.0220s/iter; left time: 126.0918s
	iters: 1200, epoch: 8 | loss: 0.0539169
	speed: 0.0220s/iter; left time: 123.7962s
	iters: 1300, epoch: 8 | loss: 0.0570075
	speed: 0.0222s/iter; left time: 122.5989s
	iters: 1400, epoch: 8 | loss: 0.0536298
	speed: 0.0220s/iter; left time: 119.4264s
	iters: 1500, epoch: 8 | loss: 0.0521135
	speed: 0.0221s/iter; left time: 117.9189s
	iters: 1600, epoch: 8 | loss: 0.0564062
	speed: 0.0225s/iter; left time: 117.8871s
	iters: 1700, epoch: 8 | loss: 0.0572390
	speed: 0.0216s/iter; left time: 110.7716s
	iters: 1800, epoch: 8 | loss: 0.0544275
	speed: 0.0228s/iter; left time: 114.9133s
	iters: 1900, epoch: 8 | loss: 0.0613640
	speed: 0.0224s/iter; left time: 110.6367s
	iters: 2000, epoch: 8 | loss: 0.0539028
	speed: 0.0223s/iter; left time: 107.7694s
	iters: 2100, epoch: 8 | loss: 0.0529942
	speed: 0.0218s/iter; left time: 103.1853s
	iters: 2200, epoch: 8 | loss: 0.0525038
	speed: 0.0226s/iter; left time: 104.9031s
Epoch: 8 cost time: 51.58950066566467
Epoch: 8, Steps: 2277 | Train Loss: 0.0552521 Vali Loss: 0.2182828 Test Loss: 0.2945468
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 0.0582660
	speed: 0.5830s/iter; left time: 2597.2386s
	iters: 200, epoch: 9 | loss: 0.0559499
	speed: 0.0216s/iter; left time: 94.1816s
	iters: 300, epoch: 9 | loss: 0.0567904
	speed: 0.0217s/iter; left time: 92.2594s
	iters: 400, epoch: 9 | loss: 0.0567483
	speed: 0.0219s/iter; left time: 91.0706s
	iters: 500, epoch: 9 | loss: 0.0578515
	speed: 0.0228s/iter; left time: 92.2782s
	iters: 600, epoch: 9 | loss: 0.0565184
	speed: 0.0220s/iter; left time: 86.9961s
	iters: 700, epoch: 9 | loss: 0.0553228
	speed: 0.0219s/iter; left time: 84.6071s
	iters: 800, epoch: 9 | loss: 0.0565236
	speed: 0.0228s/iter; left time: 85.5505s
	iters: 900, epoch: 9 | loss: 0.0551636
	speed: 0.0222s/iter; left time: 81.1620s
	iters: 1000, epoch: 9 | loss: 0.0643344
	speed: 0.0214s/iter; left time: 76.1482s
	iters: 1100, epoch: 9 | loss: 0.0600945
	speed: 0.0222s/iter; left time: 76.5905s
	iters: 1200, epoch: 9 | loss: 0.0601161
	speed: 0.0223s/iter; left time: 74.7314s
	iters: 1300, epoch: 9 | loss: 0.0509252
	speed: 0.0225s/iter; left time: 73.1589s
	iters: 1400, epoch: 9 | loss: 0.0516808
	speed: 0.0220s/iter; left time: 69.3690s
	iters: 1500, epoch: 9 | loss: 0.0517142
	speed: 0.0218s/iter; left time: 66.6207s
	iters: 1600, epoch: 9 | loss: 0.0507615
	speed: 0.0224s/iter; left time: 66.1152s
	iters: 1700, epoch: 9 | loss: 0.0598895
	speed: 0.0219s/iter; left time: 62.6488s
	iters: 1800, epoch: 9 | loss: 0.0502317
	speed: 0.0219s/iter; left time: 60.3035s
	iters: 1900, epoch: 9 | loss: 0.0620527
	speed: 0.0226s/iter; left time: 59.9439s
	iters: 2000, epoch: 9 | loss: 0.0517326
	speed: 0.0220s/iter; left time: 56.2214s
	iters: 2100, epoch: 9 | loss: 0.0617668
	speed: 0.0224s/iter; left time: 54.9204s
	iters: 2200, epoch: 9 | loss: 0.0519369
	speed: 0.0226s/iter; left time: 53.1616s
Epoch: 9 cost time: 51.82275986671448
Epoch: 9, Steps: 2277 | Train Loss: 0.0551100 Vali Loss: 0.2188186 Test Loss: 0.2951613
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 0.0544158
	speed: 0.5754s/iter; left time: 1253.2489s
	iters: 200, epoch: 10 | loss: 0.0585308
	speed: 0.0208s/iter; left time: 43.2875s
	iters: 300, epoch: 10 | loss: 0.0533089
	speed: 0.0208s/iter; left time: 41.1082s
	iters: 400, epoch: 10 | loss: 0.0531106
	speed: 0.0221s/iter; left time: 41.5623s
	iters: 500, epoch: 10 | loss: 0.0564460
	speed: 0.0227s/iter; left time: 40.3013s
	iters: 600, epoch: 10 | loss: 0.0572460
	speed: 0.0219s/iter; left time: 36.8146s
	iters: 700, epoch: 10 | loss: 0.0540373
	speed: 0.0220s/iter; left time: 34.7905s
	iters: 800, epoch: 10 | loss: 0.0497617
	speed: 0.0228s/iter; left time: 33.6956s
	iters: 900, epoch: 10 | loss: 0.0522875
	speed: 0.0219s/iter; left time: 30.1382s
	iters: 1000, epoch: 10 | loss: 0.0504436
	speed: 0.0228s/iter; left time: 29.1140s
	iters: 1100, epoch: 10 | loss: 0.0522274
	speed: 0.0225s/iter; left time: 26.4786s
	iters: 1200, epoch: 10 | loss: 0.0559748
	speed: 0.0222s/iter; left time: 23.9685s
	iters: 1300, epoch: 10 | loss: 0.0526411
	speed: 0.0225s/iter; left time: 21.9652s
	iters: 1400, epoch: 10 | loss: 0.0544892
	speed: 0.0225s/iter; left time: 19.7388s
	iters: 1500, epoch: 10 | loss: 0.0509125
	speed: 0.0221s/iter; left time: 17.1664s
	iters: 1600, epoch: 10 | loss: 0.0563280
	speed: 0.0224s/iter; left time: 15.1722s
	iters: 1700, epoch: 10 | loss: 0.0581097
	speed: 0.0222s/iter; left time: 12.8134s
	iters: 1800, epoch: 10 | loss: 0.0577778
	speed: 0.0219s/iter; left time: 10.4459s
	iters: 1900, epoch: 10 | loss: 0.0578788
	speed: 0.0227s/iter; left time: 8.5796s
	iters: 2000, epoch: 10 | loss: 0.0633802
	speed: 0.0220s/iter; left time: 6.1118s
	iters: 2100, epoch: 10 | loss: 0.0524292
	speed: 0.0223s/iter; left time: 3.9666s
	iters: 2200, epoch: 10 | loss: 0.0586242
	speed: 0.0228s/iter; left time: 1.7780s
Epoch: 10 cost time: 52.02516412734985
Epoch: 10, Steps: 2277 | Train Loss: 0.0550260 Vali Loss: 0.2191606 Test Loss: 0.2955204
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.953125e-06
>>>>>>>testing : ECL_96_96_35_emb_512_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (5165, 1, 96, 321) (5165, 1, 96, 321)
test shape: (5165, 96, 321) (5165, 96, 321)
mse:0.25807294249534607, mae:0.350458025932312
Args in experiment:
Namespace(is_training=1, model_id='ECL_96_96_36_emb_512', model='xLSTM', data='custom', root_path='./data/electricity/', data_path='/input-data/electricity.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, enc_in=321, dec_in=7, c_out=321, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.3, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=10, batch_size=32, patience=10, learning_rate=0.0001, des='test', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, use_norm=True, partial_start_index=0, hidden_size=512, num_layers=2, mark_enc_in=4, embedding_dim=512, weight_decay=0.0001, kernal_size=5, num_heads_xlstm=4, qkv_proj_blocksize=8, proj_factor=1.3, num_blocks=7, slstm_at=1, grad_clip_norm=5.0, d_state=16, d_conv=4, expand=2)
Use GPU: cuda:0
{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-L/usr/local/cuda/lib', '-lcublas'], 'extra_cflags': ['-DSLSTM_HIDDEN_SIZE=512', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__'], 'extra_cuda_cflags': ['-Xptxas="-v"', '-gencode', 'arch=compute_80,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=512', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__']}
Using /home/thetayne/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Creating extension directory /home/thetayne/.cache/torch_extensions/py310_cu121/slstm_HS512BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/thetayne/.cache/torch_extensions/py310_cu121/slstm_HS512BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0/build.ninja...
Building extension module slstm_HS512BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[1/8] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output cuda_error.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS512BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=512 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=4 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/util/cuda_error.cu -o cuda_error.cuda.o 
ptxas info    : 0 bytes gmem
[2/8] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output slstm_forward.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS512BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=512 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=4 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/cuda/slstm_forward.cu -o slstm_forward.cuda.o 
ptxas info    : 0 bytes gmem
[3/8] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output slstm_pointwise.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS512BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=512 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=4 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/cuda/slstm_pointwise.cu -o slstm_pointwise.cuda.o 
ptxas info    : 0 bytes gmem
ptxas info    : Compiling entry function '_ZN5slstm21SLSTMPointwiseForwardILb0EEEviiiPK13__nv_bfloat16S3_PKfS3_jPS1_jS6_S6_' for 'sm_80'
ptxas info    : Function properties for _ZN5slstm21SLSTMPointwiseForwardILb0EEEviiiPK13__nv_bfloat16S3_PKfS3_jPS1_jS6_S6_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 32 registers, 440 bytes cmem[0]
ptxas info    : Compiling entry function '_ZN5slstm21SLSTMPointwiseForwardILb1EEEviiiPK13__nv_bfloat16S3_PKfS3_jPS1_jS6_S6_' for 'sm_80'
ptxas info    : Function properties for _ZN5slstm21SLSTMPointwiseForwardILb1EEEviiiPK13__nv_bfloat16S3_PKfS3_jPS1_jS6_S6_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 32 registers, 440 bytes cmem[0]
ptxas info    : Compiling entry function '_ZN5slstm22SLSTMPointwiseBackwardEiiiPK13__nv_bfloat16jS2_S2_PKfS2_jS2_jPS0_jS5_S5_S5_' for 'sm_80'
ptxas info    : Function properties for _ZN5slstm22SLSTMPointwiseBackwardEiiiPK13__nv_bfloat16jS2_S2_PKfS2_jS2_jPS0_jS5_S5_S5_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 32 registers, 480 bytes cmem[0]
[4/8] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output slstm_backward_cut.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS512BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=512 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=4 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/cuda/slstm_backward_cut.cu -o slstm_backward_cut.cuda.o 
ptxas info    : 0 bytes gmem
ptxas info    : Compiling entry function '_ZN54_GLOBAL__N__2085b59d_21_slstm_backward_cut_cu_1c2c4d0129gradientBiasAggregationKernelEjjjjjjPK13__nv_bfloat16S2_Pf' for 'sm_80'
ptxas info    : Function properties for _ZN54_GLOBAL__N__2085b59d_21_slstm_backward_cut_cu_1c2c4d0129gradientBiasAggregationKernelEjjjjjjPK13__nv_bfloat16S2_Pf
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 32 registers, 400 bytes cmem[0]
[5/8] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output slstm_backward.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS512BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=512 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=4 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/cuda/slstm_backward.cu -o slstm_backward.cuda.o 
ptxas info    : 0 bytes gmem
ptxas info    : Compiling entry function '_ZN50_GLOBAL__N__d983f13f_17_slstm_backward_cu_3639fa5e29gradientBiasAggregationKernelEjjjjjjPK13__nv_bfloat16S2_Pf' for 'sm_80'
ptxas info    : Function properties for _ZN50_GLOBAL__N__d983f13f_17_slstm_backward_cu_3639fa5e29gradientBiasAggregationKernelEjjjjjjPK13__nv_bfloat16S2_Pf
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 32 registers, 400 bytes cmem[0]
[6/8] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output blas.cuda.o.d -DTORCH_EXTENSION_NAME=slstm_HS512BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -Xptxas="-v" -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DSLSTM_HIDDEN_SIZE=512 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=4 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -std=c++17 -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/util/blas.cu -o blas.cuda.o 
ptxas info    : 0 bytes gmem
ptxas info    : Compiling entry function '_Z10initKernelI13__nv_bfloat16EvPT_iS1_' for 'sm_80'
ptxas info    : Function properties for _Z10initKernelI13__nv_bfloat16EvPT_iS1_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 8 registers, 366 bytes cmem[0]
ptxas info    : Compiling entry function '_Z10initKernelI6__halfEvPT_iS1_' for 'sm_80'
ptxas info    : Function properties for _Z10initKernelI6__halfEvPT_iS1_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 8 registers, 366 bytes cmem[0]
ptxas info    : Compiling entry function '_Z10initKernelIfEvPT_iS0_' for 'sm_80'
ptxas info    : Function properties for _Z10initKernelIfEvPT_iS0_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 8 registers, 368 bytes cmem[0]
ptxas info    : Compiling entry function '_Z10initKernelIdEvPT_iS0_' for 'sm_80'
ptxas info    : Function properties for _Z10initKernelIdEvPT_iS0_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 8 registers, 376 bytes cmem[0]
[7/8] c++ -MMD -MF slstm.o.d -DTORCH_EXTENSION_NAME=slstm_HS512BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /usr/local/lib/python3.10/site-packages/torch/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/site-packages/torch/include/TH -isystem /usr/local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/local/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -DSLSTM_HIDDEN_SIZE=512 -DSLSTM_BATCH_SIZE=8 -DSLSTM_NUM_HEADS=4 -DSLSTM_NUM_STATES=4 -DSLSTM_DTYPE_B=float -DSLSTM_DTYPE_R=__nv_bfloat16 -DSLSTM_DTYPE_W=__nv_bfloat16 -DSLSTM_DTYPE_G=__nv_bfloat16 -DSLSTM_DTYPE_S=__nv_bfloat16 -DSLSTM_DTYPE_A=float -DSLSTM_NUM_GATES=4 -DSLSTM_SIMPLE_AGG=true -DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false -DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0 -DSLSTM_FORWARD_CLIPVAL_VALID=false -DSLSTM_FORWARD_CLIPVAL=0.0 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT162_CONVERSIONS__ -c /usr/local/lib/python3.10/site-packages/xlstm/blocks/slstm/src/cuda/slstm.cc -o slstm.o 
[8/8] c++ slstm.o slstm_forward.cuda.o slstm_backward.cuda.o slstm_backward_cut.cuda.o slstm_pointwise.cuda.o blas.cuda.o cuda_error.cuda.o -shared -L/usr/local/cuda/lib -lcublas -L/usr/local/lib/python3.10/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o slstm_HS512BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0.so
Loading extension module slstm_HS512BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
>>>>>>>start training : ECL_96_96_36_emb_512_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 18221
val 2537
test 5165
	iters: 100, epoch: 1 | loss: 0.3439485
	speed: 0.1151s/iter; left time: 643.6686s
	iters: 200, epoch: 1 | loss: 0.2821623
	speed: 0.0921s/iter; left time: 505.7854s
	iters: 300, epoch: 1 | loss: 0.1962534
	speed: 0.0916s/iter; left time: 493.9835s
	iters: 400, epoch: 1 | loss: 0.1592817
	speed: 0.0930s/iter; left time: 492.2782s
	iters: 500, epoch: 1 | loss: 0.1537330
	speed: 0.0938s/iter; left time: 486.6687s
Epoch: 1 cost time: 54.84114384651184
Epoch: 1, Steps: 569 | Train Loss: 0.2559231 Vali Loss: 0.2212184 Test Loss: 0.3061810
Validation loss decreased (inf --> 0.221218).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.1302696
	speed: 1.0826s/iter; left time: 5436.9332s
	iters: 200, epoch: 2 | loss: 0.1301211
	speed: 0.0941s/iter; left time: 463.2740s
	iters: 300, epoch: 2 | loss: 0.1154051
	speed: 0.0921s/iter; left time: 443.9966s
	iters: 400, epoch: 2 | loss: 0.1208289
	speed: 0.0938s/iter; left time: 443.1569s
	iters: 500, epoch: 2 | loss: 0.1104627
	speed: 0.0932s/iter; left time: 430.5431s
Epoch: 2 cost time: 54.91981792449951
Epoch: 2, Steps: 569 | Train Loss: 0.1225473 Vali Loss: 0.2172932 Test Loss: 0.2860003
Validation loss decreased (0.221218 --> 0.217293).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.1083077
	speed: 1.0730s/iter; left time: 4778.2695s
	iters: 200, epoch: 3 | loss: 0.1078648
	speed: 0.0948s/iter; left time: 412.7742s
	iters: 300, epoch: 3 | loss: 0.0998802
	speed: 0.0909s/iter; left time: 386.6209s
	iters: 400, epoch: 3 | loss: 0.1039184
	speed: 0.0931s/iter; left time: 386.6565s
	iters: 500, epoch: 3 | loss: 0.0962713
	speed: 0.0910s/iter; left time: 368.9341s
Epoch: 3 cost time: 54.23010230064392
Epoch: 3, Steps: 569 | Train Loss: 0.1025158 Vali Loss: 0.2183324 Test Loss: 0.2937046
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.0950498
	speed: 1.0473s/iter; left time: 4067.8835s
	iters: 200, epoch: 4 | loss: 0.0915764
	speed: 0.0919s/iter; left time: 347.7308s
	iters: 300, epoch: 4 | loss: 0.0923988
	speed: 0.0918s/iter; left time: 338.2376s
	iters: 400, epoch: 4 | loss: 0.0997058
	speed: 0.0948s/iter; left time: 339.6901s
	iters: 500, epoch: 4 | loss: 0.0919938
	speed: 0.0923s/iter; left time: 321.7142s
Epoch: 4 cost time: 54.742735385894775
Epoch: 4, Steps: 569 | Train Loss: 0.0949567 Vali Loss: 0.2193210 Test Loss: 0.2961058
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.0958818
	speed: 1.1098s/iter; left time: 3678.8279s
	iters: 200, epoch: 5 | loss: 0.0921520
	speed: 0.0934s/iter; left time: 300.1503s
	iters: 300, epoch: 5 | loss: 0.0899992
	speed: 0.0924s/iter; left time: 287.8236s
	iters: 400, epoch: 5 | loss: 0.0983842
	speed: 0.0919s/iter; left time: 277.0849s
	iters: 500, epoch: 5 | loss: 0.0909205
	speed: 0.0921s/iter; left time: 268.4611s
Epoch: 5 cost time: 54.45666170120239
Epoch: 5, Steps: 569 | Train Loss: 0.0913118 Vali Loss: 0.2216283 Test Loss: 0.2959768
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.0860811
	speed: 1.1164s/iter; left time: 3065.6466s
	iters: 200, epoch: 6 | loss: 0.0909899
	speed: 0.0914s/iter; left time: 241.7631s
	iters: 300, epoch: 6 | loss: 0.0912004
	speed: 0.0916s/iter; left time: 233.1834s
	iters: 400, epoch: 6 | loss: 0.0896300
	speed: 0.0928s/iter; left time: 227.0074s
	iters: 500, epoch: 6 | loss: 0.0887374
	speed: 0.0918s/iter; left time: 215.3607s
Epoch: 6 cost time: 54.398552894592285
Epoch: 6, Steps: 569 | Train Loss: 0.0894046 Vali Loss: 0.2221436 Test Loss: 0.2962674
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.0860341
	speed: 1.0710s/iter; left time: 2331.5985s
	iters: 200, epoch: 7 | loss: 0.0875939
	speed: 0.0912s/iter; left time: 189.4165s
	iters: 300, epoch: 7 | loss: 0.0816410
	speed: 0.0923s/iter; left time: 182.5483s
	iters: 400, epoch: 7 | loss: 0.0886609
	speed: 0.0936s/iter; left time: 175.7691s
	iters: 500, epoch: 7 | loss: 0.0888014
	speed: 0.0918s/iter; left time: 163.2024s
Epoch: 7 cost time: 54.026830196380615
Epoch: 7, Steps: 569 | Train Loss: 0.0883790 Vali Loss: 0.2225926 Test Loss: 0.2977629
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.0854097
	speed: 1.0943s/iter; left time: 1759.6460s
	iters: 200, epoch: 8 | loss: 0.0955440
	speed: 0.0938s/iter; left time: 141.4565s
	iters: 300, epoch: 8 | loss: 0.0884689
	speed: 0.0924s/iter; left time: 130.1212s
	iters: 400, epoch: 8 | loss: 0.0862055
	speed: 0.0921s/iter; left time: 120.5310s
	iters: 500, epoch: 8 | loss: 0.0885312
	speed: 0.0934s/iter; left time: 112.7968s
Epoch: 8 cost time: 54.28095316886902
Epoch: 8, Steps: 569 | Train Loss: 0.0878409 Vali Loss: 0.2219939 Test Loss: 0.2965170
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.0865457
	speed: 1.1075s/iter; left time: 1150.6863s
	iters: 200, epoch: 9 | loss: 0.0904621
	speed: 0.0923s/iter; left time: 86.6264s
	iters: 300, epoch: 9 | loss: 0.0881646
	speed: 0.0932s/iter; left time: 78.1857s
	iters: 400, epoch: 9 | loss: 0.0895054
	speed: 0.0927s/iter; left time: 68.5184s
	iters: 500, epoch: 9 | loss: 0.0906337
	speed: 0.0929s/iter; left time: 59.3464s
Epoch: 9 cost time: 54.3748996257782
Epoch: 9, Steps: 569 | Train Loss: 0.0875348 Vali Loss: 0.2222979 Test Loss: 0.2970155
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.0881650
	speed: 1.0792s/iter; left time: 507.2180s
	iters: 200, epoch: 10 | loss: 0.0878774
	speed: 0.0925s/iter; left time: 34.2396s
	iters: 300, epoch: 10 | loss: 0.0880591
	speed: 0.0928s/iter; left time: 25.0452s
	iters: 400, epoch: 10 | loss: 0.0928300
	speed: 0.0941s/iter; left time: 16.0002s
	iters: 500, epoch: 10 | loss: 0.0868396
	speed: 0.0942s/iter; left time: 6.5932s
Epoch: 10 cost time: 55.12796235084534
Epoch: 10, Steps: 569 | Train Loss: 0.0873757 Vali Loss: 0.2219864 Test Loss: 0.2966722
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-07
>>>>>>>testing : ECL_96_96_36_emb_512_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (5165, 1, 96, 321) (5165, 1, 96, 321)
test shape: (5165, 96, 321) (5165, 96, 321)
mse:0.2859994173049927, mae:0.37392860651016235
Args in experiment:
Namespace(is_training=1, model_id='ECL_96_96_37_emb_512', model='xLSTM', data='custom', root_path='./data/electricity/', data_path='/input-data/electricity.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, enc_in=321, dec_in=7, c_out=321, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.3, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=50, batch_size=16, patience=10, learning_rate=0.001, des='test', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, use_norm=True, partial_start_index=0, hidden_size=512, num_layers=2, mark_enc_in=4, embedding_dim=512, weight_decay=1e-05, kernal_size=5, num_heads_xlstm=2, qkv_proj_blocksize=2, proj_factor=1.3, num_blocks=2, slstm_at=1, grad_clip_norm=5.0, d_state=16, d_conv=4, expand=2)
Use GPU: cuda:0
{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-L/usr/local/cuda/lib', '-lcublas'], 'extra_cflags': ['-DSLSTM_HIDDEN_SIZE=512', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=2', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__'], 'extra_cuda_cflags': ['-Xptxas="-v"', '-gencode', 'arch=compute_80,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=512', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=2', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__']}
Using /home/thetayne/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/thetayne/.cache/torch_extensions/py310_cu121/slstm_HS512BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0/build.ninja...
Building extension module slstm_HS512BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module slstm_HS512BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
>>>>>>>start training : ECL_96_96_37_emb_512_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 18221
val 2537
test 5165
	iters: 100, epoch: 1 | loss: 0.2302757
	speed: 0.0472s/iter; left time: 2682.1777s
	iters: 200, epoch: 1 | loss: 0.1481261
	speed: 0.0268s/iter; left time: 1518.3850s
	iters: 300, epoch: 1 | loss: 0.1291946
	speed: 0.0256s/iter; left time: 1448.5509s
	iters: 400, epoch: 1 | loss: 0.1309290
	speed: 0.0248s/iter; left time: 1400.7281s
	iters: 500, epoch: 1 | loss: 0.1142901
	speed: 0.0250s/iter; left time: 1412.0083s
	iters: 600, epoch: 1 | loss: 0.0966428
	speed: 0.0257s/iter; left time: 1447.6378s
	iters: 700, epoch: 1 | loss: 0.0947025
	speed: 0.0279s/iter; left time: 1566.3675s
	iters: 800, epoch: 1 | loss: 0.0935031
	speed: 0.0283s/iter; left time: 1587.0140s
	iters: 900, epoch: 1 | loss: 0.0912522
	speed: 0.0291s/iter; left time: 1628.2304s
	iters: 1000, epoch: 1 | loss: 0.0877174
	speed: 0.0283s/iter; left time: 1581.0345s
	iters: 1100, epoch: 1 | loss: 0.0923894
	speed: 0.0283s/iter; left time: 1581.1693s
Epoch: 1 cost time: 32.636155128479004
Epoch: 1, Steps: 1138 | Train Loss: 0.1333319 Vali Loss: 0.2048287 Test Loss: 0.2679945
Validation loss decreased (inf --> 0.204829).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.0905004
	speed: 0.5531s/iter; left time: 30785.5265s
	iters: 200, epoch: 2 | loss: 0.0827645
	speed: 0.0260s/iter; left time: 1445.7710s
	iters: 300, epoch: 2 | loss: 0.0869079
	speed: 0.0276s/iter; left time: 1532.0336s
	iters: 400, epoch: 2 | loss: 0.0828037
	speed: 0.0271s/iter; left time: 1499.4782s
	iters: 500, epoch: 2 | loss: 0.0848280
	speed: 0.0288s/iter; left time: 1593.5109s
	iters: 600, epoch: 2 | loss: 0.1038932
	speed: 0.0279s/iter; left time: 1538.6519s
	iters: 700, epoch: 2 | loss: 0.0835154
	speed: 0.0273s/iter; left time: 1501.6124s
	iters: 800, epoch: 2 | loss: 0.0840420
	speed: 0.0277s/iter; left time: 1523.3750s
	iters: 900, epoch: 2 | loss: 0.0752254
	speed: 0.0274s/iter; left time: 1503.8145s
	iters: 1000, epoch: 2 | loss: 0.0786261
	speed: 0.0270s/iter; left time: 1479.6522s
	iters: 1100, epoch: 2 | loss: 0.0819345
	speed: 0.0281s/iter; left time: 1538.4831s
Epoch: 2 cost time: 32.525609254837036
Epoch: 2, Steps: 1138 | Train Loss: 0.0834136 Vali Loss: 0.1983050 Test Loss: 0.2721850
Validation loss decreased (0.204829 --> 0.198305).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.0749421
	speed: 0.5638s/iter; left time: 30739.8784s
	iters: 200, epoch: 3 | loss: 0.0682775
	speed: 0.0269s/iter; left time: 1465.3591s
	iters: 300, epoch: 3 | loss: 0.0666755
	speed: 0.0284s/iter; left time: 1543.3250s
	iters: 400, epoch: 3 | loss: 0.0717326
	speed: 0.0287s/iter; left time: 1555.9505s
	iters: 500, epoch: 3 | loss: 0.0652224
	speed: 0.0272s/iter; left time: 1472.0648s
	iters: 600, epoch: 3 | loss: 0.0684455
	speed: 0.0271s/iter; left time: 1466.3700s
	iters: 700, epoch: 3 | loss: 0.0700632
	speed: 0.0277s/iter; left time: 1496.1371s
	iters: 800, epoch: 3 | loss: 0.0635938
	speed: 0.0283s/iter; left time: 1523.2305s
	iters: 900, epoch: 3 | loss: 0.0673699
	speed: 0.0284s/iter; left time: 1525.7541s
	iters: 1000, epoch: 3 | loss: 0.0690301
	speed: 0.0291s/iter; left time: 1558.2119s
	iters: 1100, epoch: 3 | loss: 0.0715445
	speed: 0.0285s/iter; left time: 1527.0871s
Epoch: 3 cost time: 33.11199688911438
Epoch: 3, Steps: 1138 | Train Loss: 0.0694275 Vali Loss: 0.2059239 Test Loss: 0.2758085
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.0670143
	speed: 0.5715s/iter; left time: 30511.7074s
	iters: 200, epoch: 4 | loss: 0.0649523
	speed: 0.0263s/iter; left time: 1400.5305s
	iters: 300, epoch: 4 | loss: 0.0650599
	speed: 0.0285s/iter; left time: 1515.0978s
	iters: 400, epoch: 4 | loss: 0.0739698
	speed: 0.0277s/iter; left time: 1470.2652s
	iters: 500, epoch: 4 | loss: 0.0689124
	speed: 0.0278s/iter; left time: 1475.0090s
	iters: 600, epoch: 4 | loss: 0.0675110
	speed: 0.0286s/iter; left time: 1511.8256s
	iters: 700, epoch: 4 | loss: 0.0619570
	speed: 0.0278s/iter; left time: 1467.7650s
	iters: 800, epoch: 4 | loss: 0.0642038
	speed: 0.0271s/iter; left time: 1428.2979s
	iters: 900, epoch: 4 | loss: 0.0627067
	speed: 0.0278s/iter; left time: 1462.0203s
	iters: 1000, epoch: 4 | loss: 0.0624959
	speed: 0.0276s/iter; left time: 1446.1896s
	iters: 1100, epoch: 4 | loss: 0.0653427
	speed: 0.0280s/iter; left time: 1466.5701s
Epoch: 4 cost time: 32.99742364883423
Epoch: 4, Steps: 1138 | Train Loss: 0.0644419 Vali Loss: 0.2096080 Test Loss: 0.2857275
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.0636334
	speed: 0.5676s/iter; left time: 29654.8795s
	iters: 200, epoch: 5 | loss: 0.0612923
	speed: 0.0254s/iter; left time: 1326.5387s
	iters: 300, epoch: 5 | loss: 0.0603136
	speed: 0.0256s/iter; left time: 1334.9889s
	iters: 400, epoch: 5 | loss: 0.0609296
	speed: 0.0267s/iter; left time: 1385.1463s
	iters: 500, epoch: 5 | loss: 0.0638487
	speed: 0.0284s/iter; left time: 1470.3850s
	iters: 600, epoch: 5 | loss: 0.0651335
	speed: 0.0276s/iter; left time: 1426.2769s
	iters: 700, epoch: 5 | loss: 0.0605367
	speed: 0.0274s/iter; left time: 1416.9114s
	iters: 800, epoch: 5 | loss: 0.0592540
	speed: 0.0287s/iter; left time: 1478.3881s
	iters: 900, epoch: 5 | loss: 0.0596553
	speed: 0.0282s/iter; left time: 1451.6906s
	iters: 1000, epoch: 5 | loss: 0.0591103
	speed: 0.0288s/iter; left time: 1477.5068s
	iters: 1100, epoch: 5 | loss: 0.0584995
	speed: 0.0293s/iter; left time: 1499.6492s
Epoch: 5 cost time: 32.8580801486969
Epoch: 5, Steps: 1138 | Train Loss: 0.0616259 Vali Loss: 0.2091499 Test Loss: 0.2923348
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.0632681
	speed: 0.5640s/iter; left time: 28825.0857s
	iters: 200, epoch: 6 | loss: 0.0600031
	speed: 0.0268s/iter; left time: 1367.2403s
	iters: 300, epoch: 6 | loss: 0.0601018
	speed: 0.0290s/iter; left time: 1474.7317s
	iters: 400, epoch: 6 | loss: 0.0540996
	speed: 0.0281s/iter; left time: 1426.2117s
	iters: 500, epoch: 6 | loss: 0.0582772
	speed: 0.0267s/iter; left time: 1354.0453s
	iters: 600, epoch: 6 | loss: 0.0597147
	speed: 0.0285s/iter; left time: 1444.9410s
	iters: 700, epoch: 6 | loss: 0.0599164
	speed: 0.0287s/iter; left time: 1449.2855s
	iters: 800, epoch: 6 | loss: 0.0595675
	speed: 0.0275s/iter; left time: 1388.6609s
	iters: 900, epoch: 6 | loss: 0.0533936
	speed: 0.0275s/iter; left time: 1385.4547s
	iters: 1000, epoch: 6 | loss: 0.0560108
	speed: 0.0273s/iter; left time: 1369.2701s
	iters: 1100, epoch: 6 | loss: 0.0611009
	speed: 0.0275s/iter; left time: 1376.2912s
Epoch: 6 cost time: 33.16425180435181
Epoch: 6, Steps: 1138 | Train Loss: 0.0601605 Vali Loss: 0.2128641 Test Loss: 0.2954233
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.0635522
	speed: 0.5669s/iter; left time: 28328.1873s
	iters: 200, epoch: 7 | loss: 0.0603693
	speed: 0.0277s/iter; left time: 1381.8585s
	iters: 300, epoch: 7 | loss: 0.0617366
	speed: 0.0294s/iter; left time: 1461.6578s
	iters: 400, epoch: 7 | loss: 0.0557022
	speed: 0.0301s/iter; left time: 1493.5945s
	iters: 500, epoch: 7 | loss: 0.0620560
	speed: 0.0279s/iter; left time: 1381.9711s
	iters: 600, epoch: 7 | loss: 0.0591833
	speed: 0.0274s/iter; left time: 1353.2992s
	iters: 700, epoch: 7 | loss: 0.0568470
	speed: 0.0274s/iter; left time: 1352.3317s
	iters: 800, epoch: 7 | loss: 0.0601296
	speed: 0.0276s/iter; left time: 1360.0271s
	iters: 900, epoch: 7 | loss: 0.0551371
	speed: 0.0282s/iter; left time: 1386.6585s
	iters: 1000, epoch: 7 | loss: 0.0594344
	speed: 0.0286s/iter; left time: 1402.3625s
	iters: 1100, epoch: 7 | loss: 0.0578941
	speed: 0.0296s/iter; left time: 1447.6137s
Epoch: 7 cost time: 33.384174823760986
Epoch: 7, Steps: 1138 | Train Loss: 0.0593445 Vali Loss: 0.2138360 Test Loss: 0.2980565
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.0589723
	speed: 0.5667s/iter; left time: 27675.8976s
	iters: 200, epoch: 8 | loss: 0.0562470
	speed: 0.0261s/iter; left time: 1269.7624s
	iters: 300, epoch: 8 | loss: 0.0571297
	speed: 0.0257s/iter; left time: 1248.9742s
	iters: 400, epoch: 8 | loss: 0.0553639
	speed: 0.0268s/iter; left time: 1301.4963s
	iters: 500, epoch: 8 | loss: 0.0635888
	speed: 0.0257s/iter; left time: 1242.5812s
	iters: 600, epoch: 8 | loss: 0.0606885
	speed: 0.0250s/iter; left time: 1209.3919s
	iters: 700, epoch: 8 | loss: 0.0616943
	speed: 0.0265s/iter; left time: 1277.8546s
	iters: 800, epoch: 8 | loss: 0.0585514
	speed: 0.0268s/iter; left time: 1290.6442s
	iters: 900, epoch: 8 | loss: 0.0579751
	speed: 0.0269s/iter; left time: 1290.0605s
	iters: 1000, epoch: 8 | loss: 0.0605390
	speed: 0.0273s/iter; left time: 1307.5695s
	iters: 1100, epoch: 8 | loss: 0.0598490
	speed: 0.0274s/iter; left time: 1312.2091s
Epoch: 8 cost time: 31.75322127342224
Epoch: 8, Steps: 1138 | Train Loss: 0.0589358 Vali Loss: 0.2151411 Test Loss: 0.2995714
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 0.0548043
	speed: 0.5662s/iter; left time: 27008.3629s
	iters: 200, epoch: 9 | loss: 0.0578967
	speed: 0.0274s/iter; left time: 1302.6480s
	iters: 300, epoch: 9 | loss: 0.0570854
	speed: 0.0277s/iter; left time: 1316.7648s
	iters: 400, epoch: 9 | loss: 0.0578254
	speed: 0.0289s/iter; left time: 1367.7209s
	iters: 500, epoch: 9 | loss: 0.0598715
	speed: 0.0294s/iter; left time: 1389.0022s
	iters: 600, epoch: 9 | loss: 0.0599619
	speed: 0.0276s/iter; left time: 1302.1554s
	iters: 700, epoch: 9 | loss: 0.0584237
	speed: 0.0278s/iter; left time: 1308.4467s
	iters: 800, epoch: 9 | loss: 0.0588184
	speed: 0.0269s/iter; left time: 1263.9679s
	iters: 900, epoch: 9 | loss: 0.0570753
	speed: 0.0286s/iter; left time: 1341.1975s
	iters: 1000, epoch: 9 | loss: 0.0573300
	speed: 0.0280s/iter; left time: 1308.9430s
	iters: 1100, epoch: 9 | loss: 0.0564534
	speed: 0.0293s/iter; left time: 1369.5820s
Epoch: 9 cost time: 33.38261580467224
Epoch: 9, Steps: 1138 | Train Loss: 0.0587134 Vali Loss: 0.2151659 Test Loss: 0.2997943
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 0.0626380
	speed: 0.5752s/iter; left time: 26781.8853s
	iters: 200, epoch: 10 | loss: 0.0580374
	speed: 0.0264s/iter; left time: 1228.5140s
	iters: 300, epoch: 10 | loss: 0.0527652
	speed: 0.0263s/iter; left time: 1220.6669s
	iters: 400, epoch: 10 | loss: 0.0593747
	speed: 0.0283s/iter; left time: 1307.7673s
	iters: 500, epoch: 10 | loss: 0.0585351
	speed: 0.0283s/iter; left time: 1306.6867s
	iters: 600, epoch: 10 | loss: 0.0588557
	speed: 0.0276s/iter; left time: 1271.1038s
	iters: 700, epoch: 10 | loss: 0.0552976
	speed: 0.0288s/iter; left time: 1324.9317s
	iters: 800, epoch: 10 | loss: 0.0555702
	speed: 0.0286s/iter; left time: 1309.4444s
	iters: 900, epoch: 10 | loss: 0.0584268
	speed: 0.0268s/iter; left time: 1225.8249s
	iters: 1000, epoch: 10 | loss: 0.0559043
	speed: 0.0279s/iter; left time: 1275.9344s
	iters: 1100, epoch: 10 | loss: 0.0543987
	speed: 0.0271s/iter; left time: 1234.5497s
Epoch: 10 cost time: 32.89337611198425
Epoch: 10, Steps: 1138 | Train Loss: 0.0585999 Vali Loss: 0.2154464 Test Loss: 0.3004346
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 0.0612816
	speed: 0.5717s/iter; left time: 25966.6469s
	iters: 200, epoch: 11 | loss: 0.0591848
	speed: 0.0257s/iter; left time: 1165.4411s
	iters: 300, epoch: 11 | loss: 0.0554547
	speed: 0.0274s/iter; left time: 1239.6447s
	iters: 400, epoch: 11 | loss: 0.0606533
	speed: 0.0292s/iter; left time: 1317.4350s
	iters: 500, epoch: 11 | loss: 0.0567429
	speed: 0.0285s/iter; left time: 1284.0661s
	iters: 600, epoch: 11 | loss: 0.0579949
	speed: 0.0270s/iter; left time: 1213.5716s
	iters: 700, epoch: 11 | loss: 0.0585466
	speed: 0.0269s/iter; left time: 1206.4909s
	iters: 800, epoch: 11 | loss: 0.0542314
	speed: 0.0270s/iter; left time: 1207.6750s
	iters: 900, epoch: 11 | loss: 0.0576065
	speed: 0.0277s/iter; left time: 1235.6554s
	iters: 1000, epoch: 11 | loss: 0.0548820
	speed: 0.0281s/iter; left time: 1252.9996s
	iters: 1100, epoch: 11 | loss: 0.0603179
	speed: 0.0293s/iter; left time: 1299.7824s
Epoch: 11 cost time: 33.13489103317261
Epoch: 11, Steps: 1138 | Train Loss: 0.0585353 Vali Loss: 0.2160520 Test Loss: 0.3004611
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 0.0602058
	speed: 0.5720s/iter; left time: 25330.9920s
	iters: 200, epoch: 12 | loss: 0.0564569
	speed: 0.0266s/iter; left time: 1173.0745s
	iters: 300, epoch: 12 | loss: 0.0580703
	speed: 0.0280s/iter; left time: 1236.2115s
	iters: 400, epoch: 12 | loss: 0.0568933
	speed: 0.0282s/iter; left time: 1239.8455s
	iters: 500, epoch: 12 | loss: 0.0607296
	speed: 0.0277s/iter; left time: 1216.7112s
	iters: 600, epoch: 12 | loss: 0.0545885
	speed: 0.0277s/iter; left time: 1212.9687s
	iters: 700, epoch: 12 | loss: 0.0599844
	speed: 0.0282s/iter; left time: 1229.7033s
	iters: 800, epoch: 12 | loss: 0.0566442
	speed: 0.0278s/iter; left time: 1212.6658s
	iters: 900, epoch: 12 | loss: 0.0540009
	speed: 0.0268s/iter; left time: 1164.6058s
	iters: 1000, epoch: 12 | loss: 0.0573466
	speed: 0.0271s/iter; left time: 1175.6294s
	iters: 1100, epoch: 12 | loss: 0.0585057
	speed: 0.0269s/iter; left time: 1166.3332s
Epoch: 12 cost time: 32.68436861038208
Epoch: 12, Steps: 1138 | Train Loss: 0.0585283 Vali Loss: 0.2160228 Test Loss: 0.3005479
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : ECL_96_96_37_emb_512_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (5165, 1, 96, 321) (5165, 1, 96, 321)
test shape: (5165, 96, 321) (5165, 96, 321)
mse:0.27218466997146606, mae:0.3610011637210846
Args in experiment:
Namespace(is_training=1, model_id='ECL_96_96_38_emb_512', model='xLSTM', data='custom', root_path='./data/electricity/', data_path='/input-data/electricity.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, enc_in=321, dec_in=7, c_out=321, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=16, patience=10, learning_rate=0.0001, des='test', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, use_norm=True, partial_start_index=0, hidden_size=512, num_layers=2, mark_enc_in=4, embedding_dim=512, weight_decay=1e-05, kernal_size=7, num_heads_xlstm=2, qkv_proj_blocksize=8, proj_factor=1.3, num_blocks=7, slstm_at=1, grad_clip_norm=1.0, d_state=16, d_conv=4, expand=2)
Use GPU: cuda:0
{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-L/usr/local/cuda/lib', '-lcublas'], 'extra_cflags': ['-DSLSTM_HIDDEN_SIZE=512', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=2', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__'], 'extra_cuda_cflags': ['-Xptxas="-v"', '-gencode', 'arch=compute_80,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=512', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=2', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__']}
Using /home/thetayne/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/thetayne/.cache/torch_extensions/py310_cu121/slstm_HS512BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0/build.ninja...
Building extension module slstm_HS512BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module slstm_HS512BS8NH2NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
>>>>>>>start training : ECL_96_96_38_emb_512_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 18221
val 2537
test 5165
	iters: 100, epoch: 1 | loss: 0.2468332
	speed: 0.0908s/iter; left time: 3090.0178s
	iters: 200, epoch: 1 | loss: 0.2062438
	speed: 0.0669s/iter; left time: 2270.8590s
	iters: 300, epoch: 1 | loss: 0.1754590
	speed: 0.0669s/iter; left time: 2264.6120s
	iters: 400, epoch: 1 | loss: 0.1608536
	speed: 0.0644s/iter; left time: 2171.9157s
	iters: 500, epoch: 1 | loss: 0.1426511
	speed: 0.0658s/iter; left time: 2213.8411s
	iters: 600, epoch: 1 | loss: 0.1310222
	speed: 0.0617s/iter; left time: 2068.0042s
	iters: 700, epoch: 1 | loss: 0.1196621
	speed: 0.0663s/iter; left time: 2217.1981s
	iters: 800, epoch: 1 | loss: 0.1214230
	speed: 0.0637s/iter; left time: 2122.9873s
	iters: 900, epoch: 1 | loss: 0.1048808
	speed: 0.0616s/iter; left time: 2046.8385s
	iters: 1000, epoch: 1 | loss: 0.0961795
	speed: 0.0634s/iter; left time: 2101.6792s
	iters: 1100, epoch: 1 | loss: 0.0990791
	speed: 0.0617s/iter; left time: 2039.5050s
Epoch: 1 cost time: 75.56278610229492
Epoch: 1, Steps: 1138 | Train Loss: 0.1603452 Vali Loss: 0.2330486 Test Loss: 0.2923903
Validation loss decreased (inf --> 0.233049).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.0847601
	speed: 1.0066s/iter; left time: 33121.1181s
	iters: 200, epoch: 2 | loss: 0.0847474
	speed: 0.0701s/iter; left time: 2300.5850s
	iters: 300, epoch: 2 | loss: 0.0806257
	speed: 0.0692s/iter; left time: 2263.3545s
	iters: 400, epoch: 2 | loss: 0.0776218
	speed: 0.0706s/iter; left time: 2302.2534s
	iters: 500, epoch: 2 | loss: 0.0771730
	speed: 0.0638s/iter; left time: 2073.9304s
	iters: 600, epoch: 2 | loss: 0.0687910
	speed: 0.0649s/iter; left time: 2104.4507s
	iters: 700, epoch: 2 | loss: 0.0721627
	speed: 0.0639s/iter; left time: 2064.3726s
	iters: 800, epoch: 2 | loss: 0.0671844
	speed: 0.0633s/iter; left time: 2039.5086s
	iters: 900, epoch: 2 | loss: 0.0637525
	speed: 0.0661s/iter; left time: 2120.7447s
	iters: 1000, epoch: 2 | loss: 0.0636234
	speed: 0.0690s/iter; left time: 2207.3116s
	iters: 1100, epoch: 2 | loss: 0.0558118
	speed: 0.0689s/iter; left time: 2196.7863s
Epoch: 2 cost time: 77.50934910774231
Epoch: 2, Steps: 1138 | Train Loss: 0.0738741 Vali Loss: 0.2321930 Test Loss: 0.2977291
Validation loss decreased (0.233049 --> 0.232193).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.0607225
	speed: 0.9702s/iter; left time: 30817.7278s
	iters: 200, epoch: 3 | loss: 0.0614742
	speed: 0.0613s/iter; left time: 1940.6209s
	iters: 300, epoch: 3 | loss: 0.0586012
	speed: 0.0643s/iter; left time: 2028.4505s
	iters: 400, epoch: 3 | loss: 0.0565333
	speed: 0.0598s/iter; left time: 1880.1507s
	iters: 500, epoch: 3 | loss: 0.0533047
	speed: 0.0612s/iter; left time: 1918.3947s
	iters: 600, epoch: 3 | loss: 0.0531917
	speed: 0.0631s/iter; left time: 1971.5063s
	iters: 700, epoch: 3 | loss: 0.0527238
	speed: 0.0636s/iter; left time: 1981.6712s
	iters: 800, epoch: 3 | loss: 0.0513410
	speed: 0.0642s/iter; left time: 1994.9692s
	iters: 900, epoch: 3 | loss: 0.0555445
	speed: 0.0709s/iter; left time: 2193.9897s
	iters: 1000, epoch: 3 | loss: 0.0498469
	speed: 0.0649s/iter; left time: 2002.2443s
	iters: 1100, epoch: 3 | loss: 0.0513421
	speed: 0.0664s/iter; left time: 2043.2655s
Epoch: 3 cost time: 74.2573938369751
Epoch: 3, Steps: 1138 | Train Loss: 0.0546197 Vali Loss: 0.2308025 Test Loss: 0.3019442
Validation loss decreased (0.232193 --> 0.230803).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.0476977
	speed: 0.9998s/iter; left time: 30621.5565s
	iters: 200, epoch: 4 | loss: 0.0487317
	speed: 0.0635s/iter; left time: 1939.0771s
	iters: 300, epoch: 4 | loss: 0.0501072
	speed: 0.0623s/iter; left time: 1896.8952s
	iters: 400, epoch: 4 | loss: 0.0462112
	speed: 0.0628s/iter; left time: 1905.8218s
	iters: 500, epoch: 4 | loss: 0.0479559
	speed: 0.0643s/iter; left time: 1943.0752s
	iters: 600, epoch: 4 | loss: 0.0464325
	speed: 0.0719s/iter; left time: 2166.6960s
	iters: 700, epoch: 4 | loss: 0.0491927
	speed: 0.0685s/iter; left time: 2055.4200s
	iters: 800, epoch: 4 | loss: 0.0476759
	speed: 0.0698s/iter; left time: 2088.5842s
	iters: 900, epoch: 4 | loss: 0.0463076
	speed: 0.0665s/iter; left time: 1983.5629s
	iters: 1000, epoch: 4 | loss: 0.0478261
	speed: 0.0636s/iter; left time: 1891.5160s
	iters: 1100, epoch: 4 | loss: 0.0454742
	speed: 0.0633s/iter; left time: 1874.6183s
Epoch: 4 cost time: 75.70716977119446
Epoch: 4, Steps: 1138 | Train Loss: 0.0477616 Vali Loss: 0.2360599 Test Loss: 0.3065106
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.0441346
	speed: 1.0147s/iter; left time: 29922.3139s
	iters: 200, epoch: 5 | loss: 0.0442184
	speed: 0.0651s/iter; left time: 1913.1477s
	iters: 300, epoch: 5 | loss: 0.0442947
	speed: 0.0624s/iter; left time: 1827.1794s
	iters: 400, epoch: 5 | loss: 0.0417814
	speed: 0.0630s/iter; left time: 1838.6939s
	iters: 500, epoch: 5 | loss: 0.0427340
	speed: 0.0635s/iter; left time: 1847.0121s
	iters: 600, epoch: 5 | loss: 0.0446104
	speed: 0.0621s/iter; left time: 1799.9953s
	iters: 700, epoch: 5 | loss: 0.0457429
	speed: 0.0644s/iter; left time: 1860.7386s
	iters: 800, epoch: 5 | loss: 0.0420627
	speed: 0.0638s/iter; left time: 1836.5715s
	iters: 900, epoch: 5 | loss: 0.0458651
	speed: 0.0609s/iter; left time: 1748.5743s
	iters: 1000, epoch: 5 | loss: 0.0444467
	speed: 0.0671s/iter; left time: 1917.4283s
	iters: 1100, epoch: 5 | loss: 0.0432866
	speed: 0.0670s/iter; left time: 1909.2997s
Epoch: 5 cost time: 74.53754329681396
Epoch: 5, Steps: 1138 | Train Loss: 0.0445578 Vali Loss: 0.2355748 Test Loss: 0.3095188
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.0458282
	speed: 0.9705s/iter; left time: 27513.4036s
	iters: 200, epoch: 6 | loss: 0.0417057
	speed: 0.0684s/iter; left time: 1931.6128s
	iters: 300, epoch: 6 | loss: 0.0430988
	speed: 0.0677s/iter; left time: 1905.0151s
	iters: 400, epoch: 6 | loss: 0.0441654
	speed: 0.0680s/iter; left time: 1908.7609s
	iters: 500, epoch: 6 | loss: 0.0427821
	speed: 0.0631s/iter; left time: 1763.6924s
	iters: 600, epoch: 6 | loss: 0.0431520
	speed: 0.0627s/iter; left time: 1746.4761s
	iters: 700, epoch: 6 | loss: 0.0426167
	speed: 0.0653s/iter; left time: 1811.0348s
	iters: 800, epoch: 6 | loss: 0.0416126
	speed: 0.0639s/iter; left time: 1765.5530s
	iters: 900, epoch: 6 | loss: 0.0414317
	speed: 0.0610s/iter; left time: 1680.3520s
	iters: 1000, epoch: 6 | loss: 0.0418332
	speed: 0.0632s/iter; left time: 1735.7051s
	iters: 1100, epoch: 6 | loss: 0.0412427
	speed: 0.0655s/iter; left time: 1792.4386s
Epoch: 6 cost time: 75.23481297492981
Epoch: 6, Steps: 1138 | Train Loss: 0.0429216 Vali Loss: 0.2371852 Test Loss: 0.3108677
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.0438741
	speed: 0.9666s/iter; left time: 26302.8707s
	iters: 200, epoch: 7 | loss: 0.0406836
	speed: 0.0636s/iter; left time: 1723.0703s
	iters: 300, epoch: 7 | loss: 0.0429158
	speed: 0.0636s/iter; left time: 1719.1003s
	iters: 400, epoch: 7 | loss: 0.0407478
	speed: 0.0674s/iter; left time: 1813.0145s
	iters: 500, epoch: 7 | loss: 0.0420012
	speed: 0.0627s/iter; left time: 1681.6662s
	iters: 600, epoch: 7 | loss: 0.0443508
	speed: 0.0673s/iter; left time: 1797.3809s
	iters: 700, epoch: 7 | loss: 0.0451317
	speed: 0.0619s/iter; left time: 1648.6197s
	iters: 800, epoch: 7 | loss: 0.0408659
	speed: 0.0612s/iter; left time: 1621.8654s
	iters: 900, epoch: 7 | loss: 0.0420373
	speed: 0.0618s/iter; left time: 1631.8837s
	iters: 1000, epoch: 7 | loss: 0.0420421
	speed: 0.0617s/iter; left time: 1624.4170s
	iters: 1100, epoch: 7 | loss: 0.0422077
	speed: 0.0651s/iter; left time: 1707.5057s
Epoch: 7 cost time: 74.48188304901123
Epoch: 7, Steps: 1138 | Train Loss: 0.0420832 Vali Loss: 0.2384608 Test Loss: 0.3122104
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.0419383
	speed: 1.0031s/iter; left time: 26155.7631s
	iters: 200, epoch: 8 | loss: 0.0440572
	speed: 0.0684s/iter; left time: 1776.1415s
	iters: 300, epoch: 8 | loss: 0.0424355
	speed: 0.0675s/iter; left time: 1746.4986s
	iters: 400, epoch: 8 | loss: 0.0407472
	speed: 0.0615s/iter; left time: 1583.9745s
	iters: 500, epoch: 8 | loss: 0.0400658
	speed: 0.0633s/iter; left time: 1624.1325s
	iters: 600, epoch: 8 | loss: 0.0445802
	speed: 0.0675s/iter; left time: 1725.6439s
	iters: 700, epoch: 8 | loss: 0.0409412
	speed: 0.0670s/iter; left time: 1707.8502s
	iters: 800, epoch: 8 | loss: 0.0415167
	speed: 0.0628s/iter; left time: 1593.8493s
	iters: 900, epoch: 8 | loss: 0.0410377
	speed: 0.0627s/iter; left time: 1584.8408s
	iters: 1000, epoch: 8 | loss: 0.0410226
	speed: 0.0645s/iter; left time: 1622.5427s
	iters: 1100, epoch: 8 | loss: 0.0413425
	speed: 0.0612s/iter; left time: 1534.5378s
Epoch: 8 cost time: 74.85404086112976
Epoch: 8, Steps: 1138 | Train Loss: 0.0416540 Vali Loss: 0.2381516 Test Loss: 0.3126383
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.0412799
	speed: 0.9571s/iter; left time: 23868.1745s
	iters: 200, epoch: 9 | loss: 0.0427163
	speed: 0.0604s/iter; left time: 1500.9435s
	iters: 300, epoch: 9 | loss: 0.0418515
	speed: 0.0656s/iter; left time: 1622.6293s
	iters: 400, epoch: 9 | loss: 0.0407377
	speed: 0.0661s/iter; left time: 1629.5078s
	iters: 500, epoch: 9 | loss: 0.0401751
	speed: 0.0606s/iter; left time: 1487.5602s
	iters: 600, epoch: 9 | loss: 0.0401508
	speed: 0.0625s/iter; left time: 1526.8152s
	iters: 700, epoch: 9 | loss: 0.0433812
	speed: 0.0641s/iter; left time: 1559.7572s
	iters: 800, epoch: 9 | loss: 0.0422982
	speed: 0.0632s/iter; left time: 1531.7361s
	iters: 900, epoch: 9 | loss: 0.0401419
	speed: 0.0623s/iter; left time: 1503.5046s
	iters: 1000, epoch: 9 | loss: 0.0389397
	speed: 0.0612s/iter; left time: 1470.6206s
	iters: 1100, epoch: 9 | loss: 0.0406859
	speed: 0.0666s/iter; left time: 1593.6820s
Epoch: 9 cost time: 73.5906093120575
Epoch: 9, Steps: 1138 | Train Loss: 0.0414358 Vali Loss: 0.2382623 Test Loss: 0.3128251
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.0397671
	speed: 0.9593s/iter; left time: 22830.0390s
	iters: 200, epoch: 10 | loss: 0.0414452
	speed: 0.0686s/iter; left time: 1624.7918s
	iters: 300, epoch: 10 | loss: 0.0400049
	speed: 0.0637s/iter; left time: 1504.2568s
	iters: 400, epoch: 10 | loss: 0.0414722
	speed: 0.0633s/iter; left time: 1488.2026s
	iters: 500, epoch: 10 | loss: 0.0408896
	speed: 0.0616s/iter; left time: 1441.3290s
	iters: 600, epoch: 10 | loss: 0.0425160
	speed: 0.0616s/iter; left time: 1435.0566s
	iters: 700, epoch: 10 | loss: 0.0396423
	speed: 0.0610s/iter; left time: 1415.9448s
	iters: 800, epoch: 10 | loss: 0.0442362
	speed: 0.0647s/iter; left time: 1493.6327s
	iters: 900, epoch: 10 | loss: 0.0422484
	speed: 0.0643s/iter; left time: 1479.8597s
	iters: 1000, epoch: 10 | loss: 0.0418938
	speed: 0.0614s/iter; left time: 1406.3252s
	iters: 1100, epoch: 10 | loss: 0.0435456
	speed: 0.0648s/iter; left time: 1477.0571s
Epoch: 10 cost time: 74.12952470779419
Epoch: 10, Steps: 1138 | Train Loss: 0.0413194 Vali Loss: 0.2385037 Test Loss: 0.3129779
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.0410062
	speed: 0.9863s/iter; left time: 22351.6447s
	iters: 200, epoch: 11 | loss: 0.0404256
	speed: 0.0641s/iter; left time: 1445.2642s
	iters: 300, epoch: 11 | loss: 0.0411589
	speed: 0.0649s/iter; left time: 1457.6272s
	iters: 400, epoch: 11 | loss: 0.0397185
	speed: 0.0643s/iter; left time: 1438.7685s
	iters: 500, epoch: 11 | loss: 0.0401189
	speed: 0.0628s/iter; left time: 1396.9874s
	iters: 600, epoch: 11 | loss: 0.0399536
	speed: 0.0628s/iter; left time: 1391.2969s
	iters: 700, epoch: 11 | loss: 0.0412764
	speed: 0.0639s/iter; left time: 1410.5747s
	iters: 800, epoch: 11 | loss: 0.0425281
	speed: 0.0633s/iter; left time: 1389.6795s
	iters: 900, epoch: 11 | loss: 0.0434842
	speed: 0.0619s/iter; left time: 1352.3039s
	iters: 1000, epoch: 11 | loss: 0.0427488
	speed: 0.0588s/iter; left time: 1279.9709s
	iters: 1100, epoch: 11 | loss: 0.0406573
	speed: 0.0613s/iter; left time: 1328.8569s
Epoch: 11 cost time: 73.19536757469177
Epoch: 11, Steps: 1138 | Train Loss: 0.0412626 Vali Loss: 0.2384466 Test Loss: 0.3129985
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.0411368
	speed: 0.9854s/iter; left time: 21207.9533s
	iters: 200, epoch: 12 | loss: 0.0427427
	speed: 0.0720s/iter; left time: 1543.4753s
	iters: 300, epoch: 12 | loss: 0.0392643
	speed: 0.0724s/iter; left time: 1544.4633s
	iters: 400, epoch: 12 | loss: 0.0397762
	speed: 0.0631s/iter; left time: 1339.9512s
	iters: 500, epoch: 12 | loss: 0.0401647
	speed: 0.0635s/iter; left time: 1340.2847s
	iters: 600, epoch: 12 | loss: 0.0410097
	speed: 0.0636s/iter; left time: 1337.2970s
	iters: 700, epoch: 12 | loss: 0.0390912
	speed: 0.0673s/iter; left time: 1408.0873s
	iters: 800, epoch: 12 | loss: 0.0420262
	speed: 0.0624s/iter; left time: 1299.3131s
	iters: 900, epoch: 12 | loss: 0.0399894
	speed: 0.0619s/iter; left time: 1281.7813s
	iters: 1000, epoch: 12 | loss: 0.0401055
	speed: 0.0627s/iter; left time: 1292.7114s
	iters: 1100, epoch: 12 | loss: 0.0390562
	speed: 0.0624s/iter; left time: 1281.1400s
Epoch: 12 cost time: 75.99829053878784
Epoch: 12, Steps: 1138 | Train Loss: 0.0412405 Vali Loss: 0.2386327 Test Loss: 0.3130378
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.0399052
	speed: 0.9749s/iter; left time: 19872.9776s
	iters: 200, epoch: 13 | loss: 0.0436879
	speed: 0.0625s/iter; left time: 1267.5079s
	iters: 300, epoch: 13 | loss: 0.0409797
	speed: 0.0634s/iter; left time: 1278.7609s
	iters: 400, epoch: 13 | loss: 0.0422227
	speed: 0.0634s/iter; left time: 1272.7009s
	iters: 500, epoch: 13 | loss: 0.0449851
	speed: 0.0616s/iter; left time: 1230.9011s
	iters: 600, epoch: 13 | loss: 0.0439820
	speed: 0.0617s/iter; left time: 1226.6135s
	iters: 700, epoch: 13 | loss: 0.0409248
	speed: 0.0685s/iter; left time: 1354.9058s
	iters: 800, epoch: 13 | loss: 0.0429057
	speed: 0.0632s/iter; left time: 1244.0181s
	iters: 900, epoch: 13 | loss: 0.0409370
	speed: 0.0679s/iter; left time: 1329.7564s
	iters: 1000, epoch: 13 | loss: 0.0399095
	speed: 0.0702s/iter; left time: 1368.5913s
	iters: 1100, epoch: 13 | loss: 0.0405621
	speed: 0.0750s/iter; left time: 1453.3178s
Epoch: 13 cost time: 76.46314263343811
Epoch: 13, Steps: 1138 | Train Loss: 0.0412214 Vali Loss: 0.2384702 Test Loss: 0.3131021
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : ECL_96_96_38_emb_512_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (5165, 1, 96, 321) (5165, 1, 96, 321)
test shape: (5165, 96, 321) (5165, 96, 321)
mse:0.3019443452358246, mae:0.38067227602005005
Args in experiment:
Namespace(is_training=1, model_id='ECL_96_96_39_emb_512', model='xLSTM', data='custom', root_path='./data/electricity/', data_path='/input-data/electricity.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, enc_in=321, dec_in=7, c_out=321, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.5, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=8, patience=10, learning_rate=0.001, des='test', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, use_norm=True, partial_start_index=0, hidden_size=512, num_layers=2, mark_enc_in=4, embedding_dim=512, weight_decay=1e-05, kernal_size=5, num_heads_xlstm=8, qkv_proj_blocksize=4, proj_factor=1.3, num_blocks=3, slstm_at=1, grad_clip_norm=0.5, d_state=16, d_conv=4, expand=2)
Use GPU: cuda:0
{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-L/usr/local/cuda/lib', '-lcublas'], 'extra_cflags': ['-DSLSTM_HIDDEN_SIZE=512', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=8', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__'], 'extra_cuda_cflags': ['-Xptxas="-v"', '-gencode', 'arch=compute_80,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=512', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=8', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__']}
Using /home/thetayne/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/thetayne/.cache/torch_extensions/py310_cu121/slstm_HS512BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0/build.ninja...
Building extension module slstm_HS512BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module slstm_HS512BS8NH8NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
>>>>>>>start training : ECL_96_96_39_emb_512_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 18221
val 2537
test 5165
	iters: 100, epoch: 1 | loss: 0.2288395
	speed: 0.0515s/iter; left time: 3513.0225s
	iters: 200, epoch: 1 | loss: 0.1874126
	speed: 0.0266s/iter; left time: 1813.8005s
	iters: 300, epoch: 1 | loss: 0.1585065
	speed: 0.0273s/iter; left time: 1860.0675s
	iters: 400, epoch: 1 | loss: 0.1257274
	speed: 0.0267s/iter; left time: 1811.1927s
	iters: 500, epoch: 1 | loss: 0.1321494
	speed: 0.0260s/iter; left time: 1759.7149s
	iters: 600, epoch: 1 | loss: 0.1414310
	speed: 0.0265s/iter; left time: 1797.1596s
	iters: 700, epoch: 1 | loss: 0.1338775
	speed: 0.0276s/iter; left time: 1866.4864s
	iters: 800, epoch: 1 | loss: 0.1321633
	speed: 0.0294s/iter; left time: 1984.9850s
	iters: 900, epoch: 1 | loss: 0.1408818
	speed: 0.0285s/iter; left time: 1920.7647s
	iters: 1000, epoch: 1 | loss: 0.1248661
	speed: 0.0271s/iter; left time: 1826.5758s
	iters: 1100, epoch: 1 | loss: 0.1299296
	speed: 0.0259s/iter; left time: 1740.5895s
	iters: 1200, epoch: 1 | loss: 0.1268463
	speed: 0.0272s/iter; left time: 1827.1844s
	iters: 1300, epoch: 1 | loss: 0.1296571
	speed: 0.0266s/iter; left time: 1785.4616s
	iters: 1400, epoch: 1 | loss: 0.1218213
	speed: 0.0274s/iter; left time: 1833.8095s
	iters: 1500, epoch: 1 | loss: 0.1144255
	speed: 0.0282s/iter; left time: 1884.1979s
	iters: 1600, epoch: 1 | loss: 0.1301489
	speed: 0.0271s/iter; left time: 1808.0633s
	iters: 1700, epoch: 1 | loss: 0.1227515
	speed: 0.0270s/iter; left time: 1800.1736s
	iters: 1800, epoch: 1 | loss: 0.1217013
	speed: 0.0271s/iter; left time: 1805.6799s
	iters: 1900, epoch: 1 | loss: 0.1216494
	speed: 0.0275s/iter; left time: 1823.0161s
	iters: 2000, epoch: 1 | loss: 0.1107642
	speed: 0.0273s/iter; left time: 1810.9742s
	iters: 2100, epoch: 1 | loss: 0.1094824
	speed: 0.0265s/iter; left time: 1756.7721s
	iters: 2200, epoch: 1 | loss: 0.1209795
	speed: 0.0273s/iter; left time: 1806.4885s
Epoch: 1 cost time: 64.30289578437805
Epoch: 1, Steps: 2277 | Train Loss: 0.1469964 Vali Loss: 0.1965969 Test Loss: 0.2695213
Validation loss decreased (inf --> 0.196597).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.1154334
	speed: 0.6234s/iter; left time: 41104.7194s
	iters: 200, epoch: 2 | loss: 0.1210497
	speed: 0.0257s/iter; left time: 1691.0169s
	iters: 300, epoch: 2 | loss: 0.1142977
	speed: 0.0261s/iter; left time: 1716.1366s
	iters: 400, epoch: 2 | loss: 0.1048164
	speed: 0.0261s/iter; left time: 1711.0658s
	iters: 500, epoch: 2 | loss: 0.1264720
	speed: 0.0282s/iter; left time: 1850.4763s
	iters: 600, epoch: 2 | loss: 0.1073542
	speed: 0.0276s/iter; left time: 1809.1160s
	iters: 700, epoch: 2 | loss: 0.1114303
	speed: 0.0268s/iter; left time: 1749.9891s
	iters: 800, epoch: 2 | loss: 0.1098256
	speed: 0.0284s/iter; left time: 1852.7144s
	iters: 900, epoch: 2 | loss: 0.1174205
	speed: 0.0260s/iter; left time: 1692.6098s
	iters: 1000, epoch: 2 | loss: 0.1139558
	speed: 0.0272s/iter; left time: 1770.9021s
	iters: 1100, epoch: 2 | loss: 0.0954911
	speed: 0.0264s/iter; left time: 1715.0986s
	iters: 1200, epoch: 2 | loss: 0.1052325
	speed: 0.0250s/iter; left time: 1618.7682s
	iters: 1300, epoch: 2 | loss: 0.1213451
	speed: 0.0240s/iter; left time: 1551.7405s
	iters: 1400, epoch: 2 | loss: 0.1406079
	speed: 0.0239s/iter; left time: 1543.9124s
	iters: 1500, epoch: 2 | loss: 0.1275624
	speed: 0.0245s/iter; left time: 1578.6448s
	iters: 1600, epoch: 2 | loss: 0.1188359
	speed: 0.0276s/iter; left time: 1775.9684s
	iters: 1700, epoch: 2 | loss: 0.1051938
	speed: 0.0269s/iter; left time: 1728.4370s
	iters: 1800, epoch: 2 | loss: 0.1125680
	speed: 0.0245s/iter; left time: 1572.6152s
	iters: 1900, epoch: 2 | loss: 0.1120472
	speed: 0.0240s/iter; left time: 1536.1347s
	iters: 2000, epoch: 2 | loss: 0.0967156
	speed: 0.0268s/iter; left time: 1718.6213s
	iters: 2100, epoch: 2 | loss: 0.1039923
	speed: 0.0263s/iter; left time: 1684.3283s
	iters: 2200, epoch: 2 | loss: 0.1033292
	speed: 0.0271s/iter; left time: 1730.0582s
Epoch: 2 cost time: 61.34652781486511
Epoch: 2, Steps: 2277 | Train Loss: 0.1137229 Vali Loss: 0.1937245 Test Loss: 0.2657290
Validation loss decreased (0.196597 --> 0.193724).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.1013956
	speed: 0.6273s/iter; left time: 39930.8230s
	iters: 200, epoch: 3 | loss: 0.1056183
	speed: 0.0296s/iter; left time: 1883.9324s
	iters: 300, epoch: 3 | loss: 0.1035717
	speed: 0.0274s/iter; left time: 1736.5179s
	iters: 400, epoch: 3 | loss: 0.1023207
	speed: 0.0270s/iter; left time: 1708.6729s
	iters: 500, epoch: 3 | loss: 0.1003347
	speed: 0.0273s/iter; left time: 1728.6289s
	iters: 600, epoch: 3 | loss: 0.1020724
	speed: 0.0275s/iter; left time: 1738.1595s
	iters: 700, epoch: 3 | loss: 0.1131318
	speed: 0.0275s/iter; left time: 1732.6674s
	iters: 800, epoch: 3 | loss: 0.0933181
	speed: 0.0265s/iter; left time: 1670.1957s
	iters: 900, epoch: 3 | loss: 0.0979700
	speed: 0.0283s/iter; left time: 1780.6519s
	iters: 1000, epoch: 3 | loss: 0.0987190
	speed: 0.0275s/iter; left time: 1727.7683s
	iters: 1100, epoch: 3 | loss: 0.1037573
	speed: 0.0289s/iter; left time: 1812.1369s
	iters: 1200, epoch: 3 | loss: 0.1025075
	speed: 0.0283s/iter; left time: 1767.3360s
	iters: 1300, epoch: 3 | loss: 0.1012955
	speed: 0.0292s/iter; left time: 1822.3124s
	iters: 1400, epoch: 3 | loss: 0.1060072
	speed: 0.0265s/iter; left time: 1650.0701s
	iters: 1500, epoch: 3 | loss: 0.1028770
	speed: 0.0273s/iter; left time: 1699.5135s
	iters: 1600, epoch: 3 | loss: 0.1008635
	speed: 0.0277s/iter; left time: 1718.7323s
	iters: 1700, epoch: 3 | loss: 0.0956531
	speed: 0.0266s/iter; left time: 1652.7937s
	iters: 1800, epoch: 3 | loss: 0.1033770
	speed: 0.0289s/iter; left time: 1787.6284s
	iters: 1900, epoch: 3 | loss: 0.0928671
	speed: 0.0268s/iter; left time: 1658.6827s
	iters: 2000, epoch: 3 | loss: 0.0986871
	speed: 0.0290s/iter; left time: 1792.6846s
	iters: 2100, epoch: 3 | loss: 0.1031068
	speed: 0.0282s/iter; left time: 1739.4047s
	iters: 2200, epoch: 3 | loss: 0.1039148
	speed: 0.0278s/iter; left time: 1711.1143s
Epoch: 3 cost time: 65.14327645301819
Epoch: 3, Steps: 2277 | Train Loss: 0.1006019 Vali Loss: 0.2004443 Test Loss: 0.2695160
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.1022581
	speed: 0.6084s/iter; left time: 37343.4203s
	iters: 200, epoch: 4 | loss: 0.0889303
	speed: 0.0267s/iter; left time: 1638.4430s
	iters: 300, epoch: 4 | loss: 0.0937226
	speed: 0.0282s/iter; left time: 1722.4455s
	iters: 400, epoch: 4 | loss: 0.0956303
	speed: 0.0279s/iter; left time: 1704.9696s
	iters: 500, epoch: 4 | loss: 0.0984004
	speed: 0.0271s/iter; left time: 1653.6510s
	iters: 600, epoch: 4 | loss: 0.1061233
	speed: 0.0283s/iter; left time: 1723.5024s
	iters: 700, epoch: 4 | loss: 0.1031081
	speed: 0.0277s/iter; left time: 1686.2442s
	iters: 800, epoch: 4 | loss: 0.0938241
	speed: 0.0276s/iter; left time: 1677.5185s
	iters: 900, epoch: 4 | loss: 0.0977548
	speed: 0.0267s/iter; left time: 1618.7410s
	iters: 1000, epoch: 4 | loss: 0.0850582
	speed: 0.0270s/iter; left time: 1630.2552s
	iters: 1100, epoch: 4 | loss: 0.0938772
	speed: 0.0270s/iter; left time: 1633.0794s
	iters: 1200, epoch: 4 | loss: 0.1114740
	speed: 0.0266s/iter; left time: 1604.2905s
	iters: 1300, epoch: 4 | loss: 0.1055558
	speed: 0.0277s/iter; left time: 1664.2185s
	iters: 1400, epoch: 4 | loss: 0.0969455
	speed: 0.0269s/iter; left time: 1615.0637s
	iters: 1500, epoch: 4 | loss: 0.0868908
	speed: 0.0257s/iter; left time: 1540.2912s
	iters: 1600, epoch: 4 | loss: 0.0995306
	speed: 0.0243s/iter; left time: 1452.3497s
	iters: 1700, epoch: 4 | loss: 0.1010152
	speed: 0.0252s/iter; left time: 1505.1923s
	iters: 1800, epoch: 4 | loss: 0.0913021
	speed: 0.0262s/iter; left time: 1562.4290s
	iters: 1900, epoch: 4 | loss: 0.0998210
	speed: 0.0279s/iter; left time: 1663.2373s
	iters: 2000, epoch: 4 | loss: 0.1158250
	speed: 0.0283s/iter; left time: 1680.6580s
	iters: 2100, epoch: 4 | loss: 0.0982068
	speed: 0.0292s/iter; left time: 1736.4452s
	iters: 2200, epoch: 4 | loss: 0.0955396
	speed: 0.0269s/iter; left time: 1591.7822s
Epoch: 4 cost time: 63.29412221908569
Epoch: 4, Steps: 2277 | Train Loss: 0.0955686 Vali Loss: 0.1993636 Test Loss: 0.2690708
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.0989583
	speed: 0.6272s/iter; left time: 37067.1439s
	iters: 200, epoch: 5 | loss: 0.0913272
	speed: 0.0243s/iter; left time: 1436.7205s
	iters: 300, epoch: 5 | loss: 0.0973612
	speed: 0.0263s/iter; left time: 1549.5567s
	iters: 400, epoch: 5 | loss: 0.1113204
	speed: 0.0254s/iter; left time: 1495.6881s
	iters: 500, epoch: 5 | loss: 0.0891425
	speed: 0.0259s/iter; left time: 1519.6832s
	iters: 600, epoch: 5 | loss: 0.0869770
	speed: 0.0259s/iter; left time: 1518.8737s
	iters: 700, epoch: 5 | loss: 0.0886326
	speed: 0.0246s/iter; left time: 1441.6551s
	iters: 800, epoch: 5 | loss: 0.0961001
	speed: 0.0268s/iter; left time: 1567.2335s
	iters: 900, epoch: 5 | loss: 0.0884205
	speed: 0.0262s/iter; left time: 1530.3701s
	iters: 1000, epoch: 5 | loss: 0.0963196
	speed: 0.0284s/iter; left time: 1653.9296s
	iters: 1100, epoch: 5 | loss: 0.0993399
	speed: 0.0289s/iter; left time: 1679.8129s
	iters: 1200, epoch: 5 | loss: 0.0998613
	speed: 0.0262s/iter; left time: 1517.8134s
	iters: 1300, epoch: 5 | loss: 0.0938448
	speed: 0.0259s/iter; left time: 1497.4714s
	iters: 1400, epoch: 5 | loss: 0.0999766
	speed: 0.0267s/iter; left time: 1541.4427s
	iters: 1500, epoch: 5 | loss: 0.0933693
	speed: 0.0275s/iter; left time: 1585.7890s
	iters: 1600, epoch: 5 | loss: 0.0823071
	speed: 0.0259s/iter; left time: 1493.8599s
	iters: 1700, epoch: 5 | loss: 0.0932565
	speed: 0.0289s/iter; left time: 1659.8395s
	iters: 1800, epoch: 5 | loss: 0.0974104
	speed: 0.0265s/iter; left time: 1522.1340s
	iters: 1900, epoch: 5 | loss: 0.1025692
	speed: 0.0272s/iter; left time: 1556.2882s
	iters: 2000, epoch: 5 | loss: 0.0915701
	speed: 0.0256s/iter; left time: 1462.2556s
	iters: 2100, epoch: 5 | loss: 0.0990793
	speed: 0.0260s/iter; left time: 1487.5152s
	iters: 2200, epoch: 5 | loss: 0.0988693
	speed: 0.0262s/iter; left time: 1495.8145s
Epoch: 5 cost time: 61.70874643325806
Epoch: 5, Steps: 2277 | Train Loss: 0.0927237 Vali Loss: 0.2036425 Test Loss: 0.2739541
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.0917707
	speed: 0.6042s/iter; left time: 34335.3149s
	iters: 200, epoch: 6 | loss: 0.0989254
	speed: 0.0265s/iter; left time: 1504.4561s
	iters: 300, epoch: 6 | loss: 0.0999975
	speed: 0.0258s/iter; left time: 1461.9938s
	iters: 400, epoch: 6 | loss: 0.0845621
	speed: 0.0266s/iter; left time: 1501.8188s
	iters: 500, epoch: 6 | loss: 0.0898961
	speed: 0.0255s/iter; left time: 1441.0044s
	iters: 600, epoch: 6 | loss: 0.1001964
	speed: 0.0276s/iter; left time: 1554.5557s
	iters: 700, epoch: 6 | loss: 0.0896105
	speed: 0.0293s/iter; left time: 1646.3222s
	iters: 800, epoch: 6 | loss: 0.0902794
	speed: 0.0279s/iter; left time: 1567.4184s
	iters: 900, epoch: 6 | loss: 0.0860225
	speed: 0.0266s/iter; left time: 1490.0539s
	iters: 1000, epoch: 6 | loss: 0.0879853
	speed: 0.0268s/iter; left time: 1496.5138s
	iters: 1100, epoch: 6 | loss: 0.0936259
	speed: 0.0271s/iter; left time: 1511.3417s
	iters: 1200, epoch: 6 | loss: 0.0937205
	speed: 0.0276s/iter; left time: 1537.9506s
	iters: 1300, epoch: 6 | loss: 0.0908330
	speed: 0.0272s/iter; left time: 1513.2023s
	iters: 1400, epoch: 6 | loss: 0.0827323
	speed: 0.0261s/iter; left time: 1450.9591s
	iters: 1500, epoch: 6 | loss: 0.0979880
	speed: 0.0277s/iter; left time: 1533.7229s
	iters: 1600, epoch: 6 | loss: 0.0808071
	speed: 0.0271s/iter; left time: 1497.2728s
	iters: 1700, epoch: 6 | loss: 0.0883380
	speed: 0.0275s/iter; left time: 1520.0711s
	iters: 1800, epoch: 6 | loss: 0.0957053
	speed: 0.0261s/iter; left time: 1438.4292s
	iters: 1900, epoch: 6 | loss: 0.0840376
	speed: 0.0280s/iter; left time: 1540.1224s
	iters: 2000, epoch: 6 | loss: 0.0991548
	speed: 0.0272s/iter; left time: 1495.3862s
	iters: 2100, epoch: 6 | loss: 0.0865410
	speed: 0.0295s/iter; left time: 1617.2639s
	iters: 2200, epoch: 6 | loss: 0.0966581
	speed: 0.0285s/iter; left time: 1557.8508s
Epoch: 6 cost time: 63.61641716957092
Epoch: 6, Steps: 2277 | Train Loss: 0.0912645 Vali Loss: 0.2053892 Test Loss: 0.2771056
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.0865667
	speed: 0.6259s/iter; left time: 34144.1186s
	iters: 200, epoch: 7 | loss: 0.0994784
	speed: 0.0251s/iter; left time: 1368.8141s
	iters: 300, epoch: 7 | loss: 0.0924127
	speed: 0.0267s/iter; left time: 1451.0464s
	iters: 400, epoch: 7 | loss: 0.0858921
	speed: 0.0274s/iter; left time: 1484.7033s
	iters: 500, epoch: 7 | loss: 0.0898247
	speed: 0.0283s/iter; left time: 1533.4478s
	iters: 600, epoch: 7 | loss: 0.0968872
	speed: 0.0275s/iter; left time: 1485.9886s
	iters: 700, epoch: 7 | loss: 0.0856358
	speed: 0.0274s/iter; left time: 1476.0098s
	iters: 800, epoch: 7 | loss: 0.0975215
	speed: 0.0261s/iter; left time: 1405.1833s
	iters: 900, epoch: 7 | loss: 0.0980780
	speed: 0.0278s/iter; left time: 1492.0824s
	iters: 1000, epoch: 7 | loss: 0.0858561
	speed: 0.0277s/iter; left time: 1484.0006s
	iters: 1100, epoch: 7 | loss: 0.1029437
	speed: 0.0272s/iter; left time: 1458.4483s
	iters: 1200, epoch: 7 | loss: 0.0942525
	speed: 0.0285s/iter; left time: 1525.3146s
	iters: 1300, epoch: 7 | loss: 0.0902969
	speed: 0.0268s/iter; left time: 1428.1005s
	iters: 1400, epoch: 7 | loss: 0.0862206
	speed: 0.0267s/iter; left time: 1420.4305s
	iters: 1500, epoch: 7 | loss: 0.0909968
	speed: 0.0258s/iter; left time: 1371.0324s
	iters: 1600, epoch: 7 | loss: 0.0848106
	speed: 0.0276s/iter; left time: 1466.6973s
	iters: 1700, epoch: 7 | loss: 0.1029799
	speed: 0.0259s/iter; left time: 1370.9971s
	iters: 1800, epoch: 7 | loss: 0.0821526
	speed: 0.0260s/iter; left time: 1371.8828s
	iters: 1900, epoch: 7 | loss: 0.0848789
	speed: 0.0283s/iter; left time: 1490.2459s
	iters: 2000, epoch: 7 | loss: 0.0843126
	speed: 0.0280s/iter; left time: 1474.1196s
	iters: 2100, epoch: 7 | loss: 0.0932972
	speed: 0.0266s/iter; left time: 1395.6737s
	iters: 2200, epoch: 7 | loss: 0.0903111
	speed: 0.0270s/iter; left time: 1416.5268s
Epoch: 7 cost time: 62.97448372840881
Epoch: 7, Steps: 2277 | Train Loss: 0.0905067 Vali Loss: 0.2072613 Test Loss: 0.2783346
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.0863468
	speed: 0.6171s/iter; left time: 32258.0401s
	iters: 200, epoch: 8 | loss: 0.0909383
	speed: 0.0261s/iter; left time: 1363.2737s
	iters: 300, epoch: 8 | loss: 0.0942093
	speed: 0.0257s/iter; left time: 1340.2417s
	iters: 400, epoch: 8 | loss: 0.0849161
	speed: 0.0255s/iter; left time: 1326.3693s
	iters: 500, epoch: 8 | loss: 0.0792793
	speed: 0.0253s/iter; left time: 1313.0559s
	iters: 600, epoch: 8 | loss: 0.0829030
	speed: 0.0250s/iter; left time: 1292.0304s
	iters: 700, epoch: 8 | loss: 0.0804461
	speed: 0.0264s/iter; left time: 1365.0282s
	iters: 800, epoch: 8 | loss: 0.1004628
	speed: 0.0257s/iter; left time: 1325.6878s
	iters: 900, epoch: 8 | loss: 0.0883613
	speed: 0.0278s/iter; left time: 1432.2039s
	iters: 1000, epoch: 8 | loss: 0.1027474
	speed: 0.0276s/iter; left time: 1420.3730s
	iters: 1100, epoch: 8 | loss: 0.1025088
	speed: 0.0261s/iter; left time: 1340.3400s
	iters: 1200, epoch: 8 | loss: 0.0996141
	speed: 0.0277s/iter; left time: 1419.6812s
	iters: 1300, epoch: 8 | loss: 0.0938751
	speed: 0.0261s/iter; left time: 1331.0716s
	iters: 1400, epoch: 8 | loss: 0.0979141
	speed: 0.0277s/iter; left time: 1410.8726s
	iters: 1500, epoch: 8 | loss: 0.0918514
	speed: 0.0252s/iter; left time: 1282.4702s
	iters: 1600, epoch: 8 | loss: 0.0910147
	speed: 0.0263s/iter; left time: 1334.7967s
	iters: 1700, epoch: 8 | loss: 0.0921342
	speed: 0.0279s/iter; left time: 1413.0164s
	iters: 1800, epoch: 8 | loss: 0.0973421
	speed: 0.0249s/iter; left time: 1260.2390s
	iters: 1900, epoch: 8 | loss: 0.0814246
	speed: 0.0249s/iter; left time: 1259.0892s
	iters: 2000, epoch: 8 | loss: 0.0798153
	speed: 0.0242s/iter; left time: 1218.0767s
	iters: 2100, epoch: 8 | loss: 0.0911386
	speed: 0.0256s/iter; left time: 1287.8234s
	iters: 2200, epoch: 8 | loss: 0.0896737
	speed: 0.0248s/iter; left time: 1246.4289s
Epoch: 8 cost time: 60.765218019485474
Epoch: 8, Steps: 2277 | Train Loss: 0.0901193 Vali Loss: 0.2073642 Test Loss: 0.2796397
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 0.0942505
	speed: 0.6080s/iter; left time: 30399.1375s
	iters: 200, epoch: 9 | loss: 0.0927713
	speed: 0.0269s/iter; left time: 1342.0669s
	iters: 300, epoch: 9 | loss: 0.0817094
	speed: 0.0274s/iter; left time: 1366.0733s
	iters: 400, epoch: 9 | loss: 0.1076125
	speed: 0.0266s/iter; left time: 1323.7515s
	iters: 500, epoch: 9 | loss: 0.0818264
	speed: 0.0298s/iter; left time: 1476.9652s
	iters: 600, epoch: 9 | loss: 0.0853331
	speed: 0.0263s/iter; left time: 1301.7095s
	iters: 700, epoch: 9 | loss: 0.0871952
	speed: 0.0275s/iter; left time: 1358.5678s
	iters: 800, epoch: 9 | loss: 0.0890772
	speed: 0.0274s/iter; left time: 1348.8217s
	iters: 900, epoch: 9 | loss: 0.0909935
	speed: 0.0284s/iter; left time: 1399.0385s
	iters: 1000, epoch: 9 | loss: 0.0916003
	speed: 0.0289s/iter; left time: 1419.8879s
	iters: 1100, epoch: 9 | loss: 0.0836241
	speed: 0.0276s/iter; left time: 1352.2209s
	iters: 1200, epoch: 9 | loss: 0.0958339
	speed: 0.0293s/iter; left time: 1434.2698s
	iters: 1300, epoch: 9 | loss: 0.0919556
	speed: 0.0260s/iter; left time: 1270.2180s
	iters: 1400, epoch: 9 | loss: 0.0914608
	speed: 0.0278s/iter; left time: 1351.7326s
	iters: 1500, epoch: 9 | loss: 0.0890980
	speed: 0.0268s/iter; left time: 1302.5431s
	iters: 1600, epoch: 9 | loss: 0.0901136
	speed: 0.0277s/iter; left time: 1343.1581s
	iters: 1700, epoch: 9 | loss: 0.0928383
	speed: 0.0263s/iter; left time: 1272.8867s
	iters: 1800, epoch: 9 | loss: 0.0874984
	speed: 0.0266s/iter; left time: 1285.5539s
	iters: 1900, epoch: 9 | loss: 0.0982130
	speed: 0.0278s/iter; left time: 1340.7525s
	iters: 2000, epoch: 9 | loss: 0.0949225
	speed: 0.0264s/iter; left time: 1270.6505s
	iters: 2100, epoch: 9 | loss: 0.0811905
	speed: 0.0282s/iter; left time: 1351.4083s
	iters: 2200, epoch: 9 | loss: 0.0895906
	speed: 0.0272s/iter; left time: 1303.4694s
Epoch: 9 cost time: 64.13610219955444
Epoch: 9, Steps: 2277 | Train Loss: 0.0899251 Vali Loss: 0.2082279 Test Loss: 0.2798695
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 0.0873268
	speed: 0.6147s/iter; left time: 29329.9539s
	iters: 200, epoch: 10 | loss: 0.0933075
	speed: 0.0302s/iter; left time: 1437.7566s
	iters: 300, epoch: 10 | loss: 0.0883139
	speed: 0.0262s/iter; left time: 1242.9929s
	iters: 400, epoch: 10 | loss: 0.0952281
	speed: 0.0264s/iter; left time: 1253.8902s
	iters: 500, epoch: 10 | loss: 0.0782685
	speed: 0.0275s/iter; left time: 1300.7403s
	iters: 600, epoch: 10 | loss: 0.0787914
	speed: 0.0255s/iter; left time: 1202.8397s
	iters: 700, epoch: 10 | loss: 0.0826114
	speed: 0.0251s/iter; left time: 1183.1688s
	iters: 800, epoch: 10 | loss: 0.0889804
	speed: 0.0244s/iter; left time: 1146.2244s
	iters: 900, epoch: 10 | loss: 0.0925905
	speed: 0.0255s/iter; left time: 1195.9025s
	iters: 1000, epoch: 10 | loss: 0.0937742
	speed: 0.0251s/iter; left time: 1174.0014s
	iters: 1100, epoch: 10 | loss: 0.0932471
	speed: 0.0247s/iter; left time: 1153.4708s
	iters: 1200, epoch: 10 | loss: 0.0955402
	speed: 0.0272s/iter; left time: 1269.8026s
	iters: 1300, epoch: 10 | loss: 0.0992865
	speed: 0.0253s/iter; left time: 1179.0482s
	iters: 1400, epoch: 10 | loss: 0.0890593
	speed: 0.0260s/iter; left time: 1208.5076s
	iters: 1500, epoch: 10 | loss: 0.0915934
	speed: 0.0258s/iter; left time: 1194.8357s
	iters: 1600, epoch: 10 | loss: 0.0918590
	speed: 0.0280s/iter; left time: 1296.2421s
	iters: 1700, epoch: 10 | loss: 0.0862999
	speed: 0.0264s/iter; left time: 1217.3016s
	iters: 1800, epoch: 10 | loss: 0.0973974
	speed: 0.0258s/iter; left time: 1188.4998s
	iters: 1900, epoch: 10 | loss: 0.0945355
	speed: 0.0271s/iter; left time: 1246.3229s
	iters: 2000, epoch: 10 | loss: 0.0864428
	speed: 0.0252s/iter; left time: 1153.4213s
	iters: 2100, epoch: 10 | loss: 0.0912557
	speed: 0.0269s/iter; left time: 1231.2758s
	iters: 2200, epoch: 10 | loss: 0.0893392
	speed: 0.0267s/iter; left time: 1216.8580s
Epoch: 10 cost time: 61.99266862869263
Epoch: 10, Steps: 2277 | Train Loss: 0.0898174 Vali Loss: 0.2086685 Test Loss: 0.2802456
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 0.0953938
	speed: 0.6269s/iter; left time: 28488.5678s
	iters: 200, epoch: 11 | loss: 0.0902983
	speed: 0.0270s/iter; left time: 1226.0703s
	iters: 300, epoch: 11 | loss: 0.0838992
	speed: 0.0268s/iter; left time: 1213.0328s
	iters: 400, epoch: 11 | loss: 0.0914844
	speed: 0.0278s/iter; left time: 1254.4779s
	iters: 500, epoch: 11 | loss: 0.0928363
	speed: 0.0275s/iter; left time: 1240.4789s
	iters: 600, epoch: 11 | loss: 0.0840032
	speed: 0.0278s/iter; left time: 1247.3407s
	iters: 700, epoch: 11 | loss: 0.0885223
	speed: 0.0260s/iter; left time: 1163.7275s
	iters: 800, epoch: 11 | loss: 0.0924738
	speed: 0.0266s/iter; left time: 1188.7762s
	iters: 900, epoch: 11 | loss: 0.0842481
	speed: 0.0266s/iter; left time: 1186.8759s
	iters: 1000, epoch: 11 | loss: 0.0897064
	speed: 0.0291s/iter; left time: 1297.8376s
	iters: 1100, epoch: 11 | loss: 0.0804379
	speed: 0.0288s/iter; left time: 1278.4904s
	iters: 1200, epoch: 11 | loss: 0.0849345
	speed: 0.0272s/iter; left time: 1205.8859s
	iters: 1300, epoch: 11 | loss: 0.0992329
	speed: 0.0274s/iter; left time: 1211.5104s
	iters: 1400, epoch: 11 | loss: 0.0876506
	speed: 0.0279s/iter; left time: 1233.1071s
	iters: 1500, epoch: 11 | loss: 0.1020550
	speed: 0.0277s/iter; left time: 1218.7607s
	iters: 1600, epoch: 11 | loss: 0.0887582
	speed: 0.0271s/iter; left time: 1190.8010s
	iters: 1700, epoch: 11 | loss: 0.0843456
	speed: 0.0276s/iter; left time: 1210.4756s
	iters: 1800, epoch: 11 | loss: 0.0984192
	speed: 0.0282s/iter; left time: 1234.9368s
	iters: 1900, epoch: 11 | loss: 0.1025907
	speed: 0.0267s/iter; left time: 1165.1365s
	iters: 2000, epoch: 11 | loss: 0.0837137
	speed: 0.0293s/iter; left time: 1274.5274s
	iters: 2100, epoch: 11 | loss: 0.0887867
	speed: 0.0260s/iter; left time: 1128.6078s
	iters: 2200, epoch: 11 | loss: 0.0889417
	speed: 0.0282s/iter; left time: 1222.3964s
Epoch: 11 cost time: 64.58538126945496
Epoch: 11, Steps: 2277 | Train Loss: 0.0897884 Vali Loss: 0.2086864 Test Loss: 0.2803483
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 0.0889654
	speed: 0.6212s/iter; left time: 26812.5214s
	iters: 200, epoch: 12 | loss: 0.0950666
	speed: 0.0248s/iter; left time: 1069.1154s
	iters: 300, epoch: 12 | loss: 0.1012796
	speed: 0.0264s/iter; left time: 1132.3566s
	iters: 400, epoch: 12 | loss: 0.0922471
	speed: 0.0254s/iter; left time: 1088.5549s
	iters: 500, epoch: 12 | loss: 0.0955150
	speed: 0.0249s/iter; left time: 1065.4867s
	iters: 600, epoch: 12 | loss: 0.0917369
	speed: 0.0249s/iter; left time: 1060.9555s
	iters: 700, epoch: 12 | loss: 0.0835277
	speed: 0.0258s/iter; left time: 1098.0394s
	iters: 800, epoch: 12 | loss: 0.0946639
	speed: 0.0270s/iter; left time: 1146.1897s
	iters: 900, epoch: 12 | loss: 0.0873267
	speed: 0.0281s/iter; left time: 1191.8452s
	iters: 1000, epoch: 12 | loss: 0.0846547
	speed: 0.0287s/iter; left time: 1211.0193s
	iters: 1100, epoch: 12 | loss: 0.0937151
	speed: 0.0299s/iter; left time: 1262.5675s
	iters: 1200, epoch: 12 | loss: 0.0995074
	speed: 0.0270s/iter; left time: 1135.3877s
	iters: 1300, epoch: 12 | loss: 0.0861932
	speed: 0.0258s/iter; left time: 1083.0960s
	iters: 1400, epoch: 12 | loss: 0.0877775
	speed: 0.0259s/iter; left time: 1086.3309s
	iters: 1500, epoch: 12 | loss: 0.0884321
	speed: 0.0258s/iter; left time: 1077.1310s
	iters: 1600, epoch: 12 | loss: 0.1013366
	speed: 0.0251s/iter; left time: 1044.4570s
	iters: 1700, epoch: 12 | loss: 0.0963288
	speed: 0.0250s/iter; left time: 1037.4965s
	iters: 1800, epoch: 12 | loss: 0.0862345
	speed: 0.0257s/iter; left time: 1066.9001s
	iters: 1900, epoch: 12 | loss: 0.1009253
	speed: 0.0250s/iter; left time: 1034.0807s
	iters: 2000, epoch: 12 | loss: 0.0930020
	speed: 0.0257s/iter; left time: 1058.4714s
	iters: 2100, epoch: 12 | loss: 0.0820942
	speed: 0.0250s/iter; left time: 1029.2716s
	iters: 2200, epoch: 12 | loss: 0.0816875
	speed: 0.0254s/iter; left time: 1043.2260s
Epoch: 12 cost time: 60.8189742565155
Epoch: 12, Steps: 2277 | Train Loss: 0.0897445 Vali Loss: 0.2088459 Test Loss: 0.2802056
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : ECL_96_96_39_emb_512_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (5165, 1, 96, 321) (5165, 1, 96, 321)
test shape: (5165, 96, 321) (5165, 96, 321)
mse:0.2657296359539032, mae:0.3558093011379242
Args in experiment:
Namespace(is_training=1, model_id='ECL_96_96_40_emb_512', model='xLSTM', data='custom', root_path='./data/electricity/', data_path='/input-data/electricity.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, enc_in=321, dec_in=7, c_out=321, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=10, batch_size=16, patience=10, learning_rate=0.0001, des='test', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, use_norm=True, partial_start_index=0, hidden_size=512, num_layers=2, mark_enc_in=4, embedding_dim=512, weight_decay=0.0001, kernal_size=3, num_heads_xlstm=4, qkv_proj_blocksize=2, proj_factor=1.3, num_blocks=2, slstm_at=1, grad_clip_norm=5.0, d_state=16, d_conv=4, expand=2)
Use GPU: cuda:0
{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-L/usr/local/cuda/lib', '-lcublas'], 'extra_cflags': ['-DSLSTM_HIDDEN_SIZE=512', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__'], 'extra_cuda_cflags': ['-Xptxas="-v"', '-gencode', 'arch=compute_80,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=512', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__']}
Using /home/thetayne/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/thetayne/.cache/torch_extensions/py310_cu121/slstm_HS512BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0/build.ninja...
Building extension module slstm_HS512BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module slstm_HS512BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...
>>>>>>>start training : ECL_96_96_40_emb_512_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 18221
val 2537
test 5165
	iters: 100, epoch: 1 | loss: 0.2926581
	speed: 0.0471s/iter; left time: 531.7164s
	iters: 200, epoch: 1 | loss: 0.2302203
	speed: 0.0253s/iter; left time: 282.6279s
	iters: 300, epoch: 1 | loss: 0.1966153
	speed: 0.0253s/iter; left time: 280.3265s
	iters: 400, epoch: 1 | loss: 0.1922329
	speed: 0.0255s/iter; left time: 280.3609s
	iters: 500, epoch: 1 | loss: 0.1527236
	speed: 0.0252s/iter; left time: 274.2174s
	iters: 600, epoch: 1 | loss: 0.1592198
	speed: 0.0258s/iter; left time: 278.3816s
	iters: 700, epoch: 1 | loss: 0.1408187
	speed: 0.0260s/iter; left time: 278.0252s
	iters: 800, epoch: 1 | loss: 0.1323611
	speed: 0.0286s/iter; left time: 302.9496s
	iters: 900, epoch: 1 | loss: 0.1165439
	speed: 0.0271s/iter; left time: 283.8543s
	iters: 1000, epoch: 1 | loss: 0.1116419
	speed: 0.0281s/iter; left time: 292.1218s
	iters: 1100, epoch: 1 | loss: 0.1091769
	speed: 0.0276s/iter; left time: 283.9647s
Epoch: 1 cost time: 32.128113746643066
Epoch: 1, Steps: 1138 | Train Loss: 0.1857526 Vali Loss: 0.2274921 Test Loss: 0.3020646
Validation loss decreased (inf --> 0.227492).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.1127005
	speed: 0.5573s/iter; left time: 5652.3884s
	iters: 200, epoch: 2 | loss: 0.0972578
	speed: 0.0263s/iter; left time: 264.0026s
	iters: 300, epoch: 2 | loss: 0.1018403
	speed: 0.0258s/iter; left time: 256.5670s
	iters: 400, epoch: 2 | loss: 0.0957097
	speed: 0.0255s/iter; left time: 251.2453s
	iters: 500, epoch: 2 | loss: 0.1002432
	speed: 0.0252s/iter; left time: 245.5719s
	iters: 600, epoch: 2 | loss: 0.0962661
	speed: 0.0274s/iter; left time: 264.6185s
	iters: 700, epoch: 2 | loss: 0.0983320
	speed: 0.0281s/iter; left time: 268.5173s
	iters: 800, epoch: 2 | loss: 0.0862289
	speed: 0.0280s/iter; left time: 264.4127s
	iters: 900, epoch: 2 | loss: 0.0846637
	speed: 0.0277s/iter; left time: 258.6460s
	iters: 1000, epoch: 2 | loss: 0.0844228
	speed: 0.0284s/iter; left time: 262.0624s
	iters: 1100, epoch: 2 | loss: 0.0796767
	speed: 0.0278s/iter; left time: 254.3202s
Epoch: 2 cost time: 32.086381673812866
Epoch: 2, Steps: 1138 | Train Loss: 0.0948148 Vali Loss: 0.2260110 Test Loss: 0.2990543
Validation loss decreased (0.227492 --> 0.226011).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.0797082
	speed: 0.5703s/iter; left time: 5135.3337s
	iters: 200, epoch: 3 | loss: 0.0786002
	speed: 0.0254s/iter; left time: 226.5449s
	iters: 300, epoch: 3 | loss: 0.0819954
	speed: 0.0258s/iter; left time: 227.2429s
	iters: 400, epoch: 3 | loss: 0.0822988
	speed: 0.0264s/iter; left time: 229.4928s
	iters: 500, epoch: 3 | loss: 0.0827252
	speed: 0.0283s/iter; left time: 243.8177s
	iters: 600, epoch: 3 | loss: 0.0715123
	speed: 0.0280s/iter; left time: 238.4375s
	iters: 700, epoch: 3 | loss: 0.0754284
	speed: 0.0282s/iter; left time: 236.8874s
	iters: 800, epoch: 3 | loss: 0.0778237
	speed: 0.0278s/iter; left time: 231.1384s
	iters: 900, epoch: 3 | loss: 0.0736976
	speed: 0.0284s/iter; left time: 232.9137s
	iters: 1000, epoch: 3 | loss: 0.0726446
	speed: 0.0280s/iter; left time: 226.7030s
	iters: 1100, epoch: 3 | loss: 0.0748372
	speed: 0.0282s/iter; left time: 225.5881s
Epoch: 3 cost time: 32.69792342185974
Epoch: 3, Steps: 1138 | Train Loss: 0.0782359 Vali Loss: 0.2304208 Test Loss: 0.2976906
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.0814890
	speed: 0.5794s/iter; left time: 4558.2666s
	iters: 200, epoch: 4 | loss: 0.0724859
	speed: 0.0251s/iter; left time: 195.2602s
	iters: 300, epoch: 4 | loss: 0.0695777
	speed: 0.0261s/iter; left time: 200.1482s
	iters: 400, epoch: 4 | loss: 0.0749031
	speed: 0.0255s/iter; left time: 192.9261s
	iters: 500, epoch: 4 | loss: 0.0711746
	speed: 0.0258s/iter; left time: 192.5639s
	iters: 600, epoch: 4 | loss: 0.0723743
	speed: 0.0256s/iter; left time: 188.2771s
	iters: 700, epoch: 4 | loss: 0.0705555
	speed: 0.0285s/iter; left time: 206.7883s
	iters: 800, epoch: 4 | loss: 0.0707536
	speed: 0.0282s/iter; left time: 202.1101s
	iters: 900, epoch: 4 | loss: 0.0740062
	speed: 0.0280s/iter; left time: 197.8367s
	iters: 1000, epoch: 4 | loss: 0.0745096
	speed: 0.0285s/iter; left time: 198.6092s
	iters: 1100, epoch: 4 | loss: 0.0701803
	speed: 0.0284s/iter; left time: 195.1567s
Epoch: 4 cost time: 32.060654401779175
Epoch: 4, Steps: 1138 | Train Loss: 0.0718859 Vali Loss: 0.2320338 Test Loss: 0.2980112
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.0678099
	speed: 0.5706s/iter; left time: 3839.7824s
	iters: 200, epoch: 5 | loss: 0.0640561
	speed: 0.0260s/iter; left time: 172.6065s
	iters: 300, epoch: 5 | loss: 0.0703385
	speed: 0.0277s/iter; left time: 180.6849s
	iters: 400, epoch: 5 | loss: 0.0661825
	speed: 0.0288s/iter; left time: 185.4440s
	iters: 500, epoch: 5 | loss: 0.0662228
	speed: 0.0285s/iter; left time: 180.5642s
	iters: 600, epoch: 5 | loss: 0.0730061
	speed: 0.0286s/iter; left time: 177.8957s
	iters: 700, epoch: 5 | loss: 0.0612954
	speed: 0.0284s/iter; left time: 173.8899s
	iters: 800, epoch: 5 | loss: 0.0676715
	speed: 0.0280s/iter; left time: 168.6717s
	iters: 900, epoch: 5 | loss: 0.0644261
	speed: 0.0284s/iter; left time: 168.5990s
	iters: 1000, epoch: 5 | loss: 0.0701862
	speed: 0.0285s/iter; left time: 166.4027s
	iters: 1100, epoch: 5 | loss: 0.0671428
	speed: 0.0281s/iter; left time: 160.9070s
Epoch: 5 cost time: 33.29581952095032
Epoch: 5, Steps: 1138 | Train Loss: 0.0687582 Vali Loss: 0.2334432 Test Loss: 0.2978862
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.0701563
	speed: 0.5777s/iter; left time: 3229.9724s
	iters: 200, epoch: 6 | loss: 0.0673014
	speed: 0.0268s/iter; left time: 147.0536s
	iters: 300, epoch: 6 | loss: 0.0664156
	speed: 0.0269s/iter; left time: 145.1231s
	iters: 400, epoch: 6 | loss: 0.0646413
	speed: 0.0291s/iter; left time: 153.9900s
	iters: 500, epoch: 6 | loss: 0.0651554
	speed: 0.0278s/iter; left time: 144.4753s
	iters: 600, epoch: 6 | loss: 0.0683365
	speed: 0.0277s/iter; left time: 140.7724s
	iters: 700, epoch: 6 | loss: 0.0661369
	speed: 0.0283s/iter; left time: 141.4843s
	iters: 800, epoch: 6 | loss: 0.0676622
	speed: 0.0280s/iter; left time: 137.1230s
	iters: 900, epoch: 6 | loss: 0.0679710
	speed: 0.0274s/iter; left time: 131.0878s
	iters: 1000, epoch: 6 | loss: 0.0687272
	speed: 0.0272s/iter; left time: 127.4349s
	iters: 1100, epoch: 6 | loss: 0.0650561
	speed: 0.0286s/iter; left time: 131.4001s
Epoch: 6 cost time: 33.04046416282654
Epoch: 6, Steps: 1138 | Train Loss: 0.0671559 Vali Loss: 0.2338546 Test Loss: 0.2980477
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.0687689
	speed: 0.5706s/iter; left time: 2540.6697s
	iters: 200, epoch: 7 | loss: 0.0656963
	speed: 0.0262s/iter; left time: 114.0273s
	iters: 300, epoch: 7 | loss: 0.0660222
	speed: 0.0275s/iter; left time: 116.8718s
	iters: 400, epoch: 7 | loss: 0.0629150
	speed: 0.0281s/iter; left time: 116.6055s
	iters: 500, epoch: 7 | loss: 0.0720802
	speed: 0.0267s/iter; left time: 108.2638s
	iters: 600, epoch: 7 | loss: 0.0685162
	speed: 0.0287s/iter; left time: 113.4400s
	iters: 700, epoch: 7 | loss: 0.0701423
	speed: 0.0264s/iter; left time: 101.7285s
	iters: 800, epoch: 7 | loss: 0.0649176
	speed: 0.0275s/iter; left time: 103.2645s
	iters: 900, epoch: 7 | loss: 0.0639445
	speed: 0.0279s/iter; left time: 101.7498s
	iters: 1000, epoch: 7 | loss: 0.0705502
	speed: 0.0282s/iter; left time: 100.0524s
	iters: 1100, epoch: 7 | loss: 0.0614358
	speed: 0.0269s/iter; left time: 92.8296s
Epoch: 7 cost time: 32.20092058181763
Epoch: 7, Steps: 1138 | Train Loss: 0.0663268 Vali Loss: 0.2352289 Test Loss: 0.2984945
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.0654931
	speed: 0.5681s/iter; left time: 1883.3784s
	iters: 200, epoch: 8 | loss: 0.0683205
	speed: 0.0259s/iter; left time: 83.2298s
	iters: 300, epoch: 8 | loss: 0.0664011
	speed: 0.0268s/iter; left time: 83.3335s
	iters: 400, epoch: 8 | loss: 0.0637855
	speed: 0.0287s/iter; left time: 86.6562s
	iters: 500, epoch: 8 | loss: 0.0667010
	speed: 0.0279s/iter; left time: 81.3628s
	iters: 600, epoch: 8 | loss: 0.0646206
	speed: 0.0277s/iter; left time: 77.9101s
	iters: 700, epoch: 8 | loss: 0.0648586
	speed: 0.0270s/iter; left time: 73.3876s
	iters: 800, epoch: 8 | loss: 0.0669881
	speed: 0.0288s/iter; left time: 75.4309s
	iters: 900, epoch: 8 | loss: 0.0635540
	speed: 0.0271s/iter; left time: 68.2666s
	iters: 1000, epoch: 8 | loss: 0.0637907
	speed: 0.0285s/iter; left time: 68.7528s
	iters: 1100, epoch: 8 | loss: 0.0688646
	speed: 0.0282s/iter; left time: 65.2834s
Epoch: 8 cost time: 32.68202519416809
Epoch: 8, Steps: 1138 | Train Loss: 0.0659004 Vali Loss: 0.2346625 Test Loss: 0.2980999
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.0635514
	speed: 0.5616s/iter; left time: 1222.6173s
	iters: 200, epoch: 9 | loss: 0.0694216
	speed: 0.0248s/iter; left time: 51.6010s
	iters: 300, epoch: 9 | loss: 0.0686318
	speed: 0.0242s/iter; left time: 47.9351s
	iters: 400, epoch: 9 | loss: 0.0647237
	speed: 0.0261s/iter; left time: 48.9438s
	iters: 500, epoch: 9 | loss: 0.0627694
	speed: 0.0266s/iter; left time: 47.3017s
	iters: 600, epoch: 9 | loss: 0.0654728
	speed: 0.0283s/iter; left time: 47.5288s
	iters: 700, epoch: 9 | loss: 0.0657293
	speed: 0.0280s/iter; left time: 44.1684s
	iters: 800, epoch: 9 | loss: 0.0630860
	speed: 0.0277s/iter; left time: 40.8756s
	iters: 900, epoch: 9 | loss: 0.0625133
	speed: 0.0266s/iter; left time: 36.6273s
	iters: 1000, epoch: 9 | loss: 0.0663699
	speed: 0.0281s/iter; left time: 35.8442s
	iters: 1100, epoch: 9 | loss: 0.0688720
	speed: 0.0277s/iter; left time: 32.6440s
Epoch: 9 cost time: 31.930940628051758
Epoch: 9, Steps: 1138 | Train Loss: 0.0656887 Vali Loss: 0.2350161 Test Loss: 0.2984290
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.0641145
	speed: 0.5613s/iter; left time: 583.2384s
	iters: 200, epoch: 10 | loss: 0.0658110
	speed: 0.0261s/iter; left time: 24.4681s
	iters: 300, epoch: 10 | loss: 0.0698848
	speed: 0.0259s/iter; left time: 21.6909s
	iters: 400, epoch: 10 | loss: 0.0701098
	speed: 0.0263s/iter; left time: 19.4111s
	iters: 500, epoch: 10 | loss: 0.0655185
	speed: 0.0245s/iter; left time: 15.6431s
	iters: 600, epoch: 10 | loss: 0.0635792
	speed: 0.0258s/iter; left time: 13.8881s
	iters: 700, epoch: 10 | loss: 0.0665900
	speed: 0.0257s/iter; left time: 11.2774s
	iters: 800, epoch: 10 | loss: 0.0653865
	speed: 0.0269s/iter; left time: 9.1121s
	iters: 900, epoch: 10 | loss: 0.0633806
	speed: 0.0283s/iter; left time: 6.7586s
	iters: 1000, epoch: 10 | loss: 0.0710176
	speed: 0.0279s/iter; left time: 3.8812s
	iters: 1100, epoch: 10 | loss: 0.0659191
	speed: 0.0278s/iter; left time: 1.0845s
Epoch: 10 cost time: 31.566731214523315
Epoch: 10, Steps: 1138 | Train Loss: 0.0655709 Vali Loss: 0.2350172 Test Loss: 0.2984042
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-07
>>>>>>>testing : ECL_96_96_40_emb_512_xLSTM_custom_M_ft96_sl48_ll96_pl512_dm8_nh2_el1_dl2048_df1_fctimeF_ebTrue_dttest_projection_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (5165, 1, 96, 321) (5165, 1, 96, 321)
test shape: (5165, 96, 321) (5165, 96, 321)
mse:0.2990538477897644, mae:0.37965670228004456
